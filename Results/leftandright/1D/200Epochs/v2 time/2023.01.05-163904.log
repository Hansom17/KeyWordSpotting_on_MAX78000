2023-01-05 16:39:04,131 - Log file for this run: /home/ubuntumaschin/KeyWordSpotting_on_MAX78000/ai8x-training/logs/2023.01.05-163904/2023.01.05-163904.log
2023-01-05 16:39:06,166 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2023-01-05 16:39:06,166 - Optimizer Args: {'lr': 1e-05, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2023-01-05 16:39:19,939 - Dataset sizes:
	training=9438
	validation=1048
	test=1317
2023-01-05 16:39:19,939 - Reading compression schedule from: policies/schedule_kws20_v2.yaml
2023-01-05 16:39:19,944 - 

2023-01-05 16:39:19,944 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:20,628 - Epoch: [0][   10/   37]    Overall Loss 1.098417    Objective Loss 1.098417                                        LR 0.000010    Time 0.068304    
2023-01-05 16:39:20,872 - Epoch: [0][   20/   37]    Overall Loss 1.098316    Objective Loss 1.098316                                        LR 0.000010    Time 0.046280    
2023-01-05 16:39:21,105 - Epoch: [0][   30/   37]    Overall Loss 1.098204    Objective Loss 1.098204                                        LR 0.000010    Time 0.038557    
2023-01-05 16:39:21,257 - Epoch: [0][   37/   37]    Overall Loss 1.098113    Objective Loss 1.098113    Top1 56.276151    LR 0.000010    Time 0.035380    
2023-01-05 16:39:21,333 - --- validate (epoch=0)-----------
2023-01-05 16:39:21,333 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:21,538 - Epoch: [0][    5/    5]    Loss 1.097549    Top1 59.064885    
2023-01-05 16:39:21,596 - ==> Top1: 59.065    Loss: 1.098

2023-01-05 16:39:21,596 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:39:21,598 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 0]
2023-01-05 16:39:21,598 - Saving checkpoint to: logs/2023.01.05-163904/checkpoint.pth.tar
2023-01-05 16:39:21,609 - 

2023-01-05 16:39:21,609 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:22,000 - Epoch: [1][   10/   37]    Overall Loss 1.097347    Objective Loss 1.097347                                        LR 0.000010    Time 0.038987    
2023-01-05 16:39:22,230 - Epoch: [1][   20/   37]    Overall Loss 1.097060    Objective Loss 1.097060                                        LR 0.000010    Time 0.030966    
2023-01-05 16:39:22,473 - Epoch: [1][   30/   37]    Overall Loss 1.096691    Objective Loss 1.096691                                        LR 0.000010    Time 0.028623    
2023-01-05 16:39:22,628 - Epoch: [1][   37/   37]    Overall Loss 1.096356    Objective Loss 1.096356    Top1 56.903766    LR 0.000010    Time 0.027397    
2023-01-05 16:39:22,699 - --- validate (epoch=1)-----------
2023-01-05 16:39:22,699 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:22,911 - Epoch: [1][    5/    5]    Loss 1.094195    Top1 59.064885    
2023-01-05 16:39:22,978 - ==> Top1: 59.065    Loss: 1.094

2023-01-05 16:39:22,979 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:39:22,980 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 1]
2023-01-05 16:39:22,980 - Saving checkpoint to: logs/2023.01.05-163904/checkpoint.pth.tar
2023-01-05 16:39:23,000 - 

2023-01-05 16:39:23,001 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:23,404 - Epoch: [2][   10/   37]    Overall Loss 1.093450    Objective Loss 1.093450                                        LR 0.000010    Time 0.040310    
2023-01-05 16:39:23,640 - Epoch: [2][   20/   37]    Overall Loss 1.092198    Objective Loss 1.092198                                        LR 0.000010    Time 0.031904    
2023-01-05 16:39:23,874 - Epoch: [2][   30/   37]    Overall Loss 1.090503    Objective Loss 1.090503                                        LR 0.000010    Time 0.029049    
2023-01-05 16:39:24,027 - Epoch: [2][   37/   37]    Overall Loss 1.089013    Objective Loss 1.089013    Top1 58.368201    LR 0.000010    Time 0.027679    
2023-01-05 16:39:24,109 - --- validate (epoch=2)-----------
2023-01-05 16:39:24,109 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:24,311 - Epoch: [2][    5/    5]    Loss 1.080042    Top1 59.064885    
2023-01-05 16:39:24,365 - ==> Top1: 59.065    Loss: 1.080

2023-01-05 16:39:24,366 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:39:24,367 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 2]
2023-01-05 16:39:24,367 - Saving checkpoint to: logs/2023.01.05-163904/checkpoint.pth.tar
2023-01-05 16:39:24,387 - 

2023-01-05 16:39:24,388 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:24,796 - Epoch: [3][   10/   37]    Overall Loss 1.076314    Objective Loss 1.076314                                        LR 0.000010    Time 0.040712    
2023-01-05 16:39:25,033 - Epoch: [3][   20/   37]    Overall Loss 1.070826    Objective Loss 1.070826                                        LR 0.000010    Time 0.032187    
2023-01-05 16:39:25,275 - Epoch: [3][   30/   37]    Overall Loss 1.063933    Objective Loss 1.063933                                        LR 0.000010    Time 0.029503    
2023-01-05 16:39:25,432 - Epoch: [3][   37/   37]    Overall Loss 1.057570    Objective Loss 1.057570    Top1 58.786611    LR 0.000010    Time 0.028162    
2023-01-05 16:39:25,514 - --- validate (epoch=3)-----------
2023-01-05 16:39:25,514 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:25,723 - Epoch: [3][    5/    5]    Loss 1.018981    Top1 59.064885    
2023-01-05 16:39:25,782 - ==> Top1: 59.065    Loss: 1.019

2023-01-05 16:39:25,783 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:39:25,784 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 3]
2023-01-05 16:39:25,784 - Saving checkpoint to: logs/2023.01.05-163904/checkpoint.pth.tar
2023-01-05 16:39:25,807 - 

2023-01-05 16:39:25,807 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:26,222 - Epoch: [4][   10/   37]    Overall Loss 1.007867    Objective Loss 1.007867                                        LR 0.000010    Time 0.041360    
2023-01-05 16:39:26,444 - Epoch: [4][   20/   37]    Overall Loss 0.989527    Objective Loss 0.989527                                        LR 0.000010    Time 0.031752    
2023-01-05 16:39:26,673 - Epoch: [4][   30/   37]    Overall Loss 0.968133    Objective Loss 0.968133                                        LR 0.000010    Time 0.028783    
2023-01-05 16:39:26,827 - Epoch: [4][   37/   37]    Overall Loss 0.952210    Objective Loss 0.952210    Top1 55.439331    LR 0.000010    Time 0.027508    
2023-01-05 16:39:26,908 - --- validate (epoch=4)-----------
2023-01-05 16:39:26,909 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:27,109 - Epoch: [4][    5/    5]    Loss 0.853346    Top1 59.064885    
2023-01-05 16:39:27,169 - ==> Top1: 59.065    Loss: 0.853

2023-01-05 16:39:27,169 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:39:27,170 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 4]
2023-01-05 16:39:27,170 - Saving checkpoint to: logs/2023.01.05-163904/checkpoint.pth.tar
2023-01-05 16:39:27,191 - 

2023-01-05 16:39:27,191 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:27,600 - Epoch: [5][   10/   37]    Overall Loss 0.847755    Objective Loss 0.847755                                        LR 0.000010    Time 0.040745    
2023-01-05 16:39:27,840 - Epoch: [5][   20/   37]    Overall Loss 0.826476    Objective Loss 0.826476                                        LR 0.000010    Time 0.032350    
2023-01-05 16:39:28,071 - Epoch: [5][   30/   37]    Overall Loss 0.812525    Objective Loss 0.812525                                        LR 0.000010    Time 0.029273    
2023-01-05 16:39:28,217 - Epoch: [5][   37/   37]    Overall Loss 0.805534    Objective Loss 0.805534    Top1 58.158996    LR 0.000010    Time 0.027679    
2023-01-05 16:39:28,291 - --- validate (epoch=5)-----------
2023-01-05 16:39:28,291 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:28,492 - Epoch: [5][    5/    5]    Loss 0.766488    Top1 59.064885    
2023-01-05 16:39:28,557 - ==> Top1: 59.065    Loss: 0.766

2023-01-05 16:39:28,557 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:39:28,559 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 5]
2023-01-05 16:39:28,559 - Saving checkpoint to: logs/2023.01.05-163904/checkpoint.pth.tar
2023-01-05 16:39:28,579 - 

2023-01-05 16:39:28,579 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:29,132 - Epoch: [6][   10/   37]    Overall Loss 0.774182    Objective Loss 0.774182                                        LR 0.000010    Time 0.055187    
2023-01-05 16:39:29,361 - Epoch: [6][   20/   37]    Overall Loss 0.770198    Objective Loss 0.770198                                        LR 0.000010    Time 0.038994    
2023-01-05 16:39:29,595 - Epoch: [6][   30/   37]    Overall Loss 0.768067    Objective Loss 0.768067                                        LR 0.000010    Time 0.033807    
2023-01-05 16:39:29,744 - Epoch: [6][   37/   37]    Overall Loss 0.766604    Objective Loss 0.766604    Top1 52.719665    LR 0.000010    Time 0.031433    
2023-01-05 16:39:29,816 - --- validate (epoch=6)-----------
2023-01-05 16:39:29,816 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:30,021 - Epoch: [6][    5/    5]    Loss 0.755773    Top1 59.064885    
2023-01-05 16:39:30,080 - ==> Top1: 59.065    Loss: 0.756

2023-01-05 16:39:30,080 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:39:30,081 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 6]
2023-01-05 16:39:30,082 - Saving checkpoint to: logs/2023.01.05-163904/checkpoint.pth.tar
2023-01-05 16:39:30,102 - 

2023-01-05 16:39:30,102 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:30,521 - Epoch: [7][   10/   37]    Overall Loss 0.756522    Objective Loss 0.756522                                        LR 0.000010    Time 0.041862    
2023-01-05 16:39:30,757 - Epoch: [7][   20/   37]    Overall Loss 0.754605    Objective Loss 0.754605                                        LR 0.000010    Time 0.032716    
2023-01-05 16:39:31,007 - Epoch: [7][   30/   37]    Overall Loss 0.753187    Objective Loss 0.753187                                        LR 0.000010    Time 0.030132    
2023-01-05 16:39:31,158 - Epoch: [7][   37/   37]    Overall Loss 0.752302    Objective Loss 0.752302    Top1 59.623431    LR 0.000010    Time 0.028483    
2023-01-05 16:39:31,232 - --- validate (epoch=7)-----------
2023-01-05 16:39:31,233 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:31,439 - Epoch: [7][    5/    5]    Loss 0.747607    Top1 59.064885    
2023-01-05 16:39:31,502 - ==> Top1: 59.065    Loss: 0.748

2023-01-05 16:39:31,502 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:39:31,503 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 7]
2023-01-05 16:39:31,503 - Saving checkpoint to: logs/2023.01.05-163904/checkpoint.pth.tar
2023-01-05 16:39:31,526 - 

2023-01-05 16:39:31,527 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:31,956 - Epoch: [8][   10/   37]    Overall Loss 0.747070    Objective Loss 0.747070                                        LR 0.000010    Time 0.042895    
2023-01-05 16:39:32,203 - Epoch: [8][   20/   37]    Overall Loss 0.746115    Objective Loss 0.746115                                        LR 0.000010    Time 0.033656    
2023-01-05 16:39:32,453 - Epoch: [8][   30/   37]    Overall Loss 0.745255    Objective Loss 0.745255                                        LR 0.000010    Time 0.030778    
2023-01-05 16:39:32,607 - Epoch: [8][   37/   37]    Overall Loss 0.744667    Objective Loss 0.744667    Top1 56.066946    LR 0.000010    Time 0.029111    
2023-01-05 16:39:32,687 - --- validate (epoch=8)-----------
2023-01-05 16:39:32,687 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:32,900 - Epoch: [8][    5/    5]    Loss 0.741709    Top1 59.064885    
2023-01-05 16:39:32,968 - ==> Top1: 59.065    Loss: 0.742

2023-01-05 16:39:32,968 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:39:32,969 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 8]
2023-01-05 16:39:32,969 - Saving checkpoint to: logs/2023.01.05-163904/checkpoint.pth.tar
2023-01-05 16:39:32,994 - 

2023-01-05 16:39:32,994 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:33,417 - Epoch: [9][   10/   37]    Overall Loss 0.740855    Objective Loss 0.740855                                        LR 0.000010    Time 0.042171    
2023-01-05 16:39:33,666 - Epoch: [9][   20/   37]    Overall Loss 0.740244    Objective Loss 0.740244                                        LR 0.000010    Time 0.033449    
2023-01-05 16:39:33,920 - Epoch: [9][   30/   37]    Overall Loss 0.739591    Objective Loss 0.739591                                        LR 0.000010    Time 0.030753    
2023-01-05 16:39:34,076 - Epoch: [9][   37/   37]    Overall Loss 0.739160    Objective Loss 0.739160    Top1 53.974895    LR 0.000010    Time 0.029134    
2023-01-05 16:39:34,154 - --- validate (epoch=9)-----------
2023-01-05 16:39:34,155 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:34,372 - Epoch: [9][    5/    5]    Loss 0.736849    Top1 59.064885    
2023-01-05 16:39:34,434 - ==> Top1: 59.065    Loss: 0.737

2023-01-05 16:39:34,434 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:39:34,435 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 9]
2023-01-05 16:39:34,435 - Saving checkpoint to: logs/2023.01.05-163904/checkpoint.pth.tar
2023-01-05 16:39:34,473 - 

2023-01-05 16:39:34,473 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:34,961 - Epoch: [10][   10/   37]    Overall Loss 0.693612    Objective Loss 0.693612                                        LR 0.000010    Time 0.048784    
2023-01-05 16:39:35,256 - Epoch: [10][   20/   37]    Overall Loss 0.693321    Objective Loss 0.693321                                        LR 0.000010    Time 0.039081    
2023-01-05 16:39:35,562 - Epoch: [10][   30/   37]    Overall Loss 0.693511    Objective Loss 0.693511                                        LR 0.000010    Time 0.036258    
2023-01-05 16:39:35,758 - Epoch: [10][   37/   37]    Overall Loss 0.693286    Objective Loss 0.693286    Top1 60.251046    LR 0.000010    Time 0.034686    
2023-01-05 16:39:35,831 - --- validate (epoch=10)-----------
2023-01-05 16:39:35,831 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:36,061 - Epoch: [10][    5/    5]    Loss 0.693272    Top1 59.064885    
2023-01-05 16:39:36,117 - ==> Top1: 59.065    Loss: 0.693

2023-01-05 16:39:36,117 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:39:36,119 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 10]
2023-01-05 16:39:36,119 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:39:36,131 - 

2023-01-05 16:39:36,131 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:36,627 - Epoch: [11][   10/   37]    Overall Loss 0.693617    Objective Loss 0.693617                                        LR 0.000010    Time 0.049468    
2023-01-05 16:39:36,925 - Epoch: [11][   20/   37]    Overall Loss 0.692739    Objective Loss 0.692739                                        LR 0.000010    Time 0.039606    
2023-01-05 16:39:37,224 - Epoch: [11][   30/   37]    Overall Loss 0.693606    Objective Loss 0.693606                                        LR 0.000010    Time 0.036386    
2023-01-05 16:39:37,420 - Epoch: [11][   37/   37]    Overall Loss 0.693971    Objective Loss 0.693971    Top1 52.510460    LR 0.000010    Time 0.034789    
2023-01-05 16:39:37,494 - --- validate (epoch=11)-----------
2023-01-05 16:39:37,494 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:37,734 - Epoch: [11][    5/    5]    Loss 0.692344    Top1 59.064885    
2023-01-05 16:39:37,794 - ==> Top1: 59.065    Loss: 0.692

2023-01-05 16:39:37,794 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:39:37,795 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 11]
2023-01-05 16:39:37,795 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:39:37,815 - 

2023-01-05 16:39:37,815 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:38,298 - Epoch: [12][   10/   37]    Overall Loss 0.693863    Objective Loss 0.693863                                        LR 0.000010    Time 0.048130    
2023-01-05 16:39:38,598 - Epoch: [12][   20/   37]    Overall Loss 0.694588    Objective Loss 0.694588                                        LR 0.000010    Time 0.039048    
2023-01-05 16:39:38,884 - Epoch: [12][   30/   37]    Overall Loss 0.693845    Objective Loss 0.693845                                        LR 0.000010    Time 0.035562    
2023-01-05 16:39:39,071 - Epoch: [12][   37/   37]    Overall Loss 0.693886    Objective Loss 0.693886    Top1 53.765690    LR 0.000010    Time 0.033885    
2023-01-05 16:39:39,152 - --- validate (epoch=12)-----------
2023-01-05 16:39:39,152 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:39,394 - Epoch: [12][    5/    5]    Loss 0.693160    Top1 59.064885    
2023-01-05 16:39:39,462 - ==> Top1: 59.065    Loss: 0.693

2023-01-05 16:39:39,462 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:39:39,464 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 12]
2023-01-05 16:39:39,464 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:39:39,485 - 

2023-01-05 16:39:39,485 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:39,962 - Epoch: [13][   10/   37]    Overall Loss 0.693536    Objective Loss 0.693536                                        LR 0.000010    Time 0.047662    
2023-01-05 16:39:40,256 - Epoch: [13][   20/   37]    Overall Loss 0.693453    Objective Loss 0.693453                                        LR 0.000010    Time 0.038509    
2023-01-05 16:39:40,555 - Epoch: [13][   30/   37]    Overall Loss 0.693610    Objective Loss 0.693610                                        LR 0.000010    Time 0.035609    
2023-01-05 16:39:40,742 - Epoch: [13][   37/   37]    Overall Loss 0.693452    Objective Loss 0.693452    Top1 42.468619    LR 0.000010    Time 0.033924    
2023-01-05 16:39:40,822 - --- validate (epoch=13)-----------
2023-01-05 16:39:40,822 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:41,067 - Epoch: [13][    5/    5]    Loss 0.698510    Top1 40.935115    
2023-01-05 16:39:41,142 - ==> Top1: 40.935    Loss: 0.699

2023-01-05 16:39:41,142 - ==> Confusion:
[[427   2   0]
 [617   2   0]
 [  0   0   0]]

2023-01-05 16:39:41,144 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 12]
2023-01-05 16:39:41,144 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:39:41,164 - 

2023-01-05 16:39:41,164 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:41,647 - Epoch: [14][   10/   37]    Overall Loss 0.694165    Objective Loss 0.694165                                        LR 0.000010    Time 0.048183    
2023-01-05 16:39:41,939 - Epoch: [14][   20/   37]    Overall Loss 0.693410    Objective Loss 0.693410                                        LR 0.000010    Time 0.038678    
2023-01-05 16:39:42,233 - Epoch: [14][   30/   37]    Overall Loss 0.693354    Objective Loss 0.693354                                        LR 0.000010    Time 0.035565    
2023-01-05 16:39:42,428 - Epoch: [14][   37/   37]    Overall Loss 0.693252    Objective Loss 0.693252    Top1 55.648536    LR 0.000010    Time 0.034113    
2023-01-05 16:39:42,495 - --- validate (epoch=14)-----------
2023-01-05 16:39:42,495 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:42,736 - Epoch: [14][    5/    5]    Loss 0.692739    Top1 50.286260    
2023-01-05 16:39:42,799 - ==> Top1: 50.286    Loss: 0.693

2023-01-05 16:39:42,799 - ==> Confusion:
[[267 162   0]
 [359 260   0]
 [  0   0   0]]

2023-01-05 16:39:42,801 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 12]
2023-01-05 16:39:42,801 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:39:42,818 - 

2023-01-05 16:39:42,818 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:43,302 - Epoch: [15][   10/   37]    Overall Loss 0.692228    Objective Loss 0.692228                                        LR 0.000010    Time 0.048319    
2023-01-05 16:39:43,585 - Epoch: [15][   20/   37]    Overall Loss 0.693696    Objective Loss 0.693696                                        LR 0.000010    Time 0.038264    
2023-01-05 16:39:43,881 - Epoch: [15][   30/   37]    Overall Loss 0.693764    Objective Loss 0.693764                                        LR 0.000010    Time 0.035381    
2023-01-05 16:39:44,073 - Epoch: [15][   37/   37]    Overall Loss 0.693588    Objective Loss 0.693588    Top1 56.903766    LR 0.000010    Time 0.033872    
2023-01-05 16:39:44,150 - --- validate (epoch=15)-----------
2023-01-05 16:39:44,151 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:44,388 - Epoch: [15][    5/    5]    Loss 0.691849    Top1 54.961832    
2023-01-05 16:39:44,453 - ==> Top1: 54.962    Loss: 0.692

2023-01-05 16:39:44,453 - ==> Confusion:
[[178 251   0]
 [221 398   0]
 [  0   0   0]]

2023-01-05 16:39:44,454 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 12]
2023-01-05 16:39:44,454 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:39:44,464 - 

2023-01-05 16:39:44,464 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:44,954 - Epoch: [16][   10/   37]    Overall Loss 0.692709    Objective Loss 0.692709                                        LR 0.000010    Time 0.048884    
2023-01-05 16:39:45,256 - Epoch: [16][   20/   37]    Overall Loss 0.692603    Objective Loss 0.692603                                        LR 0.000010    Time 0.039524    
2023-01-05 16:39:45,563 - Epoch: [16][   30/   37]    Overall Loss 0.692549    Objective Loss 0.692549                                        LR 0.000010    Time 0.036588    
2023-01-05 16:39:45,759 - Epoch: [16][   37/   37]    Overall Loss 0.692513    Objective Loss 0.692513    Top1 46.234310    LR 0.000010    Time 0.034940    
2023-01-05 16:39:45,827 - --- validate (epoch=16)-----------
2023-01-05 16:39:45,827 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:46,062 - Epoch: [16][    5/    5]    Loss 0.694100    Top1 43.606870    
2023-01-05 16:39:46,121 - ==> Top1: 43.607    Loss: 0.694

2023-01-05 16:39:46,121 - ==> Confusion:
[[391  38   0]
 [553  66   0]
 [  0   0   0]]

2023-01-05 16:39:46,122 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 361664 on epoch: 12]
2023-01-05 16:39:46,123 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:39:46,132 - 

2023-01-05 16:39:46,132 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:46,609 - Epoch: [17][   10/   37]    Overall Loss 0.692757    Objective Loss 0.692757                                        LR 0.000010    Time 0.047657    
2023-01-05 16:39:46,891 - Epoch: [17][   20/   37]    Overall Loss 0.692676    Objective Loss 0.692676                                        LR 0.000010    Time 0.037898    
2023-01-05 16:39:47,210 - Epoch: [17][   30/   37]    Overall Loss 0.692545    Objective Loss 0.692545                                        LR 0.000010    Time 0.035869    
2023-01-05 16:39:47,406 - Epoch: [17][   37/   37]    Overall Loss 0.692642    Objective Loss 0.692642    Top1 58.786611    LR 0.000010    Time 0.034385    
2023-01-05 16:39:47,482 - --- validate (epoch=17)-----------
2023-01-05 16:39:47,482 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:47,719 - Epoch: [17][    5/    5]    Loss 0.690365    Top1 59.351145    
2023-01-05 16:39:47,799 - ==> Top1: 59.351    Loss: 0.690

2023-01-05 16:39:47,799 - ==> Confusion:
[[  5 424   0]
 [  2 617   0]
 [  0   0   0]]

2023-01-05 16:39:47,801 - ==> Best [Top1: 59.351   Sparsity:0.00   Params: 361664 on epoch: 17]
2023-01-05 16:39:47,801 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:39:47,820 - 

2023-01-05 16:39:47,820 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:48,303 - Epoch: [18][   10/   37]    Overall Loss 0.691719    Objective Loss 0.691719                                        LR 0.000010    Time 0.048203    
2023-01-05 16:39:48,600 - Epoch: [18][   20/   37]    Overall Loss 0.692774    Objective Loss 0.692774                                        LR 0.000010    Time 0.038902    
2023-01-05 16:39:48,902 - Epoch: [18][   30/   37]    Overall Loss 0.692956    Objective Loss 0.692956                                        LR 0.000010    Time 0.036000    
2023-01-05 16:39:49,098 - Epoch: [18][   37/   37]    Overall Loss 0.693511    Objective Loss 0.693511    Top1 56.066946    LR 0.000010    Time 0.034468    
2023-01-05 16:39:49,170 - --- validate (epoch=18)-----------
2023-01-05 16:39:49,170 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:49,412 - Epoch: [18][    5/    5]    Loss 0.695295    Top1 43.034351    
2023-01-05 16:39:49,483 - ==> Top1: 43.034    Loss: 0.695

2023-01-05 16:39:49,484 - ==> Confusion:
[[407  22   0]
 [575  44   0]
 [  0   0   0]]

2023-01-05 16:39:49,485 - ==> Best [Top1: 59.351   Sparsity:0.00   Params: 361664 on epoch: 17]
2023-01-05 16:39:49,485 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:39:49,505 - 

2023-01-05 16:39:49,505 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:49,999 - Epoch: [19][   10/   37]    Overall Loss 0.692455    Objective Loss 0.692455                                        LR 0.000010    Time 0.049283    
2023-01-05 16:39:50,300 - Epoch: [19][   20/   37]    Overall Loss 0.692861    Objective Loss 0.692861                                        LR 0.000010    Time 0.039680    
2023-01-05 16:39:50,604 - Epoch: [19][   30/   37]    Overall Loss 0.692786    Objective Loss 0.692786                                        LR 0.000010    Time 0.036558    
2023-01-05 16:39:50,798 - Epoch: [19][   37/   37]    Overall Loss 0.692934    Objective Loss 0.692934    Top1 49.372385    LR 0.000010    Time 0.034870    
2023-01-05 16:39:50,872 - --- validate (epoch=19)-----------
2023-01-05 16:39:50,872 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:51,113 - Epoch: [19][    5/    5]    Loss 0.692599    Top1 60.019084    
2023-01-05 16:39:51,176 - ==> Top1: 60.019    Loss: 0.693

2023-01-05 16:39:51,176 - ==> Confusion:
[[ 69 360   0]
 [ 59 560   0]
 [  0   0   0]]

2023-01-05 16:39:51,178 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:39:51,178 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:39:51,202 - 

2023-01-05 16:39:51,202 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:51,695 - Epoch: [20][   10/   37]    Overall Loss 0.693102    Objective Loss 0.693102                                        LR 0.000010    Time 0.049194    
2023-01-05 16:39:51,994 - Epoch: [20][   20/   37]    Overall Loss 0.693282    Objective Loss 0.693282                                        LR 0.000010    Time 0.039519    
2023-01-05 16:39:52,298 - Epoch: [20][   30/   37]    Overall Loss 0.693083    Objective Loss 0.693083                                        LR 0.000010    Time 0.036366    
2023-01-05 16:39:52,492 - Epoch: [20][   37/   37]    Overall Loss 0.693035    Objective Loss 0.693035    Top1 41.631799    LR 0.000010    Time 0.034736    
2023-01-05 16:39:52,563 - --- validate (epoch=20)-----------
2023-01-05 16:39:52,564 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:52,794 - Epoch: [20][    5/    5]    Loss 0.694798    Top1 41.412214    
2023-01-05 16:39:52,859 - ==> Top1: 41.412    Loss: 0.695

2023-01-05 16:39:52,859 - ==> Confusion:
[[427   2   0]
 [612   7   0]
 [  0   0   0]]

2023-01-05 16:39:52,860 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:39:52,861 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:39:52,880 - 

2023-01-05 16:39:52,881 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:53,472 - Epoch: [21][   10/   37]    Overall Loss 0.693678    Objective Loss 0.693678                                        LR 0.000010    Time 0.059092    
2023-01-05 16:39:53,775 - Epoch: [21][   20/   37]    Overall Loss 0.693202    Objective Loss 0.693202                                        LR 0.000010    Time 0.044673    
2023-01-05 16:39:54,095 - Epoch: [21][   30/   37]    Overall Loss 0.693085    Objective Loss 0.693085                                        LR 0.000010    Time 0.040308    
2023-01-05 16:39:54,291 - Epoch: [21][   37/   37]    Overall Loss 0.693029    Objective Loss 0.693029    Top1 54.602510    LR 0.000010    Time 0.037974    
2023-01-05 16:39:54,361 - --- validate (epoch=21)-----------
2023-01-05 16:39:54,362 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:54,596 - Epoch: [21][    5/    5]    Loss 0.693298    Top1 43.702290    
2023-01-05 16:39:54,665 - ==> Top1: 43.702    Loss: 0.693

2023-01-05 16:39:54,665 - ==> Confusion:
[[413  16   0]
 [574  45   0]
 [  0   0   0]]

2023-01-05 16:39:54,666 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:39:54,666 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:39:54,686 - 

2023-01-05 16:39:54,686 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:55,168 - Epoch: [22][   10/   37]    Overall Loss 0.694671    Objective Loss 0.694671                                        LR 0.000010    Time 0.048103    
2023-01-05 16:39:55,464 - Epoch: [22][   20/   37]    Overall Loss 0.693792    Objective Loss 0.693792                                        LR 0.000010    Time 0.038820    
2023-01-05 16:39:55,766 - Epoch: [22][   30/   37]    Overall Loss 0.693674    Objective Loss 0.693674                                        LR 0.000010    Time 0.035820    
2023-01-05 16:39:55,960 - Epoch: [22][   37/   37]    Overall Loss 0.693354    Objective Loss 0.693354    Top1 54.602510    LR 0.000010    Time 0.034297    
2023-01-05 16:39:56,033 - --- validate (epoch=22)-----------
2023-01-05 16:39:56,033 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:56,268 - Epoch: [22][    5/    5]    Loss 0.692761    Top1 58.969466    
2023-01-05 16:39:56,335 - ==> Top1: 58.969    Loss: 0.693

2023-01-05 16:39:56,336 - ==> Confusion:
[[  0 429   0]
 [  1 618   0]
 [  0   0   0]]

2023-01-05 16:39:56,337 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:39:56,337 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:39:56,347 - 

2023-01-05 16:39:56,347 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:56,844 - Epoch: [23][   10/   37]    Overall Loss 0.691880    Objective Loss 0.691880                                        LR 0.000010    Time 0.049641    
2023-01-05 16:39:57,161 - Epoch: [23][   20/   37]    Overall Loss 0.691694    Objective Loss 0.691694                                        LR 0.000010    Time 0.040661    
2023-01-05 16:39:57,478 - Epoch: [23][   30/   37]    Overall Loss 0.692092    Objective Loss 0.692092                                        LR 0.000010    Time 0.037660    
2023-01-05 16:39:57,673 - Epoch: [23][   37/   37]    Overall Loss 0.691987    Objective Loss 0.691987    Top1 43.096234    LR 0.000010    Time 0.035807    
2023-01-05 16:39:57,751 - --- validate (epoch=23)-----------
2023-01-05 16:39:57,751 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:57,994 - Epoch: [23][    5/    5]    Loss 0.692115    Top1 58.492366    
2023-01-05 16:39:58,057 - ==> Top1: 58.492    Loss: 0.692

2023-01-05 16:39:58,057 - ==> Confusion:
[[ 76 353   0]
 [ 82 537   0]
 [  0   0   0]]

2023-01-05 16:39:58,058 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:39:58,058 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:39:58,068 - 

2023-01-05 16:39:58,068 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:39:58,552 - Epoch: [24][   10/   37]    Overall Loss 0.691225    Objective Loss 0.691225                                        LR 0.000010    Time 0.048269    
2023-01-05 16:39:58,848 - Epoch: [24][   20/   37]    Overall Loss 0.692299    Objective Loss 0.692299                                        LR 0.000010    Time 0.038943    
2023-01-05 16:39:59,150 - Epoch: [24][   30/   37]    Overall Loss 0.691742    Objective Loss 0.691742                                        LR 0.000010    Time 0.036001    
2023-01-05 16:39:59,345 - Epoch: [24][   37/   37]    Overall Loss 0.691857    Objective Loss 0.691857    Top1 54.602510    LR 0.000010    Time 0.034454    
2023-01-05 16:39:59,415 - --- validate (epoch=24)-----------
2023-01-05 16:39:59,415 - 1048 samples (256 per mini-batch)
2023-01-05 16:39:59,654 - Epoch: [24][    5/    5]    Loss 0.691086    Top1 57.347328    
2023-01-05 16:39:59,721 - ==> Top1: 57.347    Loss: 0.691

2023-01-05 16:39:59,721 - ==> Confusion:
[[192 237   0]
 [210 409   0]
 [  0   0   0]]

2023-01-05 16:39:59,722 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:39:59,722 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:39:59,742 - 

2023-01-05 16:39:59,742 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:00,229 - Epoch: [25][   10/   37]    Overall Loss 0.692465    Objective Loss 0.692465                                        LR 0.000010    Time 0.048545    
2023-01-05 16:40:00,532 - Epoch: [25][   20/   37]    Overall Loss 0.692546    Objective Loss 0.692546                                        LR 0.000010    Time 0.039417    
2023-01-05 16:40:00,838 - Epoch: [25][   30/   37]    Overall Loss 0.691996    Objective Loss 0.691996                                        LR 0.000010    Time 0.036452    
2023-01-05 16:40:01,034 - Epoch: [25][   37/   37]    Overall Loss 0.692057    Objective Loss 0.692057    Top1 58.158996    LR 0.000010    Time 0.034865    
2023-01-05 16:40:01,114 - --- validate (epoch=25)-----------
2023-01-05 16:40:01,114 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:01,348 - Epoch: [25][    5/    5]    Loss 0.693563    Top1 43.416031    
2023-01-05 16:40:01,414 - ==> Top1: 43.416    Loss: 0.694

2023-01-05 16:40:01,414 - ==> Confusion:
[[410  19   0]
 [574  45   0]
 [  0   0   0]]

2023-01-05 16:40:01,415 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:01,415 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:01,425 - 

2023-01-05 16:40:01,425 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:01,906 - Epoch: [26][   10/   37]    Overall Loss 0.694795    Objective Loss 0.694795                                        LR 0.000010    Time 0.048005    
2023-01-05 16:40:02,206 - Epoch: [26][   20/   37]    Overall Loss 0.693968    Objective Loss 0.693968                                        LR 0.000010    Time 0.039020    
2023-01-05 16:40:02,504 - Epoch: [26][   30/   37]    Overall Loss 0.693646    Objective Loss 0.693646                                        LR 0.000010    Time 0.035916    
2023-01-05 16:40:02,697 - Epoch: [26][   37/   37]    Overall Loss 0.693545    Objective Loss 0.693545    Top1 56.276151    LR 0.000010    Time 0.034345    
2023-01-05 16:40:02,762 - --- validate (epoch=26)-----------
2023-01-05 16:40:02,762 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:03,010 - Epoch: [26][    5/    5]    Loss 0.691365    Top1 53.816794    
2023-01-05 16:40:03,080 - ==> Top1: 53.817    Loss: 0.691

2023-01-05 16:40:03,080 - ==> Confusion:
[[173 256   0]
 [228 391   0]
 [  0   0   0]]

2023-01-05 16:40:03,082 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:03,082 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:03,092 - 

2023-01-05 16:40:03,092 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:03,576 - Epoch: [27][   10/   37]    Overall Loss 0.691314    Objective Loss 0.691314                                        LR 0.000010    Time 0.048365    
2023-01-05 16:40:03,868 - Epoch: [27][   20/   37]    Overall Loss 0.691235    Objective Loss 0.691235                                        LR 0.000010    Time 0.038738    
2023-01-05 16:40:04,156 - Epoch: [27][   30/   37]    Overall Loss 0.691306    Objective Loss 0.691306                                        LR 0.000010    Time 0.035441    
2023-01-05 16:40:04,352 - Epoch: [27][   37/   37]    Overall Loss 0.691673    Objective Loss 0.691673    Top1 40.794979    LR 0.000010    Time 0.034008    
2023-01-05 16:40:04,424 - --- validate (epoch=27)-----------
2023-01-05 16:40:04,425 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:04,661 - Epoch: [27][    5/    5]    Loss 0.693976    Top1 41.793893    
2023-01-05 16:40:04,729 - ==> Top1: 41.794    Loss: 0.694

2023-01-05 16:40:04,729 - ==> Confusion:
[[419  10   0]
 [600  19   0]
 [  0   0   0]]

2023-01-05 16:40:04,730 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:04,731 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:04,751 - 

2023-01-05 16:40:04,751 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:05,243 - Epoch: [28][   10/   37]    Overall Loss 0.691228    Objective Loss 0.691228                                        LR 0.000010    Time 0.049119    
2023-01-05 16:40:05,536 - Epoch: [28][   20/   37]    Overall Loss 0.691493    Objective Loss 0.691493                                        LR 0.000010    Time 0.039183    
2023-01-05 16:40:05,840 - Epoch: [28][   30/   37]    Overall Loss 0.691379    Objective Loss 0.691379                                        LR 0.000010    Time 0.036253    
2023-01-05 16:40:06,029 - Epoch: [28][   37/   37]    Overall Loss 0.691523    Objective Loss 0.691523    Top1 50.627615    LR 0.000010    Time 0.034501    
2023-01-05 16:40:06,108 - --- validate (epoch=28)-----------
2023-01-05 16:40:06,109 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:06,358 - Epoch: [28][    5/    5]    Loss 0.690546    Top1 44.465649    
2023-01-05 16:40:06,422 - ==> Top1: 44.466    Loss: 0.691

2023-01-05 16:40:06,423 - ==> Confusion:
[[416  13   0]
 [569  50   0]
 [  0   0   0]]

2023-01-05 16:40:06,424 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:06,424 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:06,444 - 

2023-01-05 16:40:06,444 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:06,916 - Epoch: [29][   10/   37]    Overall Loss 0.691984    Objective Loss 0.691984                                        LR 0.000010    Time 0.047119    
2023-01-05 16:40:07,201 - Epoch: [29][   20/   37]    Overall Loss 0.691630    Objective Loss 0.691630                                        LR 0.000010    Time 0.037791    
2023-01-05 16:40:07,500 - Epoch: [29][   30/   37]    Overall Loss 0.691516    Objective Loss 0.691516                                        LR 0.000010    Time 0.035144    
2023-01-05 16:40:07,697 - Epoch: [29][   37/   37]    Overall Loss 0.691547    Objective Loss 0.691547    Top1 52.301255    LR 0.000010    Time 0.033819    
2023-01-05 16:40:07,762 - --- validate (epoch=29)-----------
2023-01-05 16:40:07,763 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:07,997 - Epoch: [29][    5/    5]    Loss 0.690707    Top1 55.629771    
2023-01-05 16:40:08,060 - ==> Top1: 55.630    Loss: 0.691

2023-01-05 16:40:08,060 - ==> Confusion:
[[298 131   0]
 [334 285   0]
 [  0   0   0]]

2023-01-05 16:40:08,062 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:08,062 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:08,071 - 

2023-01-05 16:40:08,071 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:08,564 - Epoch: [30][   10/   37]    Overall Loss 0.691694    Objective Loss 0.691694                                        LR 0.000010    Time 0.049246    
2023-01-05 16:40:08,861 - Epoch: [30][   20/   37]    Overall Loss 0.691847    Objective Loss 0.691847                                        LR 0.000010    Time 0.039423    
2023-01-05 16:40:09,156 - Epoch: [30][   30/   37]    Overall Loss 0.691778    Objective Loss 0.691778                                        LR 0.000010    Time 0.036111    
2023-01-05 16:40:09,352 - Epoch: [30][   37/   37]    Overall Loss 0.691855    Objective Loss 0.691855    Top1 55.020921    LR 0.000010    Time 0.034577    
2023-01-05 16:40:09,422 - --- validate (epoch=30)-----------
2023-01-05 16:40:09,422 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:09,663 - Epoch: [30][    5/    5]    Loss 0.689753    Top1 59.255725    
2023-01-05 16:40:09,735 - ==> Top1: 59.256    Loss: 0.690

2023-01-05 16:40:09,735 - ==> Confusion:
[[  2 427   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:40:09,736 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:09,736 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:09,746 - 

2023-01-05 16:40:09,746 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:10,233 - Epoch: [31][   10/   37]    Overall Loss 0.692109    Objective Loss 0.692109                                        LR 0.000010    Time 0.048586    
2023-01-05 16:40:10,530 - Epoch: [31][   20/   37]    Overall Loss 0.692083    Objective Loss 0.692083                                        LR 0.000010    Time 0.039114    
2023-01-05 16:40:10,831 - Epoch: [31][   30/   37]    Overall Loss 0.691881    Objective Loss 0.691881                                        LR 0.000010    Time 0.036091    
2023-01-05 16:40:11,026 - Epoch: [31][   37/   37]    Overall Loss 0.691858    Objective Loss 0.691858    Top1 51.882845    LR 0.000010    Time 0.034547    
2023-01-05 16:40:11,104 - --- validate (epoch=31)-----------
2023-01-05 16:40:11,105 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:11,347 - Epoch: [31][    5/    5]    Loss 0.691873    Top1 53.244275    
2023-01-05 16:40:11,415 - ==> Top1: 53.244    Loss: 0.692

2023-01-05 16:40:11,416 - ==> Confusion:
[[158 271   0]
 [219 400   0]
 [  0   0   0]]

2023-01-05 16:40:11,417 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:11,417 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:11,427 - 

2023-01-05 16:40:11,427 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:11,904 - Epoch: [32][   10/   37]    Overall Loss 0.691826    Objective Loss 0.691826                                        LR 0.000010    Time 0.047601    
2023-01-05 16:40:12,201 - Epoch: [32][   20/   37]    Overall Loss 0.691819    Objective Loss 0.691819                                        LR 0.000010    Time 0.038653    
2023-01-05 16:40:12,502 - Epoch: [32][   30/   37]    Overall Loss 0.691921    Objective Loss 0.691921                                        LR 0.000010    Time 0.035768    
2023-01-05 16:40:12,698 - Epoch: [32][   37/   37]    Overall Loss 0.691838    Objective Loss 0.691838    Top1 47.071130    LR 0.000010    Time 0.034287    
2023-01-05 16:40:12,777 - --- validate (epoch=32)-----------
2023-01-05 16:40:12,777 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:13,007 - Epoch: [32][    5/    5]    Loss 0.691519    Top1 52.194656    
2023-01-05 16:40:13,079 - ==> Top1: 52.195    Loss: 0.692

2023-01-05 16:40:13,079 - ==> Confusion:
[[311 118   0]
 [383 236   0]
 [  0   0   0]]

2023-01-05 16:40:13,080 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:13,080 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:13,100 - 

2023-01-05 16:40:13,100 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:13,599 - Epoch: [33][   10/   37]    Overall Loss 0.691181    Objective Loss 0.691181                                        LR 0.000010    Time 0.049813    
2023-01-05 16:40:13,905 - Epoch: [33][   20/   37]    Overall Loss 0.691476    Objective Loss 0.691476                                        LR 0.000010    Time 0.040166    
2023-01-05 16:40:14,217 - Epoch: [33][   30/   37]    Overall Loss 0.691601    Objective Loss 0.691601                                        LR 0.000010    Time 0.037171    
2023-01-05 16:40:14,413 - Epoch: [33][   37/   37]    Overall Loss 0.691474    Objective Loss 0.691474    Top1 57.740586    LR 0.000010    Time 0.035438    
2023-01-05 16:40:14,483 - --- validate (epoch=33)-----------
2023-01-05 16:40:14,483 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:14,717 - Epoch: [33][    5/    5]    Loss 0.688305    Top1 59.064885    
2023-01-05 16:40:14,786 - ==> Top1: 59.065    Loss: 0.688

2023-01-05 16:40:14,787 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:40:14,788 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:14,788 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:14,798 - 

2023-01-05 16:40:14,798 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:15,295 - Epoch: [34][   10/   37]    Overall Loss 0.691040    Objective Loss 0.691040                                        LR 0.000010    Time 0.049673    
2023-01-05 16:40:15,591 - Epoch: [34][   20/   37]    Overall Loss 0.690839    Objective Loss 0.690839                                        LR 0.000010    Time 0.039589    
2023-01-05 16:40:15,898 - Epoch: [34][   30/   37]    Overall Loss 0.691148    Objective Loss 0.691148                                        LR 0.000010    Time 0.036606    
2023-01-05 16:40:16,093 - Epoch: [34][   37/   37]    Overall Loss 0.691103    Objective Loss 0.691103    Top1 58.158996    LR 0.000010    Time 0.034956    
2023-01-05 16:40:16,166 - --- validate (epoch=34)-----------
2023-01-05 16:40:16,167 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:16,401 - Epoch: [34][    5/    5]    Loss 0.690969    Top1 59.064885    
2023-01-05 16:40:16,459 - ==> Top1: 59.065    Loss: 0.691

2023-01-05 16:40:16,459 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:40:16,460 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:16,460 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:16,470 - 

2023-01-05 16:40:16,470 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:16,945 - Epoch: [35][   10/   37]    Overall Loss 0.690097    Objective Loss 0.690097                                        LR 0.000010    Time 0.047419    
2023-01-05 16:40:17,242 - Epoch: [35][   20/   37]    Overall Loss 0.691102    Objective Loss 0.691102                                        LR 0.000010    Time 0.038520    
2023-01-05 16:40:17,539 - Epoch: [35][   30/   37]    Overall Loss 0.692743    Objective Loss 0.692743                                        LR 0.000010    Time 0.035595    
2023-01-05 16:40:17,736 - Epoch: [35][   37/   37]    Overall Loss 0.692695    Objective Loss 0.692695    Top1 44.769874    LR 0.000010    Time 0.034177    
2023-01-05 16:40:17,809 - --- validate (epoch=35)-----------
2023-01-05 16:40:17,809 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:18,041 - Epoch: [35][    5/    5]    Loss 0.690751    Top1 59.828244    
2023-01-05 16:40:18,119 - ==> Top1: 59.828    Loss: 0.691

2023-01-05 16:40:18,119 - ==> Confusion:
[[ 22 407   0]
 [ 14 605   0]
 [  0   0   0]]

2023-01-05 16:40:18,120 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:18,121 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:18,141 - 

2023-01-05 16:40:18,141 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:18,634 - Epoch: [36][   10/   37]    Overall Loss 0.691176    Objective Loss 0.691176                                        LR 0.000010    Time 0.049222    
2023-01-05 16:40:18,934 - Epoch: [36][   20/   37]    Overall Loss 0.691099    Objective Loss 0.691099                                        LR 0.000010    Time 0.039598    
2023-01-05 16:40:19,231 - Epoch: [36][   30/   37]    Overall Loss 0.690977    Objective Loss 0.690977                                        LR 0.000010    Time 0.036303    
2023-01-05 16:40:19,428 - Epoch: [36][   37/   37]    Overall Loss 0.690989    Objective Loss 0.690989    Top1 48.953975    LR 0.000010    Time 0.034755    
2023-01-05 16:40:19,502 - --- validate (epoch=36)-----------
2023-01-05 16:40:19,502 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:19,750 - Epoch: [36][    5/    5]    Loss 0.691762    Top1 51.431298    
2023-01-05 16:40:19,819 - ==> Top1: 51.431    Loss: 0.692

2023-01-05 16:40:19,819 - ==> Confusion:
[[356  73   0]
 [436 183   0]
 [  0   0   0]]

2023-01-05 16:40:19,821 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:19,821 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:19,840 - 

2023-01-05 16:40:19,841 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:20,385 - Epoch: [37][   10/   37]    Overall Loss 0.691493    Objective Loss 0.691493                                        LR 0.000010    Time 0.054366    
2023-01-05 16:40:20,693 - Epoch: [37][   20/   37]    Overall Loss 0.691522    Objective Loss 0.691522                                        LR 0.000010    Time 0.042547    
2023-01-05 16:40:21,001 - Epoch: [37][   30/   37]    Overall Loss 0.691692    Objective Loss 0.691692                                        LR 0.000010    Time 0.038542    
2023-01-05 16:40:21,197 - Epoch: [37][   37/   37]    Overall Loss 0.691527    Objective Loss 0.691527    Top1 44.979079    LR 0.000010    Time 0.036524    
2023-01-05 16:40:21,273 - --- validate (epoch=37)-----------
2023-01-05 16:40:21,273 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:21,778 - Epoch: [37][    5/    5]    Loss 0.693332    Top1 41.793893    
2023-01-05 16:40:21,852 - ==> Top1: 41.794    Loss: 0.693

2023-01-05 16:40:21,853 - ==> Confusion:
[[424   5   0]
 [605  14   0]
 [  0   0   0]]

2023-01-05 16:40:21,854 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:21,854 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:21,864 - 

2023-01-05 16:40:21,864 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:22,375 - Epoch: [38][   10/   37]    Overall Loss 0.692658    Objective Loss 0.692658                                        LR 0.000010    Time 0.051010    
2023-01-05 16:40:22,698 - Epoch: [38][   20/   37]    Overall Loss 0.691422    Objective Loss 0.691422                                        LR 0.000010    Time 0.041624    
2023-01-05 16:40:23,015 - Epoch: [38][   30/   37]    Overall Loss 0.691472    Objective Loss 0.691472                                        LR 0.000010    Time 0.038328    
2023-01-05 16:40:23,211 - Epoch: [38][   37/   37]    Overall Loss 0.691124    Objective Loss 0.691124    Top1 55.020921    LR 0.000010    Time 0.036365    
2023-01-05 16:40:23,282 - --- validate (epoch=38)-----------
2023-01-05 16:40:23,282 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:23,516 - Epoch: [38][    5/    5]    Loss 0.691513    Top1 51.717557    
2023-01-05 16:40:23,585 - ==> Top1: 51.718    Loss: 0.692

2023-01-05 16:40:23,585 - ==> Confusion:
[[303 126   0]
 [380 239   0]
 [  0   0   0]]

2023-01-05 16:40:23,587 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:23,587 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:23,596 - 

2023-01-05 16:40:23,596 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:24,098 - Epoch: [39][   10/   37]    Overall Loss 0.689957    Objective Loss 0.689957                                        LR 0.000010    Time 0.050066    
2023-01-05 16:40:24,409 - Epoch: [39][   20/   37]    Overall Loss 0.690742    Objective Loss 0.690742                                        LR 0.000010    Time 0.040554    
2023-01-05 16:40:24,718 - Epoch: [39][   30/   37]    Overall Loss 0.691137    Objective Loss 0.691137                                        LR 0.000010    Time 0.037347    
2023-01-05 16:40:24,914 - Epoch: [39][   37/   37]    Overall Loss 0.691386    Objective Loss 0.691386    Top1 54.811715    LR 0.000010    Time 0.035554    
2023-01-05 16:40:24,991 - --- validate (epoch=39)-----------
2023-01-05 16:40:24,991 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:25,223 - Epoch: [39][    5/    5]    Loss 0.687690    Top1 59.064885    
2023-01-05 16:40:25,283 - ==> Top1: 59.065    Loss: 0.688

2023-01-05 16:40:25,283 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:40:25,285 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:25,285 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:25,305 - 

2023-01-05 16:40:25,305 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:25,822 - Epoch: [40][   10/   37]    Overall Loss 0.690145    Objective Loss 0.690145                                        LR 0.000006    Time 0.051681    
2023-01-05 16:40:26,118 - Epoch: [40][   20/   37]    Overall Loss 0.689857    Objective Loss 0.689857                                        LR 0.000006    Time 0.040604    
2023-01-05 16:40:26,422 - Epoch: [40][   30/   37]    Overall Loss 0.689239    Objective Loss 0.689239                                        LR 0.000006    Time 0.037198    
2023-01-05 16:40:26,617 - Epoch: [40][   37/   37]    Overall Loss 0.689166    Objective Loss 0.689166    Top1 60.460251    LR 0.000006    Time 0.035409    
2023-01-05 16:40:26,693 - --- validate (epoch=40)-----------
2023-01-05 16:40:26,693 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:26,931 - Epoch: [40][    5/    5]    Loss 0.685349    Top1 59.064885    
2023-01-05 16:40:27,002 - ==> Top1: 59.065    Loss: 0.685

2023-01-05 16:40:27,002 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:40:27,004 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:27,004 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:27,013 - 

2023-01-05 16:40:27,013 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:27,493 - Epoch: [41][   10/   37]    Overall Loss 0.690550    Objective Loss 0.690550                                        LR 0.000006    Time 0.047868    
2023-01-05 16:40:27,793 - Epoch: [41][   20/   37]    Overall Loss 0.690382    Objective Loss 0.690382                                        LR 0.000006    Time 0.038900    
2023-01-05 16:40:28,095 - Epoch: [41][   30/   37]    Overall Loss 0.690292    Objective Loss 0.690292                                        LR 0.000006    Time 0.036003    
2023-01-05 16:40:28,290 - Epoch: [41][   37/   37]    Overall Loss 0.690079    Objective Loss 0.690079    Top1 47.698745    LR 0.000006    Time 0.034440    
2023-01-05 16:40:28,375 - --- validate (epoch=41)-----------
2023-01-05 16:40:28,375 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:28,618 - Epoch: [41][    5/    5]    Loss 0.691938    Top1 44.656489    
2023-01-05 16:40:28,674 - ==> Top1: 44.656    Loss: 0.692

2023-01-05 16:40:28,675 - ==> Confusion:
[[418  11   0]
 [569  50   0]
 [  0   0   0]]

2023-01-05 16:40:28,676 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:28,676 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:28,686 - 

2023-01-05 16:40:28,686 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:29,183 - Epoch: [42][   10/   37]    Overall Loss 0.690265    Objective Loss 0.690265                                        LR 0.000006    Time 0.049594    
2023-01-05 16:40:29,481 - Epoch: [42][   20/   37]    Overall Loss 0.690417    Objective Loss 0.690417                                        LR 0.000006    Time 0.039700    
2023-01-05 16:40:29,788 - Epoch: [42][   30/   37]    Overall Loss 0.690211    Objective Loss 0.690211                                        LR 0.000006    Time 0.036681    
2023-01-05 16:40:29,982 - Epoch: [42][   37/   37]    Overall Loss 0.690114    Objective Loss 0.690114    Top1 44.979079    LR 0.000006    Time 0.034977    
2023-01-05 16:40:30,065 - --- validate (epoch=42)-----------
2023-01-05 16:40:30,065 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:30,309 - Epoch: [42][    5/    5]    Loss 0.688572    Top1 44.847328    
2023-01-05 16:40:30,368 - ==> Top1: 44.847    Loss: 0.689

2023-01-05 16:40:30,368 - ==> Confusion:
[[413  16   0]
 [562  57   0]
 [  0   0   0]]

2023-01-05 16:40:30,369 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:30,370 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:30,389 - 

2023-01-05 16:40:30,389 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:30,891 - Epoch: [43][   10/   37]    Overall Loss 0.689169    Objective Loss 0.689169                                        LR 0.000006    Time 0.050128    
2023-01-05 16:40:31,193 - Epoch: [43][   20/   37]    Overall Loss 0.690900    Objective Loss 0.690900                                        LR 0.000006    Time 0.040105    
2023-01-05 16:40:31,498 - Epoch: [43][   30/   37]    Overall Loss 0.690428    Objective Loss 0.690428                                        LR 0.000006    Time 0.036913    
2023-01-05 16:40:31,696 - Epoch: [43][   37/   37]    Overall Loss 0.690339    Objective Loss 0.690339    Top1 58.577406    LR 0.000006    Time 0.035273    
2023-01-05 16:40:31,766 - --- validate (epoch=43)-----------
2023-01-05 16:40:31,767 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:32,000 - Epoch: [43][    5/    5]    Loss 0.690825    Top1 51.526718    
2023-01-05 16:40:32,058 - ==> Top1: 51.527    Loss: 0.691

2023-01-05 16:40:32,058 - ==> Confusion:
[[380  49   0]
 [459 160   0]
 [  0   0   0]]

2023-01-05 16:40:32,060 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:32,060 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:32,069 - 

2023-01-05 16:40:32,070 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:32,578 - Epoch: [44][   10/   37]    Overall Loss 0.688005    Objective Loss 0.688005                                        LR 0.000006    Time 0.050780    
2023-01-05 16:40:32,892 - Epoch: [44][   20/   37]    Overall Loss 0.689737    Objective Loss 0.689737                                        LR 0.000006    Time 0.041047    
2023-01-05 16:40:33,191 - Epoch: [44][   30/   37]    Overall Loss 0.689751    Objective Loss 0.689751                                        LR 0.000006    Time 0.037327    
2023-01-05 16:40:33,386 - Epoch: [44][   37/   37]    Overall Loss 0.689696    Objective Loss 0.689696    Top1 46.443515    LR 0.000006    Time 0.035524    
2023-01-05 16:40:33,457 - --- validate (epoch=44)-----------
2023-01-05 16:40:33,458 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:33,701 - Epoch: [44][    5/    5]    Loss 0.700933    Top1 41.793893    
2023-01-05 16:40:33,764 - ==> Top1: 41.794    Loss: 0.701

2023-01-05 16:40:33,765 - ==> Confusion:
[[427   2   0]
 [608  11   0]
 [  0   0   0]]

2023-01-05 16:40:33,766 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:33,766 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:33,786 - 

2023-01-05 16:40:33,786 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:34,280 - Epoch: [45][   10/   37]    Overall Loss 0.691284    Objective Loss 0.691284                                        LR 0.000006    Time 0.049344    
2023-01-05 16:40:34,593 - Epoch: [45][   20/   37]    Overall Loss 0.690377    Objective Loss 0.690377                                        LR 0.000006    Time 0.040266    
2023-01-05 16:40:34,902 - Epoch: [45][   30/   37]    Overall Loss 0.689861    Objective Loss 0.689861                                        LR 0.000006    Time 0.037130    
2023-01-05 16:40:35,097 - Epoch: [45][   37/   37]    Overall Loss 0.690199    Objective Loss 0.690199    Top1 61.924686    LR 0.000006    Time 0.035380    
2023-01-05 16:40:35,179 - --- validate (epoch=45)-----------
2023-01-05 16:40:35,179 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:35,415 - Epoch: [45][    5/    5]    Loss 0.682274    Top1 59.064885    
2023-01-05 16:40:35,474 - ==> Top1: 59.065    Loss: 0.682

2023-01-05 16:40:35,474 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:40:35,476 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:35,476 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:35,496 - 

2023-01-05 16:40:35,496 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:35,988 - Epoch: [46][   10/   37]    Overall Loss 0.694153    Objective Loss 0.694153                                        LR 0.000006    Time 0.049187    
2023-01-05 16:40:36,291 - Epoch: [46][   20/   37]    Overall Loss 0.691275    Objective Loss 0.691275                                        LR 0.000006    Time 0.039675    
2023-01-05 16:40:36,595 - Epoch: [46][   30/   37]    Overall Loss 0.690803    Objective Loss 0.690803                                        LR 0.000006    Time 0.036596    
2023-01-05 16:40:36,791 - Epoch: [46][   37/   37]    Overall Loss 0.690352    Objective Loss 0.690352    Top1 50.209205    LR 0.000006    Time 0.034948    
2023-01-05 16:40:36,862 - --- validate (epoch=46)-----------
2023-01-05 16:40:36,862 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:37,109 - Epoch: [46][    5/    5]    Loss 0.689867    Top1 46.946565    
2023-01-05 16:40:37,189 - ==> Top1: 46.947    Loss: 0.690

2023-01-05 16:40:37,190 - ==> Confusion:
[[411  18   0]
 [538  81   0]
 [  0   0   0]]

2023-01-05 16:40:37,191 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:37,191 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:37,201 - 

2023-01-05 16:40:37,201 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:37,698 - Epoch: [47][   10/   37]    Overall Loss 0.688949    Objective Loss 0.688949                                        LR 0.000006    Time 0.049597    
2023-01-05 16:40:37,996 - Epoch: [47][   20/   37]    Overall Loss 0.689235    Objective Loss 0.689235                                        LR 0.000006    Time 0.039675    
2023-01-05 16:40:38,306 - Epoch: [47][   30/   37]    Overall Loss 0.688813    Objective Loss 0.688813                                        LR 0.000006    Time 0.036757    
2023-01-05 16:40:38,500 - Epoch: [47][   37/   37]    Overall Loss 0.688674    Objective Loss 0.688674    Top1 56.485356    LR 0.000006    Time 0.035046    
2023-01-05 16:40:38,573 - --- validate (epoch=47)-----------
2023-01-05 16:40:38,573 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:38,814 - Epoch: [47][    5/    5]    Loss 0.688690    Top1 50.858779    
2023-01-05 16:40:38,881 - ==> Top1: 50.859    Loss: 0.689

2023-01-05 16:40:38,882 - ==> Confusion:
[[385  44   0]
 [471 148   0]
 [  0   0   0]]

2023-01-05 16:40:38,883 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:38,883 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:38,893 - 

2023-01-05 16:40:38,893 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:39,379 - Epoch: [48][   10/   37]    Overall Loss 0.689063    Objective Loss 0.689063                                        LR 0.000006    Time 0.048492    
2023-01-05 16:40:39,677 - Epoch: [48][   20/   37]    Overall Loss 0.689058    Objective Loss 0.689058                                        LR 0.000006    Time 0.039160    
2023-01-05 16:40:39,977 - Epoch: [48][   30/   37]    Overall Loss 0.689729    Objective Loss 0.689729                                        LR 0.000006    Time 0.036080    
2023-01-05 16:40:40,171 - Epoch: [48][   37/   37]    Overall Loss 0.689738    Objective Loss 0.689738    Top1 48.535565    LR 0.000006    Time 0.034496    
2023-01-05 16:40:40,250 - --- validate (epoch=48)-----------
2023-01-05 16:40:40,251 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:40,492 - Epoch: [48][    5/    5]    Loss 0.689708    Top1 49.904580    
2023-01-05 16:40:40,566 - ==> Top1: 49.905    Loss: 0.690

2023-01-05 16:40:40,566 - ==> Confusion:
[[394  35   0]
 [490 129   0]
 [  0   0   0]]

2023-01-05 16:40:40,568 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:40,568 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:40,578 - 

2023-01-05 16:40:40,578 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:41,041 - Epoch: [49][   10/   37]    Overall Loss 0.689195    Objective Loss 0.689195                                        LR 0.000006    Time 0.046262    
2023-01-05 16:40:41,315 - Epoch: [49][   20/   37]    Overall Loss 0.689091    Objective Loss 0.689091                                        LR 0.000006    Time 0.036792    
2023-01-05 16:40:41,598 - Epoch: [49][   30/   37]    Overall Loss 0.688753    Objective Loss 0.688753                                        LR 0.000006    Time 0.033942    
2023-01-05 16:40:41,791 - Epoch: [49][   37/   37]    Overall Loss 0.688940    Objective Loss 0.688940    Top1 63.179916    LR 0.000006    Time 0.032734    
2023-01-05 16:40:41,869 - --- validate (epoch=49)-----------
2023-01-05 16:40:41,869 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:42,107 - Epoch: [49][    5/    5]    Loss 0.689537    Top1 56.583969    
2023-01-05 16:40:42,166 - ==> Top1: 56.584    Loss: 0.690

2023-01-05 16:40:42,166 - ==> Confusion:
[[307 122   0]
 [333 286   0]
 [  0   0   0]]

2023-01-05 16:40:42,168 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:42,168 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:42,177 - 

2023-01-05 16:40:42,178 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:42,656 - Epoch: [50][   10/   37]    Overall Loss 0.690033    Objective Loss 0.690033                                        LR 0.000006    Time 0.047806    
2023-01-05 16:40:42,935 - Epoch: [50][   20/   37]    Overall Loss 0.689839    Objective Loss 0.689839                                        LR 0.000006    Time 0.037828    
2023-01-05 16:40:43,215 - Epoch: [50][   30/   37]    Overall Loss 0.689753    Objective Loss 0.689753                                        LR 0.000006    Time 0.034429    
2023-01-05 16:40:43,407 - Epoch: [50][   37/   37]    Overall Loss 0.689979    Objective Loss 0.689979    Top1 51.255230    LR 0.000006    Time 0.033116    
2023-01-05 16:40:43,476 - --- validate (epoch=50)-----------
2023-01-05 16:40:43,476 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:43,719 - Epoch: [50][    5/    5]    Loss 0.686180    Top1 49.427481    
2023-01-05 16:40:43,779 - ==> Top1: 49.427    Loss: 0.686

2023-01-05 16:40:43,779 - ==> Confusion:
[[394  35   0]
 [495 124   0]
 [  0   0   0]]

2023-01-05 16:40:43,780 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:43,780 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:43,790 - 

2023-01-05 16:40:43,790 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:44,268 - Epoch: [51][   10/   37]    Overall Loss 0.688550    Objective Loss 0.688550                                        LR 0.000006    Time 0.047751    
2023-01-05 16:40:44,573 - Epoch: [51][   20/   37]    Overall Loss 0.689027    Objective Loss 0.689027                                        LR 0.000006    Time 0.039087    
2023-01-05 16:40:44,864 - Epoch: [51][   30/   37]    Overall Loss 0.689494    Objective Loss 0.689494                                        LR 0.000006    Time 0.035740    
2023-01-05 16:40:45,059 - Epoch: [51][   37/   37]    Overall Loss 0.689441    Objective Loss 0.689441    Top1 57.740586    LR 0.000006    Time 0.034244    
2023-01-05 16:40:45,134 - --- validate (epoch=51)-----------
2023-01-05 16:40:45,134 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:45,369 - Epoch: [51][    5/    5]    Loss 0.688624    Top1 59.064885    
2023-01-05 16:40:45,440 - ==> Top1: 59.065    Loss: 0.689

2023-01-05 16:40:45,441 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:40:45,442 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:45,442 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:45,451 - 

2023-01-05 16:40:45,452 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:46,042 - Epoch: [52][   10/   37]    Overall Loss 0.689086    Objective Loss 0.689086                                        LR 0.000006    Time 0.058974    
2023-01-05 16:40:46,321 - Epoch: [52][   20/   37]    Overall Loss 0.688759    Objective Loss 0.688759                                        LR 0.000006    Time 0.043405    
2023-01-05 16:40:46,601 - Epoch: [52][   30/   37]    Overall Loss 0.688618    Objective Loss 0.688618                                        LR 0.000006    Time 0.038259    
2023-01-05 16:40:46,788 - Epoch: [52][   37/   37]    Overall Loss 0.688473    Objective Loss 0.688473    Top1 57.949791    LR 0.000006    Time 0.036068    
2023-01-05 16:40:46,859 - --- validate (epoch=52)-----------
2023-01-05 16:40:46,860 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:47,103 - Epoch: [52][    5/    5]    Loss 0.686606    Top1 59.541985    
2023-01-05 16:40:47,165 - ==> Top1: 59.542    Loss: 0.687

2023-01-05 16:40:47,165 - ==> Confusion:
[[  8 421   0]
 [  3 616   0]
 [  0   0   0]]

2023-01-05 16:40:47,166 - ==> Best [Top1: 60.019   Sparsity:0.00   Params: 361664 on epoch: 19]
2023-01-05 16:40:47,167 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:47,176 - 

2023-01-05 16:40:47,176 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:47,665 - Epoch: [53][   10/   37]    Overall Loss 0.688983    Objective Loss 0.688983                                        LR 0.000006    Time 0.048769    
2023-01-05 16:40:47,973 - Epoch: [53][   20/   37]    Overall Loss 0.688763    Objective Loss 0.688763                                        LR 0.000006    Time 0.039791    
2023-01-05 16:40:48,276 - Epoch: [53][   30/   37]    Overall Loss 0.688681    Objective Loss 0.688681                                        LR 0.000006    Time 0.036605    
2023-01-05 16:40:48,472 - Epoch: [53][   37/   37]    Overall Loss 0.688685    Objective Loss 0.688685    Top1 60.251046    LR 0.000006    Time 0.034956    
2023-01-05 16:40:48,538 - --- validate (epoch=53)-----------
2023-01-05 16:40:48,539 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:48,779 - Epoch: [53][    5/    5]    Loss 0.686900    Top1 60.973282    
2023-01-05 16:40:48,849 - ==> Top1: 60.973    Loss: 0.687

2023-01-05 16:40:48,849 - ==> Confusion:
[[ 74 355   0]
 [ 54 565   0]
 [  0   0   0]]

2023-01-05 16:40:48,850 - ==> Best [Top1: 60.973   Sparsity:0.00   Params: 361664 on epoch: 53]
2023-01-05 16:40:48,850 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:48,881 - 

2023-01-05 16:40:48,881 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:49,377 - Epoch: [54][   10/   37]    Overall Loss 0.687780    Objective Loss 0.687780                                        LR 0.000006    Time 0.049546    
2023-01-05 16:40:49,674 - Epoch: [54][   20/   37]    Overall Loss 0.687783    Objective Loss 0.687783                                        LR 0.000006    Time 0.039585    
2023-01-05 16:40:49,964 - Epoch: [54][   30/   37]    Overall Loss 0.688264    Objective Loss 0.688264                                        LR 0.000006    Time 0.036046    
2023-01-05 16:40:50,157 - Epoch: [54][   37/   37]    Overall Loss 0.688554    Objective Loss 0.688554    Top1 43.514644    LR 0.000006    Time 0.034421    
2023-01-05 16:40:50,232 - --- validate (epoch=54)-----------
2023-01-05 16:40:50,232 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:50,466 - Epoch: [54][    5/    5]    Loss 0.694423    Top1 42.843511    
2023-01-05 16:40:50,529 - ==> Top1: 42.844    Loss: 0.694

2023-01-05 16:40:50,530 - ==> Confusion:
[[422   7   0]
 [592  27   0]
 [  0   0   0]]

2023-01-05 16:40:50,531 - ==> Best [Top1: 60.973   Sparsity:0.00   Params: 361664 on epoch: 53]
2023-01-05 16:40:50,531 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:50,541 - 

2023-01-05 16:40:50,541 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:51,030 - Epoch: [55][   10/   37]    Overall Loss 0.688914    Objective Loss 0.688914                                        LR 0.000006    Time 0.048853    
2023-01-05 16:40:51,336 - Epoch: [55][   20/   37]    Overall Loss 0.688200    Objective Loss 0.688200                                        LR 0.000006    Time 0.039700    
2023-01-05 16:40:51,642 - Epoch: [55][   30/   37]    Overall Loss 0.688297    Objective Loss 0.688297                                        LR 0.000006    Time 0.036647    
2023-01-05 16:40:51,840 - Epoch: [55][   37/   37]    Overall Loss 0.688236    Objective Loss 0.688236    Top1 55.857741    LR 0.000006    Time 0.035074    
2023-01-05 16:40:51,912 - --- validate (epoch=55)-----------
2023-01-05 16:40:51,912 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:52,155 - Epoch: [55][    5/    5]    Loss 0.686386    Top1 57.442748    
2023-01-05 16:40:52,224 - ==> Top1: 57.443    Loss: 0.686

2023-01-05 16:40:52,224 - ==> Confusion:
[[340  89   0]
 [357 262   0]
 [  0   0   0]]

2023-01-05 16:40:52,226 - ==> Best [Top1: 60.973   Sparsity:0.00   Params: 361664 on epoch: 53]
2023-01-05 16:40:52,226 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:52,235 - 

2023-01-05 16:40:52,235 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:52,703 - Epoch: [56][   10/   37]    Overall Loss 0.688227    Objective Loss 0.688227                                        LR 0.000006    Time 0.046688    
2023-01-05 16:40:53,002 - Epoch: [56][   20/   37]    Overall Loss 0.688279    Objective Loss 0.688279                                        LR 0.000006    Time 0.038295    
2023-01-05 16:40:53,304 - Epoch: [56][   30/   37]    Overall Loss 0.687955    Objective Loss 0.687955                                        LR 0.000006    Time 0.035498    
2023-01-05 16:40:53,497 - Epoch: [56][   37/   37]    Overall Loss 0.687851    Objective Loss 0.687851    Top1 57.531381    LR 0.000006    Time 0.034001    
2023-01-05 16:40:53,575 - --- validate (epoch=56)-----------
2023-01-05 16:40:53,575 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:53,812 - Epoch: [56][    5/    5]    Loss 0.687268    Top1 59.351145    
2023-01-05 16:40:53,877 - ==> Top1: 59.351    Loss: 0.687

2023-01-05 16:40:53,877 - ==> Confusion:
[[  3 426   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:40:53,879 - ==> Best [Top1: 60.973   Sparsity:0.00   Params: 361664 on epoch: 53]
2023-01-05 16:40:53,879 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:53,899 - 

2023-01-05 16:40:53,899 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:54,386 - Epoch: [57][   10/   37]    Overall Loss 0.687024    Objective Loss 0.687024                                        LR 0.000006    Time 0.048634    
2023-01-05 16:40:54,686 - Epoch: [57][   20/   37]    Overall Loss 0.688044    Objective Loss 0.688044                                        LR 0.000006    Time 0.039284    
2023-01-05 16:40:54,994 - Epoch: [57][   30/   37]    Overall Loss 0.687870    Objective Loss 0.687870                                        LR 0.000006    Time 0.036443    
2023-01-05 16:40:55,188 - Epoch: [57][   37/   37]    Overall Loss 0.687697    Objective Loss 0.687697    Top1 59.414226    LR 0.000006    Time 0.034787    
2023-01-05 16:40:55,260 - --- validate (epoch=57)-----------
2023-01-05 16:40:55,260 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:55,493 - Epoch: [57][    5/    5]    Loss 0.684678    Top1 59.160305    
2023-01-05 16:40:55,564 - ==> Top1: 59.160    Loss: 0.685

2023-01-05 16:40:55,565 - ==> Confusion:
[[  1 428   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:40:55,566 - ==> Best [Top1: 60.973   Sparsity:0.00   Params: 361664 on epoch: 53]
2023-01-05 16:40:55,566 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:55,576 - 

2023-01-05 16:40:55,576 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:56,070 - Epoch: [58][   10/   37]    Overall Loss 0.688174    Objective Loss 0.688174                                        LR 0.000006    Time 0.049283    
2023-01-05 16:40:56,373 - Epoch: [58][   20/   37]    Overall Loss 0.688175    Objective Loss 0.688175                                        LR 0.000006    Time 0.039775    
2023-01-05 16:40:56,676 - Epoch: [58][   30/   37]    Overall Loss 0.688760    Objective Loss 0.688760                                        LR 0.000006    Time 0.036593    
2023-01-05 16:40:56,872 - Epoch: [58][   37/   37]    Overall Loss 0.688318    Objective Loss 0.688318    Top1 60.878661    LR 0.000006    Time 0.034974    
2023-01-05 16:40:56,946 - --- validate (epoch=58)-----------
2023-01-05 16:40:56,946 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:57,183 - Epoch: [58][    5/    5]    Loss 0.688135    Top1 59.160305    
2023-01-05 16:40:57,241 - ==> Top1: 59.160    Loss: 0.688

2023-01-05 16:40:57,242 - ==> Confusion:
[[346  83   0]
 [345 274   0]
 [  0   0   0]]

2023-01-05 16:40:57,243 - ==> Best [Top1: 60.973   Sparsity:0.00   Params: 361664 on epoch: 53]
2023-01-05 16:40:57,243 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:57,253 - 

2023-01-05 16:40:57,253 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:57,748 - Epoch: [59][   10/   37]    Overall Loss 0.688347    Objective Loss 0.688347                                        LR 0.000006    Time 0.049374    
2023-01-05 16:40:58,042 - Epoch: [59][   20/   37]    Overall Loss 0.688347    Objective Loss 0.688347                                        LR 0.000006    Time 0.039405    
2023-01-05 16:40:58,343 - Epoch: [59][   30/   37]    Overall Loss 0.687909    Objective Loss 0.687909                                        LR 0.000006    Time 0.036270    
2023-01-05 16:40:58,540 - Epoch: [59][   37/   37]    Overall Loss 0.687773    Objective Loss 0.687773    Top1 49.790795    LR 0.000006    Time 0.034730    
2023-01-05 16:40:58,612 - --- validate (epoch=59)-----------
2023-01-05 16:40:58,613 - 1048 samples (256 per mini-batch)
2023-01-05 16:40:58,854 - Epoch: [59][    5/    5]    Loss 0.686636    Top1 44.179389    
2023-01-05 16:40:58,930 - ==> Top1: 44.179    Loss: 0.687

2023-01-05 16:40:58,930 - ==> Confusion:
[[416  13   0]
 [572  47   0]
 [  0   0   0]]

2023-01-05 16:40:58,931 - ==> Best [Top1: 60.973   Sparsity:0.00   Params: 361664 on epoch: 53]
2023-01-05 16:40:58,931 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:40:58,941 - 

2023-01-05 16:40:58,941 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:40:59,435 - Epoch: [60][   10/   37]    Overall Loss 0.688435    Objective Loss 0.688435                                        LR 0.000006    Time 0.049341    
2023-01-05 16:40:59,732 - Epoch: [60][   20/   37]    Overall Loss 0.689173    Objective Loss 0.689173                                        LR 0.000006    Time 0.039483    
2023-01-05 16:41:00,031 - Epoch: [60][   30/   37]    Overall Loss 0.689705    Objective Loss 0.689705                                        LR 0.000006    Time 0.036271    
2023-01-05 16:41:00,226 - Epoch: [60][   37/   37]    Overall Loss 0.689353    Objective Loss 0.689353    Top1 60.041841    LR 0.000006    Time 0.034692    
2023-01-05 16:41:00,301 - --- validate (epoch=60)-----------
2023-01-05 16:41:00,301 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:00,545 - Epoch: [60][    5/    5]    Loss 0.685527    Top1 66.221374    
2023-01-05 16:41:00,620 - ==> Top1: 66.221    Loss: 0.686

2023-01-05 16:41:00,621 - ==> Confusion:
[[182 247   0]
 [107 512   0]
 [  0   0   0]]

2023-01-05 16:41:00,622 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:00,622 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:00,646 - 

2023-01-05 16:41:00,646 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:01,143 - Epoch: [61][   10/   37]    Overall Loss 0.686256    Objective Loss 0.686256                                        LR 0.000006    Time 0.049646    
2023-01-05 16:41:01,447 - Epoch: [61][   20/   37]    Overall Loss 0.686944    Objective Loss 0.686944                                        LR 0.000006    Time 0.039999    
2023-01-05 16:41:01,758 - Epoch: [61][   30/   37]    Overall Loss 0.686879    Objective Loss 0.686879                                        LR 0.000006    Time 0.037017    
2023-01-05 16:41:01,954 - Epoch: [61][   37/   37]    Overall Loss 0.687076    Objective Loss 0.687076    Top1 59.623431    LR 0.000006    Time 0.035301    
2023-01-05 16:41:02,023 - --- validate (epoch=61)-----------
2023-01-05 16:41:02,023 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:02,255 - Epoch: [61][    5/    5]    Loss 0.684455    Top1 65.267176    
2023-01-05 16:41:02,318 - ==> Top1: 65.267    Loss: 0.684

2023-01-05 16:41:02,318 - ==> Confusion:
[[231 198   0]
 [166 453   0]
 [  0   0   0]]

2023-01-05 16:41:02,319 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:02,319 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:02,329 - 

2023-01-05 16:41:02,329 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:02,811 - Epoch: [62][   10/   37]    Overall Loss 0.686019    Objective Loss 0.686019                                        LR 0.000006    Time 0.048119    
2023-01-05 16:41:03,101 - Epoch: [62][   20/   37]    Overall Loss 0.686313    Objective Loss 0.686313                                        LR 0.000006    Time 0.038560    
2023-01-05 16:41:03,413 - Epoch: [62][   30/   37]    Overall Loss 0.686734    Objective Loss 0.686734                                        LR 0.000006    Time 0.036060    
2023-01-05 16:41:03,610 - Epoch: [62][   37/   37]    Overall Loss 0.687305    Objective Loss 0.687305    Top1 57.740586    LR 0.000006    Time 0.034555    
2023-01-05 16:41:03,687 - --- validate (epoch=62)-----------
2023-01-05 16:41:03,688 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:03,920 - Epoch: [62][    5/    5]    Loss 0.691390    Top1 59.064885    
2023-01-05 16:41:03,980 - ==> Top1: 59.065    Loss: 0.691

2023-01-05 16:41:03,980 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:41:03,982 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:03,982 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:03,991 - 

2023-01-05 16:41:03,991 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:04,474 - Epoch: [63][   10/   37]    Overall Loss 0.691966    Objective Loss 0.691966                                        LR 0.000006    Time 0.048162    
2023-01-05 16:41:04,769 - Epoch: [63][   20/   37]    Overall Loss 0.689696    Objective Loss 0.689696                                        LR 0.000006    Time 0.038846    
2023-01-05 16:41:05,065 - Epoch: [63][   30/   37]    Overall Loss 0.688801    Objective Loss 0.688801                                        LR 0.000006    Time 0.035744    
2023-01-05 16:41:05,260 - Epoch: [63][   37/   37]    Overall Loss 0.688670    Objective Loss 0.688670    Top1 51.255230    LR 0.000006    Time 0.034232    
2023-01-05 16:41:05,331 - --- validate (epoch=63)-----------
2023-01-05 16:41:05,332 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:05,573 - Epoch: [63][    5/    5]    Loss 0.688961    Top1 48.187023    
2023-01-05 16:41:05,629 - ==> Top1: 48.187    Loss: 0.689

2023-01-05 16:41:05,629 - ==> Confusion:
[[405  24   0]
 [519 100   0]
 [  0   0   0]]

2023-01-05 16:41:05,631 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:05,631 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:05,652 - 

2023-01-05 16:41:05,652 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:06,154 - Epoch: [64][   10/   37]    Overall Loss 0.686343    Objective Loss 0.686343                                        LR 0.000006    Time 0.050200    
2023-01-05 16:41:06,464 - Epoch: [64][   20/   37]    Overall Loss 0.686797    Objective Loss 0.686797                                        LR 0.000006    Time 0.040527    
2023-01-05 16:41:06,774 - Epoch: [64][   30/   37]    Overall Loss 0.686759    Objective Loss 0.686759                                        LR 0.000006    Time 0.037371    
2023-01-05 16:41:06,970 - Epoch: [64][   37/   37]    Overall Loss 0.686711    Objective Loss 0.686711    Top1 58.158996    LR 0.000006    Time 0.035584    
2023-01-05 16:41:07,045 - --- validate (epoch=64)-----------
2023-01-05 16:41:07,045 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:07,287 - Epoch: [64][    5/    5]    Loss 0.685573    Top1 59.064885    
2023-01-05 16:41:07,361 - ==> Top1: 59.065    Loss: 0.686

2023-01-05 16:41:07,362 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:41:07,363 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:07,363 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:07,373 - 

2023-01-05 16:41:07,373 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:07,841 - Epoch: [65][   10/   37]    Overall Loss 0.686540    Objective Loss 0.686540                                        LR 0.000006    Time 0.046697    
2023-01-05 16:41:08,134 - Epoch: [65][   20/   37]    Overall Loss 0.686700    Objective Loss 0.686700                                        LR 0.000006    Time 0.038006    
2023-01-05 16:41:08,440 - Epoch: [65][   30/   37]    Overall Loss 0.686516    Objective Loss 0.686516                                        LR 0.000006    Time 0.035508    
2023-01-05 16:41:08,635 - Epoch: [65][   37/   37]    Overall Loss 0.686768    Objective Loss 0.686768    Top1 44.142259    LR 0.000006    Time 0.034062    
2023-01-05 16:41:08,715 - --- validate (epoch=65)-----------
2023-01-05 16:41:08,716 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:08,955 - Epoch: [65][    5/    5]    Loss 0.684122    Top1 57.156489    
2023-01-05 16:41:09,022 - ==> Top1: 57.156    Loss: 0.684

2023-01-05 16:41:09,022 - ==> Confusion:
[[368  61   0]
 [388 231   0]
 [  0   0   0]]

2023-01-05 16:41:09,024 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:09,024 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:09,044 - 

2023-01-05 16:41:09,044 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:09,574 - Epoch: [66][   10/   37]    Overall Loss 0.689687    Objective Loss 0.689687                                        LR 0.000006    Time 0.052915    
2023-01-05 16:41:09,884 - Epoch: [66][   20/   37]    Overall Loss 0.688149    Objective Loss 0.688149                                        LR 0.000006    Time 0.041939    
2023-01-05 16:41:10,199 - Epoch: [66][   30/   37]    Overall Loss 0.687772    Objective Loss 0.687772                                        LR 0.000006    Time 0.038332    
2023-01-05 16:41:10,394 - Epoch: [66][   37/   37]    Overall Loss 0.687930    Objective Loss 0.687930    Top1 54.602510    LR 0.000006    Time 0.036354    
2023-01-05 16:41:10,470 - --- validate (epoch=66)-----------
2023-01-05 16:41:10,470 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:10,712 - Epoch: [66][    5/    5]    Loss 0.685254    Top1 59.541985    
2023-01-05 16:41:10,781 - ==> Top1: 59.542    Loss: 0.685

2023-01-05 16:41:10,782 - ==> Confusion:
[[ 14 415   0]
 [  9 610   0]
 [  0   0   0]]

2023-01-05 16:41:10,783 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:10,783 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:10,793 - 

2023-01-05 16:41:10,793 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:11,401 - Epoch: [67][   10/   37]    Overall Loss 0.686368    Objective Loss 0.686368                                        LR 0.000006    Time 0.060727    
2023-01-05 16:41:11,700 - Epoch: [67][   20/   37]    Overall Loss 0.686322    Objective Loss 0.686322                                        LR 0.000006    Time 0.045273    
2023-01-05 16:41:12,002 - Epoch: [67][   30/   37]    Overall Loss 0.686158    Objective Loss 0.686158                                        LR 0.000006    Time 0.040253    
2023-01-05 16:41:12,196 - Epoch: [67][   37/   37]    Overall Loss 0.685942    Objective Loss 0.685942    Top1 60.460251    LR 0.000006    Time 0.037877    
2023-01-05 16:41:12,260 - --- validate (epoch=67)-----------
2023-01-05 16:41:12,261 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:12,497 - Epoch: [67][    5/    5]    Loss 0.688442    Top1 59.064885    
2023-01-05 16:41:12,564 - ==> Top1: 59.065    Loss: 0.688

2023-01-05 16:41:12,565 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-05 16:41:12,566 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:12,566 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:12,575 - 

2023-01-05 16:41:12,576 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:13,081 - Epoch: [68][   10/   37]    Overall Loss 0.689563    Objective Loss 0.689563                                        LR 0.000006    Time 0.050438    
2023-01-05 16:41:13,375 - Epoch: [68][   20/   37]    Overall Loss 0.687546    Objective Loss 0.687546                                        LR 0.000006    Time 0.039912    
2023-01-05 16:41:13,676 - Epoch: [68][   30/   37]    Overall Loss 0.686836    Objective Loss 0.686836                                        LR 0.000006    Time 0.036640    
2023-01-05 16:41:13,871 - Epoch: [68][   37/   37]    Overall Loss 0.686947    Objective Loss 0.686947    Top1 61.924686    LR 0.000006    Time 0.034972    
2023-01-05 16:41:13,936 - --- validate (epoch=68)-----------
2023-01-05 16:41:13,936 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:14,169 - Epoch: [68][    5/    5]    Loss 0.682310    Top1 62.977099    
2023-01-05 16:41:14,234 - ==> Top1: 62.977    Loss: 0.682

2023-01-05 16:41:14,234 - ==> Confusion:
[[111 318   0]
 [ 70 549   0]
 [  0   0   0]]

2023-01-05 16:41:14,236 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:14,236 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:14,256 - 

2023-01-05 16:41:14,257 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:14,740 - Epoch: [69][   10/   37]    Overall Loss 0.685534    Objective Loss 0.685534                                        LR 0.000006    Time 0.048214    
2023-01-05 16:41:15,041 - Epoch: [69][   20/   37]    Overall Loss 0.686041    Objective Loss 0.686041                                        LR 0.000006    Time 0.039173    
2023-01-05 16:41:15,343 - Epoch: [69][   30/   37]    Overall Loss 0.685993    Objective Loss 0.685993                                        LR 0.000006    Time 0.036150    
2023-01-05 16:41:15,537 - Epoch: [69][   37/   37]    Overall Loss 0.686036    Objective Loss 0.686036    Top1 54.602510    LR 0.000006    Time 0.034559    
2023-01-05 16:41:15,624 - --- validate (epoch=69)-----------
2023-01-05 16:41:15,624 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:15,870 - Epoch: [69][    5/    5]    Loss 0.686054    Top1 51.908397    
2023-01-05 16:41:15,932 - ==> Top1: 51.908    Loss: 0.686

2023-01-05 16:41:15,933 - ==> Confusion:
[[391  38   0]
 [466 153   0]
 [  0   0   0]]

2023-01-05 16:41:15,934 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:15,934 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:15,944 - 

2023-01-05 16:41:15,944 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:16,446 - Epoch: [70][   10/   37]    Overall Loss 0.686386    Objective Loss 0.686386                                        LR 0.000004    Time 0.050077    
2023-01-05 16:41:16,750 - Epoch: [70][   20/   37]    Overall Loss 0.685704    Objective Loss 0.685704                                        LR 0.000004    Time 0.040210    
2023-01-05 16:41:17,059 - Epoch: [70][   30/   37]    Overall Loss 0.685377    Objective Loss 0.685377                                        LR 0.000004    Time 0.037092    
2023-01-05 16:41:17,254 - Epoch: [70][   37/   37]    Overall Loss 0.685805    Objective Loss 0.685805    Top1 46.025105    LR 0.000004    Time 0.035336    
2023-01-05 16:41:17,334 - --- validate (epoch=70)-----------
2023-01-05 16:41:17,334 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:17,576 - Epoch: [70][    5/    5]    Loss 0.686696    Top1 48.950382    
2023-01-05 16:41:17,636 - ==> Top1: 48.950    Loss: 0.687

2023-01-05 16:41:17,637 - ==> Confusion:
[[394  35   0]
 [500 119   0]
 [  0   0   0]]

2023-01-05 16:41:17,638 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:17,638 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:17,647 - 

2023-01-05 16:41:17,648 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:18,156 - Epoch: [71][   10/   37]    Overall Loss 0.685880    Objective Loss 0.685880                                        LR 0.000004    Time 0.050759    
2023-01-05 16:41:18,465 - Epoch: [71][   20/   37]    Overall Loss 0.685779    Objective Loss 0.685779                                        LR 0.000004    Time 0.040801    
2023-01-05 16:41:18,770 - Epoch: [71][   30/   37]    Overall Loss 0.685416    Objective Loss 0.685416                                        LR 0.000004    Time 0.037350    
2023-01-05 16:41:18,965 - Epoch: [71][   37/   37]    Overall Loss 0.685564    Objective Loss 0.685564    Top1 43.305439    LR 0.000004    Time 0.035560    
2023-01-05 16:41:19,034 - --- validate (epoch=71)-----------
2023-01-05 16:41:19,034 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:19,278 - Epoch: [71][    5/    5]    Loss 0.686464    Top1 45.706107    
2023-01-05 16:41:19,348 - ==> Top1: 45.706    Loss: 0.686

2023-01-05 16:41:19,348 - ==> Confusion:
[[410  19   0]
 [550  69   0]
 [  0   0   0]]

2023-01-05 16:41:19,350 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:19,350 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:19,369 - 

2023-01-05 16:41:19,370 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:19,898 - Epoch: [72][   10/   37]    Overall Loss 0.685408    Objective Loss 0.685408                                        LR 0.000004    Time 0.052798    
2023-01-05 16:41:20,248 - Epoch: [72][   20/   37]    Overall Loss 0.686136    Objective Loss 0.686136                                        LR 0.000004    Time 0.043856    
2023-01-05 16:41:20,586 - Epoch: [72][   30/   37]    Overall Loss 0.686362    Objective Loss 0.686362                                        LR 0.000004    Time 0.040503    
2023-01-05 16:41:20,808 - Epoch: [72][   37/   37]    Overall Loss 0.686229    Objective Loss 0.686229    Top1 59.205021    LR 0.000004    Time 0.038826    
2023-01-05 16:41:20,882 - --- validate (epoch=72)-----------
2023-01-05 16:41:20,882 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:21,124 - Epoch: [72][    5/    5]    Loss 0.683553    Top1 58.301527    
2023-01-05 16:41:21,196 - ==> Top1: 58.302    Loss: 0.684

2023-01-05 16:41:21,197 - ==> Confusion:
[[344  85   0]
 [352 267   0]
 [  0   0   0]]

2023-01-05 16:41:21,198 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:21,198 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:21,218 - 

2023-01-05 16:41:21,218 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:21,704 - Epoch: [73][   10/   37]    Overall Loss 0.686061    Objective Loss 0.686061                                        LR 0.000004    Time 0.048556    
2023-01-05 16:41:22,010 - Epoch: [73][   20/   37]    Overall Loss 0.685296    Objective Loss 0.685296                                        LR 0.000004    Time 0.039560    
2023-01-05 16:41:22,326 - Epoch: [73][   30/   37]    Overall Loss 0.685364    Objective Loss 0.685364                                        LR 0.000004    Time 0.036781    
2023-01-05 16:41:22,521 - Epoch: [73][   37/   37]    Overall Loss 0.685519    Objective Loss 0.685519    Top1 64.225941    LR 0.000004    Time 0.035099    
2023-01-05 16:41:22,593 - --- validate (epoch=73)-----------
2023-01-05 16:41:22,593 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:22,826 - Epoch: [73][    5/    5]    Loss 0.685888    Top1 62.595420    
2023-01-05 16:41:22,891 - ==> Top1: 62.595    Loss: 0.686

2023-01-05 16:41:22,891 - ==> Confusion:
[[113 316   0]
 [ 76 543   0]
 [  0   0   0]]

2023-01-05 16:41:22,893 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:22,893 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:22,902 - 

2023-01-05 16:41:22,902 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:23,377 - Epoch: [74][   10/   37]    Overall Loss 0.683939    Objective Loss 0.683939                                        LR 0.000004    Time 0.047368    
2023-01-05 16:41:23,669 - Epoch: [74][   20/   37]    Overall Loss 0.684688    Objective Loss 0.684688                                        LR 0.000004    Time 0.038284    
2023-01-05 16:41:23,980 - Epoch: [74][   30/   37]    Overall Loss 0.684778    Objective Loss 0.684778                                        LR 0.000004    Time 0.035863    
2023-01-05 16:41:24,174 - Epoch: [74][   37/   37]    Overall Loss 0.684975    Objective Loss 0.684975    Top1 64.016736    LR 0.000004    Time 0.034329    
2023-01-05 16:41:24,254 - --- validate (epoch=74)-----------
2023-01-05 16:41:24,254 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:24,493 - Epoch: [74][    5/    5]    Loss 0.685442    Top1 63.263359    
2023-01-05 16:41:24,571 - ==> Top1: 63.263    Loss: 0.685

2023-01-05 16:41:24,572 - ==> Confusion:
[[126 303   0]
 [ 82 537   0]
 [  0   0   0]]

2023-01-05 16:41:24,573 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:24,573 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:24,594 - 

2023-01-05 16:41:24,594 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:25,074 - Epoch: [75][   10/   37]    Overall Loss 0.684927    Objective Loss 0.684927                                        LR 0.000004    Time 0.047953    
2023-01-05 16:41:25,372 - Epoch: [75][   20/   37]    Overall Loss 0.685413    Objective Loss 0.685413                                        LR 0.000004    Time 0.038849    
2023-01-05 16:41:25,685 - Epoch: [75][   30/   37]    Overall Loss 0.685454    Objective Loss 0.685454                                        LR 0.000004    Time 0.036327    
2023-01-05 16:41:25,881 - Epoch: [75][   37/   37]    Overall Loss 0.685342    Objective Loss 0.685342    Top1 52.301255    LR 0.000004    Time 0.034733    
2023-01-05 16:41:25,955 - --- validate (epoch=75)-----------
2023-01-05 16:41:25,955 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:26,196 - Epoch: [75][    5/    5]    Loss 0.685478    Top1 58.492366    
2023-01-05 16:41:26,267 - ==> Top1: 58.492    Loss: 0.685

2023-01-05 16:41:26,267 - ==> Confusion:
[[381  48   0]
 [387 232   0]
 [  0   0   0]]

2023-01-05 16:41:26,268 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:26,269 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:26,288 - 

2023-01-05 16:41:26,289 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:26,801 - Epoch: [76][   10/   37]    Overall Loss 0.685840    Objective Loss 0.685840                                        LR 0.000004    Time 0.051146    
2023-01-05 16:41:27,117 - Epoch: [76][   20/   37]    Overall Loss 0.685151    Objective Loss 0.685151                                        LR 0.000004    Time 0.041377    
2023-01-05 16:41:27,425 - Epoch: [76][   30/   37]    Overall Loss 0.685151    Objective Loss 0.685151                                        LR 0.000004    Time 0.037844    
2023-01-05 16:41:27,621 - Epoch: [76][   37/   37]    Overall Loss 0.684743    Objective Loss 0.684743    Top1 54.602510    LR 0.000004    Time 0.035974    
2023-01-05 16:41:27,706 - --- validate (epoch=76)-----------
2023-01-05 16:41:27,707 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:27,942 - Epoch: [76][    5/    5]    Loss 0.690038    Top1 47.423664    
2023-01-05 16:41:28,010 - ==> Top1: 47.424    Loss: 0.690

2023-01-05 16:41:28,011 - ==> Confusion:
[[406  23   0]
 [528  91   0]
 [  0   0   0]]

2023-01-05 16:41:28,012 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:28,012 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:28,022 - 

2023-01-05 16:41:28,022 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:28,505 - Epoch: [77][   10/   37]    Overall Loss 0.686088    Objective Loss 0.686088                                        LR 0.000004    Time 0.048171    
2023-01-05 16:41:28,803 - Epoch: [77][   20/   37]    Overall Loss 0.686099    Objective Loss 0.686099                                        LR 0.000004    Time 0.038972    
2023-01-05 16:41:29,117 - Epoch: [77][   30/   37]    Overall Loss 0.685820    Objective Loss 0.685820                                        LR 0.000004    Time 0.036428    
2023-01-05 16:41:29,312 - Epoch: [77][   37/   37]    Overall Loss 0.685369    Objective Loss 0.685369    Top1 57.531381    LR 0.000004    Time 0.034814    
2023-01-05 16:41:29,378 - --- validate (epoch=77)-----------
2023-01-05 16:41:29,379 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:29,620 - Epoch: [77][    5/    5]    Loss 0.681148    Top1 59.541985    
2023-01-05 16:41:29,690 - ==> Top1: 59.542    Loss: 0.681

2023-01-05 16:41:29,691 - ==> Confusion:
[[358  71   0]
 [353 266   0]
 [  0   0   0]]

2023-01-05 16:41:29,692 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:29,692 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:29,712 - 

2023-01-05 16:41:29,712 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:30,208 - Epoch: [78][   10/   37]    Overall Loss 0.682569    Objective Loss 0.682569                                        LR 0.000004    Time 0.049521    
2023-01-05 16:41:30,498 - Epoch: [78][   20/   37]    Overall Loss 0.683459    Objective Loss 0.683459                                        LR 0.000004    Time 0.039228    
2023-01-05 16:41:30,792 - Epoch: [78][   30/   37]    Overall Loss 0.683999    Objective Loss 0.683999                                        LR 0.000004    Time 0.035932    
2023-01-05 16:41:30,987 - Epoch: [78][   37/   37]    Overall Loss 0.684226    Objective Loss 0.684226    Top1 56.694561    LR 0.000004    Time 0.034405    
2023-01-05 16:41:31,055 - --- validate (epoch=78)-----------
2023-01-05 16:41:31,055 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:31,291 - Epoch: [78][    5/    5]    Loss 0.685005    Top1 53.625954    
2023-01-05 16:41:31,361 - ==> Top1: 53.626    Loss: 0.685

2023-01-05 16:41:31,361 - ==> Confusion:
[[381  48   0]
 [438 181   0]
 [  0   0   0]]

2023-01-05 16:41:31,363 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:31,363 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:31,372 - 

2023-01-05 16:41:31,372 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:31,865 - Epoch: [79][   10/   37]    Overall Loss 0.682500    Objective Loss 0.682500                                        LR 0.000004    Time 0.049214    
2023-01-05 16:41:32,169 - Epoch: [79][   20/   37]    Overall Loss 0.683859    Objective Loss 0.683859                                        LR 0.000004    Time 0.039787    
2023-01-05 16:41:32,465 - Epoch: [79][   30/   37]    Overall Loss 0.684461    Objective Loss 0.684461                                        LR 0.000004    Time 0.036366    
2023-01-05 16:41:32,660 - Epoch: [79][   37/   37]    Overall Loss 0.685072    Objective Loss 0.685072    Top1 55.857741    LR 0.000004    Time 0.034768    
2023-01-05 16:41:32,728 - --- validate (epoch=79)-----------
2023-01-05 16:41:32,728 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:32,969 - Epoch: [79][    5/    5]    Loss 0.683701    Top1 65.458015    
2023-01-05 16:41:33,038 - ==> Top1: 65.458    Loss: 0.684

2023-01-05 16:41:33,039 - ==> Confusion:
[[166 263   0]
 [ 99 520   0]
 [  0   0   0]]

2023-01-05 16:41:33,040 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:33,040 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:33,050 - 

2023-01-05 16:41:33,050 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:33,542 - Epoch: [80][   10/   37]    Overall Loss 0.683729    Objective Loss 0.683729                                        LR 0.000004    Time 0.049157    
2023-01-05 16:41:33,843 - Epoch: [80][   20/   37]    Overall Loss 0.684713    Objective Loss 0.684713                                        LR 0.000004    Time 0.039600    
2023-01-05 16:41:34,146 - Epoch: [80][   30/   37]    Overall Loss 0.684189    Objective Loss 0.684189                                        LR 0.000004    Time 0.036467    
2023-01-05 16:41:34,341 - Epoch: [80][   37/   37]    Overall Loss 0.684220    Objective Loss 0.684220    Top1 60.251046    LR 0.000004    Time 0.034857    
2023-01-05 16:41:34,418 - --- validate (epoch=80)-----------
2023-01-05 16:41:34,419 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:34,654 - Epoch: [80][    5/    5]    Loss 0.684357    Top1 64.599237    
2023-01-05 16:41:34,731 - ==> Top1: 64.599    Loss: 0.684

2023-01-05 16:41:34,731 - ==> Confusion:
[[272 157   0]
 [214 405   0]
 [  0   0   0]]

2023-01-05 16:41:34,733 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:34,733 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:34,753 - 

2023-01-05 16:41:34,753 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:35,242 - Epoch: [81][   10/   37]    Overall Loss 0.684215    Objective Loss 0.684215                                        LR 0.000004    Time 0.048836    
2023-01-05 16:41:35,543 - Epoch: [81][   20/   37]    Overall Loss 0.684257    Objective Loss 0.684257                                        LR 0.000004    Time 0.039456    
2023-01-05 16:41:35,853 - Epoch: [81][   30/   37]    Overall Loss 0.683906    Objective Loss 0.683906                                        LR 0.000004    Time 0.036605    
2023-01-05 16:41:36,049 - Epoch: [81][   37/   37]    Overall Loss 0.684095    Objective Loss 0.684095    Top1 54.602510    LR 0.000004    Time 0.034976    
2023-01-05 16:41:36,127 - --- validate (epoch=81)-----------
2023-01-05 16:41:36,127 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:36,368 - Epoch: [81][    5/    5]    Loss 0.683677    Top1 60.687023    
2023-01-05 16:41:36,437 - ==> Top1: 60.687    Loss: 0.684

2023-01-05 16:41:36,437 - ==> Confusion:
[[ 34 395   0]
 [ 17 602   0]
 [  0   0   0]]

2023-01-05 16:41:36,439 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:36,439 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:36,448 - 

2023-01-05 16:41:36,448 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:36,936 - Epoch: [82][   10/   37]    Overall Loss 0.683857    Objective Loss 0.683857                                        LR 0.000004    Time 0.048709    
2023-01-05 16:41:37,238 - Epoch: [82][   20/   37]    Overall Loss 0.683918    Objective Loss 0.683918                                        LR 0.000004    Time 0.039428    
2023-01-05 16:41:37,541 - Epoch: [82][   30/   37]    Overall Loss 0.683914    Objective Loss 0.683914                                        LR 0.000004    Time 0.036371    
2023-01-05 16:41:37,739 - Epoch: [82][   37/   37]    Overall Loss 0.683818    Objective Loss 0.683818    Top1 62.133891    LR 0.000004    Time 0.034835    
2023-01-05 16:41:37,825 - --- validate (epoch=82)-----------
2023-01-05 16:41:37,825 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:38,074 - Epoch: [82][    5/    5]    Loss 0.682855    Top1 62.595420    
2023-01-05 16:41:38,143 - ==> Top1: 62.595    Loss: 0.683

2023-01-05 16:41:38,143 - ==> Confusion:
[[ 96 333   0]
 [ 59 560   0]
 [  0   0   0]]

2023-01-05 16:41:38,144 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:38,144 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:38,154 - 

2023-01-05 16:41:38,154 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:38,756 - Epoch: [83][   10/   37]    Overall Loss 0.683242    Objective Loss 0.683242                                        LR 0.000004    Time 0.060085    
2023-01-05 16:41:39,051 - Epoch: [83][   20/   37]    Overall Loss 0.683448    Objective Loss 0.683448                                        LR 0.000004    Time 0.044778    
2023-01-05 16:41:39,344 - Epoch: [83][   30/   37]    Overall Loss 0.683472    Objective Loss 0.683472                                        LR 0.000004    Time 0.039627    
2023-01-05 16:41:39,540 - Epoch: [83][   37/   37]    Overall Loss 0.683733    Objective Loss 0.683733    Top1 56.276151    LR 0.000004    Time 0.037407    
2023-01-05 16:41:39,612 - --- validate (epoch=83)-----------
2023-01-05 16:41:39,612 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:39,859 - Epoch: [83][    5/    5]    Loss 0.682080    Top1 64.503817    
2023-01-05 16:41:39,933 - ==> Top1: 64.504    Loss: 0.682

2023-01-05 16:41:39,934 - ==> Confusion:
[[280 149   0]
 [223 396   0]
 [  0   0   0]]

2023-01-05 16:41:39,935 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:39,935 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:39,956 - 

2023-01-05 16:41:39,956 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:40,436 - Epoch: [84][   10/   37]    Overall Loss 0.682942    Objective Loss 0.682942                                        LR 0.000004    Time 0.047974    
2023-01-05 16:41:40,746 - Epoch: [84][   20/   37]    Overall Loss 0.683204    Objective Loss 0.683204                                        LR 0.000004    Time 0.039451    
2023-01-05 16:41:41,060 - Epoch: [84][   30/   37]    Overall Loss 0.683551    Objective Loss 0.683551                                        LR 0.000004    Time 0.036737    
2023-01-05 16:41:41,254 - Epoch: [84][   37/   37]    Overall Loss 0.683507    Objective Loss 0.683507    Top1 53.765690    LR 0.000004    Time 0.035043    
2023-01-05 16:41:41,345 - --- validate (epoch=84)-----------
2023-01-05 16:41:41,345 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:41,583 - Epoch: [84][    5/    5]    Loss 0.684716    Top1 47.709924    
2023-01-05 16:41:41,651 - ==> Top1: 47.710    Loss: 0.685

2023-01-05 16:41:41,651 - ==> Confusion:
[[403  26   0]
 [522  97   0]
 [  0   0   0]]

2023-01-05 16:41:41,652 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:41,652 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:41,662 - 

2023-01-05 16:41:41,662 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:42,172 - Epoch: [85][   10/   37]    Overall Loss 0.684653    Objective Loss 0.684653                                        LR 0.000004    Time 0.050918    
2023-01-05 16:41:42,472 - Epoch: [85][   20/   37]    Overall Loss 0.683425    Objective Loss 0.683425                                        LR 0.000004    Time 0.040465    
2023-01-05 16:41:42,775 - Epoch: [85][   30/   37]    Overall Loss 0.682790    Objective Loss 0.682790                                        LR 0.000004    Time 0.037061    
2023-01-05 16:41:42,971 - Epoch: [85][   37/   37]    Overall Loss 0.682496    Objective Loss 0.682496    Top1 68.619247    LR 0.000004    Time 0.035325    
2023-01-05 16:41:43,055 - --- validate (epoch=85)-----------
2023-01-05 16:41:43,056 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:43,290 - Epoch: [85][    5/    5]    Loss 0.680432    Top1 61.545802    
2023-01-05 16:41:43,351 - ==> Top1: 61.546    Loss: 0.680

2023-01-05 16:41:43,351 - ==> Confusion:
[[315 114   0]
 [289 330   0]
 [  0   0   0]]

2023-01-05 16:41:43,352 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:43,352 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:43,362 - 

2023-01-05 16:41:43,362 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:43,825 - Epoch: [86][   10/   37]    Overall Loss 0.681842    Objective Loss 0.681842                                        LR 0.000004    Time 0.046250    
2023-01-05 16:41:44,117 - Epoch: [86][   20/   37]    Overall Loss 0.681725    Objective Loss 0.681725                                        LR 0.000004    Time 0.037685    
2023-01-05 16:41:44,406 - Epoch: [86][   30/   37]    Overall Loss 0.682292    Objective Loss 0.682292                                        LR 0.000004    Time 0.034764    
2023-01-05 16:41:44,601 - Epoch: [86][   37/   37]    Overall Loss 0.682076    Objective Loss 0.682076    Top1 53.347280    LR 0.000004    Time 0.033448    
2023-01-05 16:41:44,680 - --- validate (epoch=86)-----------
2023-01-05 16:41:44,681 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:44,925 - Epoch: [86][    5/    5]    Loss 0.685729    Top1 48.377863    
2023-01-05 16:41:44,991 - ==> Top1: 48.378    Loss: 0.686

2023-01-05 16:41:44,992 - ==> Confusion:
[[400  29   0]
 [512 107   0]
 [  0   0   0]]

2023-01-05 16:41:44,993 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:44,993 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:45,013 - 

2023-01-05 16:41:45,013 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:45,503 - Epoch: [87][   10/   37]    Overall Loss 0.681947    Objective Loss 0.681947                                        LR 0.000004    Time 0.048850    
2023-01-05 16:41:45,785 - Epoch: [87][   20/   37]    Overall Loss 0.682439    Objective Loss 0.682439                                        LR 0.000004    Time 0.038538    
2023-01-05 16:41:46,079 - Epoch: [87][   30/   37]    Overall Loss 0.682445    Objective Loss 0.682445                                        LR 0.000004    Time 0.035455    
2023-01-05 16:41:46,266 - Epoch: [87][   37/   37]    Overall Loss 0.682542    Objective Loss 0.682542    Top1 60.460251    LR 0.000004    Time 0.033792    
2023-01-05 16:41:46,337 - --- validate (epoch=87)-----------
2023-01-05 16:41:46,337 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:46,568 - Epoch: [87][    5/    5]    Loss 0.682202    Top1 59.160305    
2023-01-05 16:41:46,632 - ==> Top1: 59.160    Loss: 0.682

2023-01-05 16:41:46,633 - ==> Confusion:
[[363  66   0]
 [362 257   0]
 [  0   0   0]]

2023-01-05 16:41:46,634 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:46,634 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:46,654 - 

2023-01-05 16:41:46,654 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:47,156 - Epoch: [88][   10/   37]    Overall Loss 0.681629    Objective Loss 0.681629                                        LR 0.000004    Time 0.050080    
2023-01-05 16:41:47,461 - Epoch: [88][   20/   37]    Overall Loss 0.681680    Objective Loss 0.681680                                        LR 0.000004    Time 0.040260    
2023-01-05 16:41:47,766 - Epoch: [88][   30/   37]    Overall Loss 0.681268    Objective Loss 0.681268                                        LR 0.000004    Time 0.036987    
2023-01-05 16:41:47,961 - Epoch: [88][   37/   37]    Overall Loss 0.681355    Objective Loss 0.681355    Top1 59.623431    LR 0.000004    Time 0.035265    
2023-01-05 16:41:48,029 - --- validate (epoch=88)-----------
2023-01-05 16:41:48,030 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:48,264 - Epoch: [88][    5/    5]    Loss 0.680660    Top1 64.217557    
2023-01-05 16:41:48,334 - ==> Top1: 64.218    Loss: 0.681

2023-01-05 16:41:48,335 - ==> Confusion:
[[298 131   0]
 [244 375   0]
 [  0   0   0]]

2023-01-05 16:41:48,336 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:48,336 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:48,346 - 

2023-01-05 16:41:48,346 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:48,843 - Epoch: [89][   10/   37]    Overall Loss 0.681679    Objective Loss 0.681679                                        LR 0.000004    Time 0.049620    
2023-01-05 16:41:49,136 - Epoch: [89][   20/   37]    Overall Loss 0.681483    Objective Loss 0.681483                                        LR 0.000004    Time 0.039456    
2023-01-05 16:41:49,440 - Epoch: [89][   30/   37]    Overall Loss 0.681188    Objective Loss 0.681188                                        LR 0.000004    Time 0.036409    
2023-01-05 16:41:49,635 - Epoch: [89][   37/   37]    Overall Loss 0.681565    Objective Loss 0.681565    Top1 60.878661    LR 0.000004    Time 0.034803    
2023-01-05 16:41:49,704 - --- validate (epoch=89)-----------
2023-01-05 16:41:49,704 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:49,936 - Epoch: [89][    5/    5]    Loss 0.684759    Top1 63.549618    
2023-01-05 16:41:49,992 - ==> Top1: 63.550    Loss: 0.685

2023-01-05 16:41:49,993 - ==> Confusion:
[[309 120   0]
 [262 357   0]
 [  0   0   0]]

2023-01-05 16:41:49,994 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:49,994 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:50,015 - 

2023-01-05 16:41:50,015 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:50,524 - Epoch: [90][   10/   37]    Overall Loss 0.681957    Objective Loss 0.681957                                        LR 0.000004    Time 0.050776    
2023-01-05 16:41:50,828 - Epoch: [90][   20/   37]    Overall Loss 0.680632    Objective Loss 0.680632                                        LR 0.000004    Time 0.040572    
2023-01-05 16:41:51,136 - Epoch: [90][   30/   37]    Overall Loss 0.681122    Objective Loss 0.681122                                        LR 0.000004    Time 0.037296    
2023-01-05 16:41:51,330 - Epoch: [90][   37/   37]    Overall Loss 0.681492    Objective Loss 0.681492    Top1 54.811715    LR 0.000004    Time 0.035490    
2023-01-05 16:41:51,404 - --- validate (epoch=90)-----------
2023-01-05 16:41:51,404 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:51,639 - Epoch: [90][    5/    5]    Loss 0.682299    Top1 54.293893    
2023-01-05 16:41:51,708 - ==> Top1: 54.294    Loss: 0.682

2023-01-05 16:41:51,708 - ==> Confusion:
[[381  48   0]
 [431 188   0]
 [  0   0   0]]

2023-01-05 16:41:51,710 - ==> Best [Top1: 66.221   Sparsity:0.00   Params: 361664 on epoch: 60]
2023-01-05 16:41:51,710 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:51,730 - 

2023-01-05 16:41:51,730 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:52,253 - Epoch: [91][   10/   37]    Overall Loss 0.680506    Objective Loss 0.680506                                        LR 0.000004    Time 0.052250    
2023-01-05 16:41:52,550 - Epoch: [91][   20/   37]    Overall Loss 0.681401    Objective Loss 0.681401                                        LR 0.000004    Time 0.040957    
2023-01-05 16:41:52,847 - Epoch: [91][   30/   37]    Overall Loss 0.681143    Objective Loss 0.681143                                        LR 0.000004    Time 0.037202    
2023-01-05 16:41:53,042 - Epoch: [91][   37/   37]    Overall Loss 0.680978    Objective Loss 0.680978    Top1 56.694561    LR 0.000004    Time 0.035421    
2023-01-05 16:41:53,116 - --- validate (epoch=91)-----------
2023-01-05 16:41:53,116 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:53,366 - Epoch: [91][    5/    5]    Loss 0.679771    Top1 66.603053    
2023-01-05 16:41:53,434 - ==> Top1: 66.603    Loss: 0.680

2023-01-05 16:41:53,434 - ==> Confusion:
[[314 115   0]
 [235 384   0]
 [  0   0   0]]

2023-01-05 16:41:53,436 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:41:53,436 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:53,459 - 

2023-01-05 16:41:53,459 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:53,981 - Epoch: [92][   10/   37]    Overall Loss 0.680929    Objective Loss 0.680929                                        LR 0.000004    Time 0.052109    
2023-01-05 16:41:54,296 - Epoch: [92][   20/   37]    Overall Loss 0.680041    Objective Loss 0.680041                                        LR 0.000004    Time 0.041776    
2023-01-05 16:41:54,604 - Epoch: [92][   30/   37]    Overall Loss 0.680152    Objective Loss 0.680152                                        LR 0.000004    Time 0.038098    
2023-01-05 16:41:54,799 - Epoch: [92][   37/   37]    Overall Loss 0.680189    Objective Loss 0.680189    Top1 58.368201    LR 0.000004    Time 0.036155    
2023-01-05 16:41:54,878 - --- validate (epoch=92)-----------
2023-01-05 16:41:54,878 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:55,113 - Epoch: [92][    5/    5]    Loss 0.680071    Top1 54.484733    
2023-01-05 16:41:55,183 - ==> Top1: 54.485    Loss: 0.680

2023-01-05 16:41:55,183 - ==> Confusion:
[[385  44   0]
 [433 186   0]
 [  0   0   0]]

2023-01-05 16:41:55,185 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:41:55,185 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:55,194 - 

2023-01-05 16:41:55,194 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:55,682 - Epoch: [93][   10/   37]    Overall Loss 0.681000    Objective Loss 0.681000                                        LR 0.000004    Time 0.048680    
2023-01-05 16:41:55,977 - Epoch: [93][   20/   37]    Overall Loss 0.681050    Objective Loss 0.681050                                        LR 0.000004    Time 0.039093    
2023-01-05 16:41:56,289 - Epoch: [93][   30/   37]    Overall Loss 0.680405    Objective Loss 0.680405                                        LR 0.000004    Time 0.036454    
2023-01-05 16:41:56,485 - Epoch: [93][   37/   37]    Overall Loss 0.679696    Objective Loss 0.679696    Top1 61.087866    LR 0.000004    Time 0.034824    
2023-01-05 16:41:56,555 - --- validate (epoch=93)-----------
2023-01-05 16:41:56,555 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:56,800 - Epoch: [93][    5/    5]    Loss 0.683452    Top1 55.629771    
2023-01-05 16:41:56,859 - ==> Top1: 55.630    Loss: 0.683

2023-01-05 16:41:56,859 - ==> Confusion:
[[384  45   0]
 [420 199   0]
 [  0   0   0]]

2023-01-05 16:41:56,861 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:41:56,861 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:56,881 - 

2023-01-05 16:41:56,881 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:57,376 - Epoch: [94][   10/   37]    Overall Loss 0.680402    Objective Loss 0.680402                                        LR 0.000004    Time 0.049396    
2023-01-05 16:41:57,684 - Epoch: [94][   20/   37]    Overall Loss 0.680137    Objective Loss 0.680137                                        LR 0.000004    Time 0.040109    
2023-01-05 16:41:57,988 - Epoch: [94][   30/   37]    Overall Loss 0.680374    Objective Loss 0.680374                                        LR 0.000004    Time 0.036856    
2023-01-05 16:41:58,184 - Epoch: [94][   37/   37]    Overall Loss 0.680309    Objective Loss 0.680309    Top1 55.439331    LR 0.000004    Time 0.035154    
2023-01-05 16:41:58,264 - --- validate (epoch=94)-----------
2023-01-05 16:41:58,264 - 1048 samples (256 per mini-batch)
2023-01-05 16:41:58,510 - Epoch: [94][    5/    5]    Loss 0.680260    Top1 60.400763    
2023-01-05 16:41:58,573 - ==> Top1: 60.401    Loss: 0.680

2023-01-05 16:41:58,574 - ==> Confusion:
[[ 30 399   0]
 [ 16 603   0]
 [  0   0   0]]

2023-01-05 16:41:58,575 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:41:58,575 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:41:58,585 - 

2023-01-05 16:41:58,585 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:41:59,058 - Epoch: [95][   10/   37]    Overall Loss 0.679448    Objective Loss 0.679448                                        LR 0.000004    Time 0.047249    
2023-01-05 16:41:59,354 - Epoch: [95][   20/   37]    Overall Loss 0.678492    Objective Loss 0.678492                                        LR 0.000004    Time 0.038406    
2023-01-05 16:41:59,652 - Epoch: [95][   30/   37]    Overall Loss 0.679507    Objective Loss 0.679507                                        LR 0.000004    Time 0.035519    
2023-01-05 16:41:59,848 - Epoch: [95][   37/   37]    Overall Loss 0.679468    Objective Loss 0.679468    Top1 65.062762    LR 0.000004    Time 0.034092    
2023-01-05 16:41:59,916 - --- validate (epoch=95)-----------
2023-01-05 16:41:59,917 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:00,157 - Epoch: [95][    5/    5]    Loss 0.678151    Top1 63.454198    
2023-01-05 16:42:00,225 - ==> Top1: 63.454    Loss: 0.678

2023-01-05 16:42:00,225 - ==> Confusion:
[[ 96 333   0]
 [ 50 569   0]
 [  0   0   0]]

2023-01-05 16:42:00,227 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:00,227 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:00,236 - 

2023-01-05 16:42:00,236 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:00,729 - Epoch: [96][   10/   37]    Overall Loss 0.678769    Objective Loss 0.678769                                        LR 0.000004    Time 0.049204    
2023-01-05 16:42:01,034 - Epoch: [96][   20/   37]    Overall Loss 0.679316    Objective Loss 0.679316                                        LR 0.000004    Time 0.039810    
2023-01-05 16:42:01,329 - Epoch: [96][   30/   37]    Overall Loss 0.679447    Objective Loss 0.679447                                        LR 0.000004    Time 0.036284    
2023-01-05 16:42:01,526 - Epoch: [96][   37/   37]    Overall Loss 0.679148    Objective Loss 0.679148    Top1 57.531381    LR 0.000004    Time 0.034718    
2023-01-05 16:42:01,597 - --- validate (epoch=96)-----------
2023-01-05 16:42:01,597 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:01,838 - Epoch: [96][    5/    5]    Loss 0.689881    Top1 47.996183    
2023-01-05 16:42:01,904 - ==> Top1: 47.996    Loss: 0.690

2023-01-05 16:42:01,904 - ==> Confusion:
[[403  26   0]
 [519 100   0]
 [  0   0   0]]

2023-01-05 16:42:01,905 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:01,906 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:01,925 - 

2023-01-05 16:42:01,926 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:02,532 - Epoch: [97][   10/   37]    Overall Loss 0.681320    Objective Loss 0.681320                                        LR 0.000004    Time 0.060542    
2023-01-05 16:42:02,821 - Epoch: [97][   20/   37]    Overall Loss 0.679860    Objective Loss 0.679860                                        LR 0.000004    Time 0.044732    
2023-01-05 16:42:03,105 - Epoch: [97][   30/   37]    Overall Loss 0.679321    Objective Loss 0.679321                                        LR 0.000004    Time 0.039272    
2023-01-05 16:42:03,297 - Epoch: [97][   37/   37]    Overall Loss 0.679404    Objective Loss 0.679404    Top1 64.016736    LR 0.000004    Time 0.037023    
2023-01-05 16:42:03,369 - --- validate (epoch=97)-----------
2023-01-05 16:42:03,369 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:03,605 - Epoch: [97][    5/    5]    Loss 0.678706    Top1 65.171756    
2023-01-05 16:42:03,668 - ==> Top1: 65.172    Loss: 0.679

2023-01-05 16:42:03,668 - ==> Confusion:
[[238 191   0]
 [174 445   0]
 [  0   0   0]]

2023-01-05 16:42:03,670 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:03,670 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:03,679 - 

2023-01-05 16:42:03,680 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:04,165 - Epoch: [98][   10/   37]    Overall Loss 0.678904    Objective Loss 0.678904                                        LR 0.000004    Time 0.048424    
2023-01-05 16:42:04,466 - Epoch: [98][   20/   37]    Overall Loss 0.679255    Objective Loss 0.679255                                        LR 0.000004    Time 0.039249    
2023-01-05 16:42:04,757 - Epoch: [98][   30/   37]    Overall Loss 0.679188    Objective Loss 0.679188                                        LR 0.000004    Time 0.035845    
2023-01-05 16:42:04,952 - Epoch: [98][   37/   37]    Overall Loss 0.679610    Objective Loss 0.679610    Top1 65.899582    LR 0.000004    Time 0.034350    
2023-01-05 16:42:05,019 - --- validate (epoch=98)-----------
2023-01-05 16:42:05,019 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:05,262 - Epoch: [98][    5/    5]    Loss 0.679923    Top1 58.969466    
2023-01-05 16:42:05,327 - ==> Top1: 58.969    Loss: 0.680

2023-01-05 16:42:05,327 - ==> Confusion:
[[363  66   0]
 [364 255   0]
 [  0   0   0]]

2023-01-05 16:42:05,329 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:05,329 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:05,339 - 

2023-01-05 16:42:05,339 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:05,830 - Epoch: [99][   10/   37]    Overall Loss 0.678383    Objective Loss 0.678383                                        LR 0.000004    Time 0.048970    
2023-01-05 16:42:06,128 - Epoch: [99][   20/   37]    Overall Loss 0.678003    Objective Loss 0.678003                                        LR 0.000004    Time 0.039386    
2023-01-05 16:42:06,422 - Epoch: [99][   30/   37]    Overall Loss 0.678304    Objective Loss 0.678304                                        LR 0.000004    Time 0.036049    
2023-01-05 16:42:06,609 - Epoch: [99][   37/   37]    Overall Loss 0.678597    Objective Loss 0.678597    Top1 51.255230    LR 0.000004    Time 0.034278    
2023-01-05 16:42:06,694 - --- validate (epoch=99)-----------
2023-01-05 16:42:06,694 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:06,935 - Epoch: [99][    5/    5]    Loss 0.681754    Top1 50.763359    
2023-01-05 16:42:06,997 - ==> Top1: 50.763    Loss: 0.682

2023-01-05 16:42:06,997 - ==> Confusion:
[[396  33   0]
 [483 136   0]
 [  0   0   0]]

2023-01-05 16:42:06,999 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:06,999 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:07,008 - 

2023-01-05 16:42:07,008 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:07,518 - Epoch: [100][   10/   37]    Overall Loss 0.678514    Objective Loss 0.678514                                        LR 0.000002    Time 0.050839    
2023-01-05 16:42:07,819 - Epoch: [100][   20/   37]    Overall Loss 0.678251    Objective Loss 0.678251                                        LR 0.000002    Time 0.040444    
2023-01-05 16:42:08,125 - Epoch: [100][   30/   37]    Overall Loss 0.678667    Objective Loss 0.678667                                        LR 0.000002    Time 0.037152    
2023-01-05 16:42:08,315 - Epoch: [100][   37/   37]    Overall Loss 0.678363    Objective Loss 0.678363    Top1 61.087866    LR 0.000002    Time 0.035265    
2023-01-05 16:42:08,406 - --- validate (epoch=100)-----------
2023-01-05 16:42:08,406 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:08,645 - Epoch: [100][    5/    5]    Loss 0.679101    Top1 66.125954    
2023-01-05 16:42:08,710 - ==> Top1: 66.126    Loss: 0.679

2023-01-05 16:42:08,711 - ==> Confusion:
[[233 196   0]
 [159 460   0]
 [  0   0   0]]

2023-01-05 16:42:08,712 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:08,712 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:08,722 - 

2023-01-05 16:42:08,722 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:09,195 - Epoch: [101][   10/   37]    Overall Loss 0.678210    Objective Loss 0.678210                                        LR 0.000002    Time 0.047236    
2023-01-05 16:42:09,493 - Epoch: [101][   20/   37]    Overall Loss 0.678427    Objective Loss 0.678427                                        LR 0.000002    Time 0.038492    
2023-01-05 16:42:09,775 - Epoch: [101][   30/   37]    Overall Loss 0.677660    Objective Loss 0.677660                                        LR 0.000002    Time 0.035059    
2023-01-05 16:42:09,963 - Epoch: [101][   37/   37]    Overall Loss 0.678023    Objective Loss 0.678023    Top1 57.112971    LR 0.000002    Time 0.033500    
2023-01-05 16:42:10,040 - --- validate (epoch=101)-----------
2023-01-05 16:42:10,040 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:10,284 - Epoch: [101][    5/    5]    Loss 0.677307    Top1 59.351145    
2023-01-05 16:42:10,342 - ==> Top1: 59.351    Loss: 0.677

2023-01-05 16:42:10,343 - ==> Confusion:
[[355  74   0]
 [352 267   0]
 [  0   0   0]]

2023-01-05 16:42:10,344 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:10,344 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:10,364 - 

2023-01-05 16:42:10,364 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:10,851 - Epoch: [102][   10/   37]    Overall Loss 0.677665    Objective Loss 0.677665                                        LR 0.000002    Time 0.048583    
2023-01-05 16:42:11,152 - Epoch: [102][   20/   37]    Overall Loss 0.678129    Objective Loss 0.678129                                        LR 0.000002    Time 0.039357    
2023-01-05 16:42:11,441 - Epoch: [102][   30/   37]    Overall Loss 0.678240    Objective Loss 0.678240                                        LR 0.000002    Time 0.035840    
2023-01-05 16:42:11,634 - Epoch: [102][   37/   37]    Overall Loss 0.677946    Objective Loss 0.677946    Top1 63.389121    LR 0.000002    Time 0.034269    
2023-01-05 16:42:11,705 - --- validate (epoch=102)-----------
2023-01-05 16:42:11,705 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:11,945 - Epoch: [102][    5/    5]    Loss 0.678297    Top1 62.118321    
2023-01-05 16:42:12,004 - ==> Top1: 62.118    Loss: 0.678

2023-01-05 16:42:12,004 - ==> Confusion:
[[336  93   0]
 [304 315   0]
 [  0   0   0]]

2023-01-05 16:42:12,005 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:12,005 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:12,015 - 

2023-01-05 16:42:12,015 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:12,523 - Epoch: [103][   10/   37]    Overall Loss 0.678318    Objective Loss 0.678318                                        LR 0.000002    Time 0.050767    
2023-01-05 16:42:12,813 - Epoch: [103][   20/   37]    Overall Loss 0.678111    Objective Loss 0.678111                                        LR 0.000002    Time 0.039844    
2023-01-05 16:42:13,119 - Epoch: [103][   30/   37]    Overall Loss 0.677845    Objective Loss 0.677845                                        LR 0.000002    Time 0.036758    
2023-01-05 16:42:13,310 - Epoch: [103][   37/   37]    Overall Loss 0.677544    Objective Loss 0.677544    Top1 59.832636    LR 0.000002    Time 0.034946    
2023-01-05 16:42:13,382 - --- validate (epoch=103)-----------
2023-01-05 16:42:13,383 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:13,618 - Epoch: [103][    5/    5]    Loss 0.677549    Top1 58.587786    
2023-01-05 16:42:13,680 - ==> Top1: 58.588    Loss: 0.678

2023-01-05 16:42:13,680 - ==> Confusion:
[[373  56   0]
 [378 241   0]
 [  0   0   0]]

2023-01-05 16:42:13,682 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:13,682 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:13,691 - 

2023-01-05 16:42:13,691 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:14,168 - Epoch: [104][   10/   37]    Overall Loss 0.678013    Objective Loss 0.678013                                        LR 0.000002    Time 0.047594    
2023-01-05 16:42:14,457 - Epoch: [104][   20/   37]    Overall Loss 0.677557    Objective Loss 0.677557                                        LR 0.000002    Time 0.038202    
2023-01-05 16:42:14,750 - Epoch: [104][   30/   37]    Overall Loss 0.677308    Objective Loss 0.677308                                        LR 0.000002    Time 0.035225    
2023-01-05 16:42:14,941 - Epoch: [104][   37/   37]    Overall Loss 0.677124    Objective Loss 0.677124    Top1 62.970711    LR 0.000002    Time 0.033722    
2023-01-05 16:42:15,016 - --- validate (epoch=104)-----------
2023-01-05 16:42:15,016 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:15,258 - Epoch: [104][    5/    5]    Loss 0.673910    Top1 65.744275    
2023-01-05 16:42:15,323 - ==> Top1: 65.744    Loss: 0.674

2023-01-05 16:42:15,323 - ==> Confusion:
[[267 162   0]
 [197 422   0]
 [  0   0   0]]

2023-01-05 16:42:15,324 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:15,325 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:15,334 - 

2023-01-05 16:42:15,334 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:15,818 - Epoch: [105][   10/   37]    Overall Loss 0.676779    Objective Loss 0.676779                                        LR 0.000002    Time 0.048294    
2023-01-05 16:42:16,118 - Epoch: [105][   20/   37]    Overall Loss 0.676926    Objective Loss 0.676926                                        LR 0.000002    Time 0.039149    
2023-01-05 16:42:16,418 - Epoch: [105][   30/   37]    Overall Loss 0.677437    Objective Loss 0.677437                                        LR 0.000002    Time 0.036066    
2023-01-05 16:42:16,607 - Epoch: [105][   37/   37]    Overall Loss 0.677303    Objective Loss 0.677303    Top1 55.857741    LR 0.000002    Time 0.034351    
2023-01-05 16:42:16,690 - --- validate (epoch=105)-----------
2023-01-05 16:42:16,690 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:16,937 - Epoch: [105][    5/    5]    Loss 0.676968    Top1 48.854962    
2023-01-05 16:42:17,009 - ==> Top1: 48.855    Loss: 0.677

2023-01-05 16:42:17,009 - ==> Confusion:
[[396  33   0]
 [503 116   0]
 [  0   0   0]]

2023-01-05 16:42:17,011 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:17,011 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:17,020 - 

2023-01-05 16:42:17,020 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:17,499 - Epoch: [106][   10/   37]    Overall Loss 0.676687    Objective Loss 0.676687                                        LR 0.000002    Time 0.047792    
2023-01-05 16:42:17,779 - Epoch: [106][   20/   37]    Overall Loss 0.677561    Objective Loss 0.677561                                        LR 0.000002    Time 0.037869    
2023-01-05 16:42:18,082 - Epoch: [106][   30/   37]    Overall Loss 0.677416    Objective Loss 0.677416                                        LR 0.000002    Time 0.035345    
2023-01-05 16:42:18,282 - Epoch: [106][   37/   37]    Overall Loss 0.677326    Objective Loss 0.677326    Top1 58.995816    LR 0.000002    Time 0.034042    
2023-01-05 16:42:18,352 - --- validate (epoch=106)-----------
2023-01-05 16:42:18,353 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:18,597 - Epoch: [106][    5/    5]    Loss 0.676883    Top1 61.354962    
2023-01-05 16:42:18,664 - ==> Top1: 61.355    Loss: 0.677

2023-01-05 16:42:18,664 - ==> Confusion:
[[351  78   0]
 [327 292   0]
 [  0   0   0]]

2023-01-05 16:42:18,666 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:18,666 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:18,675 - 

2023-01-05 16:42:18,675 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:19,167 - Epoch: [107][   10/   37]    Overall Loss 0.676748    Objective Loss 0.676748                                        LR 0.000002    Time 0.049106    
2023-01-05 16:42:19,475 - Epoch: [107][   20/   37]    Overall Loss 0.677866    Objective Loss 0.677866                                        LR 0.000002    Time 0.039906    
2023-01-05 16:42:19,781 - Epoch: [107][   30/   37]    Overall Loss 0.676876    Objective Loss 0.676876                                        LR 0.000002    Time 0.036793    
2023-01-05 16:42:19,978 - Epoch: [107][   37/   37]    Overall Loss 0.676858    Objective Loss 0.676858    Top1 57.949791    LR 0.000002    Time 0.035151    
2023-01-05 16:42:20,056 - --- validate (epoch=107)-----------
2023-01-05 16:42:20,056 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:20,296 - Epoch: [107][    5/    5]    Loss 0.678719    Top1 59.351145    
2023-01-05 16:42:20,372 - ==> Top1: 59.351    Loss: 0.679

2023-01-05 16:42:20,372 - ==> Confusion:
[[356  73   0]
 [353 266   0]
 [  0   0   0]]

2023-01-05 16:42:20,374 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:20,374 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:20,383 - 

2023-01-05 16:42:20,383 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:20,868 - Epoch: [108][   10/   37]    Overall Loss 0.676287    Objective Loss 0.676287                                        LR 0.000002    Time 0.048442    
2023-01-05 16:42:21,167 - Epoch: [108][   20/   37]    Overall Loss 0.677527    Objective Loss 0.677527                                        LR 0.000002    Time 0.039136    
2023-01-05 16:42:21,466 - Epoch: [108][   30/   37]    Overall Loss 0.677175    Objective Loss 0.677175                                        LR 0.000002    Time 0.036046    
2023-01-05 16:42:21,661 - Epoch: [108][   37/   37]    Overall Loss 0.676260    Objective Loss 0.676260    Top1 67.154812    LR 0.000002    Time 0.034481    
2023-01-05 16:42:21,736 - --- validate (epoch=108)-----------
2023-01-05 16:42:21,737 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:21,977 - Epoch: [108][    5/    5]    Loss 0.677148    Top1 66.412214    
2023-01-05 16:42:22,046 - ==> Top1: 66.412    Loss: 0.677

2023-01-05 16:42:22,046 - ==> Confusion:
[[295 134   0]
 [218 401   0]
 [  0   0   0]]

2023-01-05 16:42:22,048 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:22,048 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:22,058 - 

2023-01-05 16:42:22,058 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:22,548 - Epoch: [109][   10/   37]    Overall Loss 0.677937    Objective Loss 0.677937                                        LR 0.000002    Time 0.048981    
2023-01-05 16:42:22,852 - Epoch: [109][   20/   37]    Overall Loss 0.676164    Objective Loss 0.676164                                        LR 0.000002    Time 0.039661    
2023-01-05 16:42:23,156 - Epoch: [109][   30/   37]    Overall Loss 0.676327    Objective Loss 0.676327                                        LR 0.000002    Time 0.036561    
2023-01-05 16:42:23,352 - Epoch: [109][   37/   37]    Overall Loss 0.676841    Objective Loss 0.676841    Top1 56.485356    LR 0.000002    Time 0.034928    
2023-01-05 16:42:23,425 - --- validate (epoch=109)-----------
2023-01-05 16:42:23,425 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:23,672 - Epoch: [109][    5/    5]    Loss 0.680795    Top1 54.484733    
2023-01-05 16:42:23,736 - ==> Top1: 54.485    Loss: 0.681

2023-01-05 16:42:23,736 - ==> Confusion:
[[385  44   0]
 [433 186   0]
 [  0   0   0]]

2023-01-05 16:42:23,738 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:23,738 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:23,747 - 

2023-01-05 16:42:23,747 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:24,251 - Epoch: [110][   10/   37]    Overall Loss 0.676824    Objective Loss 0.676824                                        LR 0.000002    Time 0.050274    
2023-01-05 16:42:24,557 - Epoch: [110][   20/   37]    Overall Loss 0.677572    Objective Loss 0.677572                                        LR 0.000002    Time 0.040438    
2023-01-05 16:42:24,843 - Epoch: [110][   30/   37]    Overall Loss 0.676716    Objective Loss 0.676716                                        LR 0.000002    Time 0.036474    
2023-01-05 16:42:25,037 - Epoch: [110][   37/   37]    Overall Loss 0.676366    Objective Loss 0.676366    Top1 59.623431    LR 0.000002    Time 0.034796    
2023-01-05 16:42:25,116 - --- validate (epoch=110)-----------
2023-01-05 16:42:25,117 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:25,351 - Epoch: [110][    5/    5]    Loss 0.680771    Top1 60.877863    
2023-01-05 16:42:25,409 - ==> Top1: 60.878    Loss: 0.681

2023-01-05 16:42:25,409 - ==> Confusion:
[[356  73   0]
 [337 282   0]
 [  0   0   0]]

2023-01-05 16:42:25,410 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:25,411 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:25,420 - 

2023-01-05 16:42:25,420 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:25,906 - Epoch: [111][   10/   37]    Overall Loss 0.674717    Objective Loss 0.674717                                        LR 0.000002    Time 0.048473    
2023-01-05 16:42:26,211 - Epoch: [111][   20/   37]    Overall Loss 0.675484    Objective Loss 0.675484                                        LR 0.000002    Time 0.039486    
2023-01-05 16:42:26,517 - Epoch: [111][   30/   37]    Overall Loss 0.676320    Objective Loss 0.676320                                        LR 0.000002    Time 0.036494    
2023-01-05 16:42:26,707 - Epoch: [111][   37/   37]    Overall Loss 0.676288    Objective Loss 0.676288    Top1 61.506276    LR 0.000002    Time 0.034723    
2023-01-05 16:42:26,778 - --- validate (epoch=111)-----------
2023-01-05 16:42:26,778 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:27,021 - Epoch: [111][    5/    5]    Loss 0.681111    Top1 53.721374    
2023-01-05 16:42:27,080 - ==> Top1: 53.721    Loss: 0.681

2023-01-05 16:42:27,080 - ==> Confusion:
[[386  43   0]
 [442 177   0]
 [  0   0   0]]

2023-01-05 16:42:27,081 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:27,082 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:27,092 - 

2023-01-05 16:42:27,092 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:27,699 - Epoch: [112][   10/   37]    Overall Loss 0.678352    Objective Loss 0.678352                                        LR 0.000002    Time 0.060689    
2023-01-05 16:42:27,994 - Epoch: [112][   20/   37]    Overall Loss 0.677974    Objective Loss 0.677974                                        LR 0.000002    Time 0.045071    
2023-01-05 16:42:28,296 - Epoch: [112][   30/   37]    Overall Loss 0.677341    Objective Loss 0.677341                                        LR 0.000002    Time 0.040088    
2023-01-05 16:42:28,495 - Epoch: [112][   37/   37]    Overall Loss 0.676562    Objective Loss 0.676562    Top1 59.623431    LR 0.000002    Time 0.037876    
2023-01-05 16:42:28,569 - --- validate (epoch=112)-----------
2023-01-05 16:42:28,570 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:28,808 - Epoch: [112][    5/    5]    Loss 0.684698    Top1 56.870229    
2023-01-05 16:42:28,876 - ==> Top1: 56.870    Loss: 0.685

2023-01-05 16:42:28,877 - ==> Confusion:
[[384  45   0]
 [407 212   0]
 [  0   0   0]]

2023-01-05 16:42:28,878 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:28,878 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:28,889 - 

2023-01-05 16:42:28,889 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:29,366 - Epoch: [113][   10/   37]    Overall Loss 0.675883    Objective Loss 0.675883                                        LR 0.000002    Time 0.047574    
2023-01-05 16:42:29,673 - Epoch: [113][   20/   37]    Overall Loss 0.675337    Objective Loss 0.675337                                        LR 0.000002    Time 0.039110    
2023-01-05 16:42:29,972 - Epoch: [113][   30/   37]    Overall Loss 0.675887    Objective Loss 0.675887                                        LR 0.000002    Time 0.036033    
2023-01-05 16:42:30,162 - Epoch: [113][   37/   37]    Overall Loss 0.676506    Objective Loss 0.676506    Top1 59.623431    LR 0.000002    Time 0.034357    
2023-01-05 16:42:30,247 - --- validate (epoch=113)-----------
2023-01-05 16:42:30,248 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:30,492 - Epoch: [113][    5/    5]    Loss 0.678344    Top1 59.732824    
2023-01-05 16:42:30,556 - ==> Top1: 59.733    Loss: 0.678

2023-01-05 16:42:30,556 - ==> Confusion:
[[369  60   0]
 [362 257   0]
 [  0   0   0]]

2023-01-05 16:42:30,557 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:30,557 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:30,578 - 

2023-01-05 16:42:30,578 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:31,047 - Epoch: [114][   10/   37]    Overall Loss 0.675146    Objective Loss 0.675146                                        LR 0.000002    Time 0.046745    
2023-01-05 16:42:31,337 - Epoch: [114][   20/   37]    Overall Loss 0.675294    Objective Loss 0.675294                                        LR 0.000002    Time 0.037883    
2023-01-05 16:42:31,631 - Epoch: [114][   30/   37]    Overall Loss 0.675774    Objective Loss 0.675774                                        LR 0.000002    Time 0.035051    
2023-01-05 16:42:31,828 - Epoch: [114][   37/   37]    Overall Loss 0.675896    Objective Loss 0.675896    Top1 61.715481    LR 0.000002    Time 0.033724    
2023-01-05 16:42:31,901 - --- validate (epoch=114)-----------
2023-01-05 16:42:31,901 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:32,142 - Epoch: [114][    5/    5]    Loss 0.676037    Top1 60.305344    
2023-01-05 16:42:32,202 - ==> Top1: 60.305    Loss: 0.676

2023-01-05 16:42:32,202 - ==> Confusion:
[[351  78   0]
 [338 281   0]
 [  0   0   0]]

2023-01-05 16:42:32,204 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:32,204 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:32,213 - 

2023-01-05 16:42:32,214 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:32,691 - Epoch: [115][   10/   37]    Overall Loss 0.675647    Objective Loss 0.675647                                        LR 0.000002    Time 0.047663    
2023-01-05 16:42:32,991 - Epoch: [115][   20/   37]    Overall Loss 0.675012    Objective Loss 0.675012                                        LR 0.000002    Time 0.038658    
2023-01-05 16:42:33,280 - Epoch: [115][   30/   37]    Overall Loss 0.676026    Objective Loss 0.676026                                        LR 0.000002    Time 0.035383    
2023-01-05 16:42:33,476 - Epoch: [115][   37/   37]    Overall Loss 0.675919    Objective Loss 0.675919    Top1 51.673640    LR 0.000002    Time 0.033964    
2023-01-05 16:42:33,554 - --- validate (epoch=115)-----------
2023-01-05 16:42:33,554 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:33,796 - Epoch: [115][    5/    5]    Loss 0.679853    Top1 49.522901    
2023-01-05 16:42:33,864 - ==> Top1: 49.523    Loss: 0.680

2023-01-05 16:42:33,864 - ==> Confusion:
[[398  31   0]
 [498 121   0]
 [  0   0   0]]

2023-01-05 16:42:33,866 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:33,866 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:33,875 - 

2023-01-05 16:42:33,875 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:34,384 - Epoch: [116][   10/   37]    Overall Loss 0.678270    Objective Loss 0.678270                                        LR 0.000002    Time 0.050731    
2023-01-05 16:42:34,706 - Epoch: [116][   20/   37]    Overall Loss 0.677414    Objective Loss 0.677414                                        LR 0.000002    Time 0.041459    
2023-01-05 16:42:35,022 - Epoch: [116][   30/   37]    Overall Loss 0.676166    Objective Loss 0.676166                                        LR 0.000002    Time 0.038168    
2023-01-05 16:42:35,218 - Epoch: [116][   37/   37]    Overall Loss 0.676229    Objective Loss 0.676229    Top1 57.740586    LR 0.000002    Time 0.036228    
2023-01-05 16:42:35,291 - --- validate (epoch=116)-----------
2023-01-05 16:42:35,292 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:35,534 - Epoch: [116][    5/    5]    Loss 0.678234    Top1 53.816794    
2023-01-05 16:42:35,602 - ==> Top1: 53.817    Loss: 0.678

2023-01-05 16:42:35,602 - ==> Confusion:
[[388  41   0]
 [443 176   0]
 [  0   0   0]]

2023-01-05 16:42:35,604 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:35,604 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:35,614 - 

2023-01-05 16:42:35,614 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:36,093 - Epoch: [117][   10/   37]    Overall Loss 0.675859    Objective Loss 0.675859                                        LR 0.000002    Time 0.047842    
2023-01-05 16:42:36,388 - Epoch: [117][   20/   37]    Overall Loss 0.676680    Objective Loss 0.676680                                        LR 0.000002    Time 0.038641    
2023-01-05 16:42:36,687 - Epoch: [117][   30/   37]    Overall Loss 0.675929    Objective Loss 0.675929                                        LR 0.000002    Time 0.035720    
2023-01-05 16:42:36,882 - Epoch: [117][   37/   37]    Overall Loss 0.675644    Objective Loss 0.675644    Top1 59.832636    LR 0.000002    Time 0.034212    
2023-01-05 16:42:36,954 - --- validate (epoch=117)-----------
2023-01-05 16:42:36,954 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:37,191 - Epoch: [117][    5/    5]    Loss 0.676632    Top1 58.587786    
2023-01-05 16:42:37,265 - ==> Top1: 58.588    Loss: 0.677

2023-01-05 16:42:37,265 - ==> Confusion:
[[373  56   0]
 [378 241   0]
 [  0   0   0]]

2023-01-05 16:42:37,267 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:37,267 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:37,277 - 

2023-01-05 16:42:37,277 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:37,764 - Epoch: [118][   10/   37]    Overall Loss 0.674957    Objective Loss 0.674957                                        LR 0.000002    Time 0.048671    
2023-01-05 16:42:38,082 - Epoch: [118][   20/   37]    Overall Loss 0.675154    Objective Loss 0.675154                                        LR 0.000002    Time 0.040216    
2023-01-05 16:42:38,390 - Epoch: [118][   30/   37]    Overall Loss 0.675322    Objective Loss 0.675322                                        LR 0.000002    Time 0.037054    
2023-01-05 16:42:38,586 - Epoch: [118][   37/   37]    Overall Loss 0.676012    Objective Loss 0.676012    Top1 52.301255    LR 0.000002    Time 0.035341    
2023-01-05 16:42:38,662 - --- validate (epoch=118)-----------
2023-01-05 16:42:38,662 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:38,897 - Epoch: [118][    5/    5]    Loss 0.679248    Top1 59.923664    
2023-01-05 16:42:38,963 - ==> Top1: 59.924    Loss: 0.679

2023-01-05 16:42:38,963 - ==> Confusion:
[[357  72   0]
 [348 271   0]
 [  0   0   0]]

2023-01-05 16:42:38,965 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:38,965 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:38,975 - 

2023-01-05 16:42:38,975 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:39,465 - Epoch: [119][   10/   37]    Overall Loss 0.674005    Objective Loss 0.674005                                        LR 0.000002    Time 0.048944    
2023-01-05 16:42:39,768 - Epoch: [119][   20/   37]    Overall Loss 0.674725    Objective Loss 0.674725                                        LR 0.000002    Time 0.039621    
2023-01-05 16:42:40,074 - Epoch: [119][   30/   37]    Overall Loss 0.675187    Objective Loss 0.675187                                        LR 0.000002    Time 0.036591    
2023-01-05 16:42:40,273 - Epoch: [119][   37/   37]    Overall Loss 0.675272    Objective Loss 0.675272    Top1 63.807531    LR 0.000002    Time 0.035025    
2023-01-05 16:42:40,346 - --- validate (epoch=119)-----------
2023-01-05 16:42:40,346 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:40,581 - Epoch: [119][    5/    5]    Loss 0.674991    Top1 60.973282    
2023-01-05 16:42:40,662 - ==> Top1: 60.973    Loss: 0.675

2023-01-05 16:42:40,662 - ==> Confusion:
[[ 52 377   0]
 [ 32 587   0]
 [  0   0   0]]

2023-01-05 16:42:40,664 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:40,664 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:40,683 - 

2023-01-05 16:42:40,684 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:41,165 - Epoch: [120][   10/   37]    Overall Loss 0.676362    Objective Loss 0.676362                                        LR 0.000002    Time 0.048016    
2023-01-05 16:42:41,451 - Epoch: [120][   20/   37]    Overall Loss 0.675332    Objective Loss 0.675332                                        LR 0.000002    Time 0.038315    
2023-01-05 16:42:41,746 - Epoch: [120][   30/   37]    Overall Loss 0.675606    Objective Loss 0.675606                                        LR 0.000002    Time 0.035338    
2023-01-05 16:42:41,941 - Epoch: [120][   37/   37]    Overall Loss 0.675622    Objective Loss 0.675622    Top1 68.619247    LR 0.000002    Time 0.033938    
2023-01-05 16:42:42,004 - --- validate (epoch=120)-----------
2023-01-05 16:42:42,005 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:42,245 - Epoch: [120][    5/    5]    Loss 0.678519    Top1 64.217557    
2023-01-05 16:42:42,312 - ==> Top1: 64.218    Loss: 0.679

2023-01-05 16:42:42,312 - ==> Confusion:
[[312 117   0]
 [258 361   0]
 [  0   0   0]]

2023-01-05 16:42:42,314 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:42,314 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:42,323 - 

2023-01-05 16:42:42,324 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:42,817 - Epoch: [121][   10/   37]    Overall Loss 0.673541    Objective Loss 0.673541                                        LR 0.000002    Time 0.049243    
2023-01-05 16:42:43,129 - Epoch: [121][   20/   37]    Overall Loss 0.675392    Objective Loss 0.675392                                        LR 0.000002    Time 0.040230    
2023-01-05 16:42:43,443 - Epoch: [121][   30/   37]    Overall Loss 0.675580    Objective Loss 0.675580                                        LR 0.000002    Time 0.037258    
2023-01-05 16:42:43,641 - Epoch: [121][   37/   37]    Overall Loss 0.675079    Objective Loss 0.675079    Top1 60.878661    LR 0.000002    Time 0.035546    
2023-01-05 16:42:43,711 - --- validate (epoch=121)-----------
2023-01-05 16:42:43,711 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:43,944 - Epoch: [121][    5/    5]    Loss 0.672934    Top1 59.637405    
2023-01-05 16:42:44,001 - ==> Top1: 59.637    Loss: 0.673

2023-01-05 16:42:44,001 - ==> Confusion:
[[358  71   0]
 [352 267   0]
 [  0   0   0]]

2023-01-05 16:42:44,002 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:44,002 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:44,012 - 

2023-01-05 16:42:44,012 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:44,495 - Epoch: [122][   10/   37]    Overall Loss 0.675166    Objective Loss 0.675166                                        LR 0.000002    Time 0.048195    
2023-01-05 16:42:44,788 - Epoch: [122][   20/   37]    Overall Loss 0.674977    Objective Loss 0.674977                                        LR 0.000002    Time 0.038725    
2023-01-05 16:42:45,070 - Epoch: [122][   30/   37]    Overall Loss 0.675151    Objective Loss 0.675151                                        LR 0.000002    Time 0.035126    
2023-01-05 16:42:45,261 - Epoch: [122][   37/   37]    Overall Loss 0.675091    Objective Loss 0.675091    Top1 55.648536    LR 0.000002    Time 0.033655    
2023-01-05 16:42:45,335 - --- validate (epoch=122)-----------
2023-01-05 16:42:45,335 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:45,570 - Epoch: [122][    5/    5]    Loss 0.675982    Top1 56.011450    
2023-01-05 16:42:45,633 - ==> Top1: 56.011    Loss: 0.676

2023-01-05 16:42:45,633 - ==> Confusion:
[[387  42   0]
 [419 200   0]
 [  0   0   0]]

2023-01-05 16:42:45,634 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:45,635 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:45,644 - 

2023-01-05 16:42:45,644 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:46,156 - Epoch: [123][   10/   37]    Overall Loss 0.675643    Objective Loss 0.675643                                        LR 0.000002    Time 0.051127    
2023-01-05 16:42:46,453 - Epoch: [123][   20/   37]    Overall Loss 0.675873    Objective Loss 0.675873                                        LR 0.000002    Time 0.040349    
2023-01-05 16:42:46,740 - Epoch: [123][   30/   37]    Overall Loss 0.675204    Objective Loss 0.675204                                        LR 0.000002    Time 0.036462    
2023-01-05 16:42:46,929 - Epoch: [123][   37/   37]    Overall Loss 0.674923    Objective Loss 0.674923    Top1 57.949791    LR 0.000002    Time 0.034671    
2023-01-05 16:42:47,000 - --- validate (epoch=123)-----------
2023-01-05 16:42:47,000 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:47,238 - Epoch: [123][    5/    5]    Loss 0.679049    Top1 54.007634    
2023-01-05 16:42:47,302 - ==> Top1: 54.008    Loss: 0.679

2023-01-05 16:42:47,302 - ==> Confusion:
[[386  43   0]
 [439 180   0]
 [  0   0   0]]

2023-01-05 16:42:47,304 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:47,304 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:47,313 - 

2023-01-05 16:42:47,313 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:47,801 - Epoch: [124][   10/   37]    Overall Loss 0.672785    Objective Loss 0.672785                                        LR 0.000002    Time 0.048703    
2023-01-05 16:42:48,092 - Epoch: [124][   20/   37]    Overall Loss 0.673683    Objective Loss 0.673683                                        LR 0.000002    Time 0.038861    
2023-01-05 16:42:48,390 - Epoch: [124][   30/   37]    Overall Loss 0.675040    Objective Loss 0.675040                                        LR 0.000002    Time 0.035836    
2023-01-05 16:42:48,581 - Epoch: [124][   37/   37]    Overall Loss 0.674796    Objective Loss 0.674796    Top1 60.669456    LR 0.000002    Time 0.034215    
2023-01-05 16:42:48,651 - --- validate (epoch=124)-----------
2023-01-05 16:42:48,652 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:48,888 - Epoch: [124][    5/    5]    Loss 0.677256    Top1 57.347328    
2023-01-05 16:42:48,957 - ==> Top1: 57.347    Loss: 0.677

2023-01-05 16:42:48,958 - ==> Confusion:
[[379  50   0]
 [397 222   0]
 [  0   0   0]]

2023-01-05 16:42:48,959 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:48,959 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:48,969 - 

2023-01-05 16:42:48,969 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:49,455 - Epoch: [125][   10/   37]    Overall Loss 0.675602    Objective Loss 0.675602                                        LR 0.000002    Time 0.048556    
2023-01-05 16:42:49,757 - Epoch: [125][   20/   37]    Overall Loss 0.675563    Objective Loss 0.675563                                        LR 0.000002    Time 0.039336    
2023-01-05 16:42:50,052 - Epoch: [125][   30/   37]    Overall Loss 0.675210    Objective Loss 0.675210                                        LR 0.000002    Time 0.036070    
2023-01-05 16:42:50,244 - Epoch: [125][   37/   37]    Overall Loss 0.674911    Objective Loss 0.674911    Top1 55.648536    LR 0.000002    Time 0.034412    
2023-01-05 16:42:50,330 - --- validate (epoch=125)-----------
2023-01-05 16:42:50,331 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:50,567 - Epoch: [125][    5/    5]    Loss 0.674955    Top1 56.679389    
2023-01-05 16:42:50,629 - ==> Top1: 56.679    Loss: 0.675

2023-01-05 16:42:50,629 - ==> Confusion:
[[382  47   0]
 [407 212   0]
 [  0   0   0]]

2023-01-05 16:42:50,631 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:50,631 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:50,651 - 

2023-01-05 16:42:50,651 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:51,119 - Epoch: [126][   10/   37]    Overall Loss 0.674030    Objective Loss 0.674030                                        LR 0.000002    Time 0.046704    
2023-01-05 16:42:51,396 - Epoch: [126][   20/   37]    Overall Loss 0.675106    Objective Loss 0.675106                                        LR 0.000002    Time 0.037163    
2023-01-05 16:42:51,681 - Epoch: [126][   30/   37]    Overall Loss 0.674520    Objective Loss 0.674520                                        LR 0.000002    Time 0.034268    
2023-01-05 16:42:51,882 - Epoch: [126][   37/   37]    Overall Loss 0.674565    Objective Loss 0.674565    Top1 54.602510    LR 0.000002    Time 0.033208    
2023-01-05 16:42:51,966 - --- validate (epoch=126)-----------
2023-01-05 16:42:51,967 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:52,211 - Epoch: [126][    5/    5]    Loss 0.670550    Top1 55.725191    
2023-01-05 16:42:52,271 - ==> Top1: 55.725    Loss: 0.671

2023-01-05 16:42:52,271 - ==> Confusion:
[[382  47   0]
 [417 202   0]
 [  0   0   0]]

2023-01-05 16:42:52,273 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:52,273 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:52,282 - 

2023-01-05 16:42:52,282 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:52,759 - Epoch: [127][   10/   37]    Overall Loss 0.675596    Objective Loss 0.675596                                        LR 0.000002    Time 0.047602    
2023-01-05 16:42:53,053 - Epoch: [127][   20/   37]    Overall Loss 0.675906    Objective Loss 0.675906                                        LR 0.000002    Time 0.038479    
2023-01-05 16:42:53,345 - Epoch: [127][   30/   37]    Overall Loss 0.674702    Objective Loss 0.674702                                        LR 0.000002    Time 0.035373    
2023-01-05 16:42:53,541 - Epoch: [127][   37/   37]    Overall Loss 0.674803    Objective Loss 0.674803    Top1 63.179916    LR 0.000002    Time 0.033965    
2023-01-05 16:42:53,595 - --- validate (epoch=127)-----------
2023-01-05 16:42:53,595 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:53,834 - Epoch: [127][    5/    5]    Loss 0.675459    Top1 62.022901    
2023-01-05 16:42:53,905 - ==> Top1: 62.023    Loss: 0.675

2023-01-05 16:42:53,906 - ==> Confusion:
[[339  90   0]
 [308 311   0]
 [  0   0   0]]

2023-01-05 16:42:53,907 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:53,907 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:53,924 - 

2023-01-05 16:42:53,924 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:54,439 - Epoch: [128][   10/   37]    Overall Loss 0.674740    Objective Loss 0.674740                                        LR 0.000002    Time 0.051346    
2023-01-05 16:42:54,734 - Epoch: [128][   20/   37]    Overall Loss 0.674794    Objective Loss 0.674794                                        LR 0.000002    Time 0.040413    
2023-01-05 16:42:55,036 - Epoch: [128][   30/   37]    Overall Loss 0.674644    Objective Loss 0.674644                                        LR 0.000002    Time 0.036988    
2023-01-05 16:42:55,231 - Epoch: [128][   37/   37]    Overall Loss 0.673941    Objective Loss 0.673941    Top1 62.133891    LR 0.000002    Time 0.035276    
2023-01-05 16:42:55,296 - --- validate (epoch=128)-----------
2023-01-05 16:42:55,296 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:55,538 - Epoch: [128][    5/    5]    Loss 0.675215    Top1 59.637405    
2023-01-05 16:42:55,600 - ==> Top1: 59.637    Loss: 0.675

2023-01-05 16:42:55,600 - ==> Confusion:
[[369  60   0]
 [363 256   0]
 [  0   0   0]]

2023-01-05 16:42:55,602 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:55,602 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:55,611 - 

2023-01-05 16:42:55,611 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:56,216 - Epoch: [129][   10/   37]    Overall Loss 0.675127    Objective Loss 0.675127                                        LR 0.000002    Time 0.060397    
2023-01-05 16:42:56,508 - Epoch: [129][   20/   37]    Overall Loss 0.675474    Objective Loss 0.675474                                        LR 0.000002    Time 0.044779    
2023-01-05 16:42:56,813 - Epoch: [129][   30/   37]    Overall Loss 0.674720    Objective Loss 0.674720                                        LR 0.000002    Time 0.040001    
2023-01-05 16:42:57,009 - Epoch: [129][   37/   37]    Overall Loss 0.674431    Objective Loss 0.674431    Top1 57.740586    LR 0.000002    Time 0.037722    
2023-01-05 16:42:57,083 - --- validate (epoch=129)-----------
2023-01-05 16:42:57,083 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:57,329 - Epoch: [129][    5/    5]    Loss 0.681394    Top1 55.916031    
2023-01-05 16:42:57,399 - ==> Top1: 55.916    Loss: 0.681

2023-01-05 16:42:57,399 - ==> Confusion:
[[384  45   0]
 [417 202   0]
 [  0   0   0]]

2023-01-05 16:42:57,401 - ==> Best [Top1: 66.603   Sparsity:0.00   Params: 361664 on epoch: 91]
2023-01-05 16:42:57,401 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:57,410 - 

2023-01-05 16:42:57,410 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:57,888 - Epoch: [130][   10/   37]    Overall Loss 0.674427    Objective Loss 0.674427                                        LR 0.000002    Time 0.047659    
2023-01-05 16:42:58,177 - Epoch: [130][   20/   37]    Overall Loss 0.673519    Objective Loss 0.673519                                        LR 0.000002    Time 0.038284    
2023-01-05 16:42:58,481 - Epoch: [130][   30/   37]    Overall Loss 0.674390    Objective Loss 0.674390                                        LR 0.000002    Time 0.035628    
2023-01-05 16:42:58,678 - Epoch: [130][   37/   37]    Overall Loss 0.674012    Objective Loss 0.674012    Top1 67.782427    LR 0.000002    Time 0.034218    
2023-01-05 16:42:58,763 - --- validate (epoch=130)-----------
2023-01-05 16:42:58,764 - 1048 samples (256 per mini-batch)
2023-01-05 16:42:59,020 - Epoch: [130][    5/    5]    Loss 0.672887    Top1 66.698473    
2023-01-05 16:42:59,087 - ==> Top1: 66.698    Loss: 0.673

2023-01-05 16:42:59,088 - ==> Confusion:
[[280 149   0]
 [200 419   0]
 [  0   0   0]]

2023-01-05 16:42:59,089 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:42:59,089 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:42:59,114 - 

2023-01-05 16:42:59,114 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:42:59,584 - Epoch: [131][   10/   37]    Overall Loss 0.673564    Objective Loss 0.673564                                        LR 0.000002    Time 0.046921    
2023-01-05 16:42:59,891 - Epoch: [131][   20/   37]    Overall Loss 0.673991    Objective Loss 0.673991                                        LR 0.000002    Time 0.038642    
2023-01-05 16:43:00,181 - Epoch: [131][   30/   37]    Overall Loss 0.674045    Objective Loss 0.674045                                        LR 0.000002    Time 0.035419    
2023-01-05 16:43:00,372 - Epoch: [131][   37/   37]    Overall Loss 0.674128    Objective Loss 0.674128    Top1 63.389121    LR 0.000002    Time 0.033851    
2023-01-05 16:43:00,444 - --- validate (epoch=131)-----------
2023-01-05 16:43:00,444 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:00,687 - Epoch: [131][    5/    5]    Loss 0.674860    Top1 64.312977    
2023-01-05 16:43:00,752 - ==> Top1: 64.313    Loss: 0.675

2023-01-05 16:43:00,752 - ==> Confusion:
[[315 114   0]
 [260 359   0]
 [  0   0   0]]

2023-01-05 16:43:00,754 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:00,754 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:00,764 - 

2023-01-05 16:43:00,764 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:01,258 - Epoch: [132][   10/   37]    Overall Loss 0.673656    Objective Loss 0.673656                                        LR 0.000002    Time 0.049372    
2023-01-05 16:43:01,558 - Epoch: [132][   20/   37]    Overall Loss 0.673349    Objective Loss 0.673349                                        LR 0.000002    Time 0.039657    
2023-01-05 16:43:01,853 - Epoch: [132][   30/   37]    Overall Loss 0.674346    Objective Loss 0.674346                                        LR 0.000002    Time 0.036247    
2023-01-05 16:43:02,047 - Epoch: [132][   37/   37]    Overall Loss 0.673962    Objective Loss 0.673962    Top1 63.179916    LR 0.000002    Time 0.034633    
2023-01-05 16:43:02,115 - --- validate (epoch=132)-----------
2023-01-05 16:43:02,115 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:02,357 - Epoch: [132][    5/    5]    Loss 0.674896    Top1 59.064885    
2023-01-05 16:43:02,424 - ==> Top1: 59.065    Loss: 0.675

2023-01-05 16:43:02,425 - ==> Confusion:
[[360  69   0]
 [360 259   0]
 [  0   0   0]]

2023-01-05 16:43:02,426 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:02,426 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:02,436 - 

2023-01-05 16:43:02,436 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:02,943 - Epoch: [133][   10/   37]    Overall Loss 0.672649    Objective Loss 0.672649                                        LR 0.000002    Time 0.050642    
2023-01-05 16:43:03,232 - Epoch: [133][   20/   37]    Overall Loss 0.673790    Objective Loss 0.673790                                        LR 0.000002    Time 0.039722    
2023-01-05 16:43:03,518 - Epoch: [133][   30/   37]    Overall Loss 0.674218    Objective Loss 0.674218                                        LR 0.000002    Time 0.036023    
2023-01-05 16:43:03,706 - Epoch: [133][   37/   37]    Overall Loss 0.674124    Objective Loss 0.674124    Top1 64.016736    LR 0.000002    Time 0.034276    
2023-01-05 16:43:03,784 - --- validate (epoch=133)-----------
2023-01-05 16:43:03,784 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:04,026 - Epoch: [133][    5/    5]    Loss 0.676323    Top1 63.454198    
2023-01-05 16:43:04,092 - ==> Top1: 63.454    Loss: 0.676

2023-01-05 16:43:04,092 - ==> Confusion:
[[332  97   0]
 [286 333   0]
 [  0   0   0]]

2023-01-05 16:43:04,094 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:04,094 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:04,107 - 

2023-01-05 16:43:04,107 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:04,609 - Epoch: [134][   10/   37]    Overall Loss 0.674390    Objective Loss 0.674390                                        LR 0.000002    Time 0.050145    
2023-01-05 16:43:04,917 - Epoch: [134][   20/   37]    Overall Loss 0.674172    Objective Loss 0.674172                                        LR 0.000002    Time 0.040445    
2023-01-05 16:43:05,225 - Epoch: [134][   30/   37]    Overall Loss 0.673478    Objective Loss 0.673478                                        LR 0.000002    Time 0.037195    
2023-01-05 16:43:05,420 - Epoch: [134][   37/   37]    Overall Loss 0.673794    Objective Loss 0.673794    Top1 58.995816    LR 0.000002    Time 0.035424    
2023-01-05 16:43:05,494 - --- validate (epoch=134)-----------
2023-01-05 16:43:05,494 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:05,740 - Epoch: [134][    5/    5]    Loss 0.669866    Top1 60.591603    
2023-01-05 16:43:05,803 - ==> Top1: 60.592    Loss: 0.670

2023-01-05 16:43:05,804 - ==> Confusion:
[[349  80   0]
 [333 286   0]
 [  0   0   0]]

2023-01-05 16:43:05,805 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:05,805 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:05,815 - 

2023-01-05 16:43:05,815 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:06,289 - Epoch: [135][   10/   37]    Overall Loss 0.675749    Objective Loss 0.675749                                        LR 0.000002    Time 0.047276    
2023-01-05 16:43:06,572 - Epoch: [135][   20/   37]    Overall Loss 0.674123    Objective Loss 0.674123                                        LR 0.000002    Time 0.037797    
2023-01-05 16:43:06,863 - Epoch: [135][   30/   37]    Overall Loss 0.673999    Objective Loss 0.673999                                        LR 0.000002    Time 0.034867    
2023-01-05 16:43:07,050 - Epoch: [135][   37/   37]    Overall Loss 0.674466    Objective Loss 0.674466    Top1 57.322176    LR 0.000002    Time 0.033338    
2023-01-05 16:43:07,125 - --- validate (epoch=135)-----------
2023-01-05 16:43:07,125 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:07,368 - Epoch: [135][    5/    5]    Loss 0.677024    Top1 60.400763    
2023-01-05 16:43:07,448 - ==> Top1: 60.401    Loss: 0.677

2023-01-05 16:43:07,448 - ==> Confusion:
[[ 40 389   0]
 [ 26 593   0]
 [  0   0   0]]

2023-01-05 16:43:07,450 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:07,450 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:07,459 - 

2023-01-05 16:43:07,460 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:07,953 - Epoch: [136][   10/   37]    Overall Loss 0.674737    Objective Loss 0.674737                                        LR 0.000002    Time 0.049286    
2023-01-05 16:43:08,252 - Epoch: [136][   20/   37]    Overall Loss 0.674523    Objective Loss 0.674523                                        LR 0.000002    Time 0.039573    
2023-01-05 16:43:08,532 - Epoch: [136][   30/   37]    Overall Loss 0.673623    Objective Loss 0.673623                                        LR 0.000002    Time 0.035694    
2023-01-05 16:43:08,720 - Epoch: [136][   37/   37]    Overall Loss 0.673613    Objective Loss 0.673613    Top1 59.832636    LR 0.000002    Time 0.034025    
2023-01-05 16:43:08,801 - --- validate (epoch=136)-----------
2023-01-05 16:43:08,801 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:09,035 - Epoch: [136][    5/    5]    Loss 0.673074    Top1 58.778626    
2023-01-05 16:43:09,112 - ==> Top1: 58.779    Loss: 0.673

2023-01-05 16:43:09,113 - ==> Confusion:
[[366  63   0]
 [369 250   0]
 [  0   0   0]]

2023-01-05 16:43:09,114 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:09,114 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:09,124 - 

2023-01-05 16:43:09,125 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:09,601 - Epoch: [137][   10/   37]    Overall Loss 0.673914    Objective Loss 0.673914                                        LR 0.000002    Time 0.047600    
2023-01-05 16:43:09,882 - Epoch: [137][   20/   37]    Overall Loss 0.673343    Objective Loss 0.673343                                        LR 0.000002    Time 0.037791    
2023-01-05 16:43:10,170 - Epoch: [137][   30/   37]    Overall Loss 0.673732    Objective Loss 0.673732                                        LR 0.000002    Time 0.034802    
2023-01-05 16:43:10,367 - Epoch: [137][   37/   37]    Overall Loss 0.673488    Objective Loss 0.673488    Top1 60.041841    LR 0.000002    Time 0.033535    
2023-01-05 16:43:10,437 - --- validate (epoch=137)-----------
2023-01-05 16:43:10,437 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:10,679 - Epoch: [137][    5/    5]    Loss 0.671063    Top1 58.778626    
2023-01-05 16:43:10,739 - ==> Top1: 58.779    Loss: 0.671

2023-01-05 16:43:10,739 - ==> Confusion:
[[365  64   0]
 [368 251   0]
 [  0   0   0]]

2023-01-05 16:43:10,740 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:10,741 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:10,750 - 

2023-01-05 16:43:10,750 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:11,229 - Epoch: [138][   10/   37]    Overall Loss 0.673324    Objective Loss 0.673324                                        LR 0.000002    Time 0.047755    
2023-01-05 16:43:11,529 - Epoch: [138][   20/   37]    Overall Loss 0.673113    Objective Loss 0.673113                                        LR 0.000002    Time 0.038853    
2023-01-05 16:43:11,824 - Epoch: [138][   30/   37]    Overall Loss 0.673491    Objective Loss 0.673491                                        LR 0.000002    Time 0.035725    
2023-01-05 16:43:12,012 - Epoch: [138][   37/   37]    Overall Loss 0.673353    Objective Loss 0.673353    Top1 61.087866    LR 0.000002    Time 0.034055    
2023-01-05 16:43:12,084 - --- validate (epoch=138)-----------
2023-01-05 16:43:12,084 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:12,330 - Epoch: [138][    5/    5]    Loss 0.674329    Top1 62.213740    
2023-01-05 16:43:12,400 - ==> Top1: 62.214    Loss: 0.674

2023-01-05 16:43:12,401 - ==> Confusion:
[[334  95   0]
 [301 318   0]
 [  0   0   0]]

2023-01-05 16:43:12,402 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:12,402 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:12,422 - 

2023-01-05 16:43:12,422 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:12,918 - Epoch: [139][   10/   37]    Overall Loss 0.674650    Objective Loss 0.674650                                        LR 0.000002    Time 0.049549    
2023-01-05 16:43:13,230 - Epoch: [139][   20/   37]    Overall Loss 0.674308    Objective Loss 0.674308                                        LR 0.000002    Time 0.040329    
2023-01-05 16:43:13,542 - Epoch: [139][   30/   37]    Overall Loss 0.673826    Objective Loss 0.673826                                        LR 0.000002    Time 0.037287    
2023-01-05 16:43:13,735 - Epoch: [139][   37/   37]    Overall Loss 0.673480    Objective Loss 0.673480    Top1 57.740586    LR 0.000002    Time 0.035450    
2023-01-05 16:43:13,807 - --- validate (epoch=139)-----------
2023-01-05 16:43:13,807 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:14,042 - Epoch: [139][    5/    5]    Loss 0.677779    Top1 56.011450    
2023-01-05 16:43:14,109 - ==> Top1: 56.011    Loss: 0.678

2023-01-05 16:43:14,109 - ==> Confusion:
[[383  46   0]
 [415 204   0]
 [  0   0   0]]

2023-01-05 16:43:14,111 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:14,111 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:14,120 - 

2023-01-05 16:43:14,121 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:14,608 - Epoch: [140][   10/   37]    Overall Loss 0.674862    Objective Loss 0.674862                                        LR 0.000001    Time 0.048670    
2023-01-05 16:43:14,906 - Epoch: [140][   20/   37]    Overall Loss 0.673728    Objective Loss 0.673728                                        LR 0.000001    Time 0.039228    
2023-01-05 16:43:15,202 - Epoch: [140][   30/   37]    Overall Loss 0.673463    Objective Loss 0.673463                                        LR 0.000001    Time 0.036006    
2023-01-05 16:43:15,391 - Epoch: [140][   37/   37]    Overall Loss 0.673434    Objective Loss 0.673434    Top1 63.389121    LR 0.000001    Time 0.034285    
2023-01-05 16:43:15,469 - --- validate (epoch=140)-----------
2023-01-05 16:43:15,469 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:15,707 - Epoch: [140][    5/    5]    Loss 0.676347    Top1 63.645038    
2023-01-05 16:43:15,785 - ==> Top1: 63.645    Loss: 0.676

2023-01-05 16:43:15,785 - ==> Confusion:
[[321 108   0]
 [273 346   0]
 [  0   0   0]]

2023-01-05 16:43:15,787 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:15,787 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:15,797 - 

2023-01-05 16:43:15,797 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:16,277 - Epoch: [141][   10/   37]    Overall Loss 0.671530    Objective Loss 0.671530                                        LR 0.000001    Time 0.047950    
2023-01-05 16:43:16,568 - Epoch: [141][   20/   37]    Overall Loss 0.671437    Objective Loss 0.671437                                        LR 0.000001    Time 0.038522    
2023-01-05 16:43:16,852 - Epoch: [141][   30/   37]    Overall Loss 0.673200    Objective Loss 0.673200                                        LR 0.000001    Time 0.035131    
2023-01-05 16:43:17,046 - Epoch: [141][   37/   37]    Overall Loss 0.673095    Objective Loss 0.673095    Top1 66.108787    LR 0.000001    Time 0.033722    
2023-01-05 16:43:17,120 - --- validate (epoch=141)-----------
2023-01-05 16:43:17,120 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:17,360 - Epoch: [141][    5/    5]    Loss 0.677189    Top1 61.832061    
2023-01-05 16:43:17,423 - ==> Top1: 61.832    Loss: 0.677

2023-01-05 16:43:17,424 - ==> Confusion:
[[340  89   0]
 [311 308   0]
 [  0   0   0]]

2023-01-05 16:43:17,425 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:17,425 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:17,435 - 

2023-01-05 16:43:17,435 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:17,911 - Epoch: [142][   10/   37]    Overall Loss 0.672603    Objective Loss 0.672603                                        LR 0.000001    Time 0.047523    
2023-01-05 16:43:18,202 - Epoch: [142][   20/   37]    Overall Loss 0.673575    Objective Loss 0.673575                                        LR 0.000001    Time 0.038310    
2023-01-05 16:43:18,491 - Epoch: [142][   30/   37]    Overall Loss 0.673434    Objective Loss 0.673434                                        LR 0.000001    Time 0.035167    
2023-01-05 16:43:18,686 - Epoch: [142][   37/   37]    Overall Loss 0.672959    Objective Loss 0.672959    Top1 65.899582    LR 0.000001    Time 0.033784    
2023-01-05 16:43:18,761 - --- validate (epoch=142)-----------
2023-01-05 16:43:18,761 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:19,001 - Epoch: [142][    5/    5]    Loss 0.676631    Top1 66.316794    
2023-01-05 16:43:19,080 - ==> Top1: 66.317    Loss: 0.677

2023-01-05 16:43:19,080 - ==> Confusion:
[[224 205   0]
 [148 471   0]
 [  0   0   0]]

2023-01-05 16:43:19,082 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:19,082 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:19,091 - 

2023-01-05 16:43:19,092 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:19,577 - Epoch: [143][   10/   37]    Overall Loss 0.670824    Objective Loss 0.670824                                        LR 0.000001    Time 0.048414    
2023-01-05 16:43:19,875 - Epoch: [143][   20/   37]    Overall Loss 0.672297    Objective Loss 0.672297                                        LR 0.000001    Time 0.039096    
2023-01-05 16:43:20,169 - Epoch: [143][   30/   37]    Overall Loss 0.672659    Objective Loss 0.672659                                        LR 0.000001    Time 0.035848    
2023-01-05 16:43:20,365 - Epoch: [143][   37/   37]    Overall Loss 0.672851    Objective Loss 0.672851    Top1 59.623431    LR 0.000001    Time 0.034362    
2023-01-05 16:43:20,433 - --- validate (epoch=143)-----------
2023-01-05 16:43:20,433 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:20,668 - Epoch: [143][    5/    5]    Loss 0.674515    Top1 59.828244    
2023-01-05 16:43:20,734 - ==> Top1: 59.828    Loss: 0.675

2023-01-05 16:43:20,734 - ==> Confusion:
[[365  64   0]
 [357 262   0]
 [  0   0   0]]

2023-01-05 16:43:20,736 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:20,736 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:20,745 - 

2023-01-05 16:43:20,746 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:21,232 - Epoch: [144][   10/   37]    Overall Loss 0.671772    Objective Loss 0.671772                                        LR 0.000001    Time 0.048606    
2023-01-05 16:43:21,549 - Epoch: [144][   20/   37]    Overall Loss 0.672642    Objective Loss 0.672642                                        LR 0.000001    Time 0.039928    
2023-01-05 16:43:21,850 - Epoch: [144][   30/   37]    Overall Loss 0.672549    Objective Loss 0.672549                                        LR 0.000001    Time 0.036644    
2023-01-05 16:43:22,045 - Epoch: [144][   37/   37]    Overall Loss 0.672906    Objective Loss 0.672906    Top1 61.297071    LR 0.000001    Time 0.034975    
2023-01-05 16:43:22,113 - --- validate (epoch=144)-----------
2023-01-05 16:43:22,113 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:22,480 - Epoch: [144][    5/    5]    Loss 0.669529    Top1 62.977099    
2023-01-05 16:43:22,553 - ==> Top1: 62.977    Loss: 0.670

2023-01-05 16:43:22,554 - ==> Confusion:
[[327 102   0]
 [286 333   0]
 [  0   0   0]]

2023-01-05 16:43:22,555 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:22,555 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:22,575 - 

2023-01-05 16:43:22,575 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:23,053 - Epoch: [145][   10/   37]    Overall Loss 0.673085    Objective Loss 0.673085                                        LR 0.000001    Time 0.047643    
2023-01-05 16:43:23,342 - Epoch: [145][   20/   37]    Overall Loss 0.673109    Objective Loss 0.673109                                        LR 0.000001    Time 0.038247    
2023-01-05 16:43:23,617 - Epoch: [145][   30/   37]    Overall Loss 0.672976    Objective Loss 0.672976                                        LR 0.000001    Time 0.034678    
2023-01-05 16:43:23,812 - Epoch: [145][   37/   37]    Overall Loss 0.672699    Objective Loss 0.672699    Top1 64.225941    LR 0.000001    Time 0.033374    
2023-01-05 16:43:23,896 - --- validate (epoch=145)-----------
2023-01-05 16:43:23,896 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:24,130 - Epoch: [145][    5/    5]    Loss 0.672242    Top1 61.927481    
2023-01-05 16:43:24,189 - ==> Top1: 61.927    Loss: 0.672

2023-01-05 16:43:24,189 - ==> Confusion:
[[345  84   0]
 [315 304   0]
 [  0   0   0]]

2023-01-05 16:43:24,191 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:24,191 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:24,200 - 

2023-01-05 16:43:24,201 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:24,703 - Epoch: [146][   10/   37]    Overall Loss 0.672199    Objective Loss 0.672199                                        LR 0.000001    Time 0.050128    
2023-01-05 16:43:24,994 - Epoch: [146][   20/   37]    Overall Loss 0.672380    Objective Loss 0.672380                                        LR 0.000001    Time 0.039612    
2023-01-05 16:43:25,287 - Epoch: [146][   30/   37]    Overall Loss 0.672384    Objective Loss 0.672384                                        LR 0.000001    Time 0.036167    
2023-01-05 16:43:25,479 - Epoch: [146][   37/   37]    Overall Loss 0.672715    Objective Loss 0.672715    Top1 60.669456    LR 0.000001    Time 0.034504    
2023-01-05 16:43:25,547 - --- validate (epoch=146)-----------
2023-01-05 16:43:25,548 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:25,781 - Epoch: [146][    5/    5]    Loss 0.680158    Top1 60.209924    
2023-01-05 16:43:25,846 - ==> Top1: 60.210    Loss: 0.680

2023-01-05 16:43:25,847 - ==> Confusion:
[[354  75   0]
 [342 277   0]
 [  0   0   0]]

2023-01-05 16:43:25,848 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:25,848 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:25,858 - 

2023-01-05 16:43:25,858 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:26,338 - Epoch: [147][   10/   37]    Overall Loss 0.672516    Objective Loss 0.672516                                        LR 0.000001    Time 0.047961    
2023-01-05 16:43:26,648 - Epoch: [147][   20/   37]    Overall Loss 0.672574    Objective Loss 0.672574                                        LR 0.000001    Time 0.039425    
2023-01-05 16:43:26,965 - Epoch: [147][   30/   37]    Overall Loss 0.673186    Objective Loss 0.673186                                        LR 0.000001    Time 0.036846    
2023-01-05 16:43:27,160 - Epoch: [147][   37/   37]    Overall Loss 0.672859    Objective Loss 0.672859    Top1 63.179916    LR 0.000001    Time 0.035132    
2023-01-05 16:43:27,239 - --- validate (epoch=147)-----------
2023-01-05 16:43:27,240 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:27,484 - Epoch: [147][    5/    5]    Loss 0.671930    Top1 65.267176    
2023-01-05 16:43:27,548 - ==> Top1: 65.267    Loss: 0.672

2023-01-05 16:43:27,548 - ==> Confusion:
[[319 110   0]
 [254 365   0]
 [  0   0   0]]

2023-01-05 16:43:27,550 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:27,550 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:27,560 - 

2023-01-05 16:43:27,560 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:28,050 - Epoch: [148][   10/   37]    Overall Loss 0.671518    Objective Loss 0.671518                                        LR 0.000001    Time 0.048867    
2023-01-05 16:43:28,364 - Epoch: [148][   20/   37]    Overall Loss 0.673104    Objective Loss 0.673104                                        LR 0.000001    Time 0.040108    
2023-01-05 16:43:28,682 - Epoch: [148][   30/   37]    Overall Loss 0.672876    Objective Loss 0.672876                                        LR 0.000001    Time 0.037332    
2023-01-05 16:43:28,877 - Epoch: [148][   37/   37]    Overall Loss 0.672841    Objective Loss 0.672841    Top1 66.108787    LR 0.000001    Time 0.035540    
2023-01-05 16:43:28,947 - --- validate (epoch=148)-----------
2023-01-05 16:43:28,947 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:29,191 - Epoch: [148][    5/    5]    Loss 0.672970    Top1 64.217557    
2023-01-05 16:43:29,251 - ==> Top1: 64.218    Loss: 0.673

2023-01-05 16:43:29,251 - ==> Confusion:
[[312 117   0]
 [258 361   0]
 [  0   0   0]]

2023-01-05 16:43:29,253 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:29,253 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:29,263 - 

2023-01-05 16:43:29,263 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:29,769 - Epoch: [149][   10/   37]    Overall Loss 0.674161    Objective Loss 0.674161                                        LR 0.000001    Time 0.050515    
2023-01-05 16:43:30,080 - Epoch: [149][   20/   37]    Overall Loss 0.673624    Objective Loss 0.673624                                        LR 0.000001    Time 0.040777    
2023-01-05 16:43:30,393 - Epoch: [149][   30/   37]    Overall Loss 0.672921    Objective Loss 0.672921                                        LR 0.000001    Time 0.037625    
2023-01-05 16:43:30,587 - Epoch: [149][   37/   37]    Overall Loss 0.672526    Objective Loss 0.672526    Top1 62.970711    LR 0.000001    Time 0.035748    
2023-01-05 16:43:30,667 - --- validate (epoch=149)-----------
2023-01-05 16:43:30,667 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:30,911 - Epoch: [149][    5/    5]    Loss 0.671813    Top1 59.160305    
2023-01-05 16:43:30,977 - ==> Top1: 59.160    Loss: 0.672

2023-01-05 16:43:30,977 - ==> Confusion:
[[367  62   0]
 [366 253   0]
 [  0   0   0]]

2023-01-05 16:43:30,979 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:30,979 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:30,989 - 

2023-01-05 16:43:30,989 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:31,478 - Epoch: [150][   10/   37]    Overall Loss 0.672730    Objective Loss 0.672730                                        LR 0.000001    Time 0.048826    
2023-01-05 16:43:31,787 - Epoch: [150][   20/   37]    Overall Loss 0.673121    Objective Loss 0.673121                                        LR 0.000001    Time 0.039843    
2023-01-05 16:43:32,094 - Epoch: [150][   30/   37]    Overall Loss 0.672666    Objective Loss 0.672666                                        LR 0.000001    Time 0.036791    
2023-01-05 16:43:32,289 - Epoch: [150][   37/   37]    Overall Loss 0.672575    Objective Loss 0.672575    Top1 55.230126    LR 0.000001    Time 0.035083    
2023-01-05 16:43:32,376 - --- validate (epoch=150)-----------
2023-01-05 16:43:32,376 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:32,611 - Epoch: [150][    5/    5]    Loss 0.671728    Top1 56.774809    
2023-01-05 16:43:32,674 - ==> Top1: 56.775    Loss: 0.672

2023-01-05 16:43:32,675 - ==> Confusion:
[[378  51   0]
 [402 217   0]
 [  0   0   0]]

2023-01-05 16:43:32,676 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:32,676 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:32,696 - 

2023-01-05 16:43:32,696 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:33,197 - Epoch: [151][   10/   37]    Overall Loss 0.672878    Objective Loss 0.672878                                        LR 0.000001    Time 0.049971    
2023-01-05 16:43:33,495 - Epoch: [151][   20/   37]    Overall Loss 0.672182    Objective Loss 0.672182                                        LR 0.000001    Time 0.039896    
2023-01-05 16:43:33,795 - Epoch: [151][   30/   37]    Overall Loss 0.671812    Objective Loss 0.671812                                        LR 0.000001    Time 0.036586    
2023-01-05 16:43:33,994 - Epoch: [151][   37/   37]    Overall Loss 0.672011    Objective Loss 0.672011    Top1 61.297071    LR 0.000001    Time 0.035034    
2023-01-05 16:43:34,058 - --- validate (epoch=151)-----------
2023-01-05 16:43:34,059 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:34,316 - Epoch: [151][    5/    5]    Loss 0.673770    Top1 64.980916    
2023-01-05 16:43:34,377 - ==> Top1: 64.981    Loss: 0.674

2023-01-05 16:43:34,378 - ==> Confusion:
[[310 119   0]
 [248 371   0]
 [  0   0   0]]

2023-01-05 16:43:34,379 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:34,379 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:34,389 - 

2023-01-05 16:43:34,390 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:34,884 - Epoch: [152][   10/   37]    Overall Loss 0.673798    Objective Loss 0.673798                                        LR 0.000001    Time 0.049330    
2023-01-05 16:43:35,163 - Epoch: [152][   20/   37]    Overall Loss 0.672807    Objective Loss 0.672807                                        LR 0.000001    Time 0.038599    
2023-01-05 16:43:35,448 - Epoch: [152][   30/   37]    Overall Loss 0.673025    Objective Loss 0.673025                                        LR 0.000001    Time 0.035211    
2023-01-05 16:43:35,635 - Epoch: [152][   37/   37]    Overall Loss 0.672346    Objective Loss 0.672346    Top1 60.460251    LR 0.000001    Time 0.033597    
2023-01-05 16:43:35,713 - --- validate (epoch=152)-----------
2023-01-05 16:43:35,714 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:35,959 - Epoch: [152][    5/    5]    Loss 0.675199    Top1 57.538168    
2023-01-05 16:43:36,029 - ==> Top1: 57.538    Loss: 0.675

2023-01-05 16:43:36,029 - ==> Confusion:
[[379  50   0]
 [395 224   0]
 [  0   0   0]]

2023-01-05 16:43:36,030 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:36,031 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:36,040 - 

2023-01-05 16:43:36,040 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:36,544 - Epoch: [153][   10/   37]    Overall Loss 0.671776    Objective Loss 0.671776                                        LR 0.000001    Time 0.050295    
2023-01-05 16:43:36,846 - Epoch: [153][   20/   37]    Overall Loss 0.672016    Objective Loss 0.672016                                        LR 0.000001    Time 0.040250    
2023-01-05 16:43:37,138 - Epoch: [153][   30/   37]    Overall Loss 0.672466    Objective Loss 0.672466                                        LR 0.000001    Time 0.036525    
2023-01-05 16:43:37,325 - Epoch: [153][   37/   37]    Overall Loss 0.672113    Objective Loss 0.672113    Top1 64.853556    LR 0.000001    Time 0.034680    
2023-01-05 16:43:37,399 - --- validate (epoch=153)-----------
2023-01-05 16:43:37,400 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:37,635 - Epoch: [153][    5/    5]    Loss 0.679358    Top1 64.217557    
2023-01-05 16:43:37,706 - ==> Top1: 64.218    Loss: 0.679

2023-01-05 16:43:37,706 - ==> Confusion:
[[325 104   0]
 [271 348   0]
 [  0   0   0]]

2023-01-05 16:43:37,707 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:37,708 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:37,717 - 

2023-01-05 16:43:37,717 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:38,210 - Epoch: [154][   10/   37]    Overall Loss 0.673252    Objective Loss 0.673252                                        LR 0.000001    Time 0.049184    
2023-01-05 16:43:38,496 - Epoch: [154][   20/   37]    Overall Loss 0.672447    Objective Loss 0.672447                                        LR 0.000001    Time 0.038910    
2023-01-05 16:43:38,812 - Epoch: [154][   30/   37]    Overall Loss 0.671461    Objective Loss 0.671461                                        LR 0.000001    Time 0.036456    
2023-01-05 16:43:39,000 - Epoch: [154][   37/   37]    Overall Loss 0.672058    Objective Loss 0.672058    Top1 58.995816    LR 0.000001    Time 0.034625    
2023-01-05 16:43:39,081 - --- validate (epoch=154)-----------
2023-01-05 16:43:39,081 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:39,328 - Epoch: [154][    5/    5]    Loss 0.678044    Top1 58.492366    
2023-01-05 16:43:39,396 - ==> Top1: 58.492    Loss: 0.678

2023-01-05 16:43:39,397 - ==> Confusion:
[[362  67   0]
 [368 251   0]
 [  0   0   0]]

2023-01-05 16:43:39,398 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:39,398 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:39,408 - 

2023-01-05 16:43:39,408 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:39,894 - Epoch: [155][   10/   37]    Overall Loss 0.672624    Objective Loss 0.672624                                        LR 0.000001    Time 0.048518    
2023-01-05 16:43:40,189 - Epoch: [155][   20/   37]    Overall Loss 0.672529    Objective Loss 0.672529                                        LR 0.000001    Time 0.038992    
2023-01-05 16:43:40,489 - Epoch: [155][   30/   37]    Overall Loss 0.672533    Objective Loss 0.672533                                        LR 0.000001    Time 0.035996    
2023-01-05 16:43:40,679 - Epoch: [155][   37/   37]    Overall Loss 0.672015    Objective Loss 0.672015    Top1 62.761506    LR 0.000001    Time 0.034315    
2023-01-05 16:43:40,764 - --- validate (epoch=155)-----------
2023-01-05 16:43:40,765 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:41,011 - Epoch: [155][    5/    5]    Loss 0.675348    Top1 59.923664    
2023-01-05 16:43:41,076 - ==> Top1: 59.924    Loss: 0.675

2023-01-05 16:43:41,077 - ==> Confusion:
[[366  63   0]
 [357 262   0]
 [  0   0   0]]

2023-01-05 16:43:41,078 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:41,078 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:41,088 - 

2023-01-05 16:43:41,088 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:41,567 - Epoch: [156][   10/   37]    Overall Loss 0.671875    Objective Loss 0.671875                                        LR 0.000001    Time 0.047783    
2023-01-05 16:43:41,845 - Epoch: [156][   20/   37]    Overall Loss 0.671667    Objective Loss 0.671667                                        LR 0.000001    Time 0.037814    
2023-01-05 16:43:42,138 - Epoch: [156][   30/   37]    Overall Loss 0.671434    Objective Loss 0.671434                                        LR 0.000001    Time 0.034943    
2023-01-05 16:43:42,327 - Epoch: [156][   37/   37]    Overall Loss 0.671800    Objective Loss 0.671800    Top1 56.066946    LR 0.000001    Time 0.033437    
2023-01-05 16:43:42,410 - --- validate (epoch=156)-----------
2023-01-05 16:43:42,410 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:42,654 - Epoch: [156][    5/    5]    Loss 0.673627    Top1 58.683206    
2023-01-05 16:43:42,719 - ==> Top1: 58.683    Loss: 0.674

2023-01-05 16:43:42,720 - ==> Confusion:
[[377  52   0]
 [381 238   0]
 [  0   0   0]]

2023-01-05 16:43:42,721 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:42,721 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:42,741 - 

2023-01-05 16:43:42,741 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:43,221 - Epoch: [157][   10/   37]    Overall Loss 0.671278    Objective Loss 0.671278                                        LR 0.000001    Time 0.047900    
2023-01-05 16:43:43,515 - Epoch: [157][   20/   37]    Overall Loss 0.671719    Objective Loss 0.671719                                        LR 0.000001    Time 0.038620    
2023-01-05 16:43:43,810 - Epoch: [157][   30/   37]    Overall Loss 0.670918    Objective Loss 0.670918                                        LR 0.000001    Time 0.035578    
2023-01-05 16:43:44,003 - Epoch: [157][   37/   37]    Overall Loss 0.671582    Objective Loss 0.671582    Top1 59.832636    LR 0.000001    Time 0.034061    
2023-01-05 16:43:44,075 - --- validate (epoch=157)-----------
2023-01-05 16:43:44,075 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:44,311 - Epoch: [157][    5/    5]    Loss 0.670191    Top1 60.400763    
2023-01-05 16:43:44,377 - ==> Top1: 60.401    Loss: 0.670

2023-01-05 16:43:44,377 - ==> Confusion:
[[344  85   0]
 [330 289   0]
 [  0   0   0]]

2023-01-05 16:43:44,379 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:44,379 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:44,388 - 

2023-01-05 16:43:44,388 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:44,983 - Epoch: [158][   10/   37]    Overall Loss 0.673239    Objective Loss 0.673239                                        LR 0.000001    Time 0.059438    
2023-01-05 16:43:45,288 - Epoch: [158][   20/   37]    Overall Loss 0.671414    Objective Loss 0.671414                                        LR 0.000001    Time 0.044909    
2023-01-05 16:43:45,594 - Epoch: [158][   30/   37]    Overall Loss 0.671952    Objective Loss 0.671952                                        LR 0.000001    Time 0.040048    
2023-01-05 16:43:45,787 - Epoch: [158][   37/   37]    Overall Loss 0.671519    Objective Loss 0.671519    Top1 60.878661    LR 0.000001    Time 0.037688    
2023-01-05 16:43:45,862 - --- validate (epoch=158)-----------
2023-01-05 16:43:45,862 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:46,102 - Epoch: [158][    5/    5]    Loss 0.680111    Top1 62.786260    
2023-01-05 16:43:46,179 - ==> Top1: 62.786    Loss: 0.680

2023-01-05 16:43:46,179 - ==> Confusion:
[[333  96   0]
 [294 325   0]
 [  0   0   0]]

2023-01-05 16:43:46,181 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:46,181 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:46,190 - 

2023-01-05 16:43:46,191 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:46,679 - Epoch: [159][   10/   37]    Overall Loss 0.672991    Objective Loss 0.672991                                        LR 0.000001    Time 0.048803    
2023-01-05 16:43:46,992 - Epoch: [159][   20/   37]    Overall Loss 0.672191    Objective Loss 0.672191                                        LR 0.000001    Time 0.039995    
2023-01-05 16:43:47,300 - Epoch: [159][   30/   37]    Overall Loss 0.671779    Objective Loss 0.671779                                        LR 0.000001    Time 0.036914    
2023-01-05 16:43:47,495 - Epoch: [159][   37/   37]    Overall Loss 0.671496    Objective Loss 0.671496    Top1 58.995816    LR 0.000001    Time 0.035195    
2023-01-05 16:43:47,570 - --- validate (epoch=159)-----------
2023-01-05 16:43:47,570 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:47,804 - Epoch: [159][    5/    5]    Loss 0.672327    Top1 61.068702    
2023-01-05 16:43:47,879 - ==> Top1: 61.069    Loss: 0.672

2023-01-05 16:43:47,879 - ==> Confusion:
[[343  86   0]
 [322 297   0]
 [  0   0   0]]

2023-01-05 16:43:47,881 - ==> Best [Top1: 66.698   Sparsity:0.00   Params: 361664 on epoch: 130]
2023-01-05 16:43:47,881 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:47,894 - 

2023-01-05 16:43:47,895 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:48,396 - Epoch: [160][   10/   37]    Overall Loss 0.672371    Objective Loss 0.672371                                        LR 0.000001    Time 0.050086    
2023-01-05 16:43:48,695 - Epoch: [160][   20/   37]    Overall Loss 0.671416    Objective Loss 0.671416                                        LR 0.000001    Time 0.039947    
2023-01-05 16:43:48,996 - Epoch: [160][   30/   37]    Overall Loss 0.671348    Objective Loss 0.671348                                        LR 0.000001    Time 0.036651    
2023-01-05 16:43:49,192 - Epoch: [160][   37/   37]    Overall Loss 0.671611    Objective Loss 0.671611    Top1 64.225941    LR 0.000001    Time 0.035000    
2023-01-05 16:43:49,264 - --- validate (epoch=160)-----------
2023-01-05 16:43:49,264 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:49,499 - Epoch: [160][    5/    5]    Loss 0.668117    Top1 66.793893    
2023-01-05 16:43:49,562 - ==> Top1: 66.794    Loss: 0.668

2023-01-05 16:43:49,563 - ==> Confusion:
[[271 158   0]
 [190 429   0]
 [  0   0   0]]

2023-01-05 16:43:49,564 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:43:49,564 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:49,589 - 

2023-01-05 16:43:49,589 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:50,100 - Epoch: [161][   10/   37]    Overall Loss 0.671215    Objective Loss 0.671215                                        LR 0.000001    Time 0.051065    
2023-01-05 16:43:50,418 - Epoch: [161][   20/   37]    Overall Loss 0.671034    Objective Loss 0.671034                                        LR 0.000001    Time 0.041389    
2023-01-05 16:43:50,738 - Epoch: [161][   30/   37]    Overall Loss 0.671577    Objective Loss 0.671577                                        LR 0.000001    Time 0.038251    
2023-01-05 16:43:50,933 - Epoch: [161][   37/   37]    Overall Loss 0.671394    Objective Loss 0.671394    Top1 59.205021    LR 0.000001    Time 0.036278    
2023-01-05 16:43:51,006 - --- validate (epoch=161)-----------
2023-01-05 16:43:51,006 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:51,247 - Epoch: [161][    5/    5]    Loss 0.675702    Top1 58.778626    
2023-01-05 16:43:51,308 - ==> Top1: 58.779    Loss: 0.676

2023-01-05 16:43:51,308 - ==> Confusion:
[[366  63   0]
 [369 250   0]
 [  0   0   0]]

2023-01-05 16:43:51,309 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:43:51,309 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:51,329 - 

2023-01-05 16:43:51,330 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:51,831 - Epoch: [162][   10/   37]    Overall Loss 0.673151    Objective Loss 0.673151                                        LR 0.000001    Time 0.050066    
2023-01-05 16:43:52,132 - Epoch: [162][   20/   37]    Overall Loss 0.671717    Objective Loss 0.671717                                        LR 0.000001    Time 0.040060    
2023-01-05 16:43:52,448 - Epoch: [162][   30/   37]    Overall Loss 0.671539    Objective Loss 0.671539                                        LR 0.000001    Time 0.037123    
2023-01-05 16:43:52,645 - Epoch: [162][   37/   37]    Overall Loss 0.671744    Objective Loss 0.671744    Top1 59.832636    LR 0.000001    Time 0.035410    
2023-01-05 16:43:52,728 - --- validate (epoch=162)-----------
2023-01-05 16:43:52,728 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:52,963 - Epoch: [162][    5/    5]    Loss 0.671806    Top1 63.740458    
2023-01-05 16:43:53,047 - ==> Top1: 63.740    Loss: 0.672

2023-01-05 16:43:53,047 - ==> Confusion:
[[323 106   0]
 [274 345   0]
 [  0   0   0]]

2023-01-05 16:43:53,049 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:43:53,049 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:53,058 - 

2023-01-05 16:43:53,058 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:53,582 - Epoch: [163][   10/   37]    Overall Loss 0.672918    Objective Loss 0.672918                                        LR 0.000001    Time 0.052242    
2023-01-05 16:43:53,898 - Epoch: [163][   20/   37]    Overall Loss 0.671545    Objective Loss 0.671545                                        LR 0.000001    Time 0.041927    
2023-01-05 16:43:54,208 - Epoch: [163][   30/   37]    Overall Loss 0.671586    Objective Loss 0.671586                                        LR 0.000001    Time 0.038272    
2023-01-05 16:43:54,404 - Epoch: [163][   37/   37]    Overall Loss 0.671666    Objective Loss 0.671666    Top1 62.552301    LR 0.000001    Time 0.036309    
2023-01-05 16:43:54,481 - --- validate (epoch=163)-----------
2023-01-05 16:43:54,481 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:54,719 - Epoch: [163][    5/    5]    Loss 0.669726    Top1 64.885496    
2023-01-05 16:43:54,783 - ==> Top1: 64.885    Loss: 0.670

2023-01-05 16:43:54,783 - ==> Confusion:
[[316 113   0]
 [255 364   0]
 [  0   0   0]]

2023-01-05 16:43:54,785 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:43:54,785 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:54,794 - 

2023-01-05 16:43:54,794 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:55,279 - Epoch: [164][   10/   37]    Overall Loss 0.672291    Objective Loss 0.672291                                        LR 0.000001    Time 0.048366    
2023-01-05 16:43:55,582 - Epoch: [164][   20/   37]    Overall Loss 0.672118    Objective Loss 0.672118                                        LR 0.000001    Time 0.039314    
2023-01-05 16:43:55,879 - Epoch: [164][   30/   37]    Overall Loss 0.671633    Objective Loss 0.671633                                        LR 0.000001    Time 0.036112    
2023-01-05 16:43:56,073 - Epoch: [164][   37/   37]    Overall Loss 0.671551    Objective Loss 0.671551    Top1 61.087866    LR 0.000001    Time 0.034510    
2023-01-05 16:43:56,149 - --- validate (epoch=164)-----------
2023-01-05 16:43:56,150 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:56,391 - Epoch: [164][    5/    5]    Loss 0.669189    Top1 64.503817    
2023-01-05 16:43:56,456 - ==> Top1: 64.504    Loss: 0.669

2023-01-05 16:43:56,456 - ==> Confusion:
[[326 103   0]
 [269 350   0]
 [  0   0   0]]

2023-01-05 16:43:56,458 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:43:56,458 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:56,477 - 

2023-01-05 16:43:56,478 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:56,978 - Epoch: [165][   10/   37]    Overall Loss 0.671372    Objective Loss 0.671372                                        LR 0.000001    Time 0.049997    
2023-01-05 16:43:57,272 - Epoch: [165][   20/   37]    Overall Loss 0.670328    Objective Loss 0.670328                                        LR 0.000001    Time 0.039655    
2023-01-05 16:43:57,579 - Epoch: [165][   30/   37]    Overall Loss 0.671847    Objective Loss 0.671847                                        LR 0.000001    Time 0.036667    
2023-01-05 16:43:57,769 - Epoch: [165][   37/   37]    Overall Loss 0.671219    Objective Loss 0.671219    Top1 60.878661    LR 0.000001    Time 0.034862    
2023-01-05 16:43:57,841 - --- validate (epoch=165)-----------
2023-01-05 16:43:57,842 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:58,080 - Epoch: [165][    5/    5]    Loss 0.672334    Top1 55.534351    
2023-01-05 16:43:58,151 - ==> Top1: 55.534    Loss: 0.672

2023-01-05 16:43:58,152 - ==> Confusion:
[[382  47   0]
 [419 200   0]
 [  0   0   0]]

2023-01-05 16:43:58,153 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:43:58,153 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:58,163 - 

2023-01-05 16:43:58,163 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:43:58,647 - Epoch: [166][   10/   37]    Overall Loss 0.673649    Objective Loss 0.673649                                        LR 0.000001    Time 0.048350    
2023-01-05 16:43:58,939 - Epoch: [166][   20/   37]    Overall Loss 0.672064    Objective Loss 0.672064                                        LR 0.000001    Time 0.038739    
2023-01-05 16:43:59,244 - Epoch: [166][   30/   37]    Overall Loss 0.671476    Objective Loss 0.671476                                        LR 0.000001    Time 0.035982    
2023-01-05 16:43:59,438 - Epoch: [166][   37/   37]    Overall Loss 0.671373    Objective Loss 0.671373    Top1 57.949791    LR 0.000001    Time 0.034413    
2023-01-05 16:43:59,510 - --- validate (epoch=166)-----------
2023-01-05 16:43:59,511 - 1048 samples (256 per mini-batch)
2023-01-05 16:43:59,747 - Epoch: [166][    5/    5]    Loss 0.673946    Top1 59.160305    
2023-01-05 16:43:59,815 - ==> Top1: 59.160    Loss: 0.674

2023-01-05 16:43:59,815 - ==> Confusion:
[[369  60   0]
 [368 251   0]
 [  0   0   0]]

2023-01-05 16:43:59,817 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:43:59,817 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:43:59,826 - 

2023-01-05 16:43:59,826 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:00,299 - Epoch: [167][   10/   37]    Overall Loss 0.669929    Objective Loss 0.669929                                        LR 0.000001    Time 0.047177    
2023-01-05 16:44:00,588 - Epoch: [167][   20/   37]    Overall Loss 0.669788    Objective Loss 0.669788                                        LR 0.000001    Time 0.038037    
2023-01-05 16:44:00,883 - Epoch: [167][   30/   37]    Overall Loss 0.670697    Objective Loss 0.670697                                        LR 0.000001    Time 0.035180    
2023-01-05 16:44:01,076 - Epoch: [167][   37/   37]    Overall Loss 0.671253    Objective Loss 0.671253    Top1 58.368201    LR 0.000001    Time 0.033719    
2023-01-05 16:44:01,144 - --- validate (epoch=167)-----------
2023-01-05 16:44:01,145 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:01,376 - Epoch: [167][    5/    5]    Loss 0.670745    Top1 60.973282    
2023-01-05 16:44:01,446 - ==> Top1: 60.973    Loss: 0.671

2023-01-05 16:44:01,446 - ==> Confusion:
[[351  78   0]
 [331 288   0]
 [  0   0   0]]

2023-01-05 16:44:01,448 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:01,448 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:01,468 - 

2023-01-05 16:44:01,468 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:01,961 - Epoch: [168][   10/   37]    Overall Loss 0.671826    Objective Loss 0.671826                                        LR 0.000001    Time 0.049234    
2023-01-05 16:44:02,255 - Epoch: [168][   20/   37]    Overall Loss 0.671489    Objective Loss 0.671489                                        LR 0.000001    Time 0.039286    
2023-01-05 16:44:02,557 - Epoch: [168][   30/   37]    Overall Loss 0.671576    Objective Loss 0.671576                                        LR 0.000001    Time 0.036227    
2023-01-05 16:44:02,751 - Epoch: [168][   37/   37]    Overall Loss 0.670934    Objective Loss 0.670934    Top1 65.271967    LR 0.000001    Time 0.034625    
2023-01-05 16:44:02,823 - --- validate (epoch=168)-----------
2023-01-05 16:44:02,824 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:03,065 - Epoch: [168][    5/    5]    Loss 0.672263    Top1 61.927481    
2023-01-05 16:44:03,131 - ==> Top1: 61.927    Loss: 0.672

2023-01-05 16:44:03,131 - ==> Confusion:
[[341  88   0]
 [311 308   0]
 [  0   0   0]]

2023-01-05 16:44:03,133 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:03,133 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:03,153 - 

2023-01-05 16:44:03,154 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:03,643 - Epoch: [169][   10/   37]    Overall Loss 0.671749    Objective Loss 0.671749                                        LR 0.000001    Time 0.048808    
2023-01-05 16:44:03,928 - Epoch: [169][   20/   37]    Overall Loss 0.671116    Objective Loss 0.671116                                        LR 0.000001    Time 0.038675    
2023-01-05 16:44:04,215 - Epoch: [169][   30/   37]    Overall Loss 0.671283    Objective Loss 0.671283                                        LR 0.000001    Time 0.035315    
2023-01-05 16:44:04,407 - Epoch: [169][   37/   37]    Overall Loss 0.670937    Objective Loss 0.670937    Top1 66.736402    LR 0.000001    Time 0.033832    
2023-01-05 16:44:04,478 - --- validate (epoch=169)-----------
2023-01-05 16:44:04,479 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:04,718 - Epoch: [169][    5/    5]    Loss 0.675471    Top1 64.790076    
2023-01-05 16:44:04,788 - ==> Top1: 64.790    Loss: 0.675

2023-01-05 16:44:04,788 - ==> Confusion:
[[303 126   0]
 [243 376   0]
 [  0   0   0]]

2023-01-05 16:44:04,789 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:04,789 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:04,799 - 

2023-01-05 16:44:04,799 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:05,280 - Epoch: [170][   10/   37]    Overall Loss 0.671466    Objective Loss 0.671466                                        LR 0.000001    Time 0.048044    
2023-01-05 16:44:05,588 - Epoch: [170][   20/   37]    Overall Loss 0.671435    Objective Loss 0.671435                                        LR 0.000001    Time 0.039395    
2023-01-05 16:44:05,890 - Epoch: [170][   30/   37]    Overall Loss 0.670860    Objective Loss 0.670860                                        LR 0.000001    Time 0.036308    
2023-01-05 16:44:06,078 - Epoch: [170][   37/   37]    Overall Loss 0.670553    Objective Loss 0.670553    Top1 64.853556    LR 0.000001    Time 0.034530    
2023-01-05 16:44:06,162 - --- validate (epoch=170)-----------
2023-01-05 16:44:06,162 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:06,408 - Epoch: [170][    5/    5]    Loss 0.667139    Top1 63.358779    
2023-01-05 16:44:06,480 - ==> Top1: 63.359    Loss: 0.667

2023-01-05 16:44:06,480 - ==> Confusion:
[[330  99   0]
 [285 334   0]
 [  0   0   0]]

2023-01-05 16:44:06,482 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:06,482 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:06,492 - 

2023-01-05 16:44:06,492 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:06,978 - Epoch: [171][   10/   37]    Overall Loss 0.670839    Objective Loss 0.670839                                        LR 0.000001    Time 0.048546    
2023-01-05 16:44:07,278 - Epoch: [171][   20/   37]    Overall Loss 0.671134    Objective Loss 0.671134                                        LR 0.000001    Time 0.039266    
2023-01-05 16:44:07,580 - Epoch: [171][   30/   37]    Overall Loss 0.671592    Objective Loss 0.671592                                        LR 0.000001    Time 0.036221    
2023-01-05 16:44:07,775 - Epoch: [171][   37/   37]    Overall Loss 0.670892    Objective Loss 0.670892    Top1 64.644351    LR 0.000001    Time 0.034645    
2023-01-05 16:44:07,853 - --- validate (epoch=171)-----------
2023-01-05 16:44:07,853 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:08,097 - Epoch: [171][    5/    5]    Loss 0.670212    Top1 60.687023    
2023-01-05 16:44:08,165 - ==> Top1: 60.687    Loss: 0.670

2023-01-05 16:44:08,166 - ==> Confusion:
[[348  81   0]
 [331 288   0]
 [  0   0   0]]

2023-01-05 16:44:08,167 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:08,167 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:08,176 - 

2023-01-05 16:44:08,177 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:08,693 - Epoch: [172][   10/   37]    Overall Loss 0.672350    Objective Loss 0.672350                                        LR 0.000001    Time 0.051585    
2023-01-05 16:44:09,003 - Epoch: [172][   20/   37]    Overall Loss 0.669688    Objective Loss 0.669688                                        LR 0.000001    Time 0.041243    
2023-01-05 16:44:09,323 - Epoch: [172][   30/   37]    Overall Loss 0.670751    Objective Loss 0.670751                                        LR 0.000001    Time 0.038040    
2023-01-05 16:44:09,518 - Epoch: [172][   37/   37]    Overall Loss 0.670798    Objective Loss 0.670798    Top1 58.786611    LR 0.000001    Time 0.036117    
2023-01-05 16:44:09,587 - --- validate (epoch=172)-----------
2023-01-05 16:44:09,588 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:09,821 - Epoch: [172][    5/    5]    Loss 0.676916    Top1 62.213740    
2023-01-05 16:44:09,889 - ==> Top1: 62.214    Loss: 0.677

2023-01-05 16:44:09,889 - ==> Confusion:
[[336  93   0]
 [303 316   0]
 [  0   0   0]]

2023-01-05 16:44:09,891 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:09,891 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:09,901 - 

2023-01-05 16:44:09,901 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:10,386 - Epoch: [173][   10/   37]    Overall Loss 0.672036    Objective Loss 0.672036                                        LR 0.000001    Time 0.048464    
2023-01-05 16:44:10,691 - Epoch: [173][   20/   37]    Overall Loss 0.671050    Objective Loss 0.671050                                        LR 0.000001    Time 0.039438    
2023-01-05 16:44:10,996 - Epoch: [173][   30/   37]    Overall Loss 0.670621    Objective Loss 0.670621                                        LR 0.000001    Time 0.036451    
2023-01-05 16:44:11,192 - Epoch: [173][   37/   37]    Overall Loss 0.670532    Objective Loss 0.670532    Top1 61.924686    LR 0.000001    Time 0.034857    
2023-01-05 16:44:11,263 - --- validate (epoch=173)-----------
2023-01-05 16:44:11,264 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:11,516 - Epoch: [173][    5/    5]    Loss 0.670928    Top1 60.496183    
2023-01-05 16:44:11,586 - ==> Top1: 60.496    Loss: 0.671

2023-01-05 16:44:11,587 - ==> Confusion:
[[365  64   0]
 [350 269   0]
 [  0   0   0]]

2023-01-05 16:44:11,588 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:11,588 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:11,609 - 

2023-01-05 16:44:11,609 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:12,085 - Epoch: [174][   10/   37]    Overall Loss 0.672095    Objective Loss 0.672095                                        LR 0.000001    Time 0.047488    
2023-01-05 16:44:12,388 - Epoch: [174][   20/   37]    Overall Loss 0.671483    Objective Loss 0.671483                                        LR 0.000001    Time 0.038881    
2023-01-05 16:44:12,690 - Epoch: [174][   30/   37]    Overall Loss 0.670923    Objective Loss 0.670923                                        LR 0.000001    Time 0.035989    
2023-01-05 16:44:12,886 - Epoch: [174][   37/   37]    Overall Loss 0.670349    Objective Loss 0.670349    Top1 58.577406    LR 0.000001    Time 0.034466    
2023-01-05 16:44:12,955 - --- validate (epoch=174)-----------
2023-01-05 16:44:12,955 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:13,190 - Epoch: [174][    5/    5]    Loss 0.670998    Top1 59.351145    
2023-01-05 16:44:13,253 - ==> Top1: 59.351    Loss: 0.671

2023-01-05 16:44:13,253 - ==> Confusion:
[[364  65   0]
 [361 258   0]
 [  0   0   0]]

2023-01-05 16:44:13,255 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:13,255 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:13,275 - 

2023-01-05 16:44:13,275 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:13,880 - Epoch: [175][   10/   37]    Overall Loss 0.669893    Objective Loss 0.669893                                        LR 0.000001    Time 0.060389    
2023-01-05 16:44:14,194 - Epoch: [175][   20/   37]    Overall Loss 0.669994    Objective Loss 0.669994                                        LR 0.000001    Time 0.045897    
2023-01-05 16:44:14,509 - Epoch: [175][   30/   37]    Overall Loss 0.670201    Objective Loss 0.670201                                        LR 0.000001    Time 0.041083    
2023-01-05 16:44:14,703 - Epoch: [175][   37/   37]    Overall Loss 0.670503    Objective Loss 0.670503    Top1 58.158996    LR 0.000001    Time 0.038547    
2023-01-05 16:44:14,765 - --- validate (epoch=175)-----------
2023-01-05 16:44:14,766 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:15,001 - Epoch: [175][    5/    5]    Loss 0.667451    Top1 63.167939    
2023-01-05 16:44:15,066 - ==> Top1: 63.168    Loss: 0.667

2023-01-05 16:44:15,067 - ==> Confusion:
[[344  85   0]
 [301 318   0]
 [  0   0   0]]

2023-01-05 16:44:15,068 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:15,068 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:15,078 - 

2023-01-05 16:44:15,078 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:15,559 - Epoch: [176][   10/   37]    Overall Loss 0.670800    Objective Loss 0.670800                                        LR 0.000001    Time 0.047985    
2023-01-05 16:44:15,854 - Epoch: [176][   20/   37]    Overall Loss 0.671754    Objective Loss 0.671754                                        LR 0.000001    Time 0.038756    
2023-01-05 16:44:16,135 - Epoch: [176][   30/   37]    Overall Loss 0.671027    Objective Loss 0.671027                                        LR 0.000001    Time 0.035188    
2023-01-05 16:44:16,329 - Epoch: [176][   37/   37]    Overall Loss 0.670301    Objective Loss 0.670301    Top1 59.623431    LR 0.000001    Time 0.033769    
2023-01-05 16:44:16,397 - --- validate (epoch=176)-----------
2023-01-05 16:44:16,397 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:16,640 - Epoch: [176][    5/    5]    Loss 0.666972    Top1 59.351145    
2023-01-05 16:44:16,700 - ==> Top1: 59.351    Loss: 0.667

2023-01-05 16:44:16,700 - ==> Confusion:
[[362  67   0]
 [359 260   0]
 [  0   0   0]]

2023-01-05 16:44:16,702 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:16,702 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:16,711 - 

2023-01-05 16:44:16,712 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:17,193 - Epoch: [177][   10/   37]    Overall Loss 0.671702    Objective Loss 0.671702                                        LR 0.000001    Time 0.048088    
2023-01-05 16:44:17,498 - Epoch: [177][   20/   37]    Overall Loss 0.672203    Objective Loss 0.672203                                        LR 0.000001    Time 0.039271    
2023-01-05 16:44:17,801 - Epoch: [177][   30/   37]    Overall Loss 0.671036    Objective Loss 0.671036                                        LR 0.000001    Time 0.036274    
2023-01-05 16:44:17,997 - Epoch: [177][   37/   37]    Overall Loss 0.670658    Objective Loss 0.670658    Top1 52.092050    LR 0.000001    Time 0.034702    
2023-01-05 16:44:18,073 - --- validate (epoch=177)-----------
2023-01-05 16:44:18,073 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:18,324 - Epoch: [177][    5/    5]    Loss 0.671143    Top1 53.435115    
2023-01-05 16:44:18,395 - ==> Top1: 53.435    Loss: 0.671

2023-01-05 16:44:18,396 - ==> Confusion:
[[393  36   0]
 [452 167   0]
 [  0   0   0]]

2023-01-05 16:44:18,397 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:18,397 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:18,407 - 

2023-01-05 16:44:18,407 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:18,884 - Epoch: [178][   10/   37]    Overall Loss 0.670210    Objective Loss 0.670210                                        LR 0.000001    Time 0.047630    
2023-01-05 16:44:19,194 - Epoch: [178][   20/   37]    Overall Loss 0.671010    Objective Loss 0.671010                                        LR 0.000001    Time 0.039140    
2023-01-05 16:44:19,498 - Epoch: [178][   30/   37]    Overall Loss 0.670353    Objective Loss 0.670353                                        LR 0.000001    Time 0.036217    
2023-01-05 16:44:19,694 - Epoch: [178][   37/   37]    Overall Loss 0.670332    Objective Loss 0.670332    Top1 58.577406    LR 0.000001    Time 0.034662    
2023-01-05 16:44:19,765 - --- validate (epoch=178)-----------
2023-01-05 16:44:19,765 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:20,011 - Epoch: [178][    5/    5]    Loss 0.671469    Top1 60.496183    
2023-01-05 16:44:20,080 - ==> Top1: 60.496    Loss: 0.671

2023-01-05 16:44:20,080 - ==> Confusion:
[[349  80   0]
 [334 285   0]
 [  0   0   0]]

2023-01-05 16:44:20,082 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:20,082 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:20,091 - 

2023-01-05 16:44:20,091 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:20,583 - Epoch: [179][   10/   37]    Overall Loss 0.667761    Objective Loss 0.667761                                        LR 0.000001    Time 0.049060    
2023-01-05 16:44:20,871 - Epoch: [179][   20/   37]    Overall Loss 0.668799    Objective Loss 0.668799                                        LR 0.000001    Time 0.038912    
2023-01-05 16:44:21,174 - Epoch: [179][   30/   37]    Overall Loss 0.669509    Objective Loss 0.669509                                        LR 0.000001    Time 0.036021    
2023-01-05 16:44:21,369 - Epoch: [179][   37/   37]    Overall Loss 0.669856    Objective Loss 0.669856    Top1 58.786611    LR 0.000001    Time 0.034482    
2023-01-05 16:44:21,444 - --- validate (epoch=179)-----------
2023-01-05 16:44:21,445 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:21,687 - Epoch: [179][    5/    5]    Loss 0.669598    Top1 60.591603    
2023-01-05 16:44:21,757 - ==> Top1: 60.592    Loss: 0.670

2023-01-05 16:44:21,758 - ==> Confusion:
[[350  79   0]
 [334 285   0]
 [  0   0   0]]

2023-01-05 16:44:21,759 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:21,759 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:21,779 - 

2023-01-05 16:44:21,779 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:22,266 - Epoch: [180][   10/   37]    Overall Loss 0.672649    Objective Loss 0.672649                                        LR 0.000001    Time 0.048633    
2023-01-05 16:44:22,567 - Epoch: [180][   20/   37]    Overall Loss 0.671411    Objective Loss 0.671411                                        LR 0.000001    Time 0.039341    
2023-01-05 16:44:22,867 - Epoch: [180][   30/   37]    Overall Loss 0.670120    Objective Loss 0.670120                                        LR 0.000001    Time 0.036147    
2023-01-05 16:44:23,063 - Epoch: [180][   37/   37]    Overall Loss 0.670095    Objective Loss 0.670095    Top1 64.016736    LR 0.000001    Time 0.034588    
2023-01-05 16:44:23,142 - --- validate (epoch=180)-----------
2023-01-05 16:44:23,143 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:23,378 - Epoch: [180][    5/    5]    Loss 0.669959    Top1 61.354962    
2023-01-05 16:44:23,442 - ==> Top1: 61.355    Loss: 0.670

2023-01-05 16:44:23,442 - ==> Confusion:
[[350  79   0]
 [326 293   0]
 [  0   0   0]]

2023-01-05 16:44:23,444 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:23,444 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:23,464 - 

2023-01-05 16:44:23,464 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:23,956 - Epoch: [181][   10/   37]    Overall Loss 0.671463    Objective Loss 0.671463                                        LR 0.000001    Time 0.049173    
2023-01-05 16:44:24,239 - Epoch: [181][   20/   37]    Overall Loss 0.669843    Objective Loss 0.669843                                        LR 0.000001    Time 0.038707    
2023-01-05 16:44:24,538 - Epoch: [181][   30/   37]    Overall Loss 0.670360    Objective Loss 0.670360                                        LR 0.000001    Time 0.035738    
2023-01-05 16:44:24,732 - Epoch: [181][   37/   37]    Overall Loss 0.670138    Objective Loss 0.670138    Top1 62.343096    LR 0.000001    Time 0.034222    
2023-01-05 16:44:24,816 - --- validate (epoch=181)-----------
2023-01-05 16:44:24,816 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:25,059 - Epoch: [181][    5/    5]    Loss 0.671626    Top1 60.877863    
2023-01-05 16:44:25,128 - ==> Top1: 60.878    Loss: 0.672

2023-01-05 16:44:25,128 - ==> Confusion:
[[352  77   0]
 [333 286   0]
 [  0   0   0]]

2023-01-05 16:44:25,130 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:25,130 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:25,140 - 

2023-01-05 16:44:25,140 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:25,621 - Epoch: [182][   10/   37]    Overall Loss 0.669181    Objective Loss 0.669181                                        LR 0.000001    Time 0.048005    
2023-01-05 16:44:25,926 - Epoch: [182][   20/   37]    Overall Loss 0.668575    Objective Loss 0.668575                                        LR 0.000001    Time 0.039243    
2023-01-05 16:44:26,231 - Epoch: [182][   30/   37]    Overall Loss 0.669923    Objective Loss 0.669923                                        LR 0.000001    Time 0.036315    
2023-01-05 16:44:26,427 - Epoch: [182][   37/   37]    Overall Loss 0.670240    Objective Loss 0.670240    Top1 61.297071    LR 0.000001    Time 0.034717    
2023-01-05 16:44:26,496 - --- validate (epoch=182)-----------
2023-01-05 16:44:26,497 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:26,734 - Epoch: [182][    5/    5]    Loss 0.679962    Top1 62.690840    
2023-01-05 16:44:26,794 - ==> Top1: 62.691    Loss: 0.680

2023-01-05 16:44:26,795 - ==> Confusion:
[[337  92   0]
 [299 320   0]
 [  0   0   0]]

2023-01-05 16:44:26,796 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:26,796 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:26,806 - 

2023-01-05 16:44:26,806 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:27,311 - Epoch: [183][   10/   37]    Overall Loss 0.671454    Objective Loss 0.671454                                        LR 0.000001    Time 0.050376    
2023-01-05 16:44:27,616 - Epoch: [183][   20/   37]    Overall Loss 0.671050    Objective Loss 0.671050                                        LR 0.000001    Time 0.040446    
2023-01-05 16:44:27,921 - Epoch: [183][   30/   37]    Overall Loss 0.670995    Objective Loss 0.670995                                        LR 0.000001    Time 0.037110    
2023-01-05 16:44:28,117 - Epoch: [183][   37/   37]    Overall Loss 0.670214    Objective Loss 0.670214    Top1 60.669456    LR 0.000001    Time 0.035373    
2023-01-05 16:44:28,193 - --- validate (epoch=183)-----------
2023-01-05 16:44:28,193 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:28,425 - Epoch: [183][    5/    5]    Loss 0.672791    Top1 60.687023    
2023-01-05 16:44:28,487 - ==> Top1: 60.687    Loss: 0.673

2023-01-05 16:44:28,488 - ==> Confusion:
[[356  73   0]
 [339 280   0]
 [  0   0   0]]

2023-01-05 16:44:28,489 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:28,489 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:28,499 - 

2023-01-05 16:44:28,499 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:28,997 - Epoch: [184][   10/   37]    Overall Loss 0.671499    Objective Loss 0.671499                                        LR 0.000001    Time 0.049688    
2023-01-05 16:44:29,293 - Epoch: [184][   20/   37]    Overall Loss 0.671918    Objective Loss 0.671918                                        LR 0.000001    Time 0.039656    
2023-01-05 16:44:29,602 - Epoch: [184][   30/   37]    Overall Loss 0.671045    Objective Loss 0.671045                                        LR 0.000001    Time 0.036718    
2023-01-05 16:44:29,800 - Epoch: [184][   37/   37]    Overall Loss 0.670017    Objective Loss 0.670017    Top1 61.506276    LR 0.000001    Time 0.035101    
2023-01-05 16:44:29,870 - --- validate (epoch=184)-----------
2023-01-05 16:44:29,871 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:30,107 - Epoch: [184][    5/    5]    Loss 0.674425    Top1 59.255725    
2023-01-05 16:44:30,164 - ==> Top1: 59.256    Loss: 0.674

2023-01-05 16:44:30,164 - ==> Confusion:
[[366  63   0]
 [364 255   0]
 [  0   0   0]]

2023-01-05 16:44:30,165 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:30,166 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:30,175 - 

2023-01-05 16:44:30,175 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:30,672 - Epoch: [185][   10/   37]    Overall Loss 0.667521    Objective Loss 0.667521                                        LR 0.000001    Time 0.049549    
2023-01-05 16:44:30,970 - Epoch: [185][   20/   37]    Overall Loss 0.669618    Objective Loss 0.669618                                        LR 0.000001    Time 0.039666    
2023-01-05 16:44:31,275 - Epoch: [185][   30/   37]    Overall Loss 0.670097    Objective Loss 0.670097                                        LR 0.000001    Time 0.036603    
2023-01-05 16:44:31,471 - Epoch: [185][   37/   37]    Overall Loss 0.670000    Objective Loss 0.670000    Top1 62.343096    LR 0.000001    Time 0.034970    
2023-01-05 16:44:31,545 - --- validate (epoch=185)-----------
2023-01-05 16:44:31,545 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:31,789 - Epoch: [185][    5/    5]    Loss 0.667599    Top1 62.881679    
2023-01-05 16:44:31,851 - ==> Top1: 62.882    Loss: 0.668

2023-01-05 16:44:31,851 - ==> Confusion:
[[331  98   0]
 [291 328   0]
 [  0   0   0]]

2023-01-05 16:44:31,853 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:31,853 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:31,873 - 

2023-01-05 16:44:31,873 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:32,375 - Epoch: [186][   10/   37]    Overall Loss 0.669598    Objective Loss 0.669598                                        LR 0.000001    Time 0.050150    
2023-01-05 16:44:32,675 - Epoch: [186][   20/   37]    Overall Loss 0.670698    Objective Loss 0.670698                                        LR 0.000001    Time 0.040020    
2023-01-05 16:44:32,975 - Epoch: [186][   30/   37]    Overall Loss 0.670085    Objective Loss 0.670085                                        LR 0.000001    Time 0.036665    
2023-01-05 16:44:33,172 - Epoch: [186][   37/   37]    Overall Loss 0.669960    Objective Loss 0.669960    Top1 64.225941    LR 0.000001    Time 0.035044    
2023-01-05 16:44:33,244 - --- validate (epoch=186)-----------
2023-01-05 16:44:33,244 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:33,477 - Epoch: [186][    5/    5]    Loss 0.670653    Top1 65.267176    
2023-01-05 16:44:33,550 - ==> Top1: 65.267    Loss: 0.671

2023-01-05 16:44:33,550 - ==> Confusion:
[[313 116   0]
 [248 371   0]
 [  0   0   0]]

2023-01-05 16:44:33,552 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:33,552 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:33,572 - 

2023-01-05 16:44:33,572 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:34,049 - Epoch: [187][   10/   37]    Overall Loss 0.670297    Objective Loss 0.670297                                        LR 0.000001    Time 0.047636    
2023-01-05 16:44:34,347 - Epoch: [187][   20/   37]    Overall Loss 0.668431    Objective Loss 0.668431                                        LR 0.000001    Time 0.038671    
2023-01-05 16:44:34,657 - Epoch: [187][   30/   37]    Overall Loss 0.669388    Objective Loss 0.669388                                        LR 0.000001    Time 0.036113    
2023-01-05 16:44:34,849 - Epoch: [187][   37/   37]    Overall Loss 0.669975    Objective Loss 0.669975    Top1 60.669456    LR 0.000001    Time 0.034473    
2023-01-05 16:44:34,922 - --- validate (epoch=187)-----------
2023-01-05 16:44:34,922 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:35,157 - Epoch: [187][    5/    5]    Loss 0.669653    Top1 62.213740    
2023-01-05 16:44:35,239 - ==> Top1: 62.214    Loss: 0.670

2023-01-05 16:44:35,239 - ==> Confusion:
[[344  85   0]
 [311 308   0]
 [  0   0   0]]

2023-01-05 16:44:35,241 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:35,241 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:35,251 - 

2023-01-05 16:44:35,251 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:35,741 - Epoch: [188][   10/   37]    Overall Loss 0.669859    Objective Loss 0.669859                                        LR 0.000001    Time 0.048972    
2023-01-05 16:44:36,035 - Epoch: [188][   20/   37]    Overall Loss 0.669827    Objective Loss 0.669827                                        LR 0.000001    Time 0.039149    
2023-01-05 16:44:36,336 - Epoch: [188][   30/   37]    Overall Loss 0.669882    Objective Loss 0.669882                                        LR 0.000001    Time 0.036127    
2023-01-05 16:44:36,532 - Epoch: [188][   37/   37]    Overall Loss 0.669719    Objective Loss 0.669719    Top1 61.087866    LR 0.000001    Time 0.034583    
2023-01-05 16:44:36,617 - --- validate (epoch=188)-----------
2023-01-05 16:44:36,618 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:36,872 - Epoch: [188][    5/    5]    Loss 0.668706    Top1 60.687023    
2023-01-05 16:44:36,940 - ==> Top1: 60.687    Loss: 0.669

2023-01-05 16:44:36,940 - ==> Confusion:
[[346  83   0]
 [329 290   0]
 [  0   0   0]]

2023-01-05 16:44:36,942 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:36,942 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:36,952 - 

2023-01-05 16:44:36,952 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:37,456 - Epoch: [189][   10/   37]    Overall Loss 0.668729    Objective Loss 0.668729                                        LR 0.000001    Time 0.050279    
2023-01-05 16:44:37,739 - Epoch: [189][   20/   37]    Overall Loss 0.669483    Objective Loss 0.669483                                        LR 0.000001    Time 0.039300    
2023-01-05 16:44:38,030 - Epoch: [189][   30/   37]    Overall Loss 0.669786    Objective Loss 0.669786                                        LR 0.000001    Time 0.035885    
2023-01-05 16:44:38,228 - Epoch: [189][   37/   37]    Overall Loss 0.669686    Objective Loss 0.669686    Top1 65.899582    LR 0.000001    Time 0.034422    
2023-01-05 16:44:38,295 - --- validate (epoch=189)-----------
2023-01-05 16:44:38,295 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:38,532 - Epoch: [189][    5/    5]    Loss 0.673083    Top1 63.358779    
2023-01-05 16:44:38,596 - ==> Top1: 63.359    Loss: 0.673

2023-01-05 16:44:38,596 - ==> Confusion:
[[327 102   0]
 [282 337   0]
 [  0   0   0]]

2023-01-05 16:44:38,597 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:38,598 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:38,607 - 

2023-01-05 16:44:38,607 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:39,099 - Epoch: [190][   10/   37]    Overall Loss 0.670607    Objective Loss 0.670607                                        LR 0.000000    Time 0.049039    
2023-01-05 16:44:39,399 - Epoch: [190][   20/   37]    Overall Loss 0.669827    Objective Loss 0.669827                                        LR 0.000000    Time 0.039495    
2023-01-05 16:44:39,698 - Epoch: [190][   30/   37]    Overall Loss 0.670450    Objective Loss 0.670450                                        LR 0.000000    Time 0.036309    
2023-01-05 16:44:39,895 - Epoch: [190][   37/   37]    Overall Loss 0.669762    Objective Loss 0.669762    Top1 59.623431    LR 0.000000    Time 0.034761    
2023-01-05 16:44:39,983 - --- validate (epoch=190)-----------
2023-01-05 16:44:39,983 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:40,223 - Epoch: [190][    5/    5]    Loss 0.670583    Top1 61.545802    
2023-01-05 16:44:40,299 - ==> Top1: 61.546    Loss: 0.671

2023-01-05 16:44:40,300 - ==> Confusion:
[[341  88   0]
 [315 304   0]
 [  0   0   0]]

2023-01-05 16:44:40,301 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:40,301 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:40,311 - 

2023-01-05 16:44:40,311 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:40,908 - Epoch: [191][   10/   37]    Overall Loss 0.671100    Objective Loss 0.671100                                        LR 0.000000    Time 0.059631    
2023-01-05 16:44:41,217 - Epoch: [191][   20/   37]    Overall Loss 0.670081    Objective Loss 0.670081                                        LR 0.000000    Time 0.045254    
2023-01-05 16:44:41,518 - Epoch: [191][   30/   37]    Overall Loss 0.669463    Objective Loss 0.669463                                        LR 0.000000    Time 0.040183    
2023-01-05 16:44:41,711 - Epoch: [191][   37/   37]    Overall Loss 0.669485    Objective Loss 0.669485    Top1 59.832636    LR 0.000000    Time 0.037795    
2023-01-05 16:44:41,782 - --- validate (epoch=191)-----------
2023-01-05 16:44:41,783 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:42,022 - Epoch: [191][    5/    5]    Loss 0.666481    Top1 61.832061    
2023-01-05 16:44:42,097 - ==> Top1: 61.832    Loss: 0.666

2023-01-05 16:44:42,097 - ==> Confusion:
[[336  93   0]
 [307 312   0]
 [  0   0   0]]

2023-01-05 16:44:42,099 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:42,099 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:42,116 - 

2023-01-05 16:44:42,116 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:42,608 - Epoch: [192][   10/   37]    Overall Loss 0.668684    Objective Loss 0.668684                                        LR 0.000000    Time 0.049208    
2023-01-05 16:44:42,897 - Epoch: [192][   20/   37]    Overall Loss 0.669832    Objective Loss 0.669832                                        LR 0.000000    Time 0.038992    
2023-01-05 16:44:43,178 - Epoch: [192][   30/   37]    Overall Loss 0.669731    Objective Loss 0.669731                                        LR 0.000000    Time 0.035371    
2023-01-05 16:44:43,371 - Epoch: [192][   37/   37]    Overall Loss 0.669572    Objective Loss 0.669572    Top1 62.970711    LR 0.000000    Time 0.033887    
2023-01-05 16:44:43,442 - --- validate (epoch=192)-----------
2023-01-05 16:44:43,442 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:43,679 - Epoch: [192][    5/    5]    Loss 0.664053    Top1 61.832061    
2023-01-05 16:44:43,739 - ==> Top1: 61.832    Loss: 0.664

2023-01-05 16:44:43,740 - ==> Confusion:
[[341  88   0]
 [312 307   0]
 [  0   0   0]]

2023-01-05 16:44:43,741 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:43,741 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:43,761 - 

2023-01-05 16:44:43,761 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:44,237 - Epoch: [193][   10/   37]    Overall Loss 0.671417    Objective Loss 0.671417                                        LR 0.000000    Time 0.047436    
2023-01-05 16:44:44,522 - Epoch: [193][   20/   37]    Overall Loss 0.669906    Objective Loss 0.669906                                        LR 0.000000    Time 0.037975    
2023-01-05 16:44:44,813 - Epoch: [193][   30/   37]    Overall Loss 0.669685    Objective Loss 0.669685                                        LR 0.000000    Time 0.034888    
2023-01-05 16:44:45,005 - Epoch: [193][   37/   37]    Overall Loss 0.669357    Objective Loss 0.669357    Top1 61.924686    LR 0.000000    Time 0.033487    
2023-01-05 16:44:45,080 - --- validate (epoch=193)-----------
2023-01-05 16:44:45,080 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:45,314 - Epoch: [193][    5/    5]    Loss 0.670817    Top1 62.213740    
2023-01-05 16:44:45,382 - ==> Top1: 62.214    Loss: 0.671

2023-01-05 16:44:45,383 - ==> Confusion:
[[338  91   0]
 [305 314   0]
 [  0   0   0]]

2023-01-05 16:44:45,384 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:45,385 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:45,394 - 

2023-01-05 16:44:45,395 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:45,895 - Epoch: [194][   10/   37]    Overall Loss 0.670888    Objective Loss 0.670888                                        LR 0.000000    Time 0.049964    
2023-01-05 16:44:46,193 - Epoch: [194][   20/   37]    Overall Loss 0.670110    Objective Loss 0.670110                                        LR 0.000000    Time 0.039843    
2023-01-05 16:44:46,502 - Epoch: [194][   30/   37]    Overall Loss 0.670388    Objective Loss 0.670388                                        LR 0.000000    Time 0.036864    
2023-01-05 16:44:46,702 - Epoch: [194][   37/   37]    Overall Loss 0.669435    Objective Loss 0.669435    Top1 64.644351    LR 0.000000    Time 0.035275    
2023-01-05 16:44:46,780 - --- validate (epoch=194)-----------
2023-01-05 16:44:46,780 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:47,020 - Epoch: [194][    5/    5]    Loss 0.673731    Top1 61.736641    
2023-01-05 16:44:47,080 - ==> Top1: 61.737    Loss: 0.674

2023-01-05 16:44:47,081 - ==> Confusion:
[[343  86   0]
 [315 304   0]
 [  0   0   0]]

2023-01-05 16:44:47,082 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:47,082 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:47,092 - 

2023-01-05 16:44:47,092 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:47,576 - Epoch: [195][   10/   37]    Overall Loss 0.668030    Objective Loss 0.668030                                        LR 0.000000    Time 0.048342    
2023-01-05 16:44:47,873 - Epoch: [195][   20/   37]    Overall Loss 0.668806    Objective Loss 0.668806                                        LR 0.000000    Time 0.038987    
2023-01-05 16:44:48,184 - Epoch: [195][   30/   37]    Overall Loss 0.669367    Objective Loss 0.669367                                        LR 0.000000    Time 0.036230    
2023-01-05 16:44:48,378 - Epoch: [195][   37/   37]    Overall Loss 0.669438    Objective Loss 0.669438    Top1 58.786611    LR 0.000000    Time 0.034623    
2023-01-05 16:44:48,452 - --- validate (epoch=195)-----------
2023-01-05 16:44:48,452 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:48,688 - Epoch: [195][    5/    5]    Loss 0.671479    Top1 60.305344    
2023-01-05 16:44:48,757 - ==> Top1: 60.305    Loss: 0.671

2023-01-05 16:44:48,758 - ==> Confusion:
[[362  67   0]
 [349 270   0]
 [  0   0   0]]

2023-01-05 16:44:48,759 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:48,759 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:48,769 - 

2023-01-05 16:44:48,769 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:49,247 - Epoch: [196][   10/   37]    Overall Loss 0.667761    Objective Loss 0.667761                                        LR 0.000000    Time 0.047732    
2023-01-05 16:44:49,546 - Epoch: [196][   20/   37]    Overall Loss 0.668431    Objective Loss 0.668431                                        LR 0.000000    Time 0.038772    
2023-01-05 16:44:49,832 - Epoch: [196][   30/   37]    Overall Loss 0.668188    Objective Loss 0.668188                                        LR 0.000000    Time 0.035374    
2023-01-05 16:44:50,025 - Epoch: [196][   37/   37]    Overall Loss 0.669162    Objective Loss 0.669162    Top1 62.970711    LR 0.000000    Time 0.033903    
2023-01-05 16:44:50,099 - --- validate (epoch=196)-----------
2023-01-05 16:44:50,099 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:50,342 - Epoch: [196][    5/    5]    Loss 0.673569    Top1 62.786260    
2023-01-05 16:44:50,419 - ==> Top1: 62.786    Loss: 0.674

2023-01-05 16:44:50,419 - ==> Confusion:
[[336  93   0]
 [297 322   0]
 [  0   0   0]]

2023-01-05 16:44:50,421 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:50,421 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:50,430 - 

2023-01-05 16:44:50,431 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:50,932 - Epoch: [197][   10/   37]    Overall Loss 0.670382    Objective Loss 0.670382                                        LR 0.000000    Time 0.050018    
2023-01-05 16:44:51,233 - Epoch: [197][   20/   37]    Overall Loss 0.670106    Objective Loss 0.670106                                        LR 0.000000    Time 0.040044    
2023-01-05 16:44:51,540 - Epoch: [197][   30/   37]    Overall Loss 0.669664    Objective Loss 0.669664                                        LR 0.000000    Time 0.036928    
2023-01-05 16:44:51,738 - Epoch: [197][   37/   37]    Overall Loss 0.669096    Objective Loss 0.669096    Top1 62.970711    LR 0.000000    Time 0.035287    
2023-01-05 16:44:51,812 - --- validate (epoch=197)-----------
2023-01-05 16:44:51,812 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:52,059 - Epoch: [197][    5/    5]    Loss 0.677809    Top1 62.690840    
2023-01-05 16:44:52,128 - ==> Top1: 62.691    Loss: 0.678

2023-01-05 16:44:52,128 - ==> Confusion:
[[337  92   0]
 [299 320   0]
 [  0   0   0]]

2023-01-05 16:44:52,130 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:52,130 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:52,150 - 

2023-01-05 16:44:52,150 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:52,637 - Epoch: [198][   10/   37]    Overall Loss 0.671916    Objective Loss 0.671916                                        LR 0.000000    Time 0.048597    
2023-01-05 16:44:52,945 - Epoch: [198][   20/   37]    Overall Loss 0.669255    Objective Loss 0.669255                                        LR 0.000000    Time 0.039677    
2023-01-05 16:44:53,249 - Epoch: [198][   30/   37]    Overall Loss 0.669023    Objective Loss 0.669023                                        LR 0.000000    Time 0.036590    
2023-01-05 16:44:53,446 - Epoch: [198][   37/   37]    Overall Loss 0.669148    Objective Loss 0.669148    Top1 60.041841    LR 0.000000    Time 0.034992    
2023-01-05 16:44:53,526 - --- validate (epoch=198)-----------
2023-01-05 16:44:53,527 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:53,772 - Epoch: [198][    5/    5]    Loss 0.670638    Top1 60.400763    
2023-01-05 16:44:53,832 - ==> Top1: 60.401    Loss: 0.671

2023-01-05 16:44:53,832 - ==> Confusion:
[[348  81   0]
 [334 285   0]
 [  0   0   0]]

2023-01-05 16:44:53,834 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:53,834 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:53,855 - 

2023-01-05 16:44:53,855 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-05 16:44:54,352 - Epoch: [199][   10/   37]    Overall Loss 0.667394    Objective Loss 0.667394                                        LR 0.000000    Time 0.049650    
2023-01-05 16:44:54,660 - Epoch: [199][   20/   37]    Overall Loss 0.668599    Objective Loss 0.668599                                        LR 0.000000    Time 0.040214    
2023-01-05 16:44:54,964 - Epoch: [199][   30/   37]    Overall Loss 0.668955    Objective Loss 0.668955                                        LR 0.000000    Time 0.036823    
2023-01-05 16:44:55,154 - Epoch: [199][   37/   37]    Overall Loss 0.668867    Objective Loss 0.668867    Top1 65.062762    LR 0.000000    Time 0.034986    
2023-01-05 16:44:55,239 - --- validate (epoch=199)-----------
2023-01-05 16:44:55,239 - 1048 samples (256 per mini-batch)
2023-01-05 16:44:55,480 - Epoch: [199][    5/    5]    Loss 0.674376    Top1 63.072519    
2023-01-05 16:44:55,545 - ==> Top1: 63.073    Loss: 0.674

2023-01-05 16:44:55,546 - ==> Confusion:
[[336  93   0]
 [294 325   0]
 [  0   0   0]]

2023-01-05 16:44:55,547 - ==> Best [Top1: 66.794   Sparsity:0.00   Params: 361664 on epoch: 160]
2023-01-05 16:44:55,548 - Saving checkpoint to: logs/2023.01.05-163904/qat_checkpoint.pth.tar
2023-01-05 16:44:55,557 - --- test ---------------------
2023-01-05 16:44:55,557 - 1317 samples (256 per mini-batch)
2023-01-05 16:44:55,823 - Test: [    6/    6]    Loss 0.679179    Top1 59.377373    
2023-01-05 16:44:55,894 - ==> Top1: 59.377    Loss: 0.679

2023-01-05 16:44:55,894 - ==> Confusion:
[[465  96   0]
 [439 317   0]
 [  0   0   0]]

2023-01-05 16:44:55,905 - 
2023-01-05 16:44:55,905 - Log file for this run: /home/ubuntumaschin/KeyWordSpotting_on_MAX78000/ai8x-training/logs/2023.01.05-163904/2023.01.05-163904.log
