2023-01-06 15:45:08,109 - Log file for this run: /home/ubuntumaschin/KeyWordSpotting_on_MAX78000/ai8x-training/logs/2023.01.06-154508/2023.01.06-154508.log
2023-01-06 15:45:10,131 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2023-01-06 15:45:10,131 - Optimizer Args: {'lr': 6e-05, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2023-01-06 15:45:19,153 - Dataset sizes:
	training=9438
	validation=1048
	test=1317
2023-01-06 15:45:19,153 - Reading compression schedule from: policies/schedule_kws20_v2.yaml
2023-01-06 15:45:19,156 - 

2023-01-06 15:45:19,156 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:19,716 - Epoch: [0][   10/   37]    Overall Loss 1.096107    Objective Loss 1.096107                                        LR 0.000060    Time 0.055916    
2023-01-06 15:45:19,865 - Epoch: [0][   20/   37]    Overall Loss 1.092156    Objective Loss 1.092156                                        LR 0.000060    Time 0.035352    
2023-01-06 15:45:20,049 - Epoch: [0][   30/   37]    Overall Loss 1.084894    Objective Loss 1.084894                                        LR 0.000060    Time 0.029700    
2023-01-06 15:45:20,160 - Epoch: [0][   37/   37]    Overall Loss 1.075898    Objective Loss 1.075898    Top1 56.276151    LR 0.000060    Time 0.027081    
2023-01-06 15:45:20,241 - --- validate (epoch=0)-----------
2023-01-06 15:45:20,242 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:20,451 - Epoch: [0][    5/    5]    Loss 1.008041    Top1 59.064885    
2023-01-06 15:45:20,518 - ==> Top1: 59.065    Loss: 1.008

2023-01-06 15:45:20,518 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:20,519 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 0]
2023-01-06 15:45:20,519 - Saving checkpoint to: logs/2023.01.06-154508/checkpoint.pth.tar
2023-01-06 15:45:20,526 - 

2023-01-06 15:45:20,526 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:20,846 - Epoch: [1][   10/   37]    Overall Loss 0.965128    Objective Loss 0.965128                                        LR 0.000060    Time 0.031885    
2023-01-06 15:45:20,999 - Epoch: [1][   20/   37]    Overall Loss 0.907206    Objective Loss 0.907206                                        LR 0.000060    Time 0.023572    
2023-01-06 15:45:21,183 - Epoch: [1][   30/   37]    Overall Loss 0.863790    Objective Loss 0.863790                                        LR 0.000060    Time 0.021823    
2023-01-06 15:45:21,288 - Epoch: [1][   37/   37]    Overall Loss 0.839665    Objective Loss 0.839665    Top1 56.903766    LR 0.000060    Time 0.020539    
2023-01-06 15:45:21,366 - --- validate (epoch=1)-----------
2023-01-06 15:45:21,366 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:21,565 - Epoch: [1][    5/    5]    Loss 0.717146    Top1 59.064885    
2023-01-06 15:45:21,630 - ==> Top1: 59.065    Loss: 0.717

2023-01-06 15:45:21,630 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:21,631 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 1]
2023-01-06 15:45:21,631 - Saving checkpoint to: logs/2023.01.06-154508/checkpoint.pth.tar
2023-01-06 15:45:21,639 - 

2023-01-06 15:45:21,639 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:21,946 - Epoch: [2][   10/   37]    Overall Loss 0.726836    Objective Loss 0.726836                                        LR 0.000060    Time 0.030619    
2023-01-06 15:45:22,068 - Epoch: [2][   20/   37]    Overall Loss 0.723749    Objective Loss 0.723749                                        LR 0.000060    Time 0.021381    
2023-01-06 15:45:22,190 - Epoch: [2][   30/   37]    Overall Loss 0.720309    Objective Loss 0.720309                                        LR 0.000060    Time 0.018331    
2023-01-06 15:45:22,270 - Epoch: [2][   37/   37]    Overall Loss 0.718966    Objective Loss 0.718966    Top1 58.368201    LR 0.000060    Time 0.017007    
2023-01-06 15:45:22,343 - --- validate (epoch=2)-----------
2023-01-06 15:45:22,343 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:22,545 - Epoch: [2][    5/    5]    Loss 0.714909    Top1 59.064885    
2023-01-06 15:45:22,608 - ==> Top1: 59.065    Loss: 0.715

2023-01-06 15:45:22,609 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:22,610 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 2]
2023-01-06 15:45:22,610 - Saving checkpoint to: logs/2023.01.06-154508/checkpoint.pth.tar
2023-01-06 15:45:22,617 - 

2023-01-06 15:45:22,618 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:22,938 - Epoch: [3][   10/   37]    Overall Loss 0.715010    Objective Loss 0.715010                                        LR 0.000060    Time 0.031940    
2023-01-06 15:45:23,074 - Epoch: [3][   20/   37]    Overall Loss 0.712543    Objective Loss 0.712543                                        LR 0.000060    Time 0.022773    
2023-01-06 15:45:23,222 - Epoch: [3][   30/   37]    Overall Loss 0.712772    Objective Loss 0.712772                                        LR 0.000060    Time 0.020087    
2023-01-06 15:45:23,306 - Epoch: [3][   37/   37]    Overall Loss 0.710627    Objective Loss 0.710627    Top1 58.786611    LR 0.000060    Time 0.018566    
2023-01-06 15:45:23,378 - --- validate (epoch=3)-----------
2023-01-06 15:45:23,378 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:23,588 - Epoch: [3][    5/    5]    Loss 0.697231    Top1 59.064885    
2023-01-06 15:45:23,652 - ==> Top1: 59.065    Loss: 0.697

2023-01-06 15:45:23,653 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:23,654 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 3]
2023-01-06 15:45:23,654 - Saving checkpoint to: logs/2023.01.06-154508/checkpoint.pth.tar
2023-01-06 15:45:23,661 - 

2023-01-06 15:45:23,661 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:23,978 - Epoch: [4][   10/   37]    Overall Loss 0.709322    Objective Loss 0.709322                                        LR 0.000060    Time 0.031591    
2023-01-06 15:45:24,106 - Epoch: [4][   20/   37]    Overall Loss 0.707892    Objective Loss 0.707892                                        LR 0.000060    Time 0.022214    
2023-01-06 15:45:24,242 - Epoch: [4][   30/   37]    Overall Loss 0.706127    Objective Loss 0.706127                                        LR 0.000060    Time 0.019318    
2023-01-06 15:45:24,318 - Epoch: [4][   37/   37]    Overall Loss 0.705537    Objective Loss 0.705537    Top1 55.439331    LR 0.000060    Time 0.017716    
2023-01-06 15:45:24,387 - --- validate (epoch=4)-----------
2023-01-06 15:45:24,388 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:24,588 - Epoch: [4][    5/    5]    Loss 0.688158    Top1 59.064885    
2023-01-06 15:45:24,646 - ==> Top1: 59.065    Loss: 0.688

2023-01-06 15:45:24,647 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:24,648 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 4]
2023-01-06 15:45:24,648 - Saving checkpoint to: logs/2023.01.06-154508/checkpoint.pth.tar
2023-01-06 15:45:24,655 - 

2023-01-06 15:45:24,656 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:24,962 - Epoch: [5][   10/   37]    Overall Loss 0.708660    Objective Loss 0.708660                                        LR 0.000060    Time 0.030529    
2023-01-06 15:45:25,094 - Epoch: [5][   20/   37]    Overall Loss 0.706128    Objective Loss 0.706128                                        LR 0.000060    Time 0.021868    
2023-01-06 15:45:25,269 - Epoch: [5][   30/   37]    Overall Loss 0.703605    Objective Loss 0.703605                                        LR 0.000060    Time 0.020336    
2023-01-06 15:45:25,367 - Epoch: [5][   37/   37]    Overall Loss 0.701933    Objective Loss 0.701933    Top1 58.158996    LR 0.000060    Time 0.019141    
2023-01-06 15:45:25,444 - --- validate (epoch=5)-----------
2023-01-06 15:45:25,445 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:25,664 - Epoch: [5][    5/    5]    Loss 0.684827    Top1 59.064885    
2023-01-06 15:45:25,724 - ==> Top1: 59.065    Loss: 0.685

2023-01-06 15:45:25,725 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:25,726 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 5]
2023-01-06 15:45:25,726 - Saving checkpoint to: logs/2023.01.06-154508/checkpoint.pth.tar
2023-01-06 15:45:25,733 - 

2023-01-06 15:45:25,733 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:26,040 - Epoch: [6][   10/   37]    Overall Loss 0.700656    Objective Loss 0.700656                                        LR 0.000060    Time 0.030611    
2023-01-06 15:45:26,160 - Epoch: [6][   20/   37]    Overall Loss 0.697762    Objective Loss 0.697762                                        LR 0.000060    Time 0.021306    
2023-01-06 15:45:26,302 - Epoch: [6][   30/   37]    Overall Loss 0.698602    Objective Loss 0.698602                                        LR 0.000060    Time 0.018904    
2023-01-06 15:45:26,402 - Epoch: [6][   37/   37]    Overall Loss 0.699198    Objective Loss 0.699198    Top1 52.719665    LR 0.000060    Time 0.018022    
2023-01-06 15:45:26,466 - --- validate (epoch=6)-----------
2023-01-06 15:45:26,467 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:26,673 - Epoch: [6][    5/    5]    Loss 0.692624    Top1 59.064885    
2023-01-06 15:45:26,739 - ==> Top1: 59.065    Loss: 0.693

2023-01-06 15:45:26,739 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:26,740 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 6]
2023-01-06 15:45:26,740 - Saving checkpoint to: logs/2023.01.06-154508/checkpoint.pth.tar
2023-01-06 15:45:26,747 - 

2023-01-06 15:45:26,747 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:27,097 - Epoch: [7][   10/   37]    Overall Loss 0.700489    Objective Loss 0.700489                                        LR 0.000060    Time 0.034903    
2023-01-06 15:45:27,280 - Epoch: [7][   20/   37]    Overall Loss 0.698995    Objective Loss 0.698995                                        LR 0.000060    Time 0.026593    
2023-01-06 15:45:27,467 - Epoch: [7][   30/   37]    Overall Loss 0.698113    Objective Loss 0.698113                                        LR 0.000060    Time 0.023937    
2023-01-06 15:45:27,574 - Epoch: [7][   37/   37]    Overall Loss 0.696953    Objective Loss 0.696953    Top1 59.623431    LR 0.000060    Time 0.022289    
2023-01-06 15:45:27,655 - --- validate (epoch=7)-----------
2023-01-06 15:45:27,655 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:27,856 - Epoch: [7][    5/    5]    Loss 0.687955    Top1 59.064885    
2023-01-06 15:45:27,912 - ==> Top1: 59.065    Loss: 0.688

2023-01-06 15:45:27,912 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:27,914 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 7]
2023-01-06 15:45:27,914 - Saving checkpoint to: logs/2023.01.06-154508/checkpoint.pth.tar
2023-01-06 15:45:27,921 - 

2023-01-06 15:45:27,922 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:28,361 - Epoch: [8][   10/   37]    Overall Loss 0.697363    Objective Loss 0.697363                                        LR 0.000060    Time 0.043915    
2023-01-06 15:45:28,488 - Epoch: [8][   20/   37]    Overall Loss 0.695640    Objective Loss 0.695640                                        LR 0.000060    Time 0.028253    
2023-01-06 15:45:28,665 - Epoch: [8][   30/   37]    Overall Loss 0.695370    Objective Loss 0.695370                                        LR 0.000060    Time 0.024722    
2023-01-06 15:45:28,771 - Epoch: [8][   37/   37]    Overall Loss 0.694988    Objective Loss 0.694988    Top1 56.066946    LR 0.000060    Time 0.022903    
2023-01-06 15:45:28,848 - --- validate (epoch=8)-----------
2023-01-06 15:45:28,849 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:29,051 - Epoch: [8][    5/    5]    Loss 0.699394    Top1 59.064885    
2023-01-06 15:45:29,110 - ==> Top1: 59.065    Loss: 0.699

2023-01-06 15:45:29,111 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:29,112 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 8]
2023-01-06 15:45:29,112 - Saving checkpoint to: logs/2023.01.06-154508/checkpoint.pth.tar
2023-01-06 15:45:29,119 - 

2023-01-06 15:45:29,119 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:29,482 - Epoch: [9][   10/   37]    Overall Loss 0.692458    Objective Loss 0.692458                                        LR 0.000060    Time 0.036145    
2023-01-06 15:45:29,656 - Epoch: [9][   20/   37]    Overall Loss 0.694870    Objective Loss 0.694870                                        LR 0.000060    Time 0.026738    
2023-01-06 15:45:29,825 - Epoch: [9][   30/   37]    Overall Loss 0.694337    Objective Loss 0.694337                                        LR 0.000060    Time 0.023472    
2023-01-06 15:45:29,923 - Epoch: [9][   37/   37]    Overall Loss 0.693487    Objective Loss 0.693487    Top1 55.230126    LR 0.000060    Time 0.021649    
2023-01-06 15:45:30,014 - --- validate (epoch=9)-----------
2023-01-06 15:45:30,015 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:30,214 - Epoch: [9][    5/    5]    Loss 0.693634    Top1 59.064885    
2023-01-06 15:45:30,278 - ==> Top1: 59.065    Loss: 0.694

2023-01-06 15:45:30,278 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:30,279 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 9]
2023-01-06 15:45:30,279 - Saving checkpoint to: logs/2023.01.06-154508/checkpoint.pth.tar
2023-01-06 15:45:30,300 - 

2023-01-06 15:45:30,300 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:30,663 - Epoch: [10][   10/   37]    Overall Loss 0.862777    Objective Loss 0.862777                                        LR 0.000060    Time 0.036274    
2023-01-06 15:45:30,839 - Epoch: [10][   20/   37]    Overall Loss 0.790519    Objective Loss 0.790519                                        LR 0.000060    Time 0.026916    
2023-01-06 15:45:31,032 - Epoch: [10][   30/   37]    Overall Loss 0.757013    Objective Loss 0.757013                                        LR 0.000060    Time 0.024368    
2023-01-06 15:45:31,144 - Epoch: [10][   37/   37]    Overall Loss 0.743039    Objective Loss 0.743039    Top1 60.251046    LR 0.000060    Time 0.022784    
2023-01-06 15:45:31,212 - --- validate (epoch=10)-----------
2023-01-06 15:45:31,212 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:31,431 - Epoch: [10][    5/    5]    Loss 0.681061    Top1 59.064885    
2023-01-06 15:45:31,495 - ==> Top1: 59.065    Loss: 0.681

2023-01-06 15:45:31,495 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:31,496 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 10]
2023-01-06 15:45:31,496 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:31,503 - 

2023-01-06 15:45:31,503 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:31,865 - Epoch: [11][   10/   37]    Overall Loss 0.686853    Objective Loss 0.686853                                        LR 0.000060    Time 0.036174    
2023-01-06 15:45:32,061 - Epoch: [11][   20/   37]    Overall Loss 0.683181    Objective Loss 0.683181                                        LR 0.000060    Time 0.027854    
2023-01-06 15:45:32,244 - Epoch: [11][   30/   37]    Overall Loss 0.683971    Objective Loss 0.683971                                        LR 0.000060    Time 0.024660    
2023-01-06 15:45:32,358 - Epoch: [11][   37/   37]    Overall Loss 0.683440    Objective Loss 0.683440    Top1 58.158996    LR 0.000060    Time 0.023055    
2023-01-06 15:45:32,432 - --- validate (epoch=11)-----------
2023-01-06 15:45:32,432 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:32,665 - Epoch: [11][    5/    5]    Loss 0.677681    Top1 59.064885    
2023-01-06 15:45:32,721 - ==> Top1: 59.065    Loss: 0.678

2023-01-06 15:45:32,721 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:32,722 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 11]
2023-01-06 15:45:32,722 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:32,730 - 

2023-01-06 15:45:32,730 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:33,091 - Epoch: [12][   10/   37]    Overall Loss 0.684576    Objective Loss 0.684576                                        LR 0.000060    Time 0.035995    
2023-01-06 15:45:33,257 - Epoch: [12][   20/   37]    Overall Loss 0.683675    Objective Loss 0.683675                                        LR 0.000060    Time 0.026276    
2023-01-06 15:45:33,445 - Epoch: [12][   30/   37]    Overall Loss 0.684181    Objective Loss 0.684181                                        LR 0.000060    Time 0.023787    
2023-01-06 15:45:33,559 - Epoch: [12][   37/   37]    Overall Loss 0.683921    Objective Loss 0.683921    Top1 56.903766    LR 0.000060    Time 0.022355    
2023-01-06 15:45:33,628 - --- validate (epoch=12)-----------
2023-01-06 15:45:33,628 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:33,841 - Epoch: [12][    5/    5]    Loss 0.681908    Top1 59.064885    
2023-01-06 15:45:33,901 - ==> Top1: 59.065    Loss: 0.682

2023-01-06 15:45:33,901 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:33,902 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 12]
2023-01-06 15:45:33,902 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:33,910 - 

2023-01-06 15:45:33,910 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:34,273 - Epoch: [13][   10/   37]    Overall Loss 0.684321    Objective Loss 0.684321                                        LR 0.000060    Time 0.036201    
2023-01-06 15:45:34,468 - Epoch: [13][   20/   37]    Overall Loss 0.683178    Objective Loss 0.683178                                        LR 0.000060    Time 0.027857    
2023-01-06 15:45:34,659 - Epoch: [13][   30/   37]    Overall Loss 0.682729    Objective Loss 0.682729                                        LR 0.000060    Time 0.024914    
2023-01-06 15:45:34,772 - Epoch: [13][   37/   37]    Overall Loss 0.683627    Objective Loss 0.683627    Top1 57.531381    LR 0.000060    Time 0.023249    
2023-01-06 15:45:34,843 - --- validate (epoch=13)-----------
2023-01-06 15:45:34,843 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:35,057 - Epoch: [13][    5/    5]    Loss 0.675188    Top1 59.064885    
2023-01-06 15:45:35,126 - ==> Top1: 59.065    Loss: 0.675

2023-01-06 15:45:35,126 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:35,127 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 13]
2023-01-06 15:45:35,128 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:35,135 - 

2023-01-06 15:45:35,135 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:35,494 - Epoch: [14][   10/   37]    Overall Loss 0.683711    Objective Loss 0.683711                                        LR 0.000060    Time 0.035763    
2023-01-06 15:45:35,677 - Epoch: [14][   20/   37]    Overall Loss 0.685827    Objective Loss 0.685827                                        LR 0.000060    Time 0.027003    
2023-01-06 15:45:35,866 - Epoch: [14][   30/   37]    Overall Loss 0.684542    Objective Loss 0.684542                                        LR 0.000060    Time 0.024249    
2023-01-06 15:45:35,980 - Epoch: [14][   37/   37]    Overall Loss 0.683509    Objective Loss 0.683509    Top1 58.786611    LR 0.000060    Time 0.022743    
2023-01-06 15:45:36,053 - --- validate (epoch=14)-----------
2023-01-06 15:45:36,053 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:36,272 - Epoch: [14][    5/    5]    Loss 0.672149    Top1 59.064885    
2023-01-06 15:45:36,348 - ==> Top1: 59.065    Loss: 0.672

2023-01-06 15:45:36,348 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:36,350 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 14]
2023-01-06 15:45:36,350 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:36,357 - 

2023-01-06 15:45:36,357 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:36,723 - Epoch: [15][   10/   37]    Overall Loss 0.676850    Objective Loss 0.676850                                        LR 0.000060    Time 0.036509    
2023-01-06 15:45:36,885 - Epoch: [15][   20/   37]    Overall Loss 0.683292    Objective Loss 0.683292                                        LR 0.000060    Time 0.026262    
2023-01-06 15:45:37,050 - Epoch: [15][   30/   37]    Overall Loss 0.684215    Objective Loss 0.684215                                        LR 0.000060    Time 0.023014    
2023-01-06 15:45:37,149 - Epoch: [15][   37/   37]    Overall Loss 0.683430    Objective Loss 0.683430    Top1 56.485356    LR 0.000060    Time 0.021318    
2023-01-06 15:45:37,217 - --- validate (epoch=15)-----------
2023-01-06 15:45:37,217 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:37,432 - Epoch: [15][    5/    5]    Loss 0.678826    Top1 59.064885    
2023-01-06 15:45:37,489 - ==> Top1: 59.065    Loss: 0.679

2023-01-06 15:45:37,489 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:37,490 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 15]
2023-01-06 15:45:37,490 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:37,498 - 

2023-01-06 15:45:37,498 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:37,853 - Epoch: [16][   10/   37]    Overall Loss 0.683447    Objective Loss 0.683447                                        LR 0.000060    Time 0.035426    
2023-01-06 15:45:38,009 - Epoch: [16][   20/   37]    Overall Loss 0.681837    Objective Loss 0.681837                                        LR 0.000060    Time 0.025506    
2023-01-06 15:45:38,173 - Epoch: [16][   30/   37]    Overall Loss 0.681871    Objective Loss 0.681871                                        LR 0.000060    Time 0.022457    
2023-01-06 15:45:38,272 - Epoch: [16][   37/   37]    Overall Loss 0.682584    Objective Loss 0.682584    Top1 54.393305    LR 0.000060    Time 0.020872    
2023-01-06 15:45:38,341 - --- validate (epoch=16)-----------
2023-01-06 15:45:38,341 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:38,554 - Epoch: [16][    5/    5]    Loss 0.672519    Top1 59.064885    
2023-01-06 15:45:38,615 - ==> Top1: 59.065    Loss: 0.673

2023-01-06 15:45:38,615 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:38,616 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 16]
2023-01-06 15:45:38,616 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:38,623 - 

2023-01-06 15:45:38,624 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:39,003 - Epoch: [17][   10/   37]    Overall Loss 0.682947    Objective Loss 0.682947                                        LR 0.000060    Time 0.037888    
2023-01-06 15:45:39,194 - Epoch: [17][   20/   37]    Overall Loss 0.681414    Objective Loss 0.681414                                        LR 0.000060    Time 0.028492    
2023-01-06 15:45:39,396 - Epoch: [17][   30/   37]    Overall Loss 0.682360    Objective Loss 0.682360                                        LR 0.000060    Time 0.025698    
2023-01-06 15:45:39,510 - Epoch: [17][   37/   37]    Overall Loss 0.681837    Objective Loss 0.681837    Top1 57.740586    LR 0.000060    Time 0.023915    
2023-01-06 15:45:39,577 - --- validate (epoch=17)-----------
2023-01-06 15:45:39,578 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:39,794 - Epoch: [17][    5/    5]    Loss 0.672835    Top1 59.064885    
2023-01-06 15:45:39,855 - ==> Top1: 59.065    Loss: 0.673

2023-01-06 15:45:39,856 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:39,857 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 17]
2023-01-06 15:45:39,857 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:39,864 - 

2023-01-06 15:45:39,864 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:40,252 - Epoch: [18][   10/   37]    Overall Loss 0.678002    Objective Loss 0.678002                                        LR 0.000060    Time 0.038678    
2023-01-06 15:45:40,444 - Epoch: [18][   20/   37]    Overall Loss 0.681571    Objective Loss 0.681571                                        LR 0.000060    Time 0.028902    
2023-01-06 15:45:40,645 - Epoch: [18][   30/   37]    Overall Loss 0.681091    Objective Loss 0.681091                                        LR 0.000060    Time 0.025962    
2023-01-06 15:45:40,759 - Epoch: [18][   37/   37]    Overall Loss 0.681806    Objective Loss 0.681806    Top1 57.322176    LR 0.000060    Time 0.024132    
2023-01-06 15:45:40,829 - --- validate (epoch=18)-----------
2023-01-06 15:45:40,829 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:41,047 - Epoch: [18][    5/    5]    Loss 0.666423    Top1 59.064885    
2023-01-06 15:45:41,119 - ==> Top1: 59.065    Loss: 0.666

2023-01-06 15:45:41,119 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:41,120 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 18]
2023-01-06 15:45:41,121 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:41,128 - 

2023-01-06 15:45:41,128 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:41,488 - Epoch: [19][   10/   37]    Overall Loss 0.681581    Objective Loss 0.681581                                        LR 0.000060    Time 0.035871    
2023-01-06 15:45:41,676 - Epoch: [19][   20/   37]    Overall Loss 0.678684    Objective Loss 0.678684                                        LR 0.000060    Time 0.027312    
2023-01-06 15:45:41,873 - Epoch: [19][   30/   37]    Overall Loss 0.679329    Objective Loss 0.679329                                        LR 0.000060    Time 0.024742    
2023-01-06 15:45:41,982 - Epoch: [19][   37/   37]    Overall Loss 0.679482    Objective Loss 0.679482    Top1 53.765690    LR 0.000060    Time 0.022982    
2023-01-06 15:45:42,072 - --- validate (epoch=19)-----------
2023-01-06 15:45:42,073 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:42,287 - Epoch: [19][    5/    5]    Loss 0.678245    Top1 59.064885    
2023-01-06 15:45:42,350 - ==> Top1: 59.065    Loss: 0.678

2023-01-06 15:45:42,350 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:42,351 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 19]
2023-01-06 15:45:42,351 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:42,359 - 

2023-01-06 15:45:42,359 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:42,723 - Epoch: [20][   10/   37]    Overall Loss 0.678783    Objective Loss 0.678783                                        LR 0.000060    Time 0.036368    
2023-01-06 15:45:42,925 - Epoch: [20][   20/   37]    Overall Loss 0.677590    Objective Loss 0.677590                                        LR 0.000060    Time 0.028237    
2023-01-06 15:45:43,113 - Epoch: [20][   30/   37]    Overall Loss 0.676417    Objective Loss 0.676417                                        LR 0.000060    Time 0.025075    
2023-01-06 15:45:43,215 - Epoch: [20][   37/   37]    Overall Loss 0.676129    Objective Loss 0.676129    Top1 58.368201    LR 0.000060    Time 0.023096    
2023-01-06 15:45:43,286 - --- validate (epoch=20)-----------
2023-01-06 15:45:43,287 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:43,512 - Epoch: [20][    5/    5]    Loss 0.668104    Top1 59.064885    
2023-01-06 15:45:43,578 - ==> Top1: 59.065    Loss: 0.668

2023-01-06 15:45:43,578 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 15:45:43,579 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 155168 on epoch: 20]
2023-01-06 15:45:43,579 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:43,587 - 

2023-01-06 15:45:43,587 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:43,946 - Epoch: [21][   10/   37]    Overall Loss 0.670361    Objective Loss 0.670361                                        LR 0.000060    Time 0.035807    
2023-01-06 15:45:44,109 - Epoch: [21][   20/   37]    Overall Loss 0.672386    Objective Loss 0.672386                                        LR 0.000060    Time 0.026039    
2023-01-06 15:45:44,309 - Epoch: [21][   30/   37]    Overall Loss 0.668968    Objective Loss 0.668968                                        LR 0.000060    Time 0.024013    
2023-01-06 15:45:44,423 - Epoch: [21][   37/   37]    Overall Loss 0.667492    Objective Loss 0.667492    Top1 55.857741    LR 0.000060    Time 0.022541    
2023-01-06 15:45:44,494 - --- validate (epoch=21)-----------
2023-01-06 15:45:44,494 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:44,713 - Epoch: [21][    5/    5]    Loss 0.653212    Top1 61.259542    
2023-01-06 15:45:44,778 - ==> Top1: 61.260    Loss: 0.653

2023-01-06 15:45:44,778 - ==> Confusion:
[[ 38 391   0]
 [ 15 604   0]
 [  0   0   0]]

2023-01-06 15:45:44,779 - ==> Best [Top1: 61.260   Sparsity:0.00   Params: 155168 on epoch: 21]
2023-01-06 15:45:44,779 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:44,786 - 

2023-01-06 15:45:44,786 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:45,181 - Epoch: [22][   10/   37]    Overall Loss 0.659223    Objective Loss 0.659223                                        LR 0.000060    Time 0.039364    
2023-01-06 15:45:45,380 - Epoch: [22][   20/   37]    Overall Loss 0.657408    Objective Loss 0.657408                                        LR 0.000060    Time 0.029598    
2023-01-06 15:45:45,562 - Epoch: [22][   30/   37]    Overall Loss 0.652973    Objective Loss 0.652973                                        LR 0.000060    Time 0.025808    
2023-01-06 15:45:45,676 - Epoch: [22][   37/   37]    Overall Loss 0.650676    Objective Loss 0.650676    Top1 60.878661    LR 0.000060    Time 0.023995    
2023-01-06 15:45:45,743 - --- validate (epoch=22)-----------
2023-01-06 15:45:45,743 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:45,958 - Epoch: [22][    5/    5]    Loss 0.635061    Top1 63.835878    
2023-01-06 15:45:46,023 - ==> Top1: 63.836    Loss: 0.635

2023-01-06 15:45:46,023 - ==> Confusion:
[[ 93 336   0]
 [ 43 576   0]
 [  0   0   0]]

2023-01-06 15:45:46,025 - ==> Best [Top1: 63.836   Sparsity:0.00   Params: 155168 on epoch: 22]
2023-01-06 15:45:46,025 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:46,032 - 

2023-01-06 15:45:46,032 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:46,530 - Epoch: [23][   10/   37]    Overall Loss 0.629120    Objective Loss 0.629120                                        LR 0.000060    Time 0.049731    
2023-01-06 15:45:46,714 - Epoch: [23][   20/   37]    Overall Loss 0.627601    Objective Loss 0.627601                                        LR 0.000060    Time 0.034018    
2023-01-06 15:45:46,887 - Epoch: [23][   30/   37]    Overall Loss 0.624504    Objective Loss 0.624504                                        LR 0.000060    Time 0.028367    
2023-01-06 15:45:46,990 - Epoch: [23][   37/   37]    Overall Loss 0.620298    Objective Loss 0.620298    Top1 66.527197    LR 0.000060    Time 0.025797    
2023-01-06 15:45:47,064 - --- validate (epoch=23)-----------
2023-01-06 15:45:47,064 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:47,284 - Epoch: [23][    5/    5]    Loss 0.591325    Top1 66.412214    
2023-01-06 15:45:47,344 - ==> Top1: 66.412    Loss: 0.591

2023-01-06 15:45:47,344 - ==> Confusion:
[[128 301   0]
 [ 51 568   0]
 [  0   0   0]]

2023-01-06 15:45:47,346 - ==> Best [Top1: 66.412   Sparsity:0.00   Params: 155168 on epoch: 23]
2023-01-06 15:45:47,346 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:47,353 - 

2023-01-06 15:45:47,353 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:47,702 - Epoch: [24][   10/   37]    Overall Loss 0.598433    Objective Loss 0.598433                                        LR 0.000060    Time 0.034800    
2023-01-06 15:45:47,868 - Epoch: [24][   20/   37]    Overall Loss 0.598636    Objective Loss 0.598636                                        LR 0.000060    Time 0.025648    
2023-01-06 15:45:48,035 - Epoch: [24][   30/   37]    Overall Loss 0.595111    Objective Loss 0.595111                                        LR 0.000060    Time 0.022659    
2023-01-06 15:45:48,139 - Epoch: [24][   37/   37]    Overall Loss 0.591863    Objective Loss 0.591863    Top1 68.410042    LR 0.000060    Time 0.021188    
2023-01-06 15:45:48,219 - --- validate (epoch=24)-----------
2023-01-06 15:45:48,220 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:48,435 - Epoch: [24][    5/    5]    Loss 0.551021    Top1 70.801527    
2023-01-06 15:45:48,503 - ==> Top1: 70.802    Loss: 0.551

2023-01-06 15:45:48,503 - ==> Confusion:
[[234 195   0]
 [111 508   0]
 [  0   0   0]]

2023-01-06 15:45:48,505 - ==> Best [Top1: 70.802   Sparsity:0.00   Params: 155168 on epoch: 24]
2023-01-06 15:45:48,505 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:48,512 - 

2023-01-06 15:45:48,512 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:48,862 - Epoch: [25][   10/   37]    Overall Loss 0.583231    Objective Loss 0.583231                                        LR 0.000060    Time 0.034862    
2023-01-06 15:45:49,031 - Epoch: [25][   20/   37]    Overall Loss 0.573882    Objective Loss 0.573882                                        LR 0.000060    Time 0.025843    
2023-01-06 15:45:49,218 - Epoch: [25][   30/   37]    Overall Loss 0.565154    Objective Loss 0.565154                                        LR 0.000060    Time 0.023421    
2023-01-06 15:45:49,334 - Epoch: [25][   37/   37]    Overall Loss 0.564162    Objective Loss 0.564162    Top1 71.338912    LR 0.000060    Time 0.022126    
2023-01-06 15:45:49,413 - --- validate (epoch=25)-----------
2023-01-06 15:45:49,414 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:49,629 - Epoch: [25][    5/    5]    Loss 0.538246    Top1 73.187023    
2023-01-06 15:45:49,693 - ==> Top1: 73.187    Loss: 0.538

2023-01-06 15:45:49,693 - ==> Confusion:
[[284 145   0]
 [136 483   0]
 [  0   0   0]]

2023-01-06 15:45:49,694 - ==> Best [Top1: 73.187   Sparsity:0.00   Params: 155168 on epoch: 25]
2023-01-06 15:45:49,695 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:49,702 - 

2023-01-06 15:45:49,702 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:50,077 - Epoch: [26][   10/   37]    Overall Loss 0.548659    Objective Loss 0.548659                                        LR 0.000060    Time 0.037461    
2023-01-06 15:45:50,278 - Epoch: [26][   20/   37]    Overall Loss 0.549436    Objective Loss 0.549436                                        LR 0.000060    Time 0.028761    
2023-01-06 15:45:50,482 - Epoch: [26][   30/   37]    Overall Loss 0.544028    Objective Loss 0.544028                                        LR 0.000060    Time 0.025945    
2023-01-06 15:45:50,597 - Epoch: [26][   37/   37]    Overall Loss 0.546169    Objective Loss 0.546169    Top1 72.175732    LR 0.000060    Time 0.024154    
2023-01-06 15:45:50,669 - --- validate (epoch=26)-----------
2023-01-06 15:45:50,669 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:50,886 - Epoch: [26][    5/    5]    Loss 0.523543    Top1 74.332061    
2023-01-06 15:45:50,941 - ==> Top1: 74.332    Loss: 0.524

2023-01-06 15:45:50,942 - ==> Confusion:
[[297 132   0]
 [137 482   0]
 [  0   0   0]]

2023-01-06 15:45:50,943 - ==> Best [Top1: 74.332   Sparsity:0.00   Params: 155168 on epoch: 26]
2023-01-06 15:45:50,943 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:50,951 - 

2023-01-06 15:45:50,951 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:51,310 - Epoch: [27][   10/   37]    Overall Loss 0.522969    Objective Loss 0.522969                                        LR 0.000060    Time 0.035868    
2023-01-06 15:45:51,468 - Epoch: [27][   20/   37]    Overall Loss 0.531322    Objective Loss 0.531322                                        LR 0.000060    Time 0.025826    
2023-01-06 15:45:51,631 - Epoch: [27][   30/   37]    Overall Loss 0.532932    Objective Loss 0.532932                                        LR 0.000060    Time 0.022613    
2023-01-06 15:45:51,736 - Epoch: [27][   37/   37]    Overall Loss 0.530673    Objective Loss 0.530673    Top1 73.430962    LR 0.000060    Time 0.021181    
2023-01-06 15:45:51,811 - --- validate (epoch=27)-----------
2023-01-06 15:45:51,812 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:52,040 - Epoch: [27][    5/    5]    Loss 0.499290    Top1 73.187023    
2023-01-06 15:45:52,105 - ==> Top1: 73.187    Loss: 0.499

2023-01-06 15:45:52,105 - ==> Confusion:
[[233 196   0]
 [ 85 534   0]
 [  0   0   0]]

2023-01-06 15:45:52,106 - ==> Best [Top1: 74.332   Sparsity:0.00   Params: 155168 on epoch: 26]
2023-01-06 15:45:52,106 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:52,112 - 

2023-01-06 15:45:52,112 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:52,478 - Epoch: [28][   10/   37]    Overall Loss 0.518169    Objective Loss 0.518169                                        LR 0.000060    Time 0.036542    
2023-01-06 15:45:52,635 - Epoch: [28][   20/   37]    Overall Loss 0.519741    Objective Loss 0.519741                                        LR 0.000060    Time 0.026094    
2023-01-06 15:45:52,793 - Epoch: [28][   30/   37]    Overall Loss 0.518178    Objective Loss 0.518178                                        LR 0.000060    Time 0.022659    
2023-01-06 15:45:52,899 - Epoch: [28][   37/   37]    Overall Loss 0.518751    Objective Loss 0.518751    Top1 73.221757    LR 0.000060    Time 0.021231    
2023-01-06 15:45:52,976 - --- validate (epoch=28)-----------
2023-01-06 15:45:52,976 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:53,204 - Epoch: [28][    5/    5]    Loss 0.471687    Top1 75.190840    
2023-01-06 15:45:53,270 - ==> Top1: 75.191    Loss: 0.472

2023-01-06 15:45:53,270 - ==> Confusion:
[[276 153   0]
 [107 512   0]
 [  0   0   0]]

2023-01-06 15:45:53,271 - ==> Best [Top1: 75.191   Sparsity:0.00   Params: 155168 on epoch: 28]
2023-01-06 15:45:53,271 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:53,279 - 

2023-01-06 15:45:53,279 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:53,633 - Epoch: [29][   10/   37]    Overall Loss 0.513308    Objective Loss 0.513308                                        LR 0.000060    Time 0.035362    
2023-01-06 15:45:53,815 - Epoch: [29][   20/   37]    Overall Loss 0.510773    Objective Loss 0.510773                                        LR 0.000060    Time 0.026751    
2023-01-06 15:45:54,001 - Epoch: [29][   30/   37]    Overall Loss 0.510764    Objective Loss 0.510764                                        LR 0.000060    Time 0.024032    
2023-01-06 15:45:54,108 - Epoch: [29][   37/   37]    Overall Loss 0.508967    Objective Loss 0.508967    Top1 75.104603    LR 0.000060    Time 0.022376    
2023-01-06 15:45:54,184 - --- validate (epoch=29)-----------
2023-01-06 15:45:54,185 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:54,405 - Epoch: [29][    5/    5]    Loss 0.493517    Top1 75.954198    
2023-01-06 15:45:54,460 - ==> Top1: 75.954    Loss: 0.494

2023-01-06 15:45:54,460 - ==> Confusion:
[[350  79   0]
 [173 446   0]
 [  0   0   0]]

2023-01-06 15:45:54,461 - ==> Best [Top1: 75.954   Sparsity:0.00   Params: 155168 on epoch: 29]
2023-01-06 15:45:54,462 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:54,469 - 

2023-01-06 15:45:54,469 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:54,839 - Epoch: [30][   10/   37]    Overall Loss 0.505199    Objective Loss 0.505199                                        LR 0.000060    Time 0.036871    
2023-01-06 15:45:55,017 - Epoch: [30][   20/   37]    Overall Loss 0.497843    Objective Loss 0.497843                                        LR 0.000060    Time 0.027316    
2023-01-06 15:45:55,198 - Epoch: [30][   30/   37]    Overall Loss 0.498027    Objective Loss 0.498027                                        LR 0.000060    Time 0.024254    
2023-01-06 15:45:55,312 - Epoch: [30][   37/   37]    Overall Loss 0.501710    Objective Loss 0.501710    Top1 73.640167    LR 0.000060    Time 0.022720    
2023-01-06 15:45:55,384 - --- validate (epoch=30)-----------
2023-01-06 15:45:55,385 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:55,604 - Epoch: [30][    5/    5]    Loss 0.455297    Top1 76.717557    
2023-01-06 15:45:55,665 - ==> Top1: 76.718    Loss: 0.455

2023-01-06 15:45:55,665 - ==> Confusion:
[[289 140   0]
 [104 515   0]
 [  0   0   0]]

2023-01-06 15:45:55,666 - ==> Best [Top1: 76.718   Sparsity:0.00   Params: 155168 on epoch: 30]
2023-01-06 15:45:55,666 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:55,674 - 

2023-01-06 15:45:55,674 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:56,030 - Epoch: [31][   10/   37]    Overall Loss 0.502739    Objective Loss 0.502739                                        LR 0.000060    Time 0.035587    
2023-01-06 15:45:56,202 - Epoch: [31][   20/   37]    Overall Loss 0.498219    Objective Loss 0.498219                                        LR 0.000060    Time 0.026324    
2023-01-06 15:45:56,374 - Epoch: [31][   30/   37]    Overall Loss 0.500601    Objective Loss 0.500601                                        LR 0.000060    Time 0.023288    
2023-01-06 15:45:56,487 - Epoch: [31][   37/   37]    Overall Loss 0.494693    Objective Loss 0.494693    Top1 77.196653    LR 0.000060    Time 0.021925    
2023-01-06 15:45:56,564 - --- validate (epoch=31)-----------
2023-01-06 15:45:56,565 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:56,781 - Epoch: [31][    5/    5]    Loss 0.466788    Top1 76.908397    
2023-01-06 15:45:56,846 - ==> Top1: 76.908    Loss: 0.467

2023-01-06 15:45:56,846 - ==> Confusion:
[[356  73   0]
 [169 450   0]
 [  0   0   0]]

2023-01-06 15:45:56,847 - ==> Best [Top1: 76.908   Sparsity:0.00   Params: 155168 on epoch: 31]
2023-01-06 15:45:56,847 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:56,854 - 

2023-01-06 15:45:56,854 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:57,210 - Epoch: [32][   10/   37]    Overall Loss 0.483865    Objective Loss 0.483865                                        LR 0.000060    Time 0.035461    
2023-01-06 15:45:57,384 - Epoch: [32][   20/   37]    Overall Loss 0.490399    Objective Loss 0.490399                                        LR 0.000060    Time 0.026370    
2023-01-06 15:45:57,558 - Epoch: [32][   30/   37]    Overall Loss 0.486618    Objective Loss 0.486618                                        LR 0.000060    Time 0.023379    
2023-01-06 15:45:57,673 - Epoch: [32][   37/   37]    Overall Loss 0.487331    Objective Loss 0.487331    Top1 77.405858    LR 0.000060    Time 0.022061    
2023-01-06 15:45:57,750 - --- validate (epoch=32)-----------
2023-01-06 15:45:57,750 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:57,971 - Epoch: [32][    5/    5]    Loss 0.456240    Top1 76.717557    
2023-01-06 15:45:58,052 - ==> Top1: 76.718    Loss: 0.456

2023-01-06 15:45:58,052 - ==> Confusion:
[[263 166   0]
 [ 78 541   0]
 [  0   0   0]]

2023-01-06 15:45:58,053 - ==> Best [Top1: 76.908   Sparsity:0.00   Params: 155168 on epoch: 31]
2023-01-06 15:45:58,053 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:58,059 - 

2023-01-06 15:45:58,059 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:58,420 - Epoch: [33][   10/   37]    Overall Loss 0.486823    Objective Loss 0.486823                                        LR 0.000060    Time 0.036026    
2023-01-06 15:45:58,582 - Epoch: [33][   20/   37]    Overall Loss 0.485088    Objective Loss 0.485088                                        LR 0.000060    Time 0.026109    
2023-01-06 15:45:58,741 - Epoch: [33][   30/   37]    Overall Loss 0.481327    Objective Loss 0.481327                                        LR 0.000060    Time 0.022675    
2023-01-06 15:45:58,840 - Epoch: [33][   37/   37]    Overall Loss 0.481999    Objective Loss 0.481999    Top1 77.615063    LR 0.000060    Time 0.021066    
2023-01-06 15:45:58,918 - --- validate (epoch=33)-----------
2023-01-06 15:45:58,919 - 1048 samples (256 per mini-batch)
2023-01-06 15:45:59,145 - Epoch: [33][    5/    5]    Loss 0.464670    Top1 77.576336    
2023-01-06 15:45:59,207 - ==> Top1: 77.576    Loss: 0.465

2023-01-06 15:45:59,208 - ==> Confusion:
[[270 159   0]
 [ 76 543   0]
 [  0   0   0]]

2023-01-06 15:45:59,209 - ==> Best [Top1: 77.576   Sparsity:0.00   Params: 155168 on epoch: 33]
2023-01-06 15:45:59,209 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:45:59,216 - 

2023-01-06 15:45:59,216 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:45:59,568 - Epoch: [34][   10/   37]    Overall Loss 0.473684    Objective Loss 0.473684                                        LR 0.000060    Time 0.035063    
2023-01-06 15:45:59,740 - Epoch: [34][   20/   37]    Overall Loss 0.480889    Objective Loss 0.480889                                        LR 0.000060    Time 0.026112    
2023-01-06 15:45:59,925 - Epoch: [34][   30/   37]    Overall Loss 0.481826    Objective Loss 0.481826                                        LR 0.000060    Time 0.023574    
2023-01-06 15:46:00,041 - Epoch: [34][   37/   37]    Overall Loss 0.476503    Objective Loss 0.476503    Top1 78.661088    LR 0.000060    Time 0.022237    
2023-01-06 15:46:00,116 - --- validate (epoch=34)-----------
2023-01-06 15:46:00,116 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:00,337 - Epoch: [34][    5/    5]    Loss 0.448185    Top1 77.290076    
2023-01-06 15:46:00,397 - ==> Top1: 77.290    Loss: 0.448

2023-01-06 15:46:00,397 - ==> Confusion:
[[273 156   0]
 [ 82 537   0]
 [  0   0   0]]

2023-01-06 15:46:00,399 - ==> Best [Top1: 77.576   Sparsity:0.00   Params: 155168 on epoch: 33]
2023-01-06 15:46:00,399 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:00,405 - 

2023-01-06 15:46:00,405 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:00,768 - Epoch: [35][   10/   37]    Overall Loss 0.476298    Objective Loss 0.476298                                        LR 0.000060    Time 0.036243    
2023-01-06 15:46:00,933 - Epoch: [35][   20/   37]    Overall Loss 0.469213    Objective Loss 0.469213                                        LR 0.000060    Time 0.026342    
2023-01-06 15:46:01,098 - Epoch: [35][   30/   37]    Overall Loss 0.471624    Objective Loss 0.471624                                        LR 0.000060    Time 0.023044    
2023-01-06 15:46:01,200 - Epoch: [35][   37/   37]    Overall Loss 0.469938    Objective Loss 0.469938    Top1 72.803347    LR 0.000060    Time 0.021446    
2023-01-06 15:46:01,277 - --- validate (epoch=35)-----------
2023-01-06 15:46:01,278 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:01,494 - Epoch: [35][    5/    5]    Loss 0.433474    Top1 78.816794    
2023-01-06 15:46:01,564 - ==> Top1: 78.817    Loss: 0.433

2023-01-06 15:46:01,565 - ==> Confusion:
[[264 165   0]
 [ 57 562   0]
 [  0   0   0]]

2023-01-06 15:46:01,566 - ==> Best [Top1: 78.817   Sparsity:0.00   Params: 155168 on epoch: 35]
2023-01-06 15:46:01,566 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:01,573 - 

2023-01-06 15:46:01,573 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:01,920 - Epoch: [36][   10/   37]    Overall Loss 0.460044    Objective Loss 0.460044                                        LR 0.000060    Time 0.034652    
2023-01-06 15:46:02,081 - Epoch: [36][   20/   37]    Overall Loss 0.460960    Objective Loss 0.460960                                        LR 0.000060    Time 0.025296    
2023-01-06 15:46:02,248 - Epoch: [36][   30/   37]    Overall Loss 0.466031    Objective Loss 0.466031                                        LR 0.000060    Time 0.022367    
2023-01-06 15:46:02,350 - Epoch: [36][   37/   37]    Overall Loss 0.465034    Objective Loss 0.465034    Top1 78.451883    LR 0.000060    Time 0.020890    
2023-01-06 15:46:02,428 - --- validate (epoch=36)-----------
2023-01-06 15:46:02,429 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:02,645 - Epoch: [36][    5/    5]    Loss 0.457427    Top1 79.103053    
2023-01-06 15:46:02,713 - ==> Top1: 79.103    Loss: 0.457

2023-01-06 15:46:02,713 - ==> Confusion:
[[288 141   0]
 [ 78 541   0]
 [  0   0   0]]

2023-01-06 15:46:02,714 - ==> Best [Top1: 79.103   Sparsity:0.00   Params: 155168 on epoch: 36]
2023-01-06 15:46:02,715 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:02,722 - 

2023-01-06 15:46:02,722 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:03,191 - Epoch: [37][   10/   37]    Overall Loss 0.446599    Objective Loss 0.446599                                        LR 0.000060    Time 0.046799    
2023-01-06 15:46:03,383 - Epoch: [37][   20/   37]    Overall Loss 0.449732    Objective Loss 0.449732                                        LR 0.000060    Time 0.032953    
2023-01-06 15:46:03,577 - Epoch: [37][   30/   37]    Overall Loss 0.452165    Objective Loss 0.452165                                        LR 0.000060    Time 0.028412    
2023-01-06 15:46:03,693 - Epoch: [37][   37/   37]    Overall Loss 0.456716    Objective Loss 0.456716    Top1 76.987448    LR 0.000060    Time 0.026171    
2023-01-06 15:46:03,769 - --- validate (epoch=37)-----------
2023-01-06 15:46:03,770 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:03,992 - Epoch: [37][    5/    5]    Loss 0.423583    Top1 81.202290    
2023-01-06 15:46:04,052 - ==> Top1: 81.202    Loss: 0.424

2023-01-06 15:46:04,052 - ==> Confusion:
[[324 105   0]
 [ 92 527   0]
 [  0   0   0]]

2023-01-06 15:46:04,053 - ==> Best [Top1: 81.202   Sparsity:0.00   Params: 155168 on epoch: 37]
2023-01-06 15:46:04,053 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:04,061 - 

2023-01-06 15:46:04,061 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:04,416 - Epoch: [38][   10/   37]    Overall Loss 0.464580    Objective Loss 0.464580                                        LR 0.000060    Time 0.035469    
2023-01-06 15:46:04,582 - Epoch: [38][   20/   37]    Overall Loss 0.461606    Objective Loss 0.461606                                        LR 0.000060    Time 0.025999    
2023-01-06 15:46:04,745 - Epoch: [38][   30/   37]    Overall Loss 0.459136    Objective Loss 0.459136                                        LR 0.000060    Time 0.022771    
2023-01-06 15:46:04,859 - Epoch: [38][   37/   37]    Overall Loss 0.457698    Objective Loss 0.457698    Top1 78.451883    LR 0.000060    Time 0.021533    
2023-01-06 15:46:04,937 - --- validate (epoch=38)-----------
2023-01-06 15:46:04,938 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:05,152 - Epoch: [38][    5/    5]    Loss 0.451641    Top1 79.007634    
2023-01-06 15:46:05,216 - ==> Top1: 79.008    Loss: 0.452

2023-01-06 15:46:05,216 - ==> Confusion:
[[279 150   0]
 [ 70 549   0]
 [  0   0   0]]

2023-01-06 15:46:05,217 - ==> Best [Top1: 81.202   Sparsity:0.00   Params: 155168 on epoch: 37]
2023-01-06 15:46:05,217 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:05,223 - 

2023-01-06 15:46:05,223 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:05,591 - Epoch: [39][   10/   37]    Overall Loss 0.449505    Objective Loss 0.449505                                        LR 0.000060    Time 0.036702    
2023-01-06 15:46:05,770 - Epoch: [39][   20/   37]    Overall Loss 0.449253    Objective Loss 0.449253                                        LR 0.000060    Time 0.027236    
2023-01-06 15:46:05,943 - Epoch: [39][   30/   37]    Overall Loss 0.449036    Objective Loss 0.449036                                        LR 0.000060    Time 0.023913    
2023-01-06 15:46:06,049 - Epoch: [39][   37/   37]    Overall Loss 0.450591    Objective Loss 0.450591    Top1 76.778243    LR 0.000060    Time 0.022250    
2023-01-06 15:46:06,127 - --- validate (epoch=39)-----------
2023-01-06 15:46:06,127 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:06,346 - Epoch: [39][    5/    5]    Loss 0.455600    Top1 80.057252    
2023-01-06 15:46:06,415 - ==> Top1: 80.057    Loss: 0.456

2023-01-06 15:46:06,415 - ==> Confusion:
[[354  75   0]
 [134 485   0]
 [  0   0   0]]

2023-01-06 15:46:06,416 - ==> Best [Top1: 81.202   Sparsity:0.00   Params: 155168 on epoch: 37]
2023-01-06 15:46:06,416 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:06,422 - 

2023-01-06 15:46:06,422 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:06,784 - Epoch: [40][   10/   37]    Overall Loss 0.446068    Objective Loss 0.446068                                        LR 0.000036    Time 0.036102    
2023-01-06 15:46:06,953 - Epoch: [40][   20/   37]    Overall Loss 0.450206    Objective Loss 0.450206                                        LR 0.000036    Time 0.026454    
2023-01-06 15:46:07,130 - Epoch: [40][   30/   37]    Overall Loss 0.452531    Objective Loss 0.452531                                        LR 0.000036    Time 0.023532    
2023-01-06 15:46:07,243 - Epoch: [40][   37/   37]    Overall Loss 0.446313    Objective Loss 0.446313    Top1 79.497908    LR 0.000036    Time 0.022122    
2023-01-06 15:46:07,327 - --- validate (epoch=40)-----------
2023-01-06 15:46:07,328 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:07,544 - Epoch: [40][    5/    5]    Loss 0.427461    Top1 79.484733    
2023-01-06 15:46:07,608 - ==> Top1: 79.485    Loss: 0.427

2023-01-06 15:46:07,608 - ==> Confusion:
[[276 153   0]
 [ 62 557   0]
 [  0   0   0]]

2023-01-06 15:46:07,609 - ==> Best [Top1: 81.202   Sparsity:0.00   Params: 155168 on epoch: 37]
2023-01-06 15:46:07,609 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:07,615 - 

2023-01-06 15:46:07,615 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:07,983 - Epoch: [41][   10/   37]    Overall Loss 0.439514    Objective Loss 0.439514                                        LR 0.000036    Time 0.036739    
2023-01-06 15:46:08,181 - Epoch: [41][   20/   37]    Overall Loss 0.447636    Objective Loss 0.447636                                        LR 0.000036    Time 0.028259    
2023-01-06 15:46:08,377 - Epoch: [41][   30/   37]    Overall Loss 0.443293    Objective Loss 0.443293                                        LR 0.000036    Time 0.025346    
2023-01-06 15:46:08,492 - Epoch: [41][   37/   37]    Overall Loss 0.441356    Objective Loss 0.441356    Top1 77.196653    LR 0.000036    Time 0.023667    
2023-01-06 15:46:08,562 - --- validate (epoch=41)-----------
2023-01-06 15:46:08,563 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:08,776 - Epoch: [41][    5/    5]    Loss 0.414351    Top1 81.297710    
2023-01-06 15:46:08,842 - ==> Top1: 81.298    Loss: 0.414

2023-01-06 15:46:08,843 - ==> Confusion:
[[338  91   0]
 [105 514   0]
 [  0   0   0]]

2023-01-06 15:46:08,844 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 155168 on epoch: 41]
2023-01-06 15:46:08,844 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:08,851 - 

2023-01-06 15:46:08,851 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:09,213 - Epoch: [42][   10/   37]    Overall Loss 0.439709    Objective Loss 0.439709                                        LR 0.000036    Time 0.036124    
2023-01-06 15:46:09,408 - Epoch: [42][   20/   37]    Overall Loss 0.445172    Objective Loss 0.445172                                        LR 0.000036    Time 0.027790    
2023-01-06 15:46:09,606 - Epoch: [42][   30/   37]    Overall Loss 0.439101    Objective Loss 0.439101                                        LR 0.000036    Time 0.025092    
2023-01-06 15:46:09,720 - Epoch: [42][   37/   37]    Overall Loss 0.439641    Objective Loss 0.439641    Top1 80.962343    LR 0.000036    Time 0.023440    
2023-01-06 15:46:09,788 - --- validate (epoch=42)-----------
2023-01-06 15:46:09,788 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:10,009 - Epoch: [42][    5/    5]    Loss 0.426399    Top1 80.629771    
2023-01-06 15:46:10,079 - ==> Top1: 80.630    Loss: 0.426

2023-01-06 15:46:10,079 - ==> Confusion:
[[344  85   0]
 [118 501   0]
 [  0   0   0]]

2023-01-06 15:46:10,080 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 155168 on epoch: 41]
2023-01-06 15:46:10,080 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:10,086 - 

2023-01-06 15:46:10,086 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:10,450 - Epoch: [43][   10/   37]    Overall Loss 0.448135    Objective Loss 0.448135                                        LR 0.000036    Time 0.036323    
2023-01-06 15:46:10,631 - Epoch: [43][   20/   37]    Overall Loss 0.441441    Objective Loss 0.441441                                        LR 0.000036    Time 0.027191    
2023-01-06 15:46:10,819 - Epoch: [43][   30/   37]    Overall Loss 0.442791    Objective Loss 0.442791                                        LR 0.000036    Time 0.024397    
2023-01-06 15:46:10,934 - Epoch: [43][   37/   37]    Overall Loss 0.440249    Objective Loss 0.440249    Top1 79.288703    LR 0.000036    Time 0.022888    
2023-01-06 15:46:11,018 - --- validate (epoch=43)-----------
2023-01-06 15:46:11,018 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:11,233 - Epoch: [43][    5/    5]    Loss 0.417591    Top1 79.770992    
2023-01-06 15:46:11,296 - ==> Top1: 79.771    Loss: 0.418

2023-01-06 15:46:11,296 - ==> Confusion:
[[350  79   0]
 [133 486   0]
 [  0   0   0]]

2023-01-06 15:46:11,297 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 155168 on epoch: 41]
2023-01-06 15:46:11,297 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:11,303 - 

2023-01-06 15:46:11,303 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:11,661 - Epoch: [44][   10/   37]    Overall Loss 0.433569    Objective Loss 0.433569                                        LR 0.000036    Time 0.035723    
2023-01-06 15:46:11,847 - Epoch: [44][   20/   37]    Overall Loss 0.437413    Objective Loss 0.437413                                        LR 0.000036    Time 0.027119    
2023-01-06 15:46:12,027 - Epoch: [44][   30/   37]    Overall Loss 0.429485    Objective Loss 0.429485                                        LR 0.000036    Time 0.024067    
2023-01-06 15:46:12,142 - Epoch: [44][   37/   37]    Overall Loss 0.433296    Objective Loss 0.433296    Top1 78.870293    LR 0.000036    Time 0.022614    
2023-01-06 15:46:12,221 - --- validate (epoch=44)-----------
2023-01-06 15:46:12,221 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:12,437 - Epoch: [44][    5/    5]    Loss 0.415402    Top1 81.202290    
2023-01-06 15:46:12,506 - ==> Top1: 81.202    Loss: 0.415

2023-01-06 15:46:12,506 - ==> Confusion:
[[349  80   0]
 [117 502   0]
 [  0   0   0]]

2023-01-06 15:46:12,507 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 155168 on epoch: 41]
2023-01-06 15:46:12,507 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:12,513 - 

2023-01-06 15:46:12,513 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:12,889 - Epoch: [45][   10/   37]    Overall Loss 0.441168    Objective Loss 0.441168                                        LR 0.000036    Time 0.037496    
2023-01-06 15:46:13,074 - Epoch: [45][   20/   37]    Overall Loss 0.432950    Objective Loss 0.432950                                        LR 0.000036    Time 0.027999    
2023-01-06 15:46:13,265 - Epoch: [45][   30/   37]    Overall Loss 0.430975    Objective Loss 0.430975                                        LR 0.000036    Time 0.025022    
2023-01-06 15:46:13,378 - Epoch: [45][   37/   37]    Overall Loss 0.431121    Objective Loss 0.431121    Top1 79.707113    LR 0.000036    Time 0.023324    
2023-01-06 15:46:13,437 - --- validate (epoch=45)-----------
2023-01-06 15:46:13,438 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:13,655 - Epoch: [45][    5/    5]    Loss 0.447501    Top1 80.343511    
2023-01-06 15:46:13,714 - ==> Top1: 80.344    Loss: 0.448

2023-01-06 15:46:13,714 - ==> Confusion:
[[289 140   0]
 [ 66 553   0]
 [  0   0   0]]

2023-01-06 15:46:13,715 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 155168 on epoch: 41]
2023-01-06 15:46:13,715 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:13,721 - 

2023-01-06 15:46:13,721 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:14,092 - Epoch: [46][   10/   37]    Overall Loss 0.423172    Objective Loss 0.423172                                        LR 0.000036    Time 0.037028    
2023-01-06 15:46:14,292 - Epoch: [46][   20/   37]    Overall Loss 0.428484    Objective Loss 0.428484                                        LR 0.000036    Time 0.028481    
2023-01-06 15:46:14,484 - Epoch: [46][   30/   37]    Overall Loss 0.431538    Objective Loss 0.431538                                        LR 0.000036    Time 0.025375    
2023-01-06 15:46:14,602 - Epoch: [46][   37/   37]    Overall Loss 0.430142    Objective Loss 0.430142    Top1 75.523013    LR 0.000036    Time 0.023763    
2023-01-06 15:46:14,673 - --- validate (epoch=46)-----------
2023-01-06 15:46:14,673 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:14,892 - Epoch: [46][    5/    5]    Loss 0.427046    Top1 81.679389    
2023-01-06 15:46:14,970 - ==> Top1: 81.679    Loss: 0.427

2023-01-06 15:46:14,970 - ==> Confusion:
[[341  88   0]
 [104 515   0]
 [  0   0   0]]

2023-01-06 15:46:14,971 - ==> Best [Top1: 81.679   Sparsity:0.00   Params: 155168 on epoch: 46]
2023-01-06 15:46:14,971 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:14,979 - 

2023-01-06 15:46:14,979 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:15,350 - Epoch: [47][   10/   37]    Overall Loss 0.437459    Objective Loss 0.437459                                        LR 0.000036    Time 0.037017    
2023-01-06 15:46:15,540 - Epoch: [47][   20/   37]    Overall Loss 0.432055    Objective Loss 0.432055                                        LR 0.000036    Time 0.027957    
2023-01-06 15:46:15,732 - Epoch: [47][   30/   37]    Overall Loss 0.430873    Objective Loss 0.430873                                        LR 0.000036    Time 0.025024    
2023-01-06 15:46:15,844 - Epoch: [47][   37/   37]    Overall Loss 0.425680    Objective Loss 0.425680    Top1 80.125523    LR 0.000036    Time 0.023317    
2023-01-06 15:46:15,919 - --- validate (epoch=47)-----------
2023-01-06 15:46:15,919 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:16,133 - Epoch: [47][    5/    5]    Loss 0.397223    Top1 80.916031    
2023-01-06 15:46:16,201 - ==> Top1: 80.916    Loss: 0.397

2023-01-06 15:46:16,201 - ==> Confusion:
[[353  76   0]
 [124 495   0]
 [  0   0   0]]

2023-01-06 15:46:16,202 - ==> Best [Top1: 81.679   Sparsity:0.00   Params: 155168 on epoch: 46]
2023-01-06 15:46:16,203 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:16,208 - 

2023-01-06 15:46:16,208 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:16,581 - Epoch: [48][   10/   37]    Overall Loss 0.419266    Objective Loss 0.419266                                        LR 0.000036    Time 0.037183    
2023-01-06 15:46:16,760 - Epoch: [48][   20/   37]    Overall Loss 0.421165    Objective Loss 0.421165                                        LR 0.000036    Time 0.027496    
2023-01-06 15:46:16,948 - Epoch: [48][   30/   37]    Overall Loss 0.426522    Objective Loss 0.426522                                        LR 0.000036    Time 0.024594    
2023-01-06 15:46:17,061 - Epoch: [48][   37/   37]    Overall Loss 0.425423    Objective Loss 0.425423    Top1 80.125523    LR 0.000036    Time 0.023008    
2023-01-06 15:46:17,127 - --- validate (epoch=48)-----------
2023-01-06 15:46:17,127 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:17,345 - Epoch: [48][    5/    5]    Loss 0.392754    Top1 79.961832    
2023-01-06 15:46:17,406 - ==> Top1: 79.962    Loss: 0.393

2023-01-06 15:46:17,407 - ==> Confusion:
[[275 154   0]
 [ 56 563   0]
 [  0   0   0]]

2023-01-06 15:46:17,408 - ==> Best [Top1: 81.679   Sparsity:0.00   Params: 155168 on epoch: 46]
2023-01-06 15:46:17,408 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:17,414 - 

2023-01-06 15:46:17,414 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:17,791 - Epoch: [49][   10/   37]    Overall Loss 0.431812    Objective Loss 0.431812                                        LR 0.000036    Time 0.037623    
2023-01-06 15:46:17,987 - Epoch: [49][   20/   37]    Overall Loss 0.419301    Objective Loss 0.419301                                        LR 0.000036    Time 0.028603    
2023-01-06 15:46:18,182 - Epoch: [49][   30/   37]    Overall Loss 0.420353    Objective Loss 0.420353                                        LR 0.000036    Time 0.025574    
2023-01-06 15:46:18,297 - Epoch: [49][   37/   37]    Overall Loss 0.422464    Objective Loss 0.422464    Top1 81.799163    LR 0.000036    Time 0.023835    
2023-01-06 15:46:18,375 - --- validate (epoch=49)-----------
2023-01-06 15:46:18,375 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:18,594 - Epoch: [49][    5/    5]    Loss 0.408207    Top1 82.347328    
2023-01-06 15:46:18,648 - ==> Top1: 82.347    Loss: 0.408

2023-01-06 15:46:18,648 - ==> Confusion:
[[329 100   0]
 [ 85 534   0]
 [  0   0   0]]

2023-01-06 15:46:18,649 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 155168 on epoch: 49]
2023-01-06 15:46:18,649 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:18,656 - 

2023-01-06 15:46:18,657 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:19,022 - Epoch: [50][   10/   37]    Overall Loss 0.412829    Objective Loss 0.412829                                        LR 0.000036    Time 0.036487    
2023-01-06 15:46:19,200 - Epoch: [50][   20/   37]    Overall Loss 0.414995    Objective Loss 0.414995                                        LR 0.000036    Time 0.027105    
2023-01-06 15:46:19,386 - Epoch: [50][   30/   37]    Overall Loss 0.423758    Objective Loss 0.423758                                        LR 0.000036    Time 0.024258    
2023-01-06 15:46:19,494 - Epoch: [50][   37/   37]    Overall Loss 0.421265    Objective Loss 0.421265    Top1 80.753138    LR 0.000036    Time 0.022579    
2023-01-06 15:46:19,569 - --- validate (epoch=50)-----------
2023-01-06 15:46:19,570 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:19,790 - Epoch: [50][    5/    5]    Loss 0.440958    Top1 81.965649    
2023-01-06 15:46:19,845 - ==> Top1: 81.966    Loss: 0.441

2023-01-06 15:46:19,845 - ==> Confusion:
[[340  89   0]
 [100 519   0]
 [  0   0   0]]

2023-01-06 15:46:19,846 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 155168 on epoch: 49]
2023-01-06 15:46:19,846 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:19,852 - 

2023-01-06 15:46:19,853 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:20,212 - Epoch: [51][   10/   37]    Overall Loss 0.417416    Objective Loss 0.417416                                        LR 0.000036    Time 0.035894    
2023-01-06 15:46:20,394 - Epoch: [51][   20/   37]    Overall Loss 0.412983    Objective Loss 0.412983                                        LR 0.000036    Time 0.027033    
2023-01-06 15:46:20,584 - Epoch: [51][   30/   37]    Overall Loss 0.415346    Objective Loss 0.415346                                        LR 0.000036    Time 0.024321    
2023-01-06 15:46:20,692 - Epoch: [51][   37/   37]    Overall Loss 0.414687    Objective Loss 0.414687    Top1 82.217573    LR 0.000036    Time 0.022640    
2023-01-06 15:46:20,769 - --- validate (epoch=51)-----------
2023-01-06 15:46:20,770 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:20,991 - Epoch: [51][    5/    5]    Loss 0.392585    Top1 81.202290    
2023-01-06 15:46:21,075 - ==> Top1: 81.202    Loss: 0.393

2023-01-06 15:46:21,075 - ==> Confusion:
[[321 108   0]
 [ 89 530   0]
 [  0   0   0]]

2023-01-06 15:46:21,076 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 155168 on epoch: 49]
2023-01-06 15:46:21,077 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:21,082 - 

2023-01-06 15:46:21,083 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:21,436 - Epoch: [52][   10/   37]    Overall Loss 0.427181    Objective Loss 0.427181                                        LR 0.000036    Time 0.035274    
2023-01-06 15:46:21,599 - Epoch: [52][   20/   37]    Overall Loss 0.421567    Objective Loss 0.421567                                        LR 0.000036    Time 0.025791    
2023-01-06 15:46:21,780 - Epoch: [52][   30/   37]    Overall Loss 0.419874    Objective Loss 0.419874                                        LR 0.000036    Time 0.023215    
2023-01-06 15:46:21,889 - Epoch: [52][   37/   37]    Overall Loss 0.415081    Objective Loss 0.415081    Top1 82.217573    LR 0.000036    Time 0.021760    
2023-01-06 15:46:21,956 - --- validate (epoch=52)-----------
2023-01-06 15:46:21,957 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:22,175 - Epoch: [52][    5/    5]    Loss 0.454644    Top1 81.202290    
2023-01-06 15:46:22,235 - ==> Top1: 81.202    Loss: 0.455

2023-01-06 15:46:22,235 - ==> Confusion:
[[344  85   0]
 [112 507   0]
 [  0   0   0]]

2023-01-06 15:46:22,237 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 155168 on epoch: 49]
2023-01-06 15:46:22,237 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:22,243 - 

2023-01-06 15:46:22,243 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:22,722 - Epoch: [53][   10/   37]    Overall Loss 0.416501    Objective Loss 0.416501                                        LR 0.000036    Time 0.047833    
2023-01-06 15:46:22,881 - Epoch: [53][   20/   37]    Overall Loss 0.411906    Objective Loss 0.411906                                        LR 0.000036    Time 0.031861    
2023-01-06 15:46:23,070 - Epoch: [53][   30/   37]    Overall Loss 0.413947    Objective Loss 0.413947                                        LR 0.000036    Time 0.027520    
2023-01-06 15:46:23,183 - Epoch: [53][   37/   37]    Overall Loss 0.412618    Objective Loss 0.412618    Top1 83.682008    LR 0.000036    Time 0.025366    
2023-01-06 15:46:23,253 - --- validate (epoch=53)-----------
2023-01-06 15:46:23,253 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:23,467 - Epoch: [53][    5/    5]    Loss 0.399636    Top1 81.679389    
2023-01-06 15:46:23,530 - ==> Top1: 81.679    Loss: 0.400

2023-01-06 15:46:23,530 - ==> Confusion:
[[321 108   0]
 [ 84 535   0]
 [  0   0   0]]

2023-01-06 15:46:23,532 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 155168 on epoch: 49]
2023-01-06 15:46:23,532 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:23,538 - 

2023-01-06 15:46:23,538 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:23,890 - Epoch: [54][   10/   37]    Overall Loss 0.417946    Objective Loss 0.417946                                        LR 0.000036    Time 0.035137    
2023-01-06 15:46:24,070 - Epoch: [54][   20/   37]    Overall Loss 0.412038    Objective Loss 0.412038                                        LR 0.000036    Time 0.026575    
2023-01-06 15:46:24,257 - Epoch: [54][   30/   37]    Overall Loss 0.415387    Objective Loss 0.415387                                        LR 0.000036    Time 0.023918    
2023-01-06 15:46:24,371 - Epoch: [54][   37/   37]    Overall Loss 0.413496    Objective Loss 0.413496    Top1 83.891213    LR 0.000036    Time 0.022472    
2023-01-06 15:46:24,446 - --- validate (epoch=54)-----------
2023-01-06 15:46:24,446 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:24,675 - Epoch: [54][    5/    5]    Loss 0.386729    Top1 82.347328    
2023-01-06 15:46:24,755 - ==> Top1: 82.347    Loss: 0.387

2023-01-06 15:46:24,756 - ==> Confusion:
[[366  63   0]
 [122 497   0]
 [  0   0   0]]

2023-01-06 15:46:24,757 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 155168 on epoch: 54]
2023-01-06 15:46:24,757 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:24,764 - 

2023-01-06 15:46:24,764 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:25,128 - Epoch: [55][   10/   37]    Overall Loss 0.398403    Objective Loss 0.398403                                        LR 0.000036    Time 0.036304    
2023-01-06 15:46:25,315 - Epoch: [55][   20/   37]    Overall Loss 0.404957    Objective Loss 0.404957                                        LR 0.000036    Time 0.027473    
2023-01-06 15:46:25,506 - Epoch: [55][   30/   37]    Overall Loss 0.408941    Objective Loss 0.408941                                        LR 0.000036    Time 0.024678    
2023-01-06 15:46:25,620 - Epoch: [55][   37/   37]    Overall Loss 0.409007    Objective Loss 0.409007    Top1 79.079498    LR 0.000036    Time 0.023080    
2023-01-06 15:46:25,692 - --- validate (epoch=55)-----------
2023-01-06 15:46:25,692 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:25,909 - Epoch: [55][    5/    5]    Loss 0.380052    Top1 82.347328    
2023-01-06 15:46:25,996 - ==> Top1: 82.347    Loss: 0.380

2023-01-06 15:46:25,996 - ==> Confusion:
[[335  94   0]
 [ 91 528   0]
 [  0   0   0]]

2023-01-06 15:46:25,998 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 155168 on epoch: 55]
2023-01-06 15:46:25,998 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:26,005 - 

2023-01-06 15:46:26,005 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:26,400 - Epoch: [56][   10/   37]    Overall Loss 0.407876    Objective Loss 0.407876                                        LR 0.000036    Time 0.039419    
2023-01-06 15:46:26,601 - Epoch: [56][   20/   37]    Overall Loss 0.414027    Objective Loss 0.414027                                        LR 0.000036    Time 0.029741    
2023-01-06 15:46:26,798 - Epoch: [56][   30/   37]    Overall Loss 0.408704    Objective Loss 0.408704                                        LR 0.000036    Time 0.026393    
2023-01-06 15:46:26,911 - Epoch: [56][   37/   37]    Overall Loss 0.406111    Objective Loss 0.406111    Top1 79.497908    LR 0.000036    Time 0.024448    
2023-01-06 15:46:26,982 - --- validate (epoch=56)-----------
2023-01-06 15:46:26,982 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:27,201 - Epoch: [56][    5/    5]    Loss 0.401907    Top1 82.347328    
2023-01-06 15:46:27,282 - ==> Top1: 82.347    Loss: 0.402

2023-01-06 15:46:27,282 - ==> Confusion:
[[334  95   0]
 [ 90 529   0]
 [  0   0   0]]

2023-01-06 15:46:27,284 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 155168 on epoch: 56]
2023-01-06 15:46:27,284 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:27,291 - 

2023-01-06 15:46:27,291 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:27,654 - Epoch: [57][   10/   37]    Overall Loss 0.406246    Objective Loss 0.406246                                        LR 0.000036    Time 0.036222    
2023-01-06 15:46:27,849 - Epoch: [57][   20/   37]    Overall Loss 0.409983    Objective Loss 0.409983                                        LR 0.000036    Time 0.027817    
2023-01-06 15:46:28,042 - Epoch: [57][   30/   37]    Overall Loss 0.402179    Objective Loss 0.402179                                        LR 0.000036    Time 0.024982    
2023-01-06 15:46:28,156 - Epoch: [57][   37/   37]    Overall Loss 0.404651    Objective Loss 0.404651    Top1 81.171548    LR 0.000036    Time 0.023332    
2023-01-06 15:46:28,232 - --- validate (epoch=57)-----------
2023-01-06 15:46:28,232 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:28,452 - Epoch: [57][    5/    5]    Loss 0.399980    Top1 81.297710    
2023-01-06 15:46:28,520 - ==> Top1: 81.298    Loss: 0.400

2023-01-06 15:46:28,520 - ==> Confusion:
[[295 134   0]
 [ 62 557   0]
 [  0   0   0]]

2023-01-06 15:46:28,521 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 155168 on epoch: 56]
2023-01-06 15:46:28,521 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:28,527 - 

2023-01-06 15:46:28,527 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:28,889 - Epoch: [58][   10/   37]    Overall Loss 0.394392    Objective Loss 0.394392                                        LR 0.000036    Time 0.036128    
2023-01-06 15:46:29,081 - Epoch: [58][   20/   37]    Overall Loss 0.399519    Objective Loss 0.399519                                        LR 0.000036    Time 0.027635    
2023-01-06 15:46:29,270 - Epoch: [58][   30/   37]    Overall Loss 0.402386    Objective Loss 0.402386                                        LR 0.000036    Time 0.024690    
2023-01-06 15:46:29,386 - Epoch: [58][   37/   37]    Overall Loss 0.402507    Objective Loss 0.402507    Top1 82.426778    LR 0.000036    Time 0.023154    
2023-01-06 15:46:29,464 - --- validate (epoch=58)-----------
2023-01-06 15:46:29,464 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:29,683 - Epoch: [58][    5/    5]    Loss 0.383951    Top1 82.251908    
2023-01-06 15:46:29,758 - ==> Top1: 82.252    Loss: 0.384

2023-01-06 15:46:29,758 - ==> Confusion:
[[323 106   0]
 [ 80 539   0]
 [  0   0   0]]

2023-01-06 15:46:29,759 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 155168 on epoch: 56]
2023-01-06 15:46:29,759 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:29,765 - 

2023-01-06 15:46:29,765 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:30,137 - Epoch: [59][   10/   37]    Overall Loss 0.407275    Objective Loss 0.407275                                        LR 0.000036    Time 0.037089    
2023-01-06 15:46:30,324 - Epoch: [59][   20/   37]    Overall Loss 0.399594    Objective Loss 0.399594                                        LR 0.000036    Time 0.027905    
2023-01-06 15:46:30,520 - Epoch: [59][   30/   37]    Overall Loss 0.401071    Objective Loss 0.401071                                        LR 0.000036    Time 0.025123    
2023-01-06 15:46:30,633 - Epoch: [59][   37/   37]    Overall Loss 0.401215    Objective Loss 0.401215    Top1 79.916318    LR 0.000036    Time 0.023416    
2023-01-06 15:46:30,708 - --- validate (epoch=59)-----------
2023-01-06 15:46:30,709 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:30,928 - Epoch: [59][    5/    5]    Loss 0.418952    Top1 81.965649    
2023-01-06 15:46:30,986 - ==> Top1: 81.966    Loss: 0.419

2023-01-06 15:46:30,987 - ==> Confusion:
[[364  65   0]
 [124 495   0]
 [  0   0   0]]

2023-01-06 15:46:30,988 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 155168 on epoch: 56]
2023-01-06 15:46:30,988 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:30,994 - 

2023-01-06 15:46:30,994 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:31,371 - Epoch: [60][   10/   37]    Overall Loss 0.381911    Objective Loss 0.381911                                        LR 0.000036    Time 0.037672    
2023-01-06 15:46:31,571 - Epoch: [60][   20/   37]    Overall Loss 0.392347    Objective Loss 0.392347                                        LR 0.000036    Time 0.028805    
2023-01-06 15:46:31,763 - Epoch: [60][   30/   37]    Overall Loss 0.399902    Objective Loss 0.399902                                        LR 0.000036    Time 0.025594    
2023-01-06 15:46:31,877 - Epoch: [60][   37/   37]    Overall Loss 0.399593    Objective Loss 0.399593    Top1 81.171548    LR 0.000036    Time 0.023825    
2023-01-06 15:46:31,947 - --- validate (epoch=60)-----------
2023-01-06 15:46:31,947 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:32,165 - Epoch: [60][    5/    5]    Loss 0.415447    Top1 82.633588    
2023-01-06 15:46:32,235 - ==> Top1: 82.634    Loss: 0.415

2023-01-06 15:46:32,236 - ==> Confusion:
[[344  85   0]
 [ 97 522   0]
 [  0   0   0]]

2023-01-06 15:46:32,237 - ==> Best [Top1: 82.634   Sparsity:0.00   Params: 155168 on epoch: 60]
2023-01-06 15:46:32,237 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:32,244 - 

2023-01-06 15:46:32,244 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:32,609 - Epoch: [61][   10/   37]    Overall Loss 0.398128    Objective Loss 0.398128                                        LR 0.000036    Time 0.036427    
2023-01-06 15:46:32,780 - Epoch: [61][   20/   37]    Overall Loss 0.396282    Objective Loss 0.396282                                        LR 0.000036    Time 0.026720    
2023-01-06 15:46:32,976 - Epoch: [61][   30/   37]    Overall Loss 0.399101    Objective Loss 0.399101                                        LR 0.000036    Time 0.024331    
2023-01-06 15:46:33,090 - Epoch: [61][   37/   37]    Overall Loss 0.394993    Objective Loss 0.394993    Top1 81.171548    LR 0.000036    Time 0.022810    
2023-01-06 15:46:33,159 - --- validate (epoch=61)-----------
2023-01-06 15:46:33,160 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:33,381 - Epoch: [61][    5/    5]    Loss 0.387717    Top1 83.110687    
2023-01-06 15:46:33,449 - ==> Top1: 83.111    Loss: 0.388

2023-01-06 15:46:33,450 - ==> Confusion:
[[344  85   0]
 [ 92 527   0]
 [  0   0   0]]

2023-01-06 15:46:33,451 - ==> Best [Top1: 83.111   Sparsity:0.00   Params: 155168 on epoch: 61]
2023-01-06 15:46:33,451 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:33,458 - 

2023-01-06 15:46:33,459 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:33,807 - Epoch: [62][   10/   37]    Overall Loss 0.385451    Objective Loss 0.385451                                        LR 0.000036    Time 0.034771    
2023-01-06 15:46:33,984 - Epoch: [62][   20/   37]    Overall Loss 0.392444    Objective Loss 0.392444                                        LR 0.000036    Time 0.026139    
2023-01-06 15:46:34,175 - Epoch: [62][   30/   37]    Overall Loss 0.392163    Objective Loss 0.392163                                        LR 0.000036    Time 0.023781    
2023-01-06 15:46:34,289 - Epoch: [62][   37/   37]    Overall Loss 0.393602    Objective Loss 0.393602    Top1 80.543933    LR 0.000036    Time 0.022367    
2023-01-06 15:46:34,361 - --- validate (epoch=62)-----------
2023-01-06 15:46:34,361 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:34,576 - Epoch: [62][    5/    5]    Loss 0.359704    Top1 83.015267    
2023-01-06 15:46:34,641 - ==> Top1: 83.015    Loss: 0.360

2023-01-06 15:46:34,641 - ==> Confusion:
[[314 115   0]
 [ 63 556   0]
 [  0   0   0]]

2023-01-06 15:46:34,642 - ==> Best [Top1: 83.111   Sparsity:0.00   Params: 155168 on epoch: 61]
2023-01-06 15:46:34,642 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:34,648 - 

2023-01-06 15:46:34,648 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:35,000 - Epoch: [63][   10/   37]    Overall Loss 0.401273    Objective Loss 0.401273                                        LR 0.000036    Time 0.035153    
2023-01-06 15:46:35,186 - Epoch: [63][   20/   37]    Overall Loss 0.397420    Objective Loss 0.397420                                        LR 0.000036    Time 0.026753    
2023-01-06 15:46:35,384 - Epoch: [63][   30/   37]    Overall Loss 0.393587    Objective Loss 0.393587                                        LR 0.000036    Time 0.024396    
2023-01-06 15:46:35,498 - Epoch: [63][   37/   37]    Overall Loss 0.393277    Objective Loss 0.393277    Top1 84.309623    LR 0.000036    Time 0.022867    
2023-01-06 15:46:35,567 - --- validate (epoch=63)-----------
2023-01-06 15:46:35,567 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:35,786 - Epoch: [63][    5/    5]    Loss 0.415286    Top1 82.538168    
2023-01-06 15:46:35,851 - ==> Top1: 82.538    Loss: 0.415

2023-01-06 15:46:35,851 - ==> Confusion:
[[331  98   0]
 [ 85 534   0]
 [  0   0   0]]

2023-01-06 15:46:35,852 - ==> Best [Top1: 83.111   Sparsity:0.00   Params: 155168 on epoch: 61]
2023-01-06 15:46:35,852 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:35,858 - 

2023-01-06 15:46:35,858 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:36,236 - Epoch: [64][   10/   37]    Overall Loss 0.392692    Objective Loss 0.392692                                        LR 0.000036    Time 0.037710    
2023-01-06 15:46:36,420 - Epoch: [64][   20/   37]    Overall Loss 0.389049    Objective Loss 0.389049                                        LR 0.000036    Time 0.028046    
2023-01-06 15:46:36,614 - Epoch: [64][   30/   37]    Overall Loss 0.389554    Objective Loss 0.389554                                        LR 0.000036    Time 0.025141    
2023-01-06 15:46:36,727 - Epoch: [64][   37/   37]    Overall Loss 0.392893    Objective Loss 0.392893    Top1 81.589958    LR 0.000036    Time 0.023427    
2023-01-06 15:46:36,789 - --- validate (epoch=64)-----------
2023-01-06 15:46:36,789 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:37,005 - Epoch: [64][    5/    5]    Loss 0.372743    Top1 83.206107    
2023-01-06 15:46:37,084 - ==> Top1: 83.206    Loss: 0.373

2023-01-06 15:46:37,084 - ==> Confusion:
[[341  88   0]
 [ 88 531   0]
 [  0   0   0]]

2023-01-06 15:46:37,085 - ==> Best [Top1: 83.206   Sparsity:0.00   Params: 155168 on epoch: 64]
2023-01-06 15:46:37,085 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:37,093 - 

2023-01-06 15:46:37,093 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:37,470 - Epoch: [65][   10/   37]    Overall Loss 0.375313    Objective Loss 0.375313                                        LR 0.000036    Time 0.037682    
2023-01-06 15:46:37,659 - Epoch: [65][   20/   37]    Overall Loss 0.383157    Objective Loss 0.383157                                        LR 0.000036    Time 0.028264    
2023-01-06 15:46:37,852 - Epoch: [65][   30/   37]    Overall Loss 0.389981    Objective Loss 0.389981                                        LR 0.000036    Time 0.025249    
2023-01-06 15:46:37,967 - Epoch: [65][   37/   37]    Overall Loss 0.389310    Objective Loss 0.389310    Top1 84.309623    LR 0.000036    Time 0.023570    
2023-01-06 15:46:38,033 - --- validate (epoch=65)-----------
2023-01-06 15:46:38,033 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:38,248 - Epoch: [65][    5/    5]    Loss 0.396037    Top1 82.251908    
2023-01-06 15:46:38,315 - ==> Top1: 82.252    Loss: 0.396

2023-01-06 15:46:38,315 - ==> Confusion:
[[299 130   0]
 [ 56 563   0]
 [  0   0   0]]

2023-01-06 15:46:38,316 - ==> Best [Top1: 83.206   Sparsity:0.00   Params: 155168 on epoch: 64]
2023-01-06 15:46:38,316 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:38,323 - 

2023-01-06 15:46:38,323 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:38,687 - Epoch: [66][   10/   37]    Overall Loss 0.399444    Objective Loss 0.399444                                        LR 0.000036    Time 0.036366    
2023-01-06 15:46:38,867 - Epoch: [66][   20/   37]    Overall Loss 0.392159    Objective Loss 0.392159                                        LR 0.000036    Time 0.027150    
2023-01-06 15:46:39,062 - Epoch: [66][   30/   37]    Overall Loss 0.390709    Objective Loss 0.390709                                        LR 0.000036    Time 0.024574    
2023-01-06 15:46:39,176 - Epoch: [66][   37/   37]    Overall Loss 0.389460    Objective Loss 0.389460    Top1 82.426778    LR 0.000036    Time 0.023019    
2023-01-06 15:46:39,246 - --- validate (epoch=66)-----------
2023-01-06 15:46:39,247 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:39,472 - Epoch: [66][    5/    5]    Loss 0.392478    Top1 82.824427    
2023-01-06 15:46:39,547 - ==> Top1: 82.824    Loss: 0.392

2023-01-06 15:46:39,547 - ==> Confusion:
[[340  89   0]
 [ 91 528   0]
 [  0   0   0]]

2023-01-06 15:46:39,548 - ==> Best [Top1: 83.206   Sparsity:0.00   Params: 155168 on epoch: 64]
2023-01-06 15:46:39,549 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:39,555 - 

2023-01-06 15:46:39,555 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:39,928 - Epoch: [67][   10/   37]    Overall Loss 0.389598    Objective Loss 0.389598                                        LR 0.000036    Time 0.037252    
2023-01-06 15:46:40,120 - Epoch: [67][   20/   37]    Overall Loss 0.388953    Objective Loss 0.388953                                        LR 0.000036    Time 0.028186    
2023-01-06 15:46:40,325 - Epoch: [67][   30/   37]    Overall Loss 0.387131    Objective Loss 0.387131                                        LR 0.000036    Time 0.025630    
2023-01-06 15:46:40,455 - Epoch: [67][   37/   37]    Overall Loss 0.388058    Objective Loss 0.388058    Top1 81.380753    LR 0.000036    Time 0.024267    
2023-01-06 15:46:40,526 - --- validate (epoch=67)-----------
2023-01-06 15:46:40,526 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:40,741 - Epoch: [67][    5/    5]    Loss 0.367838    Top1 82.156489    
2023-01-06 15:46:40,808 - ==> Top1: 82.156    Loss: 0.368

2023-01-06 15:46:40,808 - ==> Confusion:
[[313 116   0]
 [ 71 548   0]
 [  0   0   0]]

2023-01-06 15:46:40,810 - ==> Best [Top1: 83.206   Sparsity:0.00   Params: 155168 on epoch: 64]
2023-01-06 15:46:40,810 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:40,816 - 

2023-01-06 15:46:40,816 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:41,298 - Epoch: [68][   10/   37]    Overall Loss 0.390677    Objective Loss 0.390677                                        LR 0.000036    Time 0.048139    
2023-01-06 15:46:41,466 - Epoch: [68][   20/   37]    Overall Loss 0.389014    Objective Loss 0.389014                                        LR 0.000036    Time 0.032424    
2023-01-06 15:46:41,638 - Epoch: [68][   30/   37]    Overall Loss 0.386039    Objective Loss 0.386039                                        LR 0.000036    Time 0.027347    
2023-01-06 15:46:41,752 - Epoch: [68][   37/   37]    Overall Loss 0.387387    Objective Loss 0.387387    Top1 83.891213    LR 0.000036    Time 0.025251    
2023-01-06 15:46:41,831 - --- validate (epoch=68)-----------
2023-01-06 15:46:41,831 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:42,045 - Epoch: [68][    5/    5]    Loss 0.374347    Top1 83.206107    
2023-01-06 15:46:42,114 - ==> Top1: 83.206    Loss: 0.374

2023-01-06 15:46:42,115 - ==> Confusion:
[[339  90   0]
 [ 86 533   0]
 [  0   0   0]]

2023-01-06 15:46:42,116 - ==> Best [Top1: 83.206   Sparsity:0.00   Params: 155168 on epoch: 68]
2023-01-06 15:46:42,116 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:42,123 - 

2023-01-06 15:46:42,123 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:42,472 - Epoch: [69][   10/   37]    Overall Loss 0.376501    Objective Loss 0.376501                                        LR 0.000036    Time 0.034803    
2023-01-06 15:46:42,634 - Epoch: [69][   20/   37]    Overall Loss 0.376428    Objective Loss 0.376428                                        LR 0.000036    Time 0.025416    
2023-01-06 15:46:42,816 - Epoch: [69][   30/   37]    Overall Loss 0.381096    Objective Loss 0.381096                                        LR 0.000036    Time 0.022987    
2023-01-06 15:46:42,928 - Epoch: [69][   37/   37]    Overall Loss 0.382406    Objective Loss 0.382406    Top1 82.426778    LR 0.000036    Time 0.021657    
2023-01-06 15:46:43,009 - --- validate (epoch=69)-----------
2023-01-06 15:46:43,009 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:43,228 - Epoch: [69][    5/    5]    Loss 0.417616    Top1 82.824427    
2023-01-06 15:46:43,292 - ==> Top1: 82.824    Loss: 0.418

2023-01-06 15:46:43,293 - ==> Confusion:
[[348  81   0]
 [ 99 520   0]
 [  0   0   0]]

2023-01-06 15:46:43,294 - ==> Best [Top1: 83.206   Sparsity:0.00   Params: 155168 on epoch: 68]
2023-01-06 15:46:43,294 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:43,300 - 

2023-01-06 15:46:43,300 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:43,656 - Epoch: [70][   10/   37]    Overall Loss 0.391265    Objective Loss 0.391265                                        LR 0.000022    Time 0.035559    
2023-01-06 15:46:43,813 - Epoch: [70][   20/   37]    Overall Loss 0.388602    Objective Loss 0.388602                                        LR 0.000022    Time 0.025576    
2023-01-06 15:46:43,974 - Epoch: [70][   30/   37]    Overall Loss 0.384614    Objective Loss 0.384614                                        LR 0.000022    Time 0.022377    
2023-01-06 15:46:44,089 - Epoch: [70][   37/   37]    Overall Loss 0.382343    Objective Loss 0.382343    Top1 82.635983    LR 0.000022    Time 0.021251    
2023-01-06 15:46:44,157 - --- validate (epoch=70)-----------
2023-01-06 15:46:44,157 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:44,373 - Epoch: [70][    5/    5]    Loss 0.374852    Top1 83.301527    
2023-01-06 15:46:44,443 - ==> Top1: 83.302    Loss: 0.375

2023-01-06 15:46:44,443 - ==> Confusion:
[[348  81   0]
 [ 94 525   0]
 [  0   0   0]]

2023-01-06 15:46:44,444 - ==> Best [Top1: 83.302   Sparsity:0.00   Params: 155168 on epoch: 70]
2023-01-06 15:46:44,444 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:44,452 - 

2023-01-06 15:46:44,452 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:44,817 - Epoch: [71][   10/   37]    Overall Loss 0.373899    Objective Loss 0.373899                                        LR 0.000022    Time 0.036436    
2023-01-06 15:46:45,011 - Epoch: [71][   20/   37]    Overall Loss 0.377388    Objective Loss 0.377388                                        LR 0.000022    Time 0.027897    
2023-01-06 15:46:45,197 - Epoch: [71][   30/   37]    Overall Loss 0.378131    Objective Loss 0.378131                                        LR 0.000022    Time 0.024805    
2023-01-06 15:46:45,312 - Epoch: [71][   37/   37]    Overall Loss 0.378439    Objective Loss 0.378439    Top1 81.589958    LR 0.000022    Time 0.023207    
2023-01-06 15:46:45,393 - --- validate (epoch=71)-----------
2023-01-06 15:46:45,393 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:45,623 - Epoch: [71][    5/    5]    Loss 0.383730    Top1 83.015267    
2023-01-06 15:46:45,679 - ==> Top1: 83.015    Loss: 0.384

2023-01-06 15:46:45,680 - ==> Confusion:
[[344  85   0]
 [ 93 526   0]
 [  0   0   0]]

2023-01-06 15:46:45,681 - ==> Best [Top1: 83.302   Sparsity:0.00   Params: 155168 on epoch: 70]
2023-01-06 15:46:45,681 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:45,687 - 

2023-01-06 15:46:45,687 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:46,046 - Epoch: [72][   10/   37]    Overall Loss 0.363812    Objective Loss 0.363812                                        LR 0.000022    Time 0.035826    
2023-01-06 15:46:46,241 - Epoch: [72][   20/   37]    Overall Loss 0.377423    Objective Loss 0.377423                                        LR 0.000022    Time 0.027609    
2023-01-06 15:46:46,441 - Epoch: [72][   30/   37]    Overall Loss 0.380445    Objective Loss 0.380445                                        LR 0.000022    Time 0.025050    
2023-01-06 15:46:46,555 - Epoch: [72][   37/   37]    Overall Loss 0.379806    Objective Loss 0.379806    Top1 82.008368    LR 0.000022    Time 0.023377    
2023-01-06 15:46:46,626 - --- validate (epoch=72)-----------
2023-01-06 15:46:46,626 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:46,850 - Epoch: [72][    5/    5]    Loss 0.363666    Top1 83.301527    
2023-01-06 15:46:46,908 - ==> Top1: 83.302    Loss: 0.364

2023-01-06 15:46:46,909 - ==> Confusion:
[[373  56   0]
 [119 500   0]
 [  0   0   0]]

2023-01-06 15:46:46,910 - ==> Best [Top1: 83.302   Sparsity:0.00   Params: 155168 on epoch: 72]
2023-01-06 15:46:46,910 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:46,917 - 

2023-01-06 15:46:46,917 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:47,285 - Epoch: [73][   10/   37]    Overall Loss 0.385173    Objective Loss 0.385173                                        LR 0.000022    Time 0.036703    
2023-01-06 15:46:47,458 - Epoch: [73][   20/   37]    Overall Loss 0.378270    Objective Loss 0.378270                                        LR 0.000022    Time 0.026987    
2023-01-06 15:46:47,646 - Epoch: [73][   30/   37]    Overall Loss 0.374672    Objective Loss 0.374672                                        LR 0.000022    Time 0.024217    
2023-01-06 15:46:47,760 - Epoch: [73][   37/   37]    Overall Loss 0.377172    Objective Loss 0.377172    Top1 83.891213    LR 0.000022    Time 0.022688    
2023-01-06 15:46:47,832 - --- validate (epoch=73)-----------
2023-01-06 15:46:47,832 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:48,055 - Epoch: [73][    5/    5]    Loss 0.366112    Top1 83.587786    
2023-01-06 15:46:48,130 - ==> Top1: 83.588    Loss: 0.366

2023-01-06 15:46:48,130 - ==> Confusion:
[[338  91   0]
 [ 81 538   0]
 [  0   0   0]]

2023-01-06 15:46:48,131 - ==> Best [Top1: 83.588   Sparsity:0.00   Params: 155168 on epoch: 73]
2023-01-06 15:46:48,131 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:48,139 - 

2023-01-06 15:46:48,139 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:48,497 - Epoch: [74][   10/   37]    Overall Loss 0.369839    Objective Loss 0.369839                                        LR 0.000022    Time 0.035758    
2023-01-06 15:46:48,675 - Epoch: [74][   20/   37]    Overall Loss 0.372297    Objective Loss 0.372297                                        LR 0.000022    Time 0.026738    
2023-01-06 15:46:48,864 - Epoch: [74][   30/   37]    Overall Loss 0.373896    Objective Loss 0.373896                                        LR 0.000022    Time 0.024125    
2023-01-06 15:46:48,977 - Epoch: [74][   37/   37]    Overall Loss 0.375857    Objective Loss 0.375857    Top1 82.217573    LR 0.000022    Time 0.022605    
2023-01-06 15:46:49,055 - --- validate (epoch=74)-----------
2023-01-06 15:46:49,055 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:49,275 - Epoch: [74][    5/    5]    Loss 0.368522    Top1 82.729008    
2023-01-06 15:46:49,338 - ==> Top1: 82.729    Loss: 0.369

2023-01-06 15:46:49,339 - ==> Confusion:
[[355  74   0]
 [107 512   0]
 [  0   0   0]]

2023-01-06 15:46:49,340 - ==> Best [Top1: 83.588   Sparsity:0.00   Params: 155168 on epoch: 73]
2023-01-06 15:46:49,340 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:49,346 - 

2023-01-06 15:46:49,346 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:49,701 - Epoch: [75][   10/   37]    Overall Loss 0.372681    Objective Loss 0.372681                                        LR 0.000022    Time 0.035468    
2023-01-06 15:46:49,877 - Epoch: [75][   20/   37]    Overall Loss 0.376644    Objective Loss 0.376644                                        LR 0.000022    Time 0.026478    
2023-01-06 15:46:50,078 - Epoch: [75][   30/   37]    Overall Loss 0.379531    Objective Loss 0.379531                                        LR 0.000022    Time 0.024350    
2023-01-06 15:46:50,191 - Epoch: [75][   37/   37]    Overall Loss 0.375271    Objective Loss 0.375271    Top1 82.426778    LR 0.000022    Time 0.022785    
2023-01-06 15:46:50,264 - --- validate (epoch=75)-----------
2023-01-06 15:46:50,264 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:50,487 - Epoch: [75][    5/    5]    Loss 0.375380    Top1 83.492366    
2023-01-06 15:46:50,556 - ==> Top1: 83.492    Loss: 0.375

2023-01-06 15:46:50,556 - ==> Confusion:
[[335  94   0]
 [ 79 540   0]
 [  0   0   0]]

2023-01-06 15:46:50,557 - ==> Best [Top1: 83.588   Sparsity:0.00   Params: 155168 on epoch: 73]
2023-01-06 15:46:50,558 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:50,563 - 

2023-01-06 15:46:50,564 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:50,957 - Epoch: [76][   10/   37]    Overall Loss 0.365741    Objective Loss 0.365741                                        LR 0.000022    Time 0.039292    
2023-01-06 15:46:51,161 - Epoch: [76][   20/   37]    Overall Loss 0.375176    Objective Loss 0.375176                                        LR 0.000022    Time 0.029819    
2023-01-06 15:46:51,331 - Epoch: [76][   30/   37]    Overall Loss 0.375411    Objective Loss 0.375411                                        LR 0.000022    Time 0.025514    
2023-01-06 15:46:51,445 - Epoch: [76][   37/   37]    Overall Loss 0.377106    Objective Loss 0.377106    Top1 81.589958    LR 0.000022    Time 0.023776    
2023-01-06 15:46:51,513 - --- validate (epoch=76)-----------
2023-01-06 15:46:51,513 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:51,743 - Epoch: [76][    5/    5]    Loss 0.357867    Top1 83.778626    
2023-01-06 15:46:51,798 - ==> Top1: 83.779    Loss: 0.358

2023-01-06 15:46:51,799 - ==> Confusion:
[[355  74   0]
 [ 96 523   0]
 [  0   0   0]]

2023-01-06 15:46:51,800 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 155168 on epoch: 76]
2023-01-06 15:46:51,800 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:51,808 - 

2023-01-06 15:46:51,808 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:52,166 - Epoch: [77][   10/   37]    Overall Loss 0.378073    Objective Loss 0.378073                                        LR 0.000022    Time 0.035766    
2023-01-06 15:46:52,336 - Epoch: [77][   20/   37]    Overall Loss 0.380613    Objective Loss 0.380613                                        LR 0.000022    Time 0.026337    
2023-01-06 15:46:52,506 - Epoch: [77][   30/   37]    Overall Loss 0.380670    Objective Loss 0.380670                                        LR 0.000022    Time 0.023210    
2023-01-06 15:46:52,607 - Epoch: [77][   37/   37]    Overall Loss 0.375293    Objective Loss 0.375293    Top1 83.682008    LR 0.000022    Time 0.021546    
2023-01-06 15:46:52,688 - --- validate (epoch=77)-----------
2023-01-06 15:46:52,688 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:52,909 - Epoch: [77][    5/    5]    Loss 0.395644    Top1 82.729008    
2023-01-06 15:46:52,968 - ==> Top1: 82.729    Loss: 0.396

2023-01-06 15:46:52,969 - ==> Confusion:
[[310 119   0]
 [ 62 557   0]
 [  0   0   0]]

2023-01-06 15:46:52,970 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 155168 on epoch: 76]
2023-01-06 15:46:52,970 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:52,976 - 

2023-01-06 15:46:52,976 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:53,338 - Epoch: [78][   10/   37]    Overall Loss 0.387618    Objective Loss 0.387618                                        LR 0.000022    Time 0.036140    
2023-01-06 15:46:53,513 - Epoch: [78][   20/   37]    Overall Loss 0.382296    Objective Loss 0.382296                                        LR 0.000022    Time 0.026784    
2023-01-06 15:46:53,692 - Epoch: [78][   30/   37]    Overall Loss 0.374479    Objective Loss 0.374479                                        LR 0.000022    Time 0.023825    
2023-01-06 15:46:53,798 - Epoch: [78][   37/   37]    Overall Loss 0.375428    Objective Loss 0.375428    Top1 84.518828    LR 0.000022    Time 0.022164    
2023-01-06 15:46:53,868 - --- validate (epoch=78)-----------
2023-01-06 15:46:53,869 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:54,097 - Epoch: [78][    5/    5]    Loss 0.379321    Top1 83.015267    
2023-01-06 15:46:54,169 - ==> Top1: 83.015    Loss: 0.379

2023-01-06 15:46:54,170 - ==> Confusion:
[[347  82   0]
 [ 96 523   0]
 [  0   0   0]]

2023-01-06 15:46:54,171 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 155168 on epoch: 76]
2023-01-06 15:46:54,171 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:54,177 - 

2023-01-06 15:46:54,177 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:54,564 - Epoch: [79][   10/   37]    Overall Loss 0.371552    Objective Loss 0.371552                                        LR 0.000022    Time 0.038619    
2023-01-06 15:46:54,757 - Epoch: [79][   20/   37]    Overall Loss 0.376835    Objective Loss 0.376835                                        LR 0.000022    Time 0.028945    
2023-01-06 15:46:54,957 - Epoch: [79][   30/   37]    Overall Loss 0.373948    Objective Loss 0.373948                                        LR 0.000022    Time 0.025934    
2023-01-06 15:46:55,070 - Epoch: [79][   37/   37]    Overall Loss 0.373828    Objective Loss 0.373828    Top1 83.263598    LR 0.000022    Time 0.024083    
2023-01-06 15:46:55,141 - --- validate (epoch=79)-----------
2023-01-06 15:46:55,142 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:55,364 - Epoch: [79][    5/    5]    Loss 0.388360    Top1 83.683206    
2023-01-06 15:46:55,424 - ==> Top1: 83.683    Loss: 0.388

2023-01-06 15:46:55,424 - ==> Confusion:
[[336  93   0]
 [ 78 541   0]
 [  0   0   0]]

2023-01-06 15:46:55,425 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 155168 on epoch: 76]
2023-01-06 15:46:55,425 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:55,431 - 

2023-01-06 15:46:55,431 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:55,794 - Epoch: [80][   10/   37]    Overall Loss 0.377108    Objective Loss 0.377108                                        LR 0.000022    Time 0.036175    
2023-01-06 15:46:55,971 - Epoch: [80][   20/   37]    Overall Loss 0.372462    Objective Loss 0.372462                                        LR 0.000022    Time 0.026922    
2023-01-06 15:46:56,145 - Epoch: [80][   30/   37]    Overall Loss 0.369747    Objective Loss 0.369747                                        LR 0.000022    Time 0.023672    
2023-01-06 15:46:56,248 - Epoch: [80][   37/   37]    Overall Loss 0.372395    Objective Loss 0.372395    Top1 82.008368    LR 0.000022    Time 0.021986    
2023-01-06 15:46:56,326 - --- validate (epoch=80)-----------
2023-01-06 15:46:56,327 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:56,547 - Epoch: [80][    5/    5]    Loss 0.363341    Top1 82.824427    
2023-01-06 15:46:56,616 - ==> Top1: 82.824    Loss: 0.363

2023-01-06 15:46:56,617 - ==> Confusion:
[[343  86   0]
 [ 94 525   0]
 [  0   0   0]]

2023-01-06 15:46:56,618 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 155168 on epoch: 76]
2023-01-06 15:46:56,618 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:56,624 - 

2023-01-06 15:46:56,624 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:56,989 - Epoch: [81][   10/   37]    Overall Loss 0.368783    Objective Loss 0.368783                                        LR 0.000022    Time 0.036481    
2023-01-06 15:46:57,163 - Epoch: [81][   20/   37]    Overall Loss 0.368824    Objective Loss 0.368824                                        LR 0.000022    Time 0.026899    
2023-01-06 15:46:57,344 - Epoch: [81][   30/   37]    Overall Loss 0.371483    Objective Loss 0.371483                                        LR 0.000022    Time 0.023973    
2023-01-06 15:46:57,461 - Epoch: [81][   37/   37]    Overall Loss 0.370263    Objective Loss 0.370263    Top1 82.845188    LR 0.000022    Time 0.022581    
2023-01-06 15:46:57,531 - --- validate (epoch=81)-----------
2023-01-06 15:46:57,531 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:57,762 - Epoch: [81][    5/    5]    Loss 0.408691    Top1 83.396947    
2023-01-06 15:46:57,823 - ==> Top1: 83.397    Loss: 0.409

2023-01-06 15:46:57,823 - ==> Confusion:
[[346  83   0]
 [ 91 528   0]
 [  0   0   0]]

2023-01-06 15:46:57,824 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 155168 on epoch: 76]
2023-01-06 15:46:57,825 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:57,830 - 

2023-01-06 15:46:57,830 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:58,194 - Epoch: [82][   10/   37]    Overall Loss 0.373780    Objective Loss 0.373780                                        LR 0.000022    Time 0.036299    
2023-01-06 15:46:58,365 - Epoch: [82][   20/   37]    Overall Loss 0.367747    Objective Loss 0.367747                                        LR 0.000022    Time 0.026658    
2023-01-06 15:46:58,540 - Epoch: [82][   30/   37]    Overall Loss 0.370593    Objective Loss 0.370593                                        LR 0.000022    Time 0.023611    
2023-01-06 15:46:58,642 - Epoch: [82][   37/   37]    Overall Loss 0.369496    Objective Loss 0.369496    Top1 84.100418    LR 0.000022    Time 0.021894    
2023-01-06 15:46:58,711 - --- validate (epoch=82)-----------
2023-01-06 15:46:58,711 - 1048 samples (256 per mini-batch)
2023-01-06 15:46:58,932 - Epoch: [82][    5/    5]    Loss 0.381167    Top1 83.301527    
2023-01-06 15:46:58,992 - ==> Top1: 83.302    Loss: 0.381

2023-01-06 15:46:58,993 - ==> Confusion:
[[343  86   0]
 [ 89 530   0]
 [  0   0   0]]

2023-01-06 15:46:58,994 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 155168 on epoch: 76]
2023-01-06 15:46:58,994 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:46:59,000 - 

2023-01-06 15:46:59,000 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:46:59,360 - Epoch: [83][   10/   37]    Overall Loss 0.366926    Objective Loss 0.366926                                        LR 0.000022    Time 0.035934    
2023-01-06 15:46:59,528 - Epoch: [83][   20/   37]    Overall Loss 0.363940    Objective Loss 0.363940                                        LR 0.000022    Time 0.026306    
2023-01-06 15:46:59,701 - Epoch: [83][   30/   37]    Overall Loss 0.368081    Objective Loss 0.368081                                        LR 0.000022    Time 0.023290    
2023-01-06 15:46:59,800 - Epoch: [83][   37/   37]    Overall Loss 0.368088    Objective Loss 0.368088    Top1 83.682008    LR 0.000022    Time 0.021565    
2023-01-06 15:46:59,871 - --- validate (epoch=83)-----------
2023-01-06 15:46:59,871 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:00,087 - Epoch: [83][    5/    5]    Loss 0.346343    Top1 83.969466    
2023-01-06 15:47:00,153 - ==> Top1: 83.969    Loss: 0.346

2023-01-06 15:47:00,153 - ==> Confusion:
[[352  77   0]
 [ 91 528   0]
 [  0   0   0]]

2023-01-06 15:47:00,154 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 155168 on epoch: 83]
2023-01-06 15:47:00,154 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:00,162 - 

2023-01-06 15:47:00,162 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:00,687 - Epoch: [84][   10/   37]    Overall Loss 0.355901    Objective Loss 0.355901                                        LR 0.000022    Time 0.052401    
2023-01-06 15:47:00,885 - Epoch: [84][   20/   37]    Overall Loss 0.360640    Objective Loss 0.360640                                        LR 0.000022    Time 0.036084    
2023-01-06 15:47:01,097 - Epoch: [84][   30/   37]    Overall Loss 0.362332    Objective Loss 0.362332                                        LR 0.000022    Time 0.031096    
2023-01-06 15:47:01,232 - Epoch: [84][   37/   37]    Overall Loss 0.368364    Objective Loss 0.368364    Top1 79.916318    LR 0.000022    Time 0.028875    
2023-01-06 15:47:01,303 - --- validate (epoch=84)-----------
2023-01-06 15:47:01,303 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:01,553 - Epoch: [84][    5/    5]    Loss 0.379529    Top1 83.206107    
2023-01-06 15:47:01,627 - ==> Top1: 83.206    Loss: 0.380

2023-01-06 15:47:01,628 - ==> Confusion:
[[375  54   0]
 [122 497   0]
 [  0   0   0]]

2023-01-06 15:47:01,629 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 155168 on epoch: 83]
2023-01-06 15:47:01,629 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:01,635 - 

2023-01-06 15:47:01,635 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:02,000 - Epoch: [85][   10/   37]    Overall Loss 0.380091    Objective Loss 0.380091                                        LR 0.000022    Time 0.036424    
2023-01-06 15:47:02,166 - Epoch: [85][   20/   37]    Overall Loss 0.369846    Objective Loss 0.369846                                        LR 0.000022    Time 0.026464    
2023-01-06 15:47:02,334 - Epoch: [85][   30/   37]    Overall Loss 0.365316    Objective Loss 0.365316                                        LR 0.000022    Time 0.023239    
2023-01-06 15:47:02,445 - Epoch: [85][   37/   37]    Overall Loss 0.365684    Objective Loss 0.365684    Top1 80.753138    LR 0.000022    Time 0.021855    
2023-01-06 15:47:02,512 - --- validate (epoch=85)-----------
2023-01-06 15:47:02,512 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:02,733 - Epoch: [85][    5/    5]    Loss 0.357130    Top1 83.778626    
2023-01-06 15:47:02,800 - ==> Top1: 83.779    Loss: 0.357

2023-01-06 15:47:02,800 - ==> Confusion:
[[363  66   0]
 [104 515   0]
 [  0   0   0]]

2023-01-06 15:47:02,801 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 155168 on epoch: 83]
2023-01-06 15:47:02,802 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:02,808 - 

2023-01-06 15:47:02,808 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:03,149 - Epoch: [86][   10/   37]    Overall Loss 0.366920    Objective Loss 0.366920                                        LR 0.000022    Time 0.034061    
2023-01-06 15:47:03,311 - Epoch: [86][   20/   37]    Overall Loss 0.364549    Objective Loss 0.364549                                        LR 0.000022    Time 0.025049    
2023-01-06 15:47:03,479 - Epoch: [86][   30/   37]    Overall Loss 0.362078    Objective Loss 0.362078                                        LR 0.000022    Time 0.022276    
2023-01-06 15:47:03,583 - Epoch: [86][   37/   37]    Overall Loss 0.365055    Objective Loss 0.365055    Top1 82.008368    LR 0.000022    Time 0.020877    
2023-01-06 15:47:03,659 - --- validate (epoch=86)-----------
2023-01-06 15:47:03,659 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:03,875 - Epoch: [86][    5/    5]    Loss 0.394050    Top1 83.301527    
2023-01-06 15:47:03,928 - ==> Top1: 83.302    Loss: 0.394

2023-01-06 15:47:03,929 - ==> Confusion:
[[345  84   0]
 [ 91 528   0]
 [  0   0   0]]

2023-01-06 15:47:03,930 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 155168 on epoch: 83]
2023-01-06 15:47:03,930 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:03,937 - 

2023-01-06 15:47:03,937 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:04,294 - Epoch: [87][   10/   37]    Overall Loss 0.372177    Objective Loss 0.372177                                        LR 0.000022    Time 0.035625    
2023-01-06 15:47:04,455 - Epoch: [87][   20/   37]    Overall Loss 0.360871    Objective Loss 0.360871                                        LR 0.000022    Time 0.025827    
2023-01-06 15:47:04,639 - Epoch: [87][   30/   37]    Overall Loss 0.360483    Objective Loss 0.360483                                        LR 0.000022    Time 0.023342    
2023-01-06 15:47:04,754 - Epoch: [87][   37/   37]    Overall Loss 0.363935    Objective Loss 0.363935    Top1 84.309623    LR 0.000022    Time 0.022038    
2023-01-06 15:47:04,824 - --- validate (epoch=87)-----------
2023-01-06 15:47:04,824 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:05,045 - Epoch: [87][    5/    5]    Loss 0.356081    Top1 84.255725    
2023-01-06 15:47:05,111 - ==> Top1: 84.256    Loss: 0.356

2023-01-06 15:47:05,111 - ==> Confusion:
[[341  88   0]
 [ 77 542   0]
 [  0   0   0]]

2023-01-06 15:47:05,113 - ==> Best [Top1: 84.256   Sparsity:0.00   Params: 155168 on epoch: 87]
2023-01-06 15:47:05,113 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:05,121 - 

2023-01-06 15:47:05,121 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:05,481 - Epoch: [88][   10/   37]    Overall Loss 0.365866    Objective Loss 0.365866                                        LR 0.000022    Time 0.036001    
2023-01-06 15:47:05,646 - Epoch: [88][   20/   37]    Overall Loss 0.363421    Objective Loss 0.363421                                        LR 0.000022    Time 0.026219    
2023-01-06 15:47:05,816 - Epoch: [88][   30/   37]    Overall Loss 0.361290    Objective Loss 0.361290                                        LR 0.000022    Time 0.023123    
2023-01-06 15:47:05,920 - Epoch: [88][   37/   37]    Overall Loss 0.362830    Objective Loss 0.362830    Top1 82.635983    LR 0.000022    Time 0.021558    
2023-01-06 15:47:05,991 - --- validate (epoch=88)-----------
2023-01-06 15:47:05,991 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:06,211 - Epoch: [88][    5/    5]    Loss 0.415560    Top1 83.969466    
2023-01-06 15:47:06,277 - ==> Top1: 83.969    Loss: 0.416

2023-01-06 15:47:06,278 - ==> Confusion:
[[349  80   0]
 [ 88 531   0]
 [  0   0   0]]

2023-01-06 15:47:06,279 - ==> Best [Top1: 84.256   Sparsity:0.00   Params: 155168 on epoch: 87]
2023-01-06 15:47:06,279 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:06,285 - 

2023-01-06 15:47:06,285 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:06,665 - Epoch: [89][   10/   37]    Overall Loss 0.358302    Objective Loss 0.358302                                        LR 0.000022    Time 0.037890    
2023-01-06 15:47:06,862 - Epoch: [89][   20/   37]    Overall Loss 0.362079    Objective Loss 0.362079                                        LR 0.000022    Time 0.028796    
2023-01-06 15:47:07,055 - Epoch: [89][   30/   37]    Overall Loss 0.360926    Objective Loss 0.360926                                        LR 0.000022    Time 0.025594    
2023-01-06 15:47:07,164 - Epoch: [89][   37/   37]    Overall Loss 0.360372    Objective Loss 0.360372    Top1 83.054393    LR 0.000022    Time 0.023702    
2023-01-06 15:47:07,244 - --- validate (epoch=89)-----------
2023-01-06 15:47:07,244 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:07,464 - Epoch: [89][    5/    5]    Loss 0.360307    Top1 84.255725    
2023-01-06 15:47:07,531 - ==> Top1: 84.256    Loss: 0.360

2023-01-06 15:47:07,531 - ==> Confusion:
[[353  76   0]
 [ 89 530   0]
 [  0   0   0]]

2023-01-06 15:47:07,532 - ==> Best [Top1: 84.256   Sparsity:0.00   Params: 155168 on epoch: 89]
2023-01-06 15:47:07,532 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:07,539 - 

2023-01-06 15:47:07,540 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:07,894 - Epoch: [90][   10/   37]    Overall Loss 0.353077    Objective Loss 0.353077                                        LR 0.000022    Time 0.035323    
2023-01-06 15:47:08,051 - Epoch: [90][   20/   37]    Overall Loss 0.357556    Objective Loss 0.357556                                        LR 0.000022    Time 0.025467    
2023-01-06 15:47:08,233 - Epoch: [90][   30/   37]    Overall Loss 0.364171    Objective Loss 0.364171                                        LR 0.000022    Time 0.023031    
2023-01-06 15:47:08,343 - Epoch: [90][   37/   37]    Overall Loss 0.361393    Objective Loss 0.361393    Top1 83.891213    LR 0.000022    Time 0.021655    
2023-01-06 15:47:08,415 - --- validate (epoch=90)-----------
2023-01-06 15:47:08,415 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:08,631 - Epoch: [90][    5/    5]    Loss 0.338780    Top1 84.064885    
2023-01-06 15:47:08,697 - ==> Top1: 84.065    Loss: 0.339

2023-01-06 15:47:08,698 - ==> Confusion:
[[350  79   0]
 [ 88 531   0]
 [  0   0   0]]

2023-01-06 15:47:08,699 - ==> Best [Top1: 84.256   Sparsity:0.00   Params: 155168 on epoch: 89]
2023-01-06 15:47:08,699 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:08,705 - 

2023-01-06 15:47:08,705 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:09,063 - Epoch: [91][   10/   37]    Overall Loss 0.357583    Objective Loss 0.357583                                        LR 0.000022    Time 0.035701    
2023-01-06 15:47:09,222 - Epoch: [91][   20/   37]    Overall Loss 0.360970    Objective Loss 0.360970                                        LR 0.000022    Time 0.025779    
2023-01-06 15:47:09,402 - Epoch: [91][   30/   37]    Overall Loss 0.358845    Objective Loss 0.358845                                        LR 0.000022    Time 0.023172    
2023-01-06 15:47:09,516 - Epoch: [91][   37/   37]    Overall Loss 0.362507    Objective Loss 0.362507    Top1 83.682008    LR 0.000022    Time 0.021868    
2023-01-06 15:47:09,587 - --- validate (epoch=91)-----------
2023-01-06 15:47:09,588 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:09,814 - Epoch: [91][    5/    5]    Loss 0.365338    Top1 84.064885    
2023-01-06 15:47:09,875 - ==> Top1: 84.065    Loss: 0.365

2023-01-06 15:47:09,876 - ==> Confusion:
[[340  89   0]
 [ 78 541   0]
 [  0   0   0]]

2023-01-06 15:47:09,877 - ==> Best [Top1: 84.256   Sparsity:0.00   Params: 155168 on epoch: 89]
2023-01-06 15:47:09,877 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:09,883 - 

2023-01-06 15:47:09,883 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:10,247 - Epoch: [92][   10/   37]    Overall Loss 0.367581    Objective Loss 0.367581                                        LR 0.000022    Time 0.036386    
2023-01-06 15:47:10,419 - Epoch: [92][   20/   37]    Overall Loss 0.370949    Objective Loss 0.370949                                        LR 0.000022    Time 0.026776    
2023-01-06 15:47:10,593 - Epoch: [92][   30/   37]    Overall Loss 0.364418    Objective Loss 0.364418                                        LR 0.000022    Time 0.023624    
2023-01-06 15:47:10,696 - Epoch: [92][   37/   37]    Overall Loss 0.361448    Objective Loss 0.361448    Top1 85.983264    LR 0.000022    Time 0.021925    
2023-01-06 15:47:10,772 - --- validate (epoch=92)-----------
2023-01-06 15:47:10,773 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:10,993 - Epoch: [92][    5/    5]    Loss 0.407902    Top1 83.683206    
2023-01-06 15:47:11,055 - ==> Top1: 83.683    Loss: 0.408

2023-01-06 15:47:11,055 - ==> Confusion:
[[362  67   0]
 [104 515   0]
 [  0   0   0]]

2023-01-06 15:47:11,057 - ==> Best [Top1: 84.256   Sparsity:0.00   Params: 155168 on epoch: 89]
2023-01-06 15:47:11,057 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:11,063 - 

2023-01-06 15:47:11,063 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:11,439 - Epoch: [93][   10/   37]    Overall Loss 0.360624    Objective Loss 0.360624                                        LR 0.000022    Time 0.037558    
2023-01-06 15:47:11,619 - Epoch: [93][   20/   37]    Overall Loss 0.358537    Objective Loss 0.358537                                        LR 0.000022    Time 0.027752    
2023-01-06 15:47:11,803 - Epoch: [93][   30/   37]    Overall Loss 0.361614    Objective Loss 0.361614                                        LR 0.000022    Time 0.024603    
2023-01-06 15:47:11,910 - Epoch: [93][   37/   37]    Overall Loss 0.361432    Objective Loss 0.361432    Top1 85.355649    LR 0.000022    Time 0.022842    
2023-01-06 15:47:11,988 - --- validate (epoch=93)-----------
2023-01-06 15:47:11,988 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:12,209 - Epoch: [93][    5/    5]    Loss 0.362787    Top1 84.160305    
2023-01-06 15:47:12,274 - ==> Top1: 84.160    Loss: 0.363

2023-01-06 15:47:12,274 - ==> Confusion:
[[368  61   0]
 [105 514   0]
 [  0   0   0]]

2023-01-06 15:47:12,275 - ==> Best [Top1: 84.256   Sparsity:0.00   Params: 155168 on epoch: 89]
2023-01-06 15:47:12,275 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:12,282 - 

2023-01-06 15:47:12,282 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:12,653 - Epoch: [94][   10/   37]    Overall Loss 0.364454    Objective Loss 0.364454                                        LR 0.000022    Time 0.037037    
2023-01-06 15:47:12,816 - Epoch: [94][   20/   37]    Overall Loss 0.362554    Objective Loss 0.362554                                        LR 0.000022    Time 0.026675    
2023-01-06 15:47:13,001 - Epoch: [94][   30/   37]    Overall Loss 0.361569    Objective Loss 0.361569                                        LR 0.000022    Time 0.023938    
2023-01-06 15:47:13,109 - Epoch: [94][   37/   37]    Overall Loss 0.362353    Objective Loss 0.362353    Top1 82.008368    LR 0.000022    Time 0.022303    
2023-01-06 15:47:13,186 - --- validate (epoch=94)-----------
2023-01-06 15:47:13,187 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:13,407 - Epoch: [94][    5/    5]    Loss 0.365383    Top1 83.874046    
2023-01-06 15:47:13,474 - ==> Top1: 83.874    Loss: 0.365

2023-01-06 15:47:13,474 - ==> Confusion:
[[314 115   0]
 [ 54 565   0]
 [  0   0   0]]

2023-01-06 15:47:13,475 - ==> Best [Top1: 84.256   Sparsity:0.00   Params: 155168 on epoch: 89]
2023-01-06 15:47:13,475 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:13,481 - 

2023-01-06 15:47:13,482 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:13,843 - Epoch: [95][   10/   37]    Overall Loss 0.352216    Objective Loss 0.352216                                        LR 0.000022    Time 0.036037    
2023-01-06 15:47:14,018 - Epoch: [95][   20/   37]    Overall Loss 0.360272    Objective Loss 0.360272                                        LR 0.000022    Time 0.026773    
2023-01-06 15:47:14,213 - Epoch: [95][   30/   37]    Overall Loss 0.362942    Objective Loss 0.362942                                        LR 0.000022    Time 0.024316    
2023-01-06 15:47:14,330 - Epoch: [95][   37/   37]    Overall Loss 0.363077    Objective Loss 0.363077    Top1 86.192469    LR 0.000022    Time 0.022888    
2023-01-06 15:47:14,415 - --- validate (epoch=95)-----------
2023-01-06 15:47:14,415 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:14,635 - Epoch: [95][    5/    5]    Loss 0.369654    Top1 83.874046    
2023-01-06 15:47:14,711 - ==> Top1: 83.874    Loss: 0.370

2023-01-06 15:47:14,711 - ==> Confusion:
[[335  94   0]
 [ 75 544   0]
 [  0   0   0]]

2023-01-06 15:47:14,712 - ==> Best [Top1: 84.256   Sparsity:0.00   Params: 155168 on epoch: 89]
2023-01-06 15:47:14,712 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:14,718 - 

2023-01-06 15:47:14,718 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:15,083 - Epoch: [96][   10/   37]    Overall Loss 0.363390    Objective Loss 0.363390                                        LR 0.000022    Time 0.036422    
2023-01-06 15:47:15,252 - Epoch: [96][   20/   37]    Overall Loss 0.363552    Objective Loss 0.363552                                        LR 0.000022    Time 0.026652    
2023-01-06 15:47:15,425 - Epoch: [96][   30/   37]    Overall Loss 0.362756    Objective Loss 0.362756                                        LR 0.000022    Time 0.023511    
2023-01-06 15:47:15,531 - Epoch: [96][   37/   37]    Overall Loss 0.362644    Objective Loss 0.362644    Top1 82.635983    LR 0.000022    Time 0.021920    
2023-01-06 15:47:15,605 - --- validate (epoch=96)-----------
2023-01-06 15:47:15,605 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:15,821 - Epoch: [96][    5/    5]    Loss 0.362958    Top1 83.778626    
2023-01-06 15:47:15,883 - ==> Top1: 83.779    Loss: 0.363

2023-01-06 15:47:15,883 - ==> Confusion:
[[360  69   0]
 [101 518   0]
 [  0   0   0]]

2023-01-06 15:47:15,885 - ==> Best [Top1: 84.256   Sparsity:0.00   Params: 155168 on epoch: 89]
2023-01-06 15:47:15,885 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:15,891 - 

2023-01-06 15:47:15,891 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:16,269 - Epoch: [97][   10/   37]    Overall Loss 0.353991    Objective Loss 0.353991                                        LR 0.000022    Time 0.037732    
2023-01-06 15:47:16,462 - Epoch: [97][   20/   37]    Overall Loss 0.356999    Objective Loss 0.356999                                        LR 0.000022    Time 0.028521    
2023-01-06 15:47:16,656 - Epoch: [97][   30/   37]    Overall Loss 0.355351    Objective Loss 0.355351                                        LR 0.000022    Time 0.025467    
2023-01-06 15:47:16,770 - Epoch: [97][   37/   37]    Overall Loss 0.355573    Objective Loss 0.355573    Top1 82.008368    LR 0.000022    Time 0.023702    
2023-01-06 15:47:16,845 - --- validate (epoch=97)-----------
2023-01-06 15:47:16,845 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:17,067 - Epoch: [97][    5/    5]    Loss 0.337034    Top1 84.160305    
2023-01-06 15:47:17,139 - ==> Top1: 84.160    Loss: 0.337

2023-01-06 15:47:17,139 - ==> Confusion:
[[342  87   0]
 [ 79 540   0]
 [  0   0   0]]

2023-01-06 15:47:17,140 - ==> Best [Top1: 84.256   Sparsity:0.00   Params: 155168 on epoch: 89]
2023-01-06 15:47:17,140 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:17,146 - 

2023-01-06 15:47:17,146 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:17,637 - Epoch: [98][   10/   37]    Overall Loss 0.340194    Objective Loss 0.340194                                        LR 0.000022    Time 0.048999    
2023-01-06 15:47:17,809 - Epoch: [98][   20/   37]    Overall Loss 0.360910    Objective Loss 0.360910                                        LR 0.000022    Time 0.033059    
2023-01-06 15:47:17,994 - Epoch: [98][   30/   37]    Overall Loss 0.358315    Objective Loss 0.358315                                        LR 0.000022    Time 0.028199    
2023-01-06 15:47:18,106 - Epoch: [98][   37/   37]    Overall Loss 0.355857    Objective Loss 0.355857    Top1 84.937238    LR 0.000022    Time 0.025904    
2023-01-06 15:47:18,185 - --- validate (epoch=98)-----------
2023-01-06 15:47:18,185 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:18,404 - Epoch: [98][    5/    5]    Loss 0.380447    Top1 83.969466    
2023-01-06 15:47:18,482 - ==> Top1: 83.969    Loss: 0.380

2023-01-06 15:47:18,483 - ==> Confusion:
[[369  60   0]
 [108 511   0]
 [  0   0   0]]

2023-01-06 15:47:18,484 - ==> Best [Top1: 84.256   Sparsity:0.00   Params: 155168 on epoch: 89]
2023-01-06 15:47:18,484 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:18,490 - 

2023-01-06 15:47:18,490 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:18,855 - Epoch: [99][   10/   37]    Overall Loss 0.362795    Objective Loss 0.362795                                        LR 0.000022    Time 0.036475    
2023-01-06 15:47:19,040 - Epoch: [99][   20/   37]    Overall Loss 0.354984    Objective Loss 0.354984                                        LR 0.000022    Time 0.027450    
2023-01-06 15:47:19,212 - Epoch: [99][   30/   37]    Overall Loss 0.352857    Objective Loss 0.352857                                        LR 0.000022    Time 0.024007    
2023-01-06 15:47:19,326 - Epoch: [99][   37/   37]    Overall Loss 0.355195    Objective Loss 0.355195    Top1 81.799163    LR 0.000022    Time 0.022562    
2023-01-06 15:47:19,405 - --- validate (epoch=99)-----------
2023-01-06 15:47:19,406 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:19,632 - Epoch: [99][    5/    5]    Loss 0.346291    Top1 84.160305    
2023-01-06 15:47:19,705 - ==> Top1: 84.160    Loss: 0.346

2023-01-06 15:47:19,706 - ==> Confusion:
[[358  71   0]
 [ 95 524   0]
 [  0   0   0]]

2023-01-06 15:47:19,707 - ==> Best [Top1: 84.256   Sparsity:0.00   Params: 155168 on epoch: 89]
2023-01-06 15:47:19,707 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:19,713 - 

2023-01-06 15:47:19,713 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:20,072 - Epoch: [100][   10/   37]    Overall Loss 0.362047    Objective Loss 0.362047                                        LR 0.000013    Time 0.035853    
2023-01-06 15:47:20,253 - Epoch: [100][   20/   37]    Overall Loss 0.357895    Objective Loss 0.357895                                        LR 0.000013    Time 0.026894    
2023-01-06 15:47:20,430 - Epoch: [100][   30/   37]    Overall Loss 0.356318    Objective Loss 0.356318                                        LR 0.000013    Time 0.023841    
2023-01-06 15:47:20,544 - Epoch: [100][   37/   37]    Overall Loss 0.355270    Objective Loss 0.355270    Top1 80.543933    LR 0.000013    Time 0.022404    
2023-01-06 15:47:20,620 - --- validate (epoch=100)-----------
2023-01-06 15:47:20,620 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:20,838 - Epoch: [100][    5/    5]    Loss 0.371188    Top1 84.446565    
2023-01-06 15:47:20,912 - ==> Top1: 84.447    Loss: 0.371

2023-01-06 15:47:20,912 - ==> Confusion:
[[349  80   0]
 [ 83 536   0]
 [  0   0   0]]

2023-01-06 15:47:20,913 - ==> Best [Top1: 84.447   Sparsity:0.00   Params: 155168 on epoch: 100]
2023-01-06 15:47:20,913 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:20,921 - 

2023-01-06 15:47:20,921 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:21,293 - Epoch: [101][   10/   37]    Overall Loss 0.351087    Objective Loss 0.351087                                        LR 0.000013    Time 0.037111    
2023-01-06 15:47:21,477 - Epoch: [101][   20/   37]    Overall Loss 0.347891    Objective Loss 0.347891                                        LR 0.000013    Time 0.027776    
2023-01-06 15:47:21,658 - Epoch: [101][   30/   37]    Overall Loss 0.351462    Objective Loss 0.351462                                        LR 0.000013    Time 0.024522    
2023-01-06 15:47:21,766 - Epoch: [101][   37/   37]    Overall Loss 0.351180    Objective Loss 0.351180    Top1 82.217573    LR 0.000013    Time 0.022796    
2023-01-06 15:47:21,853 - --- validate (epoch=101)-----------
2023-01-06 15:47:21,853 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:22,075 - Epoch: [101][    5/    5]    Loss 0.380085    Top1 84.255725    
2023-01-06 15:47:22,140 - ==> Top1: 84.256    Loss: 0.380

2023-01-06 15:47:22,140 - ==> Confusion:
[[348  81   0]
 [ 84 535   0]
 [  0   0   0]]

2023-01-06 15:47:22,142 - ==> Best [Top1: 84.447   Sparsity:0.00   Params: 155168 on epoch: 100]
2023-01-06 15:47:22,142 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:22,148 - 

2023-01-06 15:47:22,148 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:22,498 - Epoch: [102][   10/   37]    Overall Loss 0.345322    Objective Loss 0.345322                                        LR 0.000013    Time 0.034943    
2023-01-06 15:47:22,655 - Epoch: [102][   20/   37]    Overall Loss 0.348252    Objective Loss 0.348252                                        LR 0.000013    Time 0.025297    
2023-01-06 15:47:22,812 - Epoch: [102][   30/   37]    Overall Loss 0.347771    Objective Loss 0.347771                                        LR 0.000013    Time 0.022079    
2023-01-06 15:47:22,910 - Epoch: [102][   37/   37]    Overall Loss 0.350976    Objective Loss 0.350976    Top1 81.589958    LR 0.000013    Time 0.020558    
2023-01-06 15:47:22,993 - --- validate (epoch=102)-----------
2023-01-06 15:47:22,993 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:23,207 - Epoch: [102][    5/    5]    Loss 0.392053    Top1 84.541985    
2023-01-06 15:47:23,278 - ==> Top1: 84.542    Loss: 0.392

2023-01-06 15:47:23,278 - ==> Confusion:
[[347  82   0]
 [ 80 539   0]
 [  0   0   0]]

2023-01-06 15:47:23,279 - ==> Best [Top1: 84.542   Sparsity:0.00   Params: 155168 on epoch: 102]
2023-01-06 15:47:23,279 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:23,287 - 

2023-01-06 15:47:23,287 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:23,661 - Epoch: [103][   10/   37]    Overall Loss 0.356848    Objective Loss 0.356848                                        LR 0.000013    Time 0.037316    
2023-01-06 15:47:23,845 - Epoch: [103][   20/   37]    Overall Loss 0.355775    Objective Loss 0.355775                                        LR 0.000013    Time 0.027843    
2023-01-06 15:47:24,037 - Epoch: [103][   30/   37]    Overall Loss 0.352344    Objective Loss 0.352344                                        LR 0.000013    Time 0.024948    
2023-01-06 15:47:24,145 - Epoch: [103][   37/   37]    Overall Loss 0.351477    Objective Loss 0.351477    Top1 85.983264    LR 0.000013    Time 0.023137    
2023-01-06 15:47:24,217 - --- validate (epoch=103)-----------
2023-01-06 15:47:24,218 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:24,439 - Epoch: [103][    5/    5]    Loss 0.341619    Top1 84.255725    
2023-01-06 15:47:24,504 - ==> Top1: 84.256    Loss: 0.342

2023-01-06 15:47:24,504 - ==> Confusion:
[[363  66   0]
 [ 99 520   0]
 [  0   0   0]]

2023-01-06 15:47:24,505 - ==> Best [Top1: 84.542   Sparsity:0.00   Params: 155168 on epoch: 102]
2023-01-06 15:47:24,505 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:24,512 - 

2023-01-06 15:47:24,512 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:24,902 - Epoch: [104][   10/   37]    Overall Loss 0.357194    Objective Loss 0.357194                                        LR 0.000013    Time 0.038975    
2023-01-06 15:47:25,096 - Epoch: [104][   20/   37]    Overall Loss 0.360266    Objective Loss 0.360266                                        LR 0.000013    Time 0.029142    
2023-01-06 15:47:25,291 - Epoch: [104][   30/   37]    Overall Loss 0.354528    Objective Loss 0.354528                                        LR 0.000013    Time 0.025887    
2023-01-06 15:47:25,405 - Epoch: [104][   37/   37]    Overall Loss 0.350913    Objective Loss 0.350913    Top1 86.192469    LR 0.000013    Time 0.024043    
2023-01-06 15:47:25,481 - --- validate (epoch=104)-----------
2023-01-06 15:47:25,481 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:25,700 - Epoch: [104][    5/    5]    Loss 0.368936    Top1 84.732824    
2023-01-06 15:47:25,757 - ==> Top1: 84.733    Loss: 0.369

2023-01-06 15:47:25,757 - ==> Confusion:
[[353  76   0]
 [ 84 535   0]
 [  0   0   0]]

2023-01-06 15:47:25,759 - ==> Best [Top1: 84.733   Sparsity:0.00   Params: 155168 on epoch: 104]
2023-01-06 15:47:25,759 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:25,766 - 

2023-01-06 15:47:25,766 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:26,138 - Epoch: [105][   10/   37]    Overall Loss 0.345092    Objective Loss 0.345092                                        LR 0.000013    Time 0.037115    
2023-01-06 15:47:26,326 - Epoch: [105][   20/   37]    Overall Loss 0.351685    Objective Loss 0.351685                                        LR 0.000013    Time 0.027931    
2023-01-06 15:47:26,515 - Epoch: [105][   30/   37]    Overall Loss 0.351184    Objective Loss 0.351184                                        LR 0.000013    Time 0.024906    
2023-01-06 15:47:26,632 - Epoch: [105][   37/   37]    Overall Loss 0.351138    Objective Loss 0.351138    Top1 83.682008    LR 0.000013    Time 0.023333    
2023-01-06 15:47:26,718 - --- validate (epoch=105)-----------
2023-01-06 15:47:26,718 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:26,936 - Epoch: [105][    5/    5]    Loss 0.344689    Top1 84.255725    
2023-01-06 15:47:27,003 - ==> Top1: 84.256    Loss: 0.345

2023-01-06 15:47:27,004 - ==> Confusion:
[[366  63   0]
 [102 517   0]
 [  0   0   0]]

2023-01-06 15:47:27,005 - ==> Best [Top1: 84.733   Sparsity:0.00   Params: 155168 on epoch: 104]
2023-01-06 15:47:27,005 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:27,011 - 

2023-01-06 15:47:27,011 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:27,389 - Epoch: [106][   10/   37]    Overall Loss 0.359292    Objective Loss 0.359292                                        LR 0.000013    Time 0.037732    
2023-01-06 15:47:27,584 - Epoch: [106][   20/   37]    Overall Loss 0.358446    Objective Loss 0.358446                                        LR 0.000013    Time 0.028554    
2023-01-06 15:47:27,772 - Epoch: [106][   30/   37]    Overall Loss 0.355026    Objective Loss 0.355026                                        LR 0.000013    Time 0.025312    
2023-01-06 15:47:27,881 - Epoch: [106][   37/   37]    Overall Loss 0.355110    Objective Loss 0.355110    Top1 80.543933    LR 0.000013    Time 0.023455    
2023-01-06 15:47:27,955 - --- validate (epoch=106)-----------
2023-01-06 15:47:27,955 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:28,177 - Epoch: [106][    5/    5]    Loss 0.349117    Top1 84.446565    
2023-01-06 15:47:28,236 - ==> Top1: 84.447    Loss: 0.349

2023-01-06 15:47:28,236 - ==> Confusion:
[[337  92   0]
 [ 71 548   0]
 [  0   0   0]]

2023-01-06 15:47:28,237 - ==> Best [Top1: 84.733   Sparsity:0.00   Params: 155168 on epoch: 104]
2023-01-06 15:47:28,237 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:28,244 - 

2023-01-06 15:47:28,244 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:28,639 - Epoch: [107][   10/   37]    Overall Loss 0.350208    Objective Loss 0.350208                                        LR 0.000013    Time 0.039489    
2023-01-06 15:47:28,836 - Epoch: [107][   20/   37]    Overall Loss 0.351324    Objective Loss 0.351324                                        LR 0.000013    Time 0.029552    
2023-01-06 15:47:29,023 - Epoch: [107][   30/   37]    Overall Loss 0.354009    Objective Loss 0.354009                                        LR 0.000013    Time 0.025908    
2023-01-06 15:47:29,132 - Epoch: [107][   37/   37]    Overall Loss 0.354226    Objective Loss 0.354226    Top1 84.100418    LR 0.000013    Time 0.023947    
2023-01-06 15:47:29,210 - --- validate (epoch=107)-----------
2023-01-06 15:47:29,210 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:29,430 - Epoch: [107][    5/    5]    Loss 0.386151    Top1 83.301527    
2023-01-06 15:47:29,513 - ==> Top1: 83.302    Loss: 0.386

2023-01-06 15:47:29,513 - ==> Confusion:
[[364  65   0]
 [110 509   0]
 [  0   0   0]]

2023-01-06 15:47:29,514 - ==> Best [Top1: 84.733   Sparsity:0.00   Params: 155168 on epoch: 104]
2023-01-06 15:47:29,514 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:29,520 - 

2023-01-06 15:47:29,520 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:29,889 - Epoch: [108][   10/   37]    Overall Loss 0.348113    Objective Loss 0.348113                                        LR 0.000013    Time 0.036759    
2023-01-06 15:47:30,047 - Epoch: [108][   20/   37]    Overall Loss 0.351936    Objective Loss 0.351936                                        LR 0.000013    Time 0.026236    
2023-01-06 15:47:30,213 - Epoch: [108][   30/   37]    Overall Loss 0.352997    Objective Loss 0.352997                                        LR 0.000013    Time 0.022997    
2023-01-06 15:47:30,318 - Epoch: [108][   37/   37]    Overall Loss 0.353797    Objective Loss 0.353797    Top1 87.238494    LR 0.000013    Time 0.021468    
2023-01-06 15:47:30,402 - --- validate (epoch=108)-----------
2023-01-06 15:47:30,402 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:30,625 - Epoch: [108][    5/    5]    Loss 0.358088    Top1 84.064885    
2023-01-06 15:47:30,702 - ==> Top1: 84.065    Loss: 0.358

2023-01-06 15:47:30,702 - ==> Confusion:
[[352  77   0]
 [ 90 529   0]
 [  0   0   0]]

2023-01-06 15:47:30,703 - ==> Best [Top1: 84.733   Sparsity:0.00   Params: 155168 on epoch: 104]
2023-01-06 15:47:30,703 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:30,709 - 

2023-01-06 15:47:30,709 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:31,091 - Epoch: [109][   10/   37]    Overall Loss 0.353524    Objective Loss 0.353524                                        LR 0.000013    Time 0.038035    
2023-01-06 15:47:31,288 - Epoch: [109][   20/   37]    Overall Loss 0.349162    Objective Loss 0.349162                                        LR 0.000013    Time 0.028829    
2023-01-06 15:47:31,482 - Epoch: [109][   30/   37]    Overall Loss 0.350207    Objective Loss 0.350207                                        LR 0.000013    Time 0.025670    
2023-01-06 15:47:31,597 - Epoch: [109][   37/   37]    Overall Loss 0.351762    Objective Loss 0.351762    Top1 84.518828    LR 0.000013    Time 0.023917    
2023-01-06 15:47:31,671 - --- validate (epoch=109)-----------
2023-01-06 15:47:31,672 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:31,892 - Epoch: [109][    5/    5]    Loss 0.362380    Top1 85.114504    
2023-01-06 15:47:31,950 - ==> Top1: 85.115    Loss: 0.362

2023-01-06 15:47:31,950 - ==> Confusion:
[[370  59   0]
 [ 97 522   0]
 [  0   0   0]]

2023-01-06 15:47:31,951 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 155168 on epoch: 109]
2023-01-06 15:47:31,952 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:31,959 - 

2023-01-06 15:47:31,959 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:32,346 - Epoch: [110][   10/   37]    Overall Loss 0.361622    Objective Loss 0.361622                                        LR 0.000013    Time 0.038579    
2023-01-06 15:47:32,532 - Epoch: [110][   20/   37]    Overall Loss 0.359354    Objective Loss 0.359354                                        LR 0.000013    Time 0.028604    
2023-01-06 15:47:32,719 - Epoch: [110][   30/   37]    Overall Loss 0.353967    Objective Loss 0.353967                                        LR 0.000013    Time 0.025278    
2023-01-06 15:47:32,833 - Epoch: [110][   37/   37]    Overall Loss 0.351108    Objective Loss 0.351108    Top1 86.192469    LR 0.000013    Time 0.023570    
2023-01-06 15:47:32,911 - --- validate (epoch=110)-----------
2023-01-06 15:47:32,911 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:33,132 - Epoch: [110][    5/    5]    Loss 0.411438    Top1 84.446565    
2023-01-06 15:47:33,201 - ==> Top1: 84.447    Loss: 0.411

2023-01-06 15:47:33,201 - ==> Confusion:
[[360  69   0]
 [ 94 525   0]
 [  0   0   0]]

2023-01-06 15:47:33,202 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 155168 on epoch: 109]
2023-01-06 15:47:33,202 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:33,208 - 

2023-01-06 15:47:33,208 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:33,599 - Epoch: [111][   10/   37]    Overall Loss 0.344660    Objective Loss 0.344660                                        LR 0.000013    Time 0.039012    
2023-01-06 15:47:33,801 - Epoch: [111][   20/   37]    Overall Loss 0.348749    Objective Loss 0.348749                                        LR 0.000013    Time 0.029561    
2023-01-06 15:47:33,999 - Epoch: [111][   30/   37]    Overall Loss 0.346744    Objective Loss 0.346744                                        LR 0.000013    Time 0.026312    
2023-01-06 15:47:34,113 - Epoch: [111][   37/   37]    Overall Loss 0.351835    Objective Loss 0.351835    Top1 83.682008    LR 0.000013    Time 0.024405    
2023-01-06 15:47:34,191 - --- validate (epoch=111)-----------
2023-01-06 15:47:34,191 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:34,410 - Epoch: [111][    5/    5]    Loss 0.430419    Top1 84.160305    
2023-01-06 15:47:34,476 - ==> Top1: 84.160    Loss: 0.430

2023-01-06 15:47:34,477 - ==> Confusion:
[[359  70   0]
 [ 96 523   0]
 [  0   0   0]]

2023-01-06 15:47:34,478 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 155168 on epoch: 109]
2023-01-06 15:47:34,478 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:34,484 - 

2023-01-06 15:47:34,484 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:34,844 - Epoch: [112][   10/   37]    Overall Loss 0.357949    Objective Loss 0.357949                                        LR 0.000013    Time 0.035941    
2023-01-06 15:47:35,022 - Epoch: [112][   20/   37]    Overall Loss 0.350930    Objective Loss 0.350930                                        LR 0.000013    Time 0.026836    
2023-01-06 15:47:35,199 - Epoch: [112][   30/   37]    Overall Loss 0.352502    Objective Loss 0.352502                                        LR 0.000013    Time 0.023771    
2023-01-06 15:47:35,309 - Epoch: [112][   37/   37]    Overall Loss 0.350128    Objective Loss 0.350128    Top1 85.774059    LR 0.000013    Time 0.022258    
2023-01-06 15:47:35,386 - --- validate (epoch=112)-----------
2023-01-06 15:47:35,386 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:35,608 - Epoch: [112][    5/    5]    Loss 0.335414    Top1 83.874046    
2023-01-06 15:47:35,667 - ==> Top1: 83.874    Loss: 0.335

2023-01-06 15:47:35,668 - ==> Confusion:
[[348  81   0]
 [ 88 531   0]
 [  0   0   0]]

2023-01-06 15:47:35,669 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 155168 on epoch: 109]
2023-01-06 15:47:35,669 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:35,675 - 

2023-01-06 15:47:35,675 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:36,166 - Epoch: [113][   10/   37]    Overall Loss 0.360577    Objective Loss 0.360577                                        LR 0.000013    Time 0.049033    
2023-01-06 15:47:36,344 - Epoch: [113][   20/   37]    Overall Loss 0.355535    Objective Loss 0.355535                                        LR 0.000013    Time 0.033414    
2023-01-06 15:47:36,525 - Epoch: [113][   30/   37]    Overall Loss 0.353572    Objective Loss 0.353572                                        LR 0.000013    Time 0.028277    
2023-01-06 15:47:36,634 - Epoch: [113][   37/   37]    Overall Loss 0.348205    Objective Loss 0.348205    Top1 83.891213    LR 0.000013    Time 0.025862    
2023-01-06 15:47:36,713 - --- validate (epoch=113)-----------
2023-01-06 15:47:36,713 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:36,932 - Epoch: [113][    5/    5]    Loss 0.366388    Top1 84.351145    
2023-01-06 15:47:37,000 - ==> Top1: 84.351    Loss: 0.366

2023-01-06 15:47:37,000 - ==> Confusion:
[[359  70   0]
 [ 94 525   0]
 [  0   0   0]]

2023-01-06 15:47:37,001 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 155168 on epoch: 109]
2023-01-06 15:47:37,001 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:37,007 - 

2023-01-06 15:47:37,008 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:37,384 - Epoch: [114][   10/   37]    Overall Loss 0.369248    Objective Loss 0.369248                                        LR 0.000013    Time 0.037560    
2023-01-06 15:47:37,572 - Epoch: [114][   20/   37]    Overall Loss 0.351115    Objective Loss 0.351115                                        LR 0.000013    Time 0.028168    
2023-01-06 15:47:37,763 - Epoch: [114][   30/   37]    Overall Loss 0.347386    Objective Loss 0.347386                                        LR 0.000013    Time 0.025134    
2023-01-06 15:47:37,877 - Epoch: [114][   37/   37]    Overall Loss 0.348216    Objective Loss 0.348216    Top1 84.728033    LR 0.000013    Time 0.023466    
2023-01-06 15:47:37,946 - --- validate (epoch=114)-----------
2023-01-06 15:47:37,947 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:38,164 - Epoch: [114][    5/    5]    Loss 0.336688    Top1 84.255725    
2023-01-06 15:47:38,232 - ==> Top1: 84.256    Loss: 0.337

2023-01-06 15:47:38,232 - ==> Confusion:
[[343  86   0]
 [ 79 540   0]
 [  0   0   0]]

2023-01-06 15:47:38,233 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 155168 on epoch: 109]
2023-01-06 15:47:38,233 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:38,239 - 

2023-01-06 15:47:38,239 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:38,600 - Epoch: [115][   10/   37]    Overall Loss 0.333342    Objective Loss 0.333342                                        LR 0.000013    Time 0.036006    
2023-01-06 15:47:38,785 - Epoch: [115][   20/   37]    Overall Loss 0.339821    Objective Loss 0.339821                                        LR 0.000013    Time 0.027238    
2023-01-06 15:47:38,987 - Epoch: [115][   30/   37]    Overall Loss 0.347098    Objective Loss 0.347098                                        LR 0.000013    Time 0.024867    
2023-01-06 15:47:39,101 - Epoch: [115][   37/   37]    Overall Loss 0.350867    Objective Loss 0.350867    Top1 81.799163    LR 0.000013    Time 0.023242    
2023-01-06 15:47:39,174 - --- validate (epoch=115)-----------
2023-01-06 15:47:39,174 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:39,398 - Epoch: [115][    5/    5]    Loss 0.400151    Top1 84.541985    
2023-01-06 15:47:39,456 - ==> Top1: 84.542    Loss: 0.400

2023-01-06 15:47:39,457 - ==> Confusion:
[[371  58   0]
 [104 515   0]
 [  0   0   0]]

2023-01-06 15:47:39,458 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 155168 on epoch: 109]
2023-01-06 15:47:39,458 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:39,464 - 

2023-01-06 15:47:39,464 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:39,830 - Epoch: [116][   10/   37]    Overall Loss 0.349997    Objective Loss 0.349997                                        LR 0.000013    Time 0.036515    
2023-01-06 15:47:40,022 - Epoch: [116][   20/   37]    Overall Loss 0.348652    Objective Loss 0.348652                                        LR 0.000013    Time 0.027847    
2023-01-06 15:47:40,213 - Epoch: [116][   30/   37]    Overall Loss 0.346974    Objective Loss 0.346974                                        LR 0.000013    Time 0.024924    
2023-01-06 15:47:40,330 - Epoch: [116][   37/   37]    Overall Loss 0.348502    Objective Loss 0.348502    Top1 83.054393    LR 0.000013    Time 0.023363    
2023-01-06 15:47:40,409 - --- validate (epoch=116)-----------
2023-01-06 15:47:40,409 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:40,638 - Epoch: [116][    5/    5]    Loss 0.357557    Top1 84.732824    
2023-01-06 15:47:40,703 - ==> Top1: 84.733    Loss: 0.358

2023-01-06 15:47:40,704 - ==> Confusion:
[[360  69   0]
 [ 91 528   0]
 [  0   0   0]]

2023-01-06 15:47:40,705 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 155168 on epoch: 109]
2023-01-06 15:47:40,705 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:40,711 - 

2023-01-06 15:47:40,711 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:41,076 - Epoch: [117][   10/   37]    Overall Loss 0.360889    Objective Loss 0.360889                                        LR 0.000013    Time 0.036390    
2023-01-06 15:47:41,256 - Epoch: [117][   20/   37]    Overall Loss 0.355462    Objective Loss 0.355462                                        LR 0.000013    Time 0.027185    
2023-01-06 15:47:41,435 - Epoch: [117][   30/   37]    Overall Loss 0.348616    Objective Loss 0.348616                                        LR 0.000013    Time 0.024065    
2023-01-06 15:47:41,540 - Epoch: [117][   37/   37]    Overall Loss 0.347994    Objective Loss 0.347994    Top1 80.962343    LR 0.000013    Time 0.022359    
2023-01-06 15:47:41,619 - --- validate (epoch=117)-----------
2023-01-06 15:47:41,620 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:41,836 - Epoch: [117][    5/    5]    Loss 0.338306    Top1 84.064885    
2023-01-06 15:47:41,894 - ==> Top1: 84.065    Loss: 0.338

2023-01-06 15:47:41,894 - ==> Confusion:
[[355  74   0]
 [ 93 526   0]
 [  0   0   0]]

2023-01-06 15:47:41,896 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 155168 on epoch: 109]
2023-01-06 15:47:41,896 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:41,902 - 

2023-01-06 15:47:41,902 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:42,257 - Epoch: [118][   10/   37]    Overall Loss 0.345728    Objective Loss 0.345728                                        LR 0.000013    Time 0.035474    
2023-01-06 15:47:42,433 - Epoch: [118][   20/   37]    Overall Loss 0.347488    Objective Loss 0.347488                                        LR 0.000013    Time 0.026440    
2023-01-06 15:47:42,629 - Epoch: [118][   30/   37]    Overall Loss 0.343366    Objective Loss 0.343366                                        LR 0.000013    Time 0.024151    
2023-01-06 15:47:42,746 - Epoch: [118][   37/   37]    Overall Loss 0.347133    Objective Loss 0.347133    Top1 81.799163    LR 0.000013    Time 0.022748    
2023-01-06 15:47:42,805 - --- validate (epoch=118)-----------
2023-01-06 15:47:42,805 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:43,026 - Epoch: [118][    5/    5]    Loss 0.348522    Top1 83.874046    
2023-01-06 15:47:43,091 - ==> Top1: 83.874    Loss: 0.349

2023-01-06 15:47:43,092 - ==> Confusion:
[[360  69   0]
 [100 519   0]
 [  0   0   0]]

2023-01-06 15:47:43,093 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 155168 on epoch: 109]
2023-01-06 15:47:43,093 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:43,099 - 

2023-01-06 15:47:43,099 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:43,460 - Epoch: [119][   10/   37]    Overall Loss 0.355352    Objective Loss 0.355352                                        LR 0.000013    Time 0.035965    
2023-01-06 15:47:43,647 - Epoch: [119][   20/   37]    Overall Loss 0.350210    Objective Loss 0.350210                                        LR 0.000013    Time 0.027341    
2023-01-06 15:47:43,840 - Epoch: [119][   30/   37]    Overall Loss 0.351771    Objective Loss 0.351771                                        LR 0.000013    Time 0.024647    
2023-01-06 15:47:43,955 - Epoch: [119][   37/   37]    Overall Loss 0.348580    Objective Loss 0.348580    Top1 85.774059    LR 0.000013    Time 0.023074    
2023-01-06 15:47:44,025 - --- validate (epoch=119)-----------
2023-01-06 15:47:44,025 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:44,245 - Epoch: [119][    5/    5]    Loss 0.350297    Top1 84.637405    
2023-01-06 15:47:44,320 - ==> Top1: 84.637    Loss: 0.350

2023-01-06 15:47:44,321 - ==> Confusion:
[[328 101   0]
 [ 60 559   0]
 [  0   0   0]]

2023-01-06 15:47:44,322 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 155168 on epoch: 109]
2023-01-06 15:47:44,322 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:44,328 - 

2023-01-06 15:47:44,328 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:44,681 - Epoch: [120][   10/   37]    Overall Loss 0.353150    Objective Loss 0.353150                                        LR 0.000013    Time 0.035238    
2023-01-06 15:47:44,841 - Epoch: [120][   20/   37]    Overall Loss 0.346147    Objective Loss 0.346147                                        LR 0.000013    Time 0.025580    
2023-01-06 15:47:45,008 - Epoch: [120][   30/   37]    Overall Loss 0.342721    Objective Loss 0.342721                                        LR 0.000013    Time 0.022611    
2023-01-06 15:47:45,115 - Epoch: [120][   37/   37]    Overall Loss 0.345821    Objective Loss 0.345821    Top1 84.728033    LR 0.000013    Time 0.021232    
2023-01-06 15:47:45,178 - --- validate (epoch=120)-----------
2023-01-06 15:47:45,179 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:45,396 - Epoch: [120][    5/    5]    Loss 0.365892    Top1 83.874046    
2023-01-06 15:47:45,452 - ==> Top1: 83.874    Loss: 0.366

2023-01-06 15:47:45,452 - ==> Confusion:
[[358  71   0]
 [ 98 521   0]
 [  0   0   0]]

2023-01-06 15:47:45,453 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 155168 on epoch: 109]
2023-01-06 15:47:45,453 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:45,459 - 

2023-01-06 15:47:45,459 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:45,831 - Epoch: [121][   10/   37]    Overall Loss 0.352698    Objective Loss 0.352698                                        LR 0.000013    Time 0.037080    
2023-01-06 15:47:46,015 - Epoch: [121][   20/   37]    Overall Loss 0.349998    Objective Loss 0.349998                                        LR 0.000013    Time 0.027749    
2023-01-06 15:47:46,206 - Epoch: [121][   30/   37]    Overall Loss 0.349099    Objective Loss 0.349099                                        LR 0.000013    Time 0.024839    
2023-01-06 15:47:46,305 - Epoch: [121][   37/   37]    Overall Loss 0.345480    Objective Loss 0.345480    Top1 85.983264    LR 0.000013    Time 0.022815    
2023-01-06 15:47:46,378 - --- validate (epoch=121)-----------
2023-01-06 15:47:46,379 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:46,600 - Epoch: [121][    5/    5]    Loss 0.316791    Top1 84.446565    
2023-01-06 15:47:46,654 - ==> Top1: 84.447    Loss: 0.317

2023-01-06 15:47:46,654 - ==> Confusion:
[[364  65   0]
 [ 98 521   0]
 [  0   0   0]]

2023-01-06 15:47:46,655 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 155168 on epoch: 109]
2023-01-06 15:47:46,655 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:46,661 - 

2023-01-06 15:47:46,661 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:47,018 - Epoch: [122][   10/   37]    Overall Loss 0.346814    Objective Loss 0.346814                                        LR 0.000013    Time 0.035584    
2023-01-06 15:47:47,184 - Epoch: [122][   20/   37]    Overall Loss 0.340951    Objective Loss 0.340951                                        LR 0.000013    Time 0.026057    
2023-01-06 15:47:47,346 - Epoch: [122][   30/   37]    Overall Loss 0.343569    Objective Loss 0.343569                                        LR 0.000013    Time 0.022750    
2023-01-06 15:47:47,450 - Epoch: [122][   37/   37]    Overall Loss 0.345877    Objective Loss 0.345877    Top1 86.192469    LR 0.000013    Time 0.021258    
2023-01-06 15:47:47,527 - --- validate (epoch=122)-----------
2023-01-06 15:47:47,527 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:47,755 - Epoch: [122][    5/    5]    Loss 0.341064    Top1 84.732824    
2023-01-06 15:47:47,823 - ==> Top1: 84.733    Loss: 0.341

2023-01-06 15:47:47,823 - ==> Confusion:
[[353  76   0]
 [ 84 535   0]
 [  0   0   0]]

2023-01-06 15:47:47,824 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 155168 on epoch: 109]
2023-01-06 15:47:47,824 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:47,830 - 

2023-01-06 15:47:47,830 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:48,185 - Epoch: [123][   10/   37]    Overall Loss 0.332260    Objective Loss 0.332260                                        LR 0.000013    Time 0.035446    
2023-01-06 15:47:48,352 - Epoch: [123][   20/   37]    Overall Loss 0.341493    Objective Loss 0.341493                                        LR 0.000013    Time 0.026040    
2023-01-06 15:47:48,522 - Epoch: [123][   30/   37]    Overall Loss 0.339655    Objective Loss 0.339655                                        LR 0.000013    Time 0.023017    
2023-01-06 15:47:48,626 - Epoch: [123][   37/   37]    Overall Loss 0.342841    Objective Loss 0.342841    Top1 84.518828    LR 0.000013    Time 0.021466    
2023-01-06 15:47:48,695 - --- validate (epoch=123)-----------
2023-01-06 15:47:48,696 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:48,916 - Epoch: [123][    5/    5]    Loss 0.348489    Top1 84.732824    
2023-01-06 15:47:48,983 - ==> Top1: 84.733    Loss: 0.348

2023-01-06 15:47:48,983 - ==> Confusion:
[[365  64   0]
 [ 96 523   0]
 [  0   0   0]]

2023-01-06 15:47:48,984 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 155168 on epoch: 109]
2023-01-06 15:47:48,984 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:48,990 - 

2023-01-06 15:47:48,991 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:49,359 - Epoch: [124][   10/   37]    Overall Loss 0.352454    Objective Loss 0.352454                                        LR 0.000013    Time 0.036809    
2023-01-06 15:47:49,550 - Epoch: [124][   20/   37]    Overall Loss 0.343528    Objective Loss 0.343528                                        LR 0.000013    Time 0.027908    
2023-01-06 15:47:49,738 - Epoch: [124][   30/   37]    Overall Loss 0.346657    Objective Loss 0.346657                                        LR 0.000013    Time 0.024849    
2023-01-06 15:47:49,854 - Epoch: [124][   37/   37]    Overall Loss 0.343707    Objective Loss 0.343707    Top1 85.983264    LR 0.000013    Time 0.023290    
2023-01-06 15:47:49,928 - --- validate (epoch=124)-----------
2023-01-06 15:47:49,929 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:50,145 - Epoch: [124][    5/    5]    Loss 0.320812    Top1 85.305344    
2023-01-06 15:47:50,215 - ==> Top1: 85.305    Loss: 0.321

2023-01-06 15:47:50,215 - ==> Confusion:
[[357  72   0]
 [ 82 537   0]
 [  0   0   0]]

2023-01-06 15:47:50,216 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:47:50,217 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:50,224 - 

2023-01-06 15:47:50,224 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:50,597 - Epoch: [125][   10/   37]    Overall Loss 0.357232    Objective Loss 0.357232                                        LR 0.000013    Time 0.037234    
2023-01-06 15:47:50,772 - Epoch: [125][   20/   37]    Overall Loss 0.353865    Objective Loss 0.353865                                        LR 0.000013    Time 0.027324    
2023-01-06 15:47:50,950 - Epoch: [125][   30/   37]    Overall Loss 0.347120    Objective Loss 0.347120                                        LR 0.000013    Time 0.024137    
2023-01-06 15:47:51,059 - Epoch: [125][   37/   37]    Overall Loss 0.343028    Objective Loss 0.343028    Top1 85.774059    LR 0.000013    Time 0.022528    
2023-01-06 15:47:51,129 - --- validate (epoch=125)-----------
2023-01-06 15:47:51,129 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:51,343 - Epoch: [125][    5/    5]    Loss 0.367560    Top1 83.492366    
2023-01-06 15:47:51,403 - ==> Top1: 83.492    Loss: 0.368

2023-01-06 15:47:51,404 - ==> Confusion:
[[363  66   0]
 [107 512   0]
 [  0   0   0]]

2023-01-06 15:47:51,405 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:47:51,405 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:51,411 - 

2023-01-06 15:47:51,411 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:51,769 - Epoch: [126][   10/   37]    Overall Loss 0.338293    Objective Loss 0.338293                                        LR 0.000013    Time 0.035768    
2023-01-06 15:47:51,942 - Epoch: [126][   20/   37]    Overall Loss 0.342611    Objective Loss 0.342611                                        LR 0.000013    Time 0.026491    
2023-01-06 15:47:52,124 - Epoch: [126][   30/   37]    Overall Loss 0.343803    Objective Loss 0.343803                                        LR 0.000013    Time 0.023724    
2023-01-06 15:47:52,239 - Epoch: [126][   37/   37]    Overall Loss 0.344604    Objective Loss 0.344604    Top1 83.682008    LR 0.000013    Time 0.022328    
2023-01-06 15:47:52,321 - --- validate (epoch=126)-----------
2023-01-06 15:47:52,322 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:52,542 - Epoch: [126][    5/    5]    Loss 0.359380    Top1 84.637405    
2023-01-06 15:47:52,604 - ==> Top1: 84.637    Loss: 0.359

2023-01-06 15:47:52,604 - ==> Confusion:
[[359  70   0]
 [ 91 528   0]
 [  0   0   0]]

2023-01-06 15:47:52,606 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:47:52,606 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:52,611 - 

2023-01-06 15:47:52,612 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:53,084 - Epoch: [127][   10/   37]    Overall Loss 0.345114    Objective Loss 0.345114                                        LR 0.000013    Time 0.047141    
2023-01-06 15:47:53,257 - Epoch: [127][   20/   37]    Overall Loss 0.341072    Objective Loss 0.341072                                        LR 0.000013    Time 0.032195    
2023-01-06 15:47:53,449 - Epoch: [127][   30/   37]    Overall Loss 0.343436    Objective Loss 0.343436                                        LR 0.000013    Time 0.027822    
2023-01-06 15:47:53,563 - Epoch: [127][   37/   37]    Overall Loss 0.344300    Objective Loss 0.344300    Top1 84.309623    LR 0.000013    Time 0.025647    
2023-01-06 15:47:53,630 - --- validate (epoch=127)-----------
2023-01-06 15:47:53,631 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:53,850 - Epoch: [127][    5/    5]    Loss 0.370881    Top1 84.732824    
2023-01-06 15:47:53,913 - ==> Top1: 84.733    Loss: 0.371

2023-01-06 15:47:53,913 - ==> Confusion:
[[359  70   0]
 [ 90 529   0]
 [  0   0   0]]

2023-01-06 15:47:53,914 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:47:53,914 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:53,920 - 

2023-01-06 15:47:53,920 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:54,296 - Epoch: [128][   10/   37]    Overall Loss 0.338154    Objective Loss 0.338154                                        LR 0.000013    Time 0.037510    
2023-01-06 15:47:54,504 - Epoch: [128][   20/   37]    Overall Loss 0.337701    Objective Loss 0.337701                                        LR 0.000013    Time 0.029119    
2023-01-06 15:47:54,708 - Epoch: [128][   30/   37]    Overall Loss 0.342348    Objective Loss 0.342348                                        LR 0.000013    Time 0.026216    
2023-01-06 15:47:54,822 - Epoch: [128][   37/   37]    Overall Loss 0.341691    Objective Loss 0.341691    Top1 85.146444    LR 0.000013    Time 0.024334    
2023-01-06 15:47:54,901 - --- validate (epoch=128)-----------
2023-01-06 15:47:54,902 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:55,130 - Epoch: [128][    5/    5]    Loss 0.345134    Top1 84.255725    
2023-01-06 15:47:55,195 - ==> Top1: 84.256    Loss: 0.345

2023-01-06 15:47:55,195 - ==> Confusion:
[[346  83   0]
 [ 82 537   0]
 [  0   0   0]]

2023-01-06 15:47:55,196 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:47:55,197 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:55,202 - 

2023-01-06 15:47:55,202 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:55,580 - Epoch: [129][   10/   37]    Overall Loss 0.328238    Objective Loss 0.328238                                        LR 0.000013    Time 0.037688    
2023-01-06 15:47:55,772 - Epoch: [129][   20/   37]    Overall Loss 0.336860    Objective Loss 0.336860                                        LR 0.000013    Time 0.028412    
2023-01-06 15:47:55,966 - Epoch: [129][   30/   37]    Overall Loss 0.337117    Objective Loss 0.337117                                        LR 0.000013    Time 0.025390    
2023-01-06 15:47:56,079 - Epoch: [129][   37/   37]    Overall Loss 0.342675    Objective Loss 0.342675    Top1 84.309623    LR 0.000013    Time 0.023638    
2023-01-06 15:47:56,155 - --- validate (epoch=129)-----------
2023-01-06 15:47:56,155 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:56,372 - Epoch: [129][    5/    5]    Loss 0.354479    Top1 84.255725    
2023-01-06 15:47:56,429 - ==> Top1: 84.256    Loss: 0.354

2023-01-06 15:47:56,430 - ==> Confusion:
[[349  80   0]
 [ 85 534   0]
 [  0   0   0]]

2023-01-06 15:47:56,431 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:47:56,431 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:56,437 - 

2023-01-06 15:47:56,437 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:56,821 - Epoch: [130][   10/   37]    Overall Loss 0.348931    Objective Loss 0.348931                                        LR 0.000013    Time 0.038290    
2023-01-06 15:47:57,019 - Epoch: [130][   20/   37]    Overall Loss 0.335309    Objective Loss 0.335309                                        LR 0.000013    Time 0.029053    
2023-01-06 15:47:57,217 - Epoch: [130][   30/   37]    Overall Loss 0.343537    Objective Loss 0.343537                                        LR 0.000013    Time 0.025955    
2023-01-06 15:47:57,326 - Epoch: [130][   37/   37]    Overall Loss 0.345715    Objective Loss 0.345715    Top1 84.937238    LR 0.000013    Time 0.023976    
2023-01-06 15:47:57,399 - --- validate (epoch=130)-----------
2023-01-06 15:47:57,399 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:57,622 - Epoch: [130][    5/    5]    Loss 0.359761    Top1 84.828244    
2023-01-06 15:47:57,678 - ==> Top1: 84.828    Loss: 0.360

2023-01-06 15:47:57,679 - ==> Confusion:
[[338  91   0]
 [ 68 551   0]
 [  0   0   0]]

2023-01-06 15:47:57,680 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:47:57,680 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:57,686 - 

2023-01-06 15:47:57,686 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:58,038 - Epoch: [131][   10/   37]    Overall Loss 0.346293    Objective Loss 0.346293                                        LR 0.000013    Time 0.035145    
2023-01-06 15:47:58,225 - Epoch: [131][   20/   37]    Overall Loss 0.342059    Objective Loss 0.342059                                        LR 0.000013    Time 0.026908    
2023-01-06 15:47:58,420 - Epoch: [131][   30/   37]    Overall Loss 0.345482    Objective Loss 0.345482                                        LR 0.000013    Time 0.024420    
2023-01-06 15:47:58,529 - Epoch: [131][   37/   37]    Overall Loss 0.342811    Objective Loss 0.342811    Top1 82.845188    LR 0.000013    Time 0.022724    
2023-01-06 15:47:58,601 - --- validate (epoch=131)-----------
2023-01-06 15:47:58,601 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:58,818 - Epoch: [131][    5/    5]    Loss 0.356868    Top1 84.637405    
2023-01-06 15:47:58,889 - ==> Top1: 84.637    Loss: 0.357

2023-01-06 15:47:58,889 - ==> Confusion:
[[349  80   0]
 [ 81 538   0]
 [  0   0   0]]

2023-01-06 15:47:58,890 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:47:58,890 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:47:58,896 - 

2023-01-06 15:47:58,896 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:47:59,248 - Epoch: [132][   10/   37]    Overall Loss 0.349855    Objective Loss 0.349855                                        LR 0.000013    Time 0.035121    
2023-01-06 15:47:59,403 - Epoch: [132][   20/   37]    Overall Loss 0.348259    Objective Loss 0.348259                                        LR 0.000013    Time 0.025248    
2023-01-06 15:47:59,558 - Epoch: [132][   30/   37]    Overall Loss 0.344236    Objective Loss 0.344236                                        LR 0.000013    Time 0.021960    
2023-01-06 15:47:59,663 - Epoch: [132][   37/   37]    Overall Loss 0.340221    Objective Loss 0.340221    Top1 89.958159    LR 0.000013    Time 0.020634    
2023-01-06 15:47:59,740 - --- validate (epoch=132)-----------
2023-01-06 15:47:59,740 - 1048 samples (256 per mini-batch)
2023-01-06 15:47:59,960 - Epoch: [132][    5/    5]    Loss 0.356067    Top1 84.923664    
2023-01-06 15:48:00,027 - ==> Top1: 84.924    Loss: 0.356

2023-01-06 15:48:00,028 - ==> Confusion:
[[358  71   0]
 [ 87 532   0]
 [  0   0   0]]

2023-01-06 15:48:00,029 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:48:00,029 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:00,035 - 

2023-01-06 15:48:00,035 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:00,410 - Epoch: [133][   10/   37]    Overall Loss 0.336363    Objective Loss 0.336363                                        LR 0.000013    Time 0.037417    
2023-01-06 15:48:00,596 - Epoch: [133][   20/   37]    Overall Loss 0.342440    Objective Loss 0.342440                                        LR 0.000013    Time 0.028005    
2023-01-06 15:48:00,792 - Epoch: [133][   30/   37]    Overall Loss 0.343084    Objective Loss 0.343084                                        LR 0.000013    Time 0.025176    
2023-01-06 15:48:00,905 - Epoch: [133][   37/   37]    Overall Loss 0.340510    Objective Loss 0.340510    Top1 86.610879    LR 0.000013    Time 0.023456    
2023-01-06 15:48:00,984 - --- validate (epoch=133)-----------
2023-01-06 15:48:00,985 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:01,202 - Epoch: [133][    5/    5]    Loss 0.407104    Top1 84.637405    
2023-01-06 15:48:01,273 - ==> Top1: 84.637    Loss: 0.407

2023-01-06 15:48:01,273 - ==> Confusion:
[[349  80   0]
 [ 81 538   0]
 [  0   0   0]]

2023-01-06 15:48:01,274 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:48:01,274 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:01,280 - 

2023-01-06 15:48:01,280 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:01,636 - Epoch: [134][   10/   37]    Overall Loss 0.336149    Objective Loss 0.336149                                        LR 0.000013    Time 0.035459    
2023-01-06 15:48:01,798 - Epoch: [134][   20/   37]    Overall Loss 0.337945    Objective Loss 0.337945                                        LR 0.000013    Time 0.025728    
2023-01-06 15:48:01,980 - Epoch: [134][   30/   37]    Overall Loss 0.334790    Objective Loss 0.334790                                        LR 0.000013    Time 0.023226    
2023-01-06 15:48:02,089 - Epoch: [134][   37/   37]    Overall Loss 0.338501    Objective Loss 0.338501    Top1 83.472803    LR 0.000013    Time 0.021762    
2023-01-06 15:48:02,168 - --- validate (epoch=134)-----------
2023-01-06 15:48:02,168 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:02,387 - Epoch: [134][    5/    5]    Loss 0.321491    Top1 84.351145    
2023-01-06 15:48:02,445 - ==> Top1: 84.351    Loss: 0.321

2023-01-06 15:48:02,446 - ==> Confusion:
[[354  75   0]
 [ 89 530   0]
 [  0   0   0]]

2023-01-06 15:48:02,447 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:48:02,447 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:02,453 - 

2023-01-06 15:48:02,453 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:02,841 - Epoch: [135][   10/   37]    Overall Loss 0.335538    Objective Loss 0.335538                                        LR 0.000013    Time 0.038729    
2023-01-06 15:48:03,037 - Epoch: [135][   20/   37]    Overall Loss 0.335829    Objective Loss 0.335829                                        LR 0.000013    Time 0.029155    
2023-01-06 15:48:03,230 - Epoch: [135][   30/   37]    Overall Loss 0.339080    Objective Loss 0.339080                                        LR 0.000013    Time 0.025836    
2023-01-06 15:48:03,345 - Epoch: [135][   37/   37]    Overall Loss 0.341478    Objective Loss 0.341478    Top1 83.054393    LR 0.000013    Time 0.024052    
2023-01-06 15:48:03,422 - --- validate (epoch=135)-----------
2023-01-06 15:48:03,423 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:03,652 - Epoch: [135][    5/    5]    Loss 0.370812    Top1 84.255725    
2023-01-06 15:48:03,719 - ==> Top1: 84.256    Loss: 0.371

2023-01-06 15:48:03,719 - ==> Confusion:
[[328 101   0]
 [ 64 555   0]
 [  0   0   0]]

2023-01-06 15:48:03,720 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:48:03,720 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:03,726 - 

2023-01-06 15:48:03,726 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:04,084 - Epoch: [136][   10/   37]    Overall Loss 0.334435    Objective Loss 0.334435                                        LR 0.000013    Time 0.035676    
2023-01-06 15:48:04,249 - Epoch: [136][   20/   37]    Overall Loss 0.329199    Objective Loss 0.329199                                        LR 0.000013    Time 0.026063    
2023-01-06 15:48:04,411 - Epoch: [136][   30/   37]    Overall Loss 0.338338    Objective Loss 0.338338                                        LR 0.000013    Time 0.022752    
2023-01-06 15:48:04,510 - Epoch: [136][   37/   37]    Overall Loss 0.339527    Objective Loss 0.339527    Top1 85.146444    LR 0.000013    Time 0.021122    
2023-01-06 15:48:04,584 - --- validate (epoch=136)-----------
2023-01-06 15:48:04,584 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:04,801 - Epoch: [136][    5/    5]    Loss 0.323033    Top1 84.351145    
2023-01-06 15:48:04,866 - ==> Top1: 84.351    Loss: 0.323

2023-01-06 15:48:04,866 - ==> Confusion:
[[353  76   0]
 [ 88 531   0]
 [  0   0   0]]

2023-01-06 15:48:04,868 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:48:04,868 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:04,874 - 

2023-01-06 15:48:04,874 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:05,246 - Epoch: [137][   10/   37]    Overall Loss 0.357473    Objective Loss 0.357473                                        LR 0.000013    Time 0.037121    
2023-01-06 15:48:05,417 - Epoch: [137][   20/   37]    Overall Loss 0.347653    Objective Loss 0.347653                                        LR 0.000013    Time 0.027090    
2023-01-06 15:48:05,585 - Epoch: [137][   30/   37]    Overall Loss 0.343156    Objective Loss 0.343156                                        LR 0.000013    Time 0.023657    
2023-01-06 15:48:05,686 - Epoch: [137][   37/   37]    Overall Loss 0.340845    Objective Loss 0.340845    Top1 84.728033    LR 0.000013    Time 0.021911    
2023-01-06 15:48:05,764 - --- validate (epoch=137)-----------
2023-01-06 15:48:05,765 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:05,995 - Epoch: [137][    5/    5]    Loss 0.360068    Top1 84.446565    
2023-01-06 15:48:06,080 - ==> Top1: 84.447    Loss: 0.360

2023-01-06 15:48:06,080 - ==> Confusion:
[[358  71   0]
 [ 92 527   0]
 [  0   0   0]]

2023-01-06 15:48:06,082 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:48:06,082 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:06,088 - 

2023-01-06 15:48:06,088 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:06,451 - Epoch: [138][   10/   37]    Overall Loss 0.336583    Objective Loss 0.336583                                        LR 0.000013    Time 0.036220    
2023-01-06 15:48:06,613 - Epoch: [138][   20/   37]    Overall Loss 0.339069    Objective Loss 0.339069                                        LR 0.000013    Time 0.026143    
2023-01-06 15:48:06,788 - Epoch: [138][   30/   37]    Overall Loss 0.336897    Objective Loss 0.336897                                        LR 0.000013    Time 0.023250    
2023-01-06 15:48:06,897 - Epoch: [138][   37/   37]    Overall Loss 0.338035    Objective Loss 0.338035    Top1 85.774059    LR 0.000013    Time 0.021810    
2023-01-06 15:48:06,972 - --- validate (epoch=138)-----------
2023-01-06 15:48:06,972 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:07,194 - Epoch: [138][    5/    5]    Loss 0.348354    Top1 84.064885    
2023-01-06 15:48:07,258 - ==> Top1: 84.065    Loss: 0.348

2023-01-06 15:48:07,259 - ==> Confusion:
[[353  76   0]
 [ 91 528   0]
 [  0   0   0]]

2023-01-06 15:48:07,260 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:48:07,260 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:07,266 - 

2023-01-06 15:48:07,266 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:07,628 - Epoch: [139][   10/   37]    Overall Loss 0.340535    Objective Loss 0.340535                                        LR 0.000013    Time 0.036086    
2023-01-06 15:48:07,813 - Epoch: [139][   20/   37]    Overall Loss 0.337532    Objective Loss 0.337532                                        LR 0.000013    Time 0.027274    
2023-01-06 15:48:08,006 - Epoch: [139][   30/   37]    Overall Loss 0.339990    Objective Loss 0.339990                                        LR 0.000013    Time 0.024599    
2023-01-06 15:48:08,118 - Epoch: [139][   37/   37]    Overall Loss 0.339824    Objective Loss 0.339824    Top1 84.100418    LR 0.000013    Time 0.022986    
2023-01-06 15:48:08,190 - --- validate (epoch=139)-----------
2023-01-06 15:48:08,190 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:08,416 - Epoch: [139][    5/    5]    Loss 0.318347    Top1 84.541985    
2023-01-06 15:48:08,484 - ==> Top1: 84.542    Loss: 0.318

2023-01-06 15:48:08,484 - ==> Confusion:
[[359  70   0]
 [ 92 527   0]
 [  0   0   0]]

2023-01-06 15:48:08,485 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 124]
2023-01-06 15:48:08,485 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:08,491 - 

2023-01-06 15:48:08,491 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:08,858 - Epoch: [140][   10/   37]    Overall Loss 0.349131    Objective Loss 0.349131                                        LR 0.000008    Time 0.036650    
2023-01-06 15:48:09,051 - Epoch: [140][   20/   37]    Overall Loss 0.343592    Objective Loss 0.343592                                        LR 0.000008    Time 0.027919    
2023-01-06 15:48:09,246 - Epoch: [140][   30/   37]    Overall Loss 0.340807    Objective Loss 0.340807                                        LR 0.000008    Time 0.025120    
2023-01-06 15:48:09,362 - Epoch: [140][   37/   37]    Overall Loss 0.338488    Objective Loss 0.338488    Top1 86.192469    LR 0.000008    Time 0.023479    
2023-01-06 15:48:09,446 - --- validate (epoch=140)-----------
2023-01-06 15:48:09,447 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:09,671 - Epoch: [140][    5/    5]    Loss 0.359631    Top1 85.305344    
2023-01-06 15:48:09,739 - ==> Top1: 85.305    Loss: 0.360

2023-01-06 15:48:09,740 - ==> Confusion:
[[367  62   0]
 [ 92 527   0]
 [  0   0   0]]

2023-01-06 15:48:09,741 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 140]
2023-01-06 15:48:09,741 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:09,748 - 

2023-01-06 15:48:09,748 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:10,108 - Epoch: [141][   10/   37]    Overall Loss 0.339945    Objective Loss 0.339945                                        LR 0.000008    Time 0.035860    
2023-01-06 15:48:10,267 - Epoch: [141][   20/   37]    Overall Loss 0.346022    Objective Loss 0.346022                                        LR 0.000008    Time 0.025869    
2023-01-06 15:48:10,430 - Epoch: [141][   30/   37]    Overall Loss 0.339272    Objective Loss 0.339272                                        LR 0.000008    Time 0.022665    
2023-01-06 15:48:10,536 - Epoch: [141][   37/   37]    Overall Loss 0.336336    Objective Loss 0.336336    Top1 85.355649    LR 0.000008    Time 0.021236    
2023-01-06 15:48:10,620 - --- validate (epoch=141)-----------
2023-01-06 15:48:10,620 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:10,836 - Epoch: [141][    5/    5]    Loss 0.348100    Top1 84.446565    
2023-01-06 15:48:10,900 - ==> Top1: 84.447    Loss: 0.348

2023-01-06 15:48:10,900 - ==> Confusion:
[[357  72   0]
 [ 91 528   0]
 [  0   0   0]]

2023-01-06 15:48:10,901 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 140]
2023-01-06 15:48:10,901 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:10,907 - 

2023-01-06 15:48:10,907 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:11,277 - Epoch: [142][   10/   37]    Overall Loss 0.324032    Objective Loss 0.324032                                        LR 0.000008    Time 0.036954    
2023-01-06 15:48:11,462 - Epoch: [142][   20/   37]    Overall Loss 0.339698    Objective Loss 0.339698                                        LR 0.000008    Time 0.027661    
2023-01-06 15:48:11,641 - Epoch: [142][   30/   37]    Overall Loss 0.334958    Objective Loss 0.334958                                        LR 0.000008    Time 0.024405    
2023-01-06 15:48:11,747 - Epoch: [142][   37/   37]    Overall Loss 0.335886    Objective Loss 0.335886    Top1 83.472803    LR 0.000008    Time 0.022642    
2023-01-06 15:48:11,823 - --- validate (epoch=142)-----------
2023-01-06 15:48:11,823 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:12,044 - Epoch: [142][    5/    5]    Loss 0.343083    Top1 84.828244    
2023-01-06 15:48:12,111 - ==> Top1: 84.828    Loss: 0.343

2023-01-06 15:48:12,111 - ==> Confusion:
[[346  83   0]
 [ 76 543   0]
 [  0   0   0]]

2023-01-06 15:48:12,112 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 140]
2023-01-06 15:48:12,112 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:12,118 - 

2023-01-06 15:48:12,118 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:12,603 - Epoch: [143][   10/   37]    Overall Loss 0.325993    Objective Loss 0.325993                                        LR 0.000008    Time 0.048371    
2023-01-06 15:48:12,763 - Epoch: [143][   20/   37]    Overall Loss 0.325758    Objective Loss 0.325758                                        LR 0.000008    Time 0.032089    
2023-01-06 15:48:12,924 - Epoch: [143][   30/   37]    Overall Loss 0.330250    Objective Loss 0.330250                                        LR 0.000008    Time 0.026766    
2023-01-06 15:48:13,031 - Epoch: [143][   37/   37]    Overall Loss 0.335832    Objective Loss 0.335832    Top1 83.054393    LR 0.000008    Time 0.024569    
2023-01-06 15:48:13,107 - --- validate (epoch=143)-----------
2023-01-06 15:48:13,107 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:13,331 - Epoch: [143][    5/    5]    Loss 0.336722    Top1 84.255725    
2023-01-06 15:48:13,412 - ==> Top1: 84.256    Loss: 0.337

2023-01-06 15:48:13,412 - ==> Confusion:
[[360  69   0]
 [ 96 523   0]
 [  0   0   0]]

2023-01-06 15:48:13,413 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 140]
2023-01-06 15:48:13,414 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:13,419 - 

2023-01-06 15:48:13,420 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:13,785 - Epoch: [144][   10/   37]    Overall Loss 0.324806    Objective Loss 0.324806                                        LR 0.000008    Time 0.036442    
2023-01-06 15:48:13,977 - Epoch: [144][   20/   37]    Overall Loss 0.329435    Objective Loss 0.329435                                        LR 0.000008    Time 0.027801    
2023-01-06 15:48:14,168 - Epoch: [144][   30/   37]    Overall Loss 0.332056    Objective Loss 0.332056                                        LR 0.000008    Time 0.024895    
2023-01-06 15:48:14,278 - Epoch: [144][   37/   37]    Overall Loss 0.336582    Objective Loss 0.336582    Top1 82.008368    LR 0.000008    Time 0.023155    
2023-01-06 15:48:14,347 - --- validate (epoch=144)-----------
2023-01-06 15:48:14,348 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:14,566 - Epoch: [144][    5/    5]    Loss 0.349360    Top1 84.637405    
2023-01-06 15:48:14,628 - ==> Top1: 84.637    Loss: 0.349

2023-01-06 15:48:14,629 - ==> Confusion:
[[354  75   0]
 [ 86 533   0]
 [  0   0   0]]

2023-01-06 15:48:14,630 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 140]
2023-01-06 15:48:14,630 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:14,636 - 

2023-01-06 15:48:14,636 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:14,986 - Epoch: [145][   10/   37]    Overall Loss 0.340749    Objective Loss 0.340749                                        LR 0.000008    Time 0.034957    
2023-01-06 15:48:15,143 - Epoch: [145][   20/   37]    Overall Loss 0.339682    Objective Loss 0.339682                                        LR 0.000008    Time 0.025256    
2023-01-06 15:48:15,302 - Epoch: [145][   30/   37]    Overall Loss 0.337307    Objective Loss 0.337307                                        LR 0.000008    Time 0.022106    
2023-01-06 15:48:15,407 - Epoch: [145][   37/   37]    Overall Loss 0.336358    Objective Loss 0.336358    Top1 83.472803    LR 0.000008    Time 0.020757    
2023-01-06 15:48:15,477 - --- validate (epoch=145)-----------
2023-01-06 15:48:15,477 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:15,703 - Epoch: [145][    5/    5]    Loss 0.338671    Top1 83.874046    
2023-01-06 15:48:15,763 - ==> Top1: 83.874    Loss: 0.339

2023-01-06 15:48:15,764 - ==> Confusion:
[[359  70   0]
 [ 99 520   0]
 [  0   0   0]]

2023-01-06 15:48:15,765 - ==> Best [Top1: 85.305   Sparsity:0.00   Params: 155168 on epoch: 140]
2023-01-06 15:48:15,765 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:15,771 - 

2023-01-06 15:48:15,771 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:16,135 - Epoch: [146][   10/   37]    Overall Loss 0.338681    Objective Loss 0.338681                                        LR 0.000008    Time 0.036327    
2023-01-06 15:48:16,301 - Epoch: [146][   20/   37]    Overall Loss 0.334567    Objective Loss 0.334567                                        LR 0.000008    Time 0.026452    
2023-01-06 15:48:16,465 - Epoch: [146][   30/   37]    Overall Loss 0.333196    Objective Loss 0.333196                                        LR 0.000008    Time 0.023075    
2023-01-06 15:48:16,578 - Epoch: [146][   37/   37]    Overall Loss 0.334541    Objective Loss 0.334541    Top1 85.983264    LR 0.000008    Time 0.021763    
2023-01-06 15:48:16,643 - --- validate (epoch=146)-----------
2023-01-06 15:48:16,644 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:16,866 - Epoch: [146][    5/    5]    Loss 0.350253    Top1 85.496183    
2023-01-06 15:48:16,935 - ==> Top1: 85.496    Loss: 0.350

2023-01-06 15:48:16,935 - ==> Confusion:
[[354  75   0]
 [ 77 542   0]
 [  0   0   0]]

2023-01-06 15:48:16,937 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:16,937 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:16,944 - 

2023-01-06 15:48:16,944 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:17,300 - Epoch: [147][   10/   37]    Overall Loss 0.329152    Objective Loss 0.329152                                        LR 0.000008    Time 0.035495    
2023-01-06 15:48:17,459 - Epoch: [147][   20/   37]    Overall Loss 0.332592    Objective Loss 0.332592                                        LR 0.000008    Time 0.025675    
2023-01-06 15:48:17,619 - Epoch: [147][   30/   37]    Overall Loss 0.335156    Objective Loss 0.335156                                        LR 0.000008    Time 0.022455    
2023-01-06 15:48:17,724 - Epoch: [147][   37/   37]    Overall Loss 0.336324    Objective Loss 0.336324    Top1 85.564854    LR 0.000008    Time 0.021030    
2023-01-06 15:48:17,800 - --- validate (epoch=147)-----------
2023-01-06 15:48:17,800 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:18,019 - Epoch: [147][    5/    5]    Loss 0.337236    Top1 84.541985    
2023-01-06 15:48:18,103 - ==> Top1: 84.542    Loss: 0.337

2023-01-06 15:48:18,103 - ==> Confusion:
[[355  74   0]
 [ 88 531   0]
 [  0   0   0]]

2023-01-06 15:48:18,105 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:18,105 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:18,112 - 

2023-01-06 15:48:18,113 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:18,477 - Epoch: [148][   10/   37]    Overall Loss 0.336495    Objective Loss 0.336495                                        LR 0.000008    Time 0.036364    
2023-01-06 15:48:18,673 - Epoch: [148][   20/   37]    Overall Loss 0.337716    Objective Loss 0.337716                                        LR 0.000008    Time 0.027937    
2023-01-06 15:48:18,865 - Epoch: [148][   30/   37]    Overall Loss 0.332552    Objective Loss 0.332552                                        LR 0.000008    Time 0.025029    
2023-01-06 15:48:18,974 - Epoch: [148][   37/   37]    Overall Loss 0.338293    Objective Loss 0.338293    Top1 81.799163    LR 0.000008    Time 0.023224    
2023-01-06 15:48:19,049 - --- validate (epoch=148)-----------
2023-01-06 15:48:19,049 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:19,269 - Epoch: [148][    5/    5]    Loss 0.327356    Top1 85.114504    
2023-01-06 15:48:19,334 - ==> Top1: 85.115    Loss: 0.327

2023-01-06 15:48:19,335 - ==> Confusion:
[[348  81   0]
 [ 75 544   0]
 [  0   0   0]]

2023-01-06 15:48:19,336 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:19,336 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:19,342 - 

2023-01-06 15:48:19,342 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:19,702 - Epoch: [149][   10/   37]    Overall Loss 0.325265    Objective Loss 0.325265                                        LR 0.000008    Time 0.035929    
2023-01-06 15:48:19,882 - Epoch: [149][   20/   37]    Overall Loss 0.335119    Objective Loss 0.335119                                        LR 0.000008    Time 0.026948    
2023-01-06 15:48:20,057 - Epoch: [149][   30/   37]    Overall Loss 0.338125    Objective Loss 0.338125                                        LR 0.000008    Time 0.023799    
2023-01-06 15:48:20,170 - Epoch: [149][   37/   37]    Overall Loss 0.337574    Objective Loss 0.337574    Top1 84.100418    LR 0.000008    Time 0.022328    
2023-01-06 15:48:20,254 - --- validate (epoch=149)-----------
2023-01-06 15:48:20,254 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:20,475 - Epoch: [149][    5/    5]    Loss 0.332354    Top1 85.114504    
2023-01-06 15:48:20,538 - ==> Top1: 85.115    Loss: 0.332

2023-01-06 15:48:20,539 - ==> Confusion:
[[350  79   0]
 [ 77 542   0]
 [  0   0   0]]

2023-01-06 15:48:20,540 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:20,540 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:20,546 - 

2023-01-06 15:48:20,546 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:20,919 - Epoch: [150][   10/   37]    Overall Loss 0.339174    Objective Loss 0.339174                                        LR 0.000008    Time 0.037199    
2023-01-06 15:48:21,111 - Epoch: [150][   20/   37]    Overall Loss 0.338411    Objective Loss 0.338411                                        LR 0.000008    Time 0.028162    
2023-01-06 15:48:21,302 - Epoch: [150][   30/   37]    Overall Loss 0.332602    Objective Loss 0.332602                                        LR 0.000008    Time 0.025131    
2023-01-06 15:48:21,416 - Epoch: [150][   37/   37]    Overall Loss 0.335971    Objective Loss 0.335971    Top1 84.309623    LR 0.000008    Time 0.023454    
2023-01-06 15:48:21,496 - --- validate (epoch=150)-----------
2023-01-06 15:48:21,496 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:21,717 - Epoch: [150][    5/    5]    Loss 0.325234    Top1 84.541985    
2023-01-06 15:48:21,778 - ==> Top1: 84.542    Loss: 0.325

2023-01-06 15:48:21,779 - ==> Confusion:
[[353  76   0]
 [ 86 533   0]
 [  0   0   0]]

2023-01-06 15:48:21,780 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:21,780 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:21,786 - 

2023-01-06 15:48:21,786 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:22,168 - Epoch: [151][   10/   37]    Overall Loss 0.339610    Objective Loss 0.339610                                        LR 0.000008    Time 0.038147    
2023-01-06 15:48:22,346 - Epoch: [151][   20/   37]    Overall Loss 0.341969    Objective Loss 0.341969                                        LR 0.000008    Time 0.027939    
2023-01-06 15:48:22,527 - Epoch: [151][   30/   37]    Overall Loss 0.337239    Objective Loss 0.337239                                        LR 0.000008    Time 0.024632    
2023-01-06 15:48:22,629 - Epoch: [151][   37/   37]    Overall Loss 0.336526    Objective Loss 0.336526    Top1 83.891213    LR 0.000008    Time 0.022734    
2023-01-06 15:48:22,710 - --- validate (epoch=151)-----------
2023-01-06 15:48:22,711 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:22,933 - Epoch: [151][    5/    5]    Loss 0.356348    Top1 84.828244    
2023-01-06 15:48:23,006 - ==> Top1: 84.828    Loss: 0.356

2023-01-06 15:48:23,007 - ==> Confusion:
[[355  74   0]
 [ 85 534   0]
 [  0   0   0]]

2023-01-06 15:48:23,008 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:23,008 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:23,014 - 

2023-01-06 15:48:23,014 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:23,382 - Epoch: [152][   10/   37]    Overall Loss 0.339618    Objective Loss 0.339618                                        LR 0.000008    Time 0.036679    
2023-01-06 15:48:23,553 - Epoch: [152][   20/   37]    Overall Loss 0.336230    Objective Loss 0.336230                                        LR 0.000008    Time 0.026817    
2023-01-06 15:48:23,729 - Epoch: [152][   30/   37]    Overall Loss 0.336928    Objective Loss 0.336928                                        LR 0.000008    Time 0.023734    
2023-01-06 15:48:23,834 - Epoch: [152][   37/   37]    Overall Loss 0.335951    Objective Loss 0.335951    Top1 86.192469    LR 0.000008    Time 0.022082    
2023-01-06 15:48:23,920 - --- validate (epoch=152)-----------
2023-01-06 15:48:23,920 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:24,144 - Epoch: [152][    5/    5]    Loss 0.354723    Top1 84.541985    
2023-01-06 15:48:24,213 - ==> Top1: 84.542    Loss: 0.355

2023-01-06 15:48:24,213 - ==> Confusion:
[[366  63   0]
 [ 99 520   0]
 [  0   0   0]]

2023-01-06 15:48:24,215 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:24,215 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:24,223 - 

2023-01-06 15:48:24,223 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:24,586 - Epoch: [153][   10/   37]    Overall Loss 0.343289    Objective Loss 0.343289                                        LR 0.000008    Time 0.036224    
2023-01-06 15:48:24,755 - Epoch: [153][   20/   37]    Overall Loss 0.332473    Objective Loss 0.332473                                        LR 0.000008    Time 0.026505    
2023-01-06 15:48:24,931 - Epoch: [153][   30/   37]    Overall Loss 0.332470    Objective Loss 0.332470                                        LR 0.000008    Time 0.023533    
2023-01-06 15:48:25,040 - Epoch: [153][   37/   37]    Overall Loss 0.335891    Objective Loss 0.335891    Top1 85.355649    LR 0.000008    Time 0.022018    
2023-01-06 15:48:25,123 - --- validate (epoch=153)-----------
2023-01-06 15:48:25,123 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:25,342 - Epoch: [153][    5/    5]    Loss 0.343889    Top1 84.828244    
2023-01-06 15:48:25,407 - ==> Top1: 84.828    Loss: 0.344

2023-01-06 15:48:25,407 - ==> Confusion:
[[359  70   0]
 [ 89 530   0]
 [  0   0   0]]

2023-01-06 15:48:25,408 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:25,408 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:25,414 - 

2023-01-06 15:48:25,415 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:25,791 - Epoch: [154][   10/   37]    Overall Loss 0.338060    Objective Loss 0.338060                                        LR 0.000008    Time 0.037544    
2023-01-06 15:48:25,993 - Epoch: [154][   20/   37]    Overall Loss 0.343424    Objective Loss 0.343424                                        LR 0.000008    Time 0.028789    
2023-01-06 15:48:26,186 - Epoch: [154][   30/   37]    Overall Loss 0.337019    Objective Loss 0.337019                                        LR 0.000008    Time 0.025622    
2023-01-06 15:48:26,301 - Epoch: [154][   37/   37]    Overall Loss 0.335268    Objective Loss 0.335268    Top1 85.146444    LR 0.000008    Time 0.023886    
2023-01-06 15:48:26,370 - --- validate (epoch=154)-----------
2023-01-06 15:48:26,371 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:26,591 - Epoch: [154][    5/    5]    Loss 0.342255    Top1 84.828244    
2023-01-06 15:48:26,650 - ==> Top1: 84.828    Loss: 0.342

2023-01-06 15:48:26,651 - ==> Confusion:
[[364  65   0]
 [ 94 525   0]
 [  0   0   0]]

2023-01-06 15:48:26,653 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:26,653 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:26,659 - 

2023-01-06 15:48:26,660 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:27,020 - Epoch: [155][   10/   37]    Overall Loss 0.348903    Objective Loss 0.348903                                        LR 0.000008    Time 0.035995    
2023-01-06 15:48:27,186 - Epoch: [155][   20/   37]    Overall Loss 0.336236    Objective Loss 0.336236                                        LR 0.000008    Time 0.026204    
2023-01-06 15:48:27,374 - Epoch: [155][   30/   37]    Overall Loss 0.334229    Objective Loss 0.334229                                        LR 0.000008    Time 0.023724    
2023-01-06 15:48:27,485 - Epoch: [155][   37/   37]    Overall Loss 0.334626    Objective Loss 0.334626    Top1 84.309623    LR 0.000008    Time 0.022239    
2023-01-06 15:48:27,556 - --- validate (epoch=155)-----------
2023-01-06 15:48:27,557 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:27,782 - Epoch: [155][    5/    5]    Loss 0.326593    Top1 85.209924    
2023-01-06 15:48:27,851 - ==> Top1: 85.210    Loss: 0.327

2023-01-06 15:48:27,852 - ==> Confusion:
[[354  75   0]
 [ 80 539   0]
 [  0   0   0]]

2023-01-06 15:48:27,853 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:27,853 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:27,859 - 

2023-01-06 15:48:27,859 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:28,221 - Epoch: [156][   10/   37]    Overall Loss 0.342682    Objective Loss 0.342682                                        LR 0.000008    Time 0.036145    
2023-01-06 15:48:28,392 - Epoch: [156][   20/   37]    Overall Loss 0.344903    Objective Loss 0.344903                                        LR 0.000008    Time 0.026588    
2023-01-06 15:48:28,563 - Epoch: [156][   30/   37]    Overall Loss 0.337525    Objective Loss 0.337525                                        LR 0.000008    Time 0.023414    
2023-01-06 15:48:28,669 - Epoch: [156][   37/   37]    Overall Loss 0.334963    Objective Loss 0.334963    Top1 85.146444    LR 0.000008    Time 0.021833    
2023-01-06 15:48:28,743 - --- validate (epoch=156)-----------
2023-01-06 15:48:28,744 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:28,964 - Epoch: [156][    5/    5]    Loss 0.346491    Top1 84.923664    
2023-01-06 15:48:29,027 - ==> Top1: 84.924    Loss: 0.346

2023-01-06 15:48:29,028 - ==> Confusion:
[[363  66   0]
 [ 92 527   0]
 [  0   0   0]]

2023-01-06 15:48:29,029 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:29,029 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:29,035 - 

2023-01-06 15:48:29,035 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:29,388 - Epoch: [157][   10/   37]    Overall Loss 0.321080    Objective Loss 0.321080                                        LR 0.000008    Time 0.035225    
2023-01-06 15:48:29,561 - Epoch: [157][   20/   37]    Overall Loss 0.329812    Objective Loss 0.329812                                        LR 0.000008    Time 0.026143    
2023-01-06 15:48:29,748 - Epoch: [157][   30/   37]    Overall Loss 0.333109    Objective Loss 0.333109                                        LR 0.000008    Time 0.023663    
2023-01-06 15:48:29,859 - Epoch: [157][   37/   37]    Overall Loss 0.335981    Objective Loss 0.335981    Top1 83.891213    LR 0.000008    Time 0.022174    
2023-01-06 15:48:29,933 - --- validate (epoch=157)-----------
2023-01-06 15:48:29,933 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:30,152 - Epoch: [157][    5/    5]    Loss 0.346934    Top1 84.732824    
2023-01-06 15:48:30,222 - ==> Top1: 84.733    Loss: 0.347

2023-01-06 15:48:30,222 - ==> Confusion:
[[355  74   0]
 [ 86 533   0]
 [  0   0   0]]

2023-01-06 15:48:30,223 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:30,223 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:30,229 - 

2023-01-06 15:48:30,230 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:30,603 - Epoch: [158][   10/   37]    Overall Loss 0.341526    Objective Loss 0.341526                                        LR 0.000008    Time 0.037290    
2023-01-06 15:48:30,793 - Epoch: [158][   20/   37]    Overall Loss 0.335977    Objective Loss 0.335977                                        LR 0.000008    Time 0.028098    
2023-01-06 15:48:30,998 - Epoch: [158][   30/   37]    Overall Loss 0.334992    Objective Loss 0.334992                                        LR 0.000008    Time 0.025563    
2023-01-06 15:48:31,128 - Epoch: [158][   37/   37]    Overall Loss 0.334933    Objective Loss 0.334933    Top1 85.564854    LR 0.000008    Time 0.024245    
2023-01-06 15:48:31,209 - --- validate (epoch=158)-----------
2023-01-06 15:48:31,210 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:31,428 - Epoch: [158][    5/    5]    Loss 0.404809    Top1 84.255725    
2023-01-06 15:48:31,508 - ==> Top1: 84.256    Loss: 0.405

2023-01-06 15:48:31,508 - ==> Confusion:
[[358  71   0]
 [ 94 525   0]
 [  0   0   0]]

2023-01-06 15:48:31,510 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:31,510 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:31,515 - 

2023-01-06 15:48:31,516 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:32,016 - Epoch: [159][   10/   37]    Overall Loss 0.328359    Objective Loss 0.328359                                        LR 0.000008    Time 0.049994    
2023-01-06 15:48:32,203 - Epoch: [159][   20/   37]    Overall Loss 0.330029    Objective Loss 0.330029                                        LR 0.000008    Time 0.034297    
2023-01-06 15:48:32,391 - Epoch: [159][   30/   37]    Overall Loss 0.331510    Objective Loss 0.331510                                        LR 0.000008    Time 0.029148    
2023-01-06 15:48:32,506 - Epoch: [159][   37/   37]    Overall Loss 0.333933    Objective Loss 0.333933    Top1 83.682008    LR 0.000008    Time 0.026721    
2023-01-06 15:48:32,587 - --- validate (epoch=159)-----------
2023-01-06 15:48:32,587 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:32,804 - Epoch: [159][    5/    5]    Loss 0.331734    Top1 84.732824    
2023-01-06 15:48:32,871 - ==> Top1: 84.733    Loss: 0.332

2023-01-06 15:48:32,871 - ==> Confusion:
[[357  72   0]
 [ 88 531   0]
 [  0   0   0]]

2023-01-06 15:48:32,872 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:32,873 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:32,879 - 

2023-01-06 15:48:32,879 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:33,234 - Epoch: [160][   10/   37]    Overall Loss 0.342927    Objective Loss 0.342927                                        LR 0.000008    Time 0.035396    
2023-01-06 15:48:33,421 - Epoch: [160][   20/   37]    Overall Loss 0.341739    Objective Loss 0.341739                                        LR 0.000008    Time 0.027023    
2023-01-06 15:48:33,617 - Epoch: [160][   30/   37]    Overall Loss 0.339049    Objective Loss 0.339049                                        LR 0.000008    Time 0.024503    
2023-01-06 15:48:33,733 - Epoch: [160][   37/   37]    Overall Loss 0.332577    Objective Loss 0.332577    Top1 86.820084    LR 0.000008    Time 0.022997    
2023-01-06 15:48:33,819 - --- validate (epoch=160)-----------
2023-01-06 15:48:33,819 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:34,040 - Epoch: [160][    5/    5]    Loss 0.342420    Top1 85.114504    
2023-01-06 15:48:34,106 - ==> Top1: 85.115    Loss: 0.342

2023-01-06 15:48:34,106 - ==> Confusion:
[[345  84   0]
 [ 72 547   0]
 [  0   0   0]]

2023-01-06 15:48:34,107 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:34,108 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:34,113 - 

2023-01-06 15:48:34,114 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:34,474 - Epoch: [161][   10/   37]    Overall Loss 0.312895    Objective Loss 0.312895                                        LR 0.000008    Time 0.036014    
2023-01-06 15:48:34,656 - Epoch: [161][   20/   37]    Overall Loss 0.324769    Objective Loss 0.324769                                        LR 0.000008    Time 0.027059    
2023-01-06 15:48:34,838 - Epoch: [161][   30/   37]    Overall Loss 0.333214    Objective Loss 0.333214                                        LR 0.000008    Time 0.024091    
2023-01-06 15:48:34,953 - Epoch: [161][   37/   37]    Overall Loss 0.331715    Objective Loss 0.331715    Top1 84.728033    LR 0.000008    Time 0.022651    
2023-01-06 15:48:35,024 - --- validate (epoch=161)-----------
2023-01-06 15:48:35,025 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:35,249 - Epoch: [161][    5/    5]    Loss 0.385794    Top1 84.255725    
2023-01-06 15:48:35,317 - ==> Top1: 84.256    Loss: 0.386

2023-01-06 15:48:35,318 - ==> Confusion:
[[356  73   0]
 [ 92 527   0]
 [  0   0   0]]

2023-01-06 15:48:35,319 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:35,319 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:35,325 - 

2023-01-06 15:48:35,325 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:35,703 - Epoch: [162][   10/   37]    Overall Loss 0.319468    Objective Loss 0.319468                                        LR 0.000008    Time 0.037730    
2023-01-06 15:48:35,901 - Epoch: [162][   20/   37]    Overall Loss 0.329719    Objective Loss 0.329719                                        LR 0.000008    Time 0.028727    
2023-01-06 15:48:36,093 - Epoch: [162][   30/   37]    Overall Loss 0.329208    Objective Loss 0.329208                                        LR 0.000008    Time 0.025530    
2023-01-06 15:48:36,201 - Epoch: [162][   37/   37]    Overall Loss 0.329633    Objective Loss 0.329633    Top1 82.008368    LR 0.000008    Time 0.023616    
2023-01-06 15:48:36,283 - --- validate (epoch=162)-----------
2023-01-06 15:48:36,284 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:36,504 - Epoch: [162][    5/    5]    Loss 0.326737    Top1 84.541985    
2023-01-06 15:48:36,558 - ==> Top1: 84.542    Loss: 0.327

2023-01-06 15:48:36,558 - ==> Confusion:
[[361  68   0]
 [ 94 525   0]
 [  0   0   0]]

2023-01-06 15:48:36,559 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:36,559 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:36,565 - 

2023-01-06 15:48:36,566 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:36,928 - Epoch: [163][   10/   37]    Overall Loss 0.345037    Objective Loss 0.345037                                        LR 0.000008    Time 0.036191    
2023-01-06 15:48:37,113 - Epoch: [163][   20/   37]    Overall Loss 0.334818    Objective Loss 0.334818                                        LR 0.000008    Time 0.027289    
2023-01-06 15:48:37,311 - Epoch: [163][   30/   37]    Overall Loss 0.329530    Objective Loss 0.329530                                        LR 0.000008    Time 0.024779    
2023-01-06 15:48:37,425 - Epoch: [163][   37/   37]    Overall Loss 0.330206    Objective Loss 0.330206    Top1 83.054393    LR 0.000008    Time 0.023180    
2023-01-06 15:48:37,502 - --- validate (epoch=163)-----------
2023-01-06 15:48:37,502 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:37,737 - Epoch: [163][    5/    5]    Loss 0.355875    Top1 85.305344    
2023-01-06 15:48:37,803 - ==> Top1: 85.305    Loss: 0.356

2023-01-06 15:48:37,803 - ==> Confusion:
[[364  65   0]
 [ 89 530   0]
 [  0   0   0]]

2023-01-06 15:48:37,805 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:37,805 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:37,811 - 

2023-01-06 15:48:37,811 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:38,155 - Epoch: [164][   10/   37]    Overall Loss 0.317315    Objective Loss 0.317315                                        LR 0.000008    Time 0.034277    
2023-01-06 15:48:38,314 - Epoch: [164][   20/   37]    Overall Loss 0.328494    Objective Loss 0.328494                                        LR 0.000008    Time 0.025098    
2023-01-06 15:48:38,482 - Epoch: [164][   30/   37]    Overall Loss 0.326532    Objective Loss 0.326532                                        LR 0.000008    Time 0.022318    
2023-01-06 15:48:38,586 - Epoch: [164][   37/   37]    Overall Loss 0.328844    Objective Loss 0.328844    Top1 86.820084    LR 0.000008    Time 0.020890    
2023-01-06 15:48:38,655 - --- validate (epoch=164)-----------
2023-01-06 15:48:38,655 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:38,870 - Epoch: [164][    5/    5]    Loss 0.328389    Top1 84.828244    
2023-01-06 15:48:38,933 - ==> Top1: 84.828    Loss: 0.328

2023-01-06 15:48:38,933 - ==> Confusion:
[[353  76   0]
 [ 83 536   0]
 [  0   0   0]]

2023-01-06 15:48:38,934 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:38,934 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:38,940 - 

2023-01-06 15:48:38,941 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:39,303 - Epoch: [165][   10/   37]    Overall Loss 0.327098    Objective Loss 0.327098                                        LR 0.000008    Time 0.036177    
2023-01-06 15:48:39,473 - Epoch: [165][   20/   37]    Overall Loss 0.323705    Objective Loss 0.323705                                        LR 0.000008    Time 0.026569    
2023-01-06 15:48:39,642 - Epoch: [165][   30/   37]    Overall Loss 0.332936    Objective Loss 0.332936                                        LR 0.000008    Time 0.023342    
2023-01-06 15:48:39,750 - Epoch: [165][   37/   37]    Overall Loss 0.330153    Objective Loss 0.330153    Top1 85.355649    LR 0.000008    Time 0.021834    
2023-01-06 15:48:39,829 - --- validate (epoch=165)-----------
2023-01-06 15:48:39,830 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:40,055 - Epoch: [165][    5/    5]    Loss 0.336594    Top1 84.446565    
2023-01-06 15:48:40,126 - ==> Top1: 84.447    Loss: 0.337

2023-01-06 15:48:40,126 - ==> Confusion:
[[363  66   0]
 [ 97 522   0]
 [  0   0   0]]

2023-01-06 15:48:40,128 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:40,128 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:40,134 - 

2023-01-06 15:48:40,134 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:40,491 - Epoch: [166][   10/   37]    Overall Loss 0.336685    Objective Loss 0.336685                                        LR 0.000008    Time 0.035668    
2023-01-06 15:48:40,664 - Epoch: [166][   20/   37]    Overall Loss 0.333871    Objective Loss 0.333871                                        LR 0.000008    Time 0.026392    
2023-01-06 15:48:40,851 - Epoch: [166][   30/   37]    Overall Loss 0.331999    Objective Loss 0.331999                                        LR 0.000008    Time 0.023814    
2023-01-06 15:48:40,966 - Epoch: [166][   37/   37]    Overall Loss 0.331464    Objective Loss 0.331464    Top1 85.564854    LR 0.000008    Time 0.022418    
2023-01-06 15:48:41,040 - --- validate (epoch=166)-----------
2023-01-06 15:48:41,040 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:41,260 - Epoch: [166][    5/    5]    Loss 0.370504    Top1 85.019084    
2023-01-06 15:48:41,324 - ==> Top1: 85.019    Loss: 0.371

2023-01-06 15:48:41,324 - ==> Confusion:
[[359  70   0]
 [ 87 532   0]
 [  0   0   0]]

2023-01-06 15:48:41,326 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:41,326 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:41,332 - 

2023-01-06 15:48:41,332 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:41,699 - Epoch: [167][   10/   37]    Overall Loss 0.322671    Objective Loss 0.322671                                        LR 0.000008    Time 0.036626    
2023-01-06 15:48:41,870 - Epoch: [167][   20/   37]    Overall Loss 0.326926    Objective Loss 0.326926                                        LR 0.000008    Time 0.026850    
2023-01-06 15:48:42,056 - Epoch: [167][   30/   37]    Overall Loss 0.329188    Objective Loss 0.329188                                        LR 0.000008    Time 0.024101    
2023-01-06 15:48:42,174 - Epoch: [167][   37/   37]    Overall Loss 0.330767    Objective Loss 0.330767    Top1 82.635983    LR 0.000008    Time 0.022710    
2023-01-06 15:48:42,244 - --- validate (epoch=167)-----------
2023-01-06 15:48:42,245 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:42,463 - Epoch: [167][    5/    5]    Loss 0.324626    Top1 84.541985    
2023-01-06 15:48:42,538 - ==> Top1: 84.542    Loss: 0.325

2023-01-06 15:48:42,538 - ==> Confusion:
[[336  93   0]
 [ 69 550   0]
 [  0   0   0]]

2023-01-06 15:48:42,539 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:42,539 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:42,545 - 

2023-01-06 15:48:42,545 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:42,913 - Epoch: [168][   10/   37]    Overall Loss 0.338943    Objective Loss 0.338943                                        LR 0.000008    Time 0.036678    
2023-01-06 15:48:43,102 - Epoch: [168][   20/   37]    Overall Loss 0.331875    Objective Loss 0.331875                                        LR 0.000008    Time 0.027768    
2023-01-06 15:48:43,301 - Epoch: [168][   30/   37]    Overall Loss 0.330944    Objective Loss 0.330944                                        LR 0.000008    Time 0.025141    
2023-01-06 15:48:43,412 - Epoch: [168][   37/   37]    Overall Loss 0.330218    Objective Loss 0.330218    Top1 85.564854    LR 0.000008    Time 0.023367    
2023-01-06 15:48:43,483 - --- validate (epoch=168)-----------
2023-01-06 15:48:43,483 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:43,707 - Epoch: [168][    5/    5]    Loss 0.330147    Top1 83.969466    
2023-01-06 15:48:43,777 - ==> Top1: 83.969    Loss: 0.330

2023-01-06 15:48:43,777 - ==> Confusion:
[[354  75   0]
 [ 93 526   0]
 [  0   0   0]]

2023-01-06 15:48:43,779 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:43,779 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:43,785 - 

2023-01-06 15:48:43,785 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:44,159 - Epoch: [169][   10/   37]    Overall Loss 0.329878    Objective Loss 0.329878                                        LR 0.000008    Time 0.037375    
2023-01-06 15:48:44,342 - Epoch: [169][   20/   37]    Overall Loss 0.326514    Objective Loss 0.326514                                        LR 0.000008    Time 0.027802    
2023-01-06 15:48:44,529 - Epoch: [169][   30/   37]    Overall Loss 0.331088    Objective Loss 0.331088                                        LR 0.000008    Time 0.024759    
2023-01-06 15:48:44,644 - Epoch: [169][   37/   37]    Overall Loss 0.328902    Objective Loss 0.328902    Top1 88.075314    LR 0.000008    Time 0.023163    
2023-01-06 15:48:44,717 - --- validate (epoch=169)-----------
2023-01-06 15:48:44,718 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:44,935 - Epoch: [169][    5/    5]    Loss 0.335955    Top1 85.209924    
2023-01-06 15:48:45,000 - ==> Top1: 85.210    Loss: 0.336

2023-01-06 15:48:45,001 - ==> Confusion:
[[361  68   0]
 [ 87 532   0]
 [  0   0   0]]

2023-01-06 15:48:45,002 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:45,002 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:45,008 - 

2023-01-06 15:48:45,008 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:45,361 - Epoch: [170][   10/   37]    Overall Loss 0.341878    Objective Loss 0.341878                                        LR 0.000008    Time 0.035195    
2023-01-06 15:48:45,536 - Epoch: [170][   20/   37]    Overall Loss 0.335928    Objective Loss 0.335928                                        LR 0.000008    Time 0.026315    
2023-01-06 15:48:45,724 - Epoch: [170][   30/   37]    Overall Loss 0.331791    Objective Loss 0.331791                                        LR 0.000008    Time 0.023779    
2023-01-06 15:48:45,833 - Epoch: [170][   37/   37]    Overall Loss 0.329877    Objective Loss 0.329877    Top1 85.983264    LR 0.000008    Time 0.022217    
2023-01-06 15:48:45,911 - --- validate (epoch=170)-----------
2023-01-06 15:48:45,911 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:46,141 - Epoch: [170][    5/    5]    Loss 0.321475    Top1 85.114504    
2023-01-06 15:48:46,205 - ==> Top1: 85.115    Loss: 0.321

2023-01-06 15:48:46,205 - ==> Confusion:
[[355  74   0]
 [ 82 537   0]
 [  0   0   0]]

2023-01-06 15:48:46,207 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:46,207 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:46,213 - 

2023-01-06 15:48:46,213 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:46,567 - Epoch: [171][   10/   37]    Overall Loss 0.323422    Objective Loss 0.323422                                        LR 0.000008    Time 0.035349    
2023-01-06 15:48:46,730 - Epoch: [171][   20/   37]    Overall Loss 0.334491    Objective Loss 0.334491                                        LR 0.000008    Time 0.025760    
2023-01-06 15:48:46,896 - Epoch: [171][   30/   37]    Overall Loss 0.331858    Objective Loss 0.331858                                        LR 0.000008    Time 0.022684    
2023-01-06 15:48:46,995 - Epoch: [171][   37/   37]    Overall Loss 0.330825    Objective Loss 0.330825    Top1 86.610879    LR 0.000008    Time 0.021075    
2023-01-06 15:48:47,077 - --- validate (epoch=171)-----------
2023-01-06 15:48:47,078 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:47,294 - Epoch: [171][    5/    5]    Loss 0.341211    Top1 85.209924    
2023-01-06 15:48:47,353 - ==> Top1: 85.210    Loss: 0.341

2023-01-06 15:48:47,354 - ==> Confusion:
[[366  63   0]
 [ 92 527   0]
 [  0   0   0]]

2023-01-06 15:48:47,355 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:47,355 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:47,361 - 

2023-01-06 15:48:47,361 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:47,726 - Epoch: [172][   10/   37]    Overall Loss 0.339715    Objective Loss 0.339715                                        LR 0.000008    Time 0.036421    
2023-01-06 15:48:47,905 - Epoch: [172][   20/   37]    Overall Loss 0.331597    Objective Loss 0.331597                                        LR 0.000008    Time 0.027145    
2023-01-06 15:48:48,101 - Epoch: [172][   30/   37]    Overall Loss 0.328970    Objective Loss 0.328970                                        LR 0.000008    Time 0.024617    
2023-01-06 15:48:48,214 - Epoch: [172][   37/   37]    Overall Loss 0.328869    Objective Loss 0.328869    Top1 84.100418    LR 0.000008    Time 0.023005    
2023-01-06 15:48:48,285 - --- validate (epoch=172)-----------
2023-01-06 15:48:48,285 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:48,504 - Epoch: [172][    5/    5]    Loss 0.353631    Top1 85.305344    
2023-01-06 15:48:48,575 - ==> Top1: 85.305    Loss: 0.354

2023-01-06 15:48:48,575 - ==> Confusion:
[[347  82   0]
 [ 72 547   0]
 [  0   0   0]]

2023-01-06 15:48:48,577 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:48,577 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:48,583 - 

2023-01-06 15:48:48,583 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:48,952 - Epoch: [173][   10/   37]    Overall Loss 0.338353    Objective Loss 0.338353                                        LR 0.000008    Time 0.036889    
2023-01-06 15:48:49,128 - Epoch: [173][   20/   37]    Overall Loss 0.334827    Objective Loss 0.334827                                        LR 0.000008    Time 0.027212    
2023-01-06 15:48:49,329 - Epoch: [173][   30/   37]    Overall Loss 0.332031    Objective Loss 0.332031                                        LR 0.000008    Time 0.024820    
2023-01-06 15:48:49,443 - Epoch: [173][   37/   37]    Overall Loss 0.331811    Objective Loss 0.331811    Top1 83.054393    LR 0.000008    Time 0.023211    
2023-01-06 15:48:49,513 - --- validate (epoch=173)-----------
2023-01-06 15:48:49,514 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:49,734 - Epoch: [173][    5/    5]    Loss 0.344756    Top1 84.828244    
2023-01-06 15:48:49,803 - ==> Top1: 84.828    Loss: 0.345

2023-01-06 15:48:49,804 - ==> Confusion:
[[360  69   0]
 [ 90 529   0]
 [  0   0   0]]

2023-01-06 15:48:49,805 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:49,805 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:49,811 - 

2023-01-06 15:48:49,811 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:50,193 - Epoch: [174][   10/   37]    Overall Loss 0.330517    Objective Loss 0.330517                                        LR 0.000008    Time 0.038076    
2023-01-06 15:48:50,378 - Epoch: [174][   20/   37]    Overall Loss 0.327460    Objective Loss 0.327460                                        LR 0.000008    Time 0.028279    
2023-01-06 15:48:50,570 - Epoch: [174][   30/   37]    Overall Loss 0.327706    Objective Loss 0.327706                                        LR 0.000008    Time 0.025245    
2023-01-06 15:48:50,683 - Epoch: [174][   37/   37]    Overall Loss 0.329192    Objective Loss 0.329192    Top1 85.355649    LR 0.000008    Time 0.023528    
2023-01-06 15:48:50,758 - --- validate (epoch=174)-----------
2023-01-06 15:48:50,758 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:50,975 - Epoch: [174][    5/    5]    Loss 0.369684    Top1 85.400763    
2023-01-06 15:48:51,046 - ==> Top1: 85.401    Loss: 0.370

2023-01-06 15:48:51,046 - ==> Confusion:
[[359  70   0]
 [ 83 536   0]
 [  0   0   0]]

2023-01-06 15:48:51,047 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:51,048 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:51,053 - 

2023-01-06 15:48:51,054 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:51,413 - Epoch: [175][   10/   37]    Overall Loss 0.321820    Objective Loss 0.321820                                        LR 0.000008    Time 0.035870    
2023-01-06 15:48:51,585 - Epoch: [175][   20/   37]    Overall Loss 0.328363    Objective Loss 0.328363                                        LR 0.000008    Time 0.026447    
2023-01-06 15:48:51,760 - Epoch: [175][   30/   37]    Overall Loss 0.324124    Objective Loss 0.324124                                        LR 0.000008    Time 0.023479    
2023-01-06 15:48:51,868 - Epoch: [175][   37/   37]    Overall Loss 0.328925    Objective Loss 0.328925    Top1 84.518828    LR 0.000008    Time 0.021950    
2023-01-06 15:48:51,940 - --- validate (epoch=175)-----------
2023-01-06 15:48:51,941 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:52,160 - Epoch: [175][    5/    5]    Loss 0.311172    Top1 84.541985    
2023-01-06 15:48:52,231 - ==> Top1: 84.542    Loss: 0.311

2023-01-06 15:48:52,231 - ==> Confusion:
[[349  80   0]
 [ 82 537   0]
 [  0   0   0]]

2023-01-06 15:48:52,233 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:52,233 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:52,239 - 

2023-01-06 15:48:52,239 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:52,747 - Epoch: [176][   10/   37]    Overall Loss 0.324595    Objective Loss 0.324595                                        LR 0.000008    Time 0.050744    
2023-01-06 15:48:52,937 - Epoch: [176][   20/   37]    Overall Loss 0.328901    Objective Loss 0.328901                                        LR 0.000008    Time 0.034858    
2023-01-06 15:48:53,135 - Epoch: [176][   30/   37]    Overall Loss 0.330046    Objective Loss 0.330046                                        LR 0.000008    Time 0.029827    
2023-01-06 15:48:53,249 - Epoch: [176][   37/   37]    Overall Loss 0.331197    Objective Loss 0.331197    Top1 83.682008    LR 0.000008    Time 0.027253    
2023-01-06 15:48:53,318 - --- validate (epoch=176)-----------
2023-01-06 15:48:53,318 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:53,538 - Epoch: [176][    5/    5]    Loss 0.331434    Top1 84.637405    
2023-01-06 15:48:53,604 - ==> Top1: 84.637    Loss: 0.331

2023-01-06 15:48:53,605 - ==> Confusion:
[[358  71   0]
 [ 90 529   0]
 [  0   0   0]]

2023-01-06 15:48:53,606 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:53,606 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:53,612 - 

2023-01-06 15:48:53,612 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:53,975 - Epoch: [177][   10/   37]    Overall Loss 0.324035    Objective Loss 0.324035                                        LR 0.000008    Time 0.036164    
2023-01-06 15:48:54,164 - Epoch: [177][   20/   37]    Overall Loss 0.330009    Objective Loss 0.330009                                        LR 0.000008    Time 0.027528    
2023-01-06 15:48:54,348 - Epoch: [177][   30/   37]    Overall Loss 0.330043    Objective Loss 0.330043                                        LR 0.000008    Time 0.024403    
2023-01-06 15:48:54,457 - Epoch: [177][   37/   37]    Overall Loss 0.330534    Objective Loss 0.330534    Top1 87.866109    LR 0.000008    Time 0.022739    
2023-01-06 15:48:54,535 - --- validate (epoch=177)-----------
2023-01-06 15:48:54,535 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:54,752 - Epoch: [177][    5/    5]    Loss 0.357531    Top1 84.828244    
2023-01-06 15:48:54,824 - ==> Top1: 84.828    Loss: 0.358

2023-01-06 15:48:54,824 - ==> Confusion:
[[363  66   0]
 [ 93 526   0]
 [  0   0   0]]

2023-01-06 15:48:54,825 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:54,825 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:54,831 - 

2023-01-06 15:48:54,832 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:55,219 - Epoch: [178][   10/   37]    Overall Loss 0.336935    Objective Loss 0.336935                                        LR 0.000008    Time 0.038658    
2023-01-06 15:48:55,415 - Epoch: [178][   20/   37]    Overall Loss 0.329663    Objective Loss 0.329663                                        LR 0.000008    Time 0.029090    
2023-01-06 15:48:55,615 - Epoch: [178][   30/   37]    Overall Loss 0.350662    Objective Loss 0.350662                                        LR 0.000008    Time 0.026066    
2023-01-06 15:48:55,729 - Epoch: [178][   37/   37]    Overall Loss 0.355576    Objective Loss 0.355576    Top1 85.355649    LR 0.000008    Time 0.024204    
2023-01-06 15:48:55,812 - --- validate (epoch=178)-----------
2023-01-06 15:48:55,812 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:56,041 - Epoch: [178][    5/    5]    Loss 0.382446    Top1 84.828244    
2023-01-06 15:48:56,113 - ==> Top1: 84.828    Loss: 0.382

2023-01-06 15:48:56,113 - ==> Confusion:
[[348  81   0]
 [ 78 541   0]
 [  0   0   0]]

2023-01-06 15:48:56,115 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:56,115 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:56,121 - 

2023-01-06 15:48:56,121 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:56,490 - Epoch: [179][   10/   37]    Overall Loss 0.377299    Objective Loss 0.377299                                        LR 0.000008    Time 0.036839    
2023-01-06 15:48:56,678 - Epoch: [179][   20/   37]    Overall Loss 0.377462    Objective Loss 0.377462                                        LR 0.000008    Time 0.027791    
2023-01-06 15:48:56,869 - Epoch: [179][   30/   37]    Overall Loss 0.377144    Objective Loss 0.377144                                        LR 0.000008    Time 0.024865    
2023-01-06 15:48:56,983 - Epoch: [179][   37/   37]    Overall Loss 0.379732    Objective Loss 0.379732    Top1 85.146444    LR 0.000008    Time 0.023237    
2023-01-06 15:48:57,056 - --- validate (epoch=179)-----------
2023-01-06 15:48:57,057 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:57,272 - Epoch: [179][    5/    5]    Loss 0.375231    Top1 84.923664    
2023-01-06 15:48:57,342 - ==> Top1: 84.924    Loss: 0.375

2023-01-06 15:48:57,342 - ==> Confusion:
[[353  76   0]
 [ 82 537   0]
 [  0   0   0]]

2023-01-06 15:48:57,343 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:57,343 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:57,349 - 

2023-01-06 15:48:57,349 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:57,702 - Epoch: [180][   10/   37]    Overall Loss 0.385155    Objective Loss 0.385155                                        LR 0.000005    Time 0.035246    
2023-01-06 15:48:57,873 - Epoch: [180][   20/   37]    Overall Loss 0.381662    Objective Loss 0.381662                                        LR 0.000005    Time 0.026153    
2023-01-06 15:48:58,057 - Epoch: [180][   30/   37]    Overall Loss 0.375500    Objective Loss 0.375500                                        LR 0.000005    Time 0.023538    
2023-01-06 15:48:58,170 - Epoch: [180][   37/   37]    Overall Loss 0.375908    Objective Loss 0.375908    Top1 84.728033    LR 0.000005    Time 0.022142    
2023-01-06 15:48:58,240 - --- validate (epoch=180)-----------
2023-01-06 15:48:58,240 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:58,457 - Epoch: [180][    5/    5]    Loss 0.378084    Top1 85.019084    
2023-01-06 15:48:58,536 - ==> Top1: 85.019    Loss: 0.378

2023-01-06 15:48:58,536 - ==> Confusion:
[[352  77   0]
 [ 80 539   0]
 [  0   0   0]]

2023-01-06 15:48:58,537 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:58,537 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:58,543 - 

2023-01-06 15:48:58,543 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:48:58,905 - Epoch: [181][   10/   37]    Overall Loss 0.377259    Objective Loss 0.377259                                        LR 0.000005    Time 0.036148    
2023-01-06 15:48:59,069 - Epoch: [181][   20/   37]    Overall Loss 0.375355    Objective Loss 0.375355                                        LR 0.000005    Time 0.026153    
2023-01-06 15:48:59,228 - Epoch: [181][   30/   37]    Overall Loss 0.371754    Objective Loss 0.371754                                        LR 0.000005    Time 0.022716    
2023-01-06 15:48:59,333 - Epoch: [181][   37/   37]    Overall Loss 0.371782    Objective Loss 0.371782    Top1 86.401674    LR 0.000005    Time 0.021261    
2023-01-06 15:48:59,417 - --- validate (epoch=181)-----------
2023-01-06 15:48:59,417 - 1048 samples (256 per mini-batch)
2023-01-06 15:48:59,636 - Epoch: [181][    5/    5]    Loss 0.379140    Top1 85.305344    
2023-01-06 15:48:59,699 - ==> Top1: 85.305    Loss: 0.379

2023-01-06 15:48:59,699 - ==> Confusion:
[[359  70   0]
 [ 84 535   0]
 [  0   0   0]]

2023-01-06 15:48:59,700 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:48:59,700 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:48:59,706 - 

2023-01-06 15:48:59,706 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:00,083 - Epoch: [182][   10/   37]    Overall Loss 0.362755    Objective Loss 0.362755                                        LR 0.000005    Time 0.037642    
2023-01-06 15:49:00,280 - Epoch: [182][   20/   37]    Overall Loss 0.367568    Objective Loss 0.367568                                        LR 0.000005    Time 0.028636    
2023-01-06 15:49:00,474 - Epoch: [182][   30/   37]    Overall Loss 0.370050    Objective Loss 0.370050                                        LR 0.000005    Time 0.025557    
2023-01-06 15:49:00,589 - Epoch: [182][   37/   37]    Overall Loss 0.369807    Objective Loss 0.369807    Top1 84.518828    LR 0.000005    Time 0.023820    
2023-01-06 15:49:00,661 - --- validate (epoch=182)-----------
2023-01-06 15:49:00,661 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:00,876 - Epoch: [182][    5/    5]    Loss 0.372530    Top1 84.446565    
2023-01-06 15:49:00,936 - ==> Top1: 84.447    Loss: 0.373

2023-01-06 15:49:00,937 - ==> Confusion:
[[354  75   0]
 [ 88 531   0]
 [  0   0   0]]

2023-01-06 15:49:00,938 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:00,938 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:00,945 - 

2023-01-06 15:49:00,945 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:01,300 - Epoch: [183][   10/   37]    Overall Loss 0.373807    Objective Loss 0.373807                                        LR 0.000005    Time 0.035435    
2023-01-06 15:49:01,483 - Epoch: [183][   20/   37]    Overall Loss 0.369727    Objective Loss 0.369727                                        LR 0.000005    Time 0.026834    
2023-01-06 15:49:01,670 - Epoch: [183][   30/   37]    Overall Loss 0.369878    Objective Loss 0.369878                                        LR 0.000005    Time 0.024114    
2023-01-06 15:49:01,785 - Epoch: [183][   37/   37]    Overall Loss 0.368487    Objective Loss 0.368487    Top1 86.610879    LR 0.000005    Time 0.022672    
2023-01-06 15:49:01,874 - --- validate (epoch=183)-----------
2023-01-06 15:49:01,875 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:02,092 - Epoch: [183][    5/    5]    Loss 0.382843    Top1 84.255725    
2023-01-06 15:49:02,163 - ==> Top1: 84.256    Loss: 0.383

2023-01-06 15:49:02,163 - ==> Confusion:
[[351  78   0]
 [ 87 532   0]
 [  0   0   0]]

2023-01-06 15:49:02,165 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:02,165 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:02,171 - 

2023-01-06 15:49:02,171 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:02,525 - Epoch: [184][   10/   37]    Overall Loss 0.386510    Objective Loss 0.386510                                        LR 0.000005    Time 0.035384    
2023-01-06 15:49:02,714 - Epoch: [184][   20/   37]    Overall Loss 0.373769    Objective Loss 0.373769                                        LR 0.000005    Time 0.027109    
2023-01-06 15:49:02,911 - Epoch: [184][   30/   37]    Overall Loss 0.371527    Objective Loss 0.371527                                        LR 0.000005    Time 0.024610    
2023-01-06 15:49:03,020 - Epoch: [184][   37/   37]    Overall Loss 0.368274    Objective Loss 0.368274    Top1 82.845188    LR 0.000005    Time 0.022895    
2023-01-06 15:49:03,077 - --- validate (epoch=184)-----------
2023-01-06 15:49:03,077 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:03,296 - Epoch: [184][    5/    5]    Loss 0.361393    Top1 84.446565    
2023-01-06 15:49:03,358 - ==> Top1: 84.447    Loss: 0.361

2023-01-06 15:49:03,359 - ==> Confusion:
[[362  67   0]
 [ 96 523   0]
 [  0   0   0]]

2023-01-06 15:49:03,360 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:03,360 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:03,367 - 

2023-01-06 15:49:03,367 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:03,738 - Epoch: [185][   10/   37]    Overall Loss 0.374255    Objective Loss 0.374255                                        LR 0.000005    Time 0.037095    
2023-01-06 15:49:03,912 - Epoch: [185][   20/   37]    Overall Loss 0.370609    Objective Loss 0.370609                                        LR 0.000005    Time 0.027225    
2023-01-06 15:49:04,098 - Epoch: [185][   30/   37]    Overall Loss 0.367285    Objective Loss 0.367285                                        LR 0.000005    Time 0.024329    
2023-01-06 15:49:04,213 - Epoch: [185][   37/   37]    Overall Loss 0.366170    Objective Loss 0.366170    Top1 84.100418    LR 0.000005    Time 0.022828    
2023-01-06 15:49:04,286 - --- validate (epoch=185)-----------
2023-01-06 15:49:04,286 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:04,501 - Epoch: [185][    5/    5]    Loss 0.356476    Top1 84.541985    
2023-01-06 15:49:04,565 - ==> Top1: 84.542    Loss: 0.356

2023-01-06 15:49:04,566 - ==> Confusion:
[[359  70   0]
 [ 92 527   0]
 [  0   0   0]]

2023-01-06 15:49:04,567 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:04,567 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:04,573 - 

2023-01-06 15:49:04,573 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:04,939 - Epoch: [186][   10/   37]    Overall Loss 0.366784    Objective Loss 0.366784                                        LR 0.000005    Time 0.036562    
2023-01-06 15:49:05,109 - Epoch: [186][   20/   37]    Overall Loss 0.372023    Objective Loss 0.372023                                        LR 0.000005    Time 0.026742    
2023-01-06 15:49:05,281 - Epoch: [186][   30/   37]    Overall Loss 0.365177    Objective Loss 0.365177                                        LR 0.000005    Time 0.023561    
2023-01-06 15:49:05,389 - Epoch: [186][   37/   37]    Overall Loss 0.366011    Objective Loss 0.366011    Top1 85.774059    LR 0.000005    Time 0.022015    
2023-01-06 15:49:05,461 - --- validate (epoch=186)-----------
2023-01-06 15:49:05,461 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:05,675 - Epoch: [186][    5/    5]    Loss 0.378223    Top1 83.683206    
2023-01-06 15:49:05,742 - ==> Top1: 83.683    Loss: 0.378

2023-01-06 15:49:05,742 - ==> Confusion:
[[343  86   0]
 [ 85 534   0]
 [  0   0   0]]

2023-01-06 15:49:05,744 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:05,744 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:05,752 - 

2023-01-06 15:49:05,752 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:06,114 - Epoch: [187][   10/   37]    Overall Loss 0.374104    Objective Loss 0.374104                                        LR 0.000005    Time 0.036041    
2023-01-06 15:49:06,300 - Epoch: [187][   20/   37]    Overall Loss 0.366218    Objective Loss 0.366218                                        LR 0.000005    Time 0.027300    
2023-01-06 15:49:06,500 - Epoch: [187][   30/   37]    Overall Loss 0.365391    Objective Loss 0.365391                                        LR 0.000005    Time 0.024806    
2023-01-06 15:49:06,612 - Epoch: [187][   37/   37]    Overall Loss 0.365076    Objective Loss 0.365076    Top1 84.728033    LR 0.000005    Time 0.023146    
2023-01-06 15:49:06,678 - --- validate (epoch=187)-----------
2023-01-06 15:49:06,678 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:06,894 - Epoch: [187][    5/    5]    Loss 0.345236    Top1 84.446565    
2023-01-06 15:49:06,967 - ==> Top1: 84.447    Loss: 0.345

2023-01-06 15:49:06,967 - ==> Confusion:
[[351  78   0]
 [ 85 534   0]
 [  0   0   0]]

2023-01-06 15:49:06,969 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:06,969 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:06,975 - 

2023-01-06 15:49:06,975 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:07,345 - Epoch: [188][   10/   37]    Overall Loss 0.362241    Objective Loss 0.362241                                        LR 0.000005    Time 0.036944    
2023-01-06 15:49:07,531 - Epoch: [188][   20/   37]    Overall Loss 0.365274    Objective Loss 0.365274                                        LR 0.000005    Time 0.027752    
2023-01-06 15:49:07,716 - Epoch: [188][   30/   37]    Overall Loss 0.362768    Objective Loss 0.362768                                        LR 0.000005    Time 0.024660    
2023-01-06 15:49:07,831 - Epoch: [188][   37/   37]    Overall Loss 0.363577    Objective Loss 0.363577    Top1 82.217573    LR 0.000005    Time 0.023092    
2023-01-06 15:49:07,902 - --- validate (epoch=188)-----------
2023-01-06 15:49:07,902 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:08,120 - Epoch: [188][    5/    5]    Loss 0.373729    Top1 84.828244    
2023-01-06 15:49:08,190 - ==> Top1: 84.828    Loss: 0.374

2023-01-06 15:49:08,190 - ==> Confusion:
[[355  74   0]
 [ 85 534   0]
 [  0   0   0]]

2023-01-06 15:49:08,191 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:08,191 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:08,197 - 

2023-01-06 15:49:08,197 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:08,550 - Epoch: [189][   10/   37]    Overall Loss 0.362248    Objective Loss 0.362248                                        LR 0.000005    Time 0.035205    
2023-01-06 15:49:08,727 - Epoch: [189][   20/   37]    Overall Loss 0.362866    Objective Loss 0.362866                                        LR 0.000005    Time 0.026391    
2023-01-06 15:49:08,923 - Epoch: [189][   30/   37]    Overall Loss 0.363515    Objective Loss 0.363515                                        LR 0.000005    Time 0.024094    
2023-01-06 15:49:09,038 - Epoch: [189][   37/   37]    Overall Loss 0.364268    Objective Loss 0.364268    Top1 85.146444    LR 0.000005    Time 0.022629    
2023-01-06 15:49:09,109 - --- validate (epoch=189)-----------
2023-01-06 15:49:09,109 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:09,333 - Epoch: [189][    5/    5]    Loss 0.376352    Top1 83.969466    
2023-01-06 15:49:09,419 - ==> Top1: 83.969    Loss: 0.376

2023-01-06 15:49:09,419 - ==> Confusion:
[[349  80   0]
 [ 88 531   0]
 [  0   0   0]]

2023-01-06 15:49:09,421 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:09,421 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:09,427 - 

2023-01-06 15:49:09,427 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:09,768 - Epoch: [190][   10/   37]    Overall Loss 0.364660    Objective Loss 0.364660                                        LR 0.000003    Time 0.034032    
2023-01-06 15:49:09,934 - Epoch: [190][   20/   37]    Overall Loss 0.363732    Objective Loss 0.363732                                        LR 0.000003    Time 0.025278    
2023-01-06 15:49:10,104 - Epoch: [190][   30/   37]    Overall Loss 0.365072    Objective Loss 0.365072                                        LR 0.000003    Time 0.022536    
2023-01-06 15:49:10,215 - Epoch: [190][   37/   37]    Overall Loss 0.364444    Objective Loss 0.364444    Top1 87.866109    LR 0.000003    Time 0.021267    
2023-01-06 15:49:10,291 - --- validate (epoch=190)-----------
2023-01-06 15:49:10,291 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:10,507 - Epoch: [190][    5/    5]    Loss 0.371385    Top1 83.874046    
2023-01-06 15:49:10,572 - ==> Top1: 83.874    Loss: 0.371

2023-01-06 15:49:10,573 - ==> Confusion:
[[355  74   0]
 [ 95 524   0]
 [  0   0   0]]

2023-01-06 15:49:10,574 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:10,574 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:10,580 - 

2023-01-06 15:49:10,580 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:11,081 - Epoch: [191][   10/   37]    Overall Loss 0.361741    Objective Loss 0.361741                                        LR 0.000003    Time 0.050032    
2023-01-06 15:49:11,270 - Epoch: [191][   20/   37]    Overall Loss 0.362520    Objective Loss 0.362520                                        LR 0.000003    Time 0.034456    
2023-01-06 15:49:11,447 - Epoch: [191][   30/   37]    Overall Loss 0.360479    Objective Loss 0.360479                                        LR 0.000003    Time 0.028847    
2023-01-06 15:49:11,560 - Epoch: [191][   37/   37]    Overall Loss 0.363455    Objective Loss 0.363455    Top1 80.543933    LR 0.000003    Time 0.026444    
2023-01-06 15:49:11,636 - --- validate (epoch=191)-----------
2023-01-06 15:49:11,637 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:11,865 - Epoch: [191][    5/    5]    Loss 0.361625    Top1 83.969466    
2023-01-06 15:49:11,929 - ==> Top1: 83.969    Loss: 0.362

2023-01-06 15:49:11,930 - ==> Confusion:
[[352  77   0]
 [ 91 528   0]
 [  0   0   0]]

2023-01-06 15:49:11,931 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:11,931 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:11,937 - 

2023-01-06 15:49:11,937 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:12,301 - Epoch: [192][   10/   37]    Overall Loss 0.363616    Objective Loss 0.363616                                        LR 0.000003    Time 0.036346    
2023-01-06 15:49:12,468 - Epoch: [192][   20/   37]    Overall Loss 0.361145    Objective Loss 0.361145                                        LR 0.000003    Time 0.026452    
2023-01-06 15:49:12,636 - Epoch: [192][   30/   37]    Overall Loss 0.364171    Objective Loss 0.364171                                        LR 0.000003    Time 0.023229    
2023-01-06 15:49:12,741 - Epoch: [192][   37/   37]    Overall Loss 0.363933    Objective Loss 0.363933    Top1 84.518828    LR 0.000003    Time 0.021681    
2023-01-06 15:49:12,818 - --- validate (epoch=192)-----------
2023-01-06 15:49:12,818 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:13,043 - Epoch: [192][    5/    5]    Loss 0.354737    Top1 83.396947    
2023-01-06 15:49:13,112 - ==> Top1: 83.397    Loss: 0.355

2023-01-06 15:49:13,112 - ==> Confusion:
[[346  83   0]
 [ 91 528   0]
 [  0   0   0]]

2023-01-06 15:49:13,114 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:13,114 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:13,120 - 

2023-01-06 15:49:13,120 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:13,487 - Epoch: [193][   10/   37]    Overall Loss 0.368210    Objective Loss 0.368210                                        LR 0.000003    Time 0.036671    
2023-01-06 15:49:13,656 - Epoch: [193][   20/   37]    Overall Loss 0.367272    Objective Loss 0.367272                                        LR 0.000003    Time 0.026740    
2023-01-06 15:49:13,844 - Epoch: [193][   30/   37]    Overall Loss 0.366099    Objective Loss 0.366099                                        LR 0.000003    Time 0.024079    
2023-01-06 15:49:13,951 - Epoch: [193][   37/   37]    Overall Loss 0.363399    Objective Loss 0.363399    Top1 85.774059    LR 0.000003    Time 0.022426    
2023-01-06 15:49:14,022 - --- validate (epoch=193)-----------
2023-01-06 15:49:14,022 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:14,240 - Epoch: [193][    5/    5]    Loss 0.370562    Top1 84.446565    
2023-01-06 15:49:14,305 - ==> Top1: 84.447    Loss: 0.371

2023-01-06 15:49:14,305 - ==> Confusion:
[[352  77   0]
 [ 86 533   0]
 [  0   0   0]]

2023-01-06 15:49:14,307 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:14,307 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:14,313 - 

2023-01-06 15:49:14,313 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:14,671 - Epoch: [194][   10/   37]    Overall Loss 0.355937    Objective Loss 0.355937                                        LR 0.000003    Time 0.035730    
2023-01-06 15:49:14,861 - Epoch: [194][   20/   37]    Overall Loss 0.357649    Objective Loss 0.357649                                        LR 0.000003    Time 0.027349    
2023-01-06 15:49:15,057 - Epoch: [194][   30/   37]    Overall Loss 0.357995    Objective Loss 0.357995                                        LR 0.000003    Time 0.024750    
2023-01-06 15:49:15,171 - Epoch: [194][   37/   37]    Overall Loss 0.361570    Objective Loss 0.361570    Top1 81.589958    LR 0.000003    Time 0.023159    
2023-01-06 15:49:15,242 - --- validate (epoch=194)-----------
2023-01-06 15:49:15,242 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:15,461 - Epoch: [194][    5/    5]    Loss 0.402529    Top1 84.541985    
2023-01-06 15:49:15,527 - ==> Top1: 84.542    Loss: 0.403

2023-01-06 15:49:15,528 - ==> Confusion:
[[359  70   0]
 [ 92 527   0]
 [  0   0   0]]

2023-01-06 15:49:15,529 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:15,529 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:15,536 - 

2023-01-06 15:49:15,536 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:15,901 - Epoch: [195][   10/   37]    Overall Loss 0.354840    Objective Loss 0.354840                                        LR 0.000003    Time 0.036423    
2023-01-06 15:49:16,075 - Epoch: [195][   20/   37]    Overall Loss 0.357594    Objective Loss 0.357594                                        LR 0.000003    Time 0.026893    
2023-01-06 15:49:16,253 - Epoch: [195][   30/   37]    Overall Loss 0.362634    Objective Loss 0.362634                                        LR 0.000003    Time 0.023865    
2023-01-06 15:49:16,359 - Epoch: [195][   37/   37]    Overall Loss 0.361751    Objective Loss 0.361751    Top1 82.008368    LR 0.000003    Time 0.022205    
2023-01-06 15:49:16,433 - --- validate (epoch=195)-----------
2023-01-06 15:49:16,433 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:16,657 - Epoch: [195][    5/    5]    Loss 0.347485    Top1 84.351145    
2023-01-06 15:49:16,721 - ==> Top1: 84.351    Loss: 0.347

2023-01-06 15:49:16,722 - ==> Confusion:
[[353  76   0]
 [ 88 531   0]
 [  0   0   0]]

2023-01-06 15:49:16,723 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:16,723 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:16,729 - 

2023-01-06 15:49:16,730 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:17,101 - Epoch: [196][   10/   37]    Overall Loss 0.357744    Objective Loss 0.357744                                        LR 0.000003    Time 0.037077    
2023-01-06 15:49:17,290 - Epoch: [196][   20/   37]    Overall Loss 0.358045    Objective Loss 0.358045                                        LR 0.000003    Time 0.027961    
2023-01-06 15:49:17,482 - Epoch: [196][   30/   37]    Overall Loss 0.358876    Objective Loss 0.358876                                        LR 0.000003    Time 0.024996    
2023-01-06 15:49:17,596 - Epoch: [196][   37/   37]    Overall Loss 0.360698    Objective Loss 0.360698    Top1 83.682008    LR 0.000003    Time 0.023350    
2023-01-06 15:49:17,671 - --- validate (epoch=196)-----------
2023-01-06 15:49:17,671 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:17,892 - Epoch: [196][    5/    5]    Loss 0.354786    Top1 84.732824    
2023-01-06 15:49:17,959 - ==> Top1: 84.733    Loss: 0.355

2023-01-06 15:49:17,959 - ==> Confusion:
[[358  71   0]
 [ 89 530   0]
 [  0   0   0]]

2023-01-06 15:49:17,961 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:17,961 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:17,970 - 

2023-01-06 15:49:17,970 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:18,337 - Epoch: [197][   10/   37]    Overall Loss 0.364655    Objective Loss 0.364655                                        LR 0.000003    Time 0.036624    
2023-01-06 15:49:18,513 - Epoch: [197][   20/   37]    Overall Loss 0.366895    Objective Loss 0.366895                                        LR 0.000003    Time 0.027038    
2023-01-06 15:49:18,713 - Epoch: [197][   30/   37]    Overall Loss 0.359561    Objective Loss 0.359561                                        LR 0.000003    Time 0.024671    
2023-01-06 15:49:18,827 - Epoch: [197][   37/   37]    Overall Loss 0.360517    Objective Loss 0.360517    Top1 82.845188    LR 0.000003    Time 0.023082    
2023-01-06 15:49:18,898 - --- validate (epoch=197)-----------
2023-01-06 15:49:18,898 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:19,113 - Epoch: [197][    5/    5]    Loss 0.360040    Top1 84.541985    
2023-01-06 15:49:19,182 - ==> Top1: 84.542    Loss: 0.360

2023-01-06 15:49:19,182 - ==> Confusion:
[[358  71   0]
 [ 91 528   0]
 [  0   0   0]]

2023-01-06 15:49:19,183 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:19,183 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:19,190 - 

2023-01-06 15:49:19,190 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:19,572 - Epoch: [198][   10/   37]    Overall Loss 0.357589    Objective Loss 0.357589                                        LR 0.000003    Time 0.038126    
2023-01-06 15:49:19,761 - Epoch: [198][   20/   37]    Overall Loss 0.357638    Objective Loss 0.357638                                        LR 0.000003    Time 0.028496    
2023-01-06 15:49:19,953 - Epoch: [198][   30/   37]    Overall Loss 0.357799    Objective Loss 0.357799                                        LR 0.000003    Time 0.025395    
2023-01-06 15:49:20,062 - Epoch: [198][   37/   37]    Overall Loss 0.359141    Objective Loss 0.359141    Top1 84.309623    LR 0.000003    Time 0.023529    
2023-01-06 15:49:20,142 - --- validate (epoch=198)-----------
2023-01-06 15:49:20,142 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:20,376 - Epoch: [198][    5/    5]    Loss 0.335172    Top1 83.969466    
2023-01-06 15:49:20,435 - ==> Top1: 83.969    Loss: 0.335

2023-01-06 15:49:20,435 - ==> Confusion:
[[353  76   0]
 [ 92 527   0]
 [  0   0   0]]

2023-01-06 15:49:20,437 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:20,437 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:20,443 - 

2023-01-06 15:49:20,443 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 15:49:20,821 - Epoch: [199][   10/   37]    Overall Loss 0.367209    Objective Loss 0.367209                                        LR 0.000003    Time 0.037715    
2023-01-06 15:49:21,005 - Epoch: [199][   20/   37]    Overall Loss 0.358489    Objective Loss 0.358489                                        LR 0.000003    Time 0.028083    
2023-01-06 15:49:21,196 - Epoch: [199][   30/   37]    Overall Loss 0.359786    Objective Loss 0.359786                                        LR 0.000003    Time 0.025068    
2023-01-06 15:49:21,312 - Epoch: [199][   37/   37]    Overall Loss 0.359618    Objective Loss 0.359618    Top1 83.682008    LR 0.000003    Time 0.023442    
2023-01-06 15:49:21,374 - --- validate (epoch=199)-----------
2023-01-06 15:49:21,375 - 1048 samples (256 per mini-batch)
2023-01-06 15:49:21,589 - Epoch: [199][    5/    5]    Loss 0.349687    Top1 84.351145    
2023-01-06 15:49:21,654 - ==> Top1: 84.351    Loss: 0.350

2023-01-06 15:49:21,654 - ==> Confusion:
[[353  76   0]
 [ 88 531   0]
 [  0   0   0]]

2023-01-06 15:49:21,655 - ==> Best [Top1: 85.496   Sparsity:0.00   Params: 155168 on epoch: 146]
2023-01-06 15:49:21,656 - Saving checkpoint to: logs/2023.01.06-154508/qat_checkpoint.pth.tar
2023-01-06 15:49:21,662 - --- test ---------------------
2023-01-06 15:49:21,662 - 1317 samples (256 per mini-batch)
2023-01-06 15:49:21,891 - Test: [    6/    6]    Loss 0.400480    Top1 81.700835    
2023-01-06 15:49:21,957 - ==> Top1: 81.701    Loss: 0.400

2023-01-06 15:49:21,957 - ==> Confusion:
[[446 115   0]
 [126 630   0]
 [  0   0   0]]

2023-01-06 15:49:21,968 - 
2023-01-06 15:49:21,969 - Log file for this run: /home/ubuntumaschin/KeyWordSpotting_on_MAX78000/ai8x-training/logs/2023.01.06-154508/2023.01.06-154508.log
