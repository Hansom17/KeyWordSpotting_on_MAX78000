2023-01-06 12:57:53,935 - Log file for this run: /home/ubuntumaschin/KeyWordSpotting_on_MAX78000/ai8x-training/logs/2023.01.06-125753/2023.01.06-125753.log
2023-01-06 12:57:55,923 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2023-01-06 12:57:55,923 - Optimizer Args: {'lr': 6e-05, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2023-01-06 12:58:02,982 - Dataset sizes:
	training=9438
	validation=1048
	test=1317
2023-01-06 12:58:02,982 - Reading compression schedule from: policies/schedule_kws20_v2.yaml
2023-01-06 12:58:02,985 - 

2023-01-06 12:58:02,985 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:03,583 - Epoch: [0][   10/   37]    Overall Loss 1.098141    Objective Loss 1.098141                                        LR 0.000060    Time 0.059636    
2023-01-06 12:58:03,794 - Epoch: [0][   20/   37]    Overall Loss 1.096960    Objective Loss 1.096960                                        LR 0.000060    Time 0.040362    
2023-01-06 12:58:04,047 - Epoch: [0][   30/   37]    Overall Loss 1.093257    Objective Loss 1.093257                                        LR 0.000060    Time 0.035335    
2023-01-06 12:58:04,195 - Epoch: [0][   37/   37]    Overall Loss 1.086492    Objective Loss 1.086492    Top1 56.276151    LR 0.000060    Time 0.032646    
2023-01-06 12:58:04,263 - --- validate (epoch=0)-----------
2023-01-06 12:58:04,263 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:04,452 - Epoch: [0][    5/    5]    Loss 1.028269    Top1 59.064885    
2023-01-06 12:58:04,516 - ==> Top1: 59.065    Loss: 1.028

2023-01-06 12:58:04,520 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:04,524 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 0]
2023-01-06 12:58:04,524 - Saving checkpoint to: logs/2023.01.06-125753/checkpoint.pth.tar
2023-01-06 12:58:04,536 - 

2023-01-06 12:58:04,537 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:04,878 - Epoch: [1][   10/   37]    Overall Loss 0.968611    Objective Loss 0.968611                                        LR 0.000060    Time 0.034024    
2023-01-06 12:58:05,098 - Epoch: [1][   20/   37]    Overall Loss 0.883168    Objective Loss 0.883168                                        LR 0.000060    Time 0.027991    
2023-01-06 12:58:05,326 - Epoch: [1][   30/   37]    Overall Loss 0.838533    Objective Loss 0.838533                                        LR 0.000060    Time 0.026260    
2023-01-06 12:58:05,467 - Epoch: [1][   37/   37]    Overall Loss 0.818598    Objective Loss 0.818598    Top1 56.903766    LR 0.000060    Time 0.025087    
2023-01-06 12:58:05,541 - --- validate (epoch=1)-----------
2023-01-06 12:58:05,541 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:05,719 - Epoch: [1][    5/    5]    Loss 0.719176    Top1 59.064885    
2023-01-06 12:58:05,778 - ==> Top1: 59.065    Loss: 0.719

2023-01-06 12:58:05,778 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:05,779 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 1]
2023-01-06 12:58:05,779 - Saving checkpoint to: logs/2023.01.06-125753/checkpoint.pth.tar
2023-01-06 12:58:05,803 - 

2023-01-06 12:58:05,803 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:06,125 - Epoch: [2][   10/   37]    Overall Loss 0.727472    Objective Loss 0.727472                                        LR 0.000060    Time 0.032066    
2023-01-06 12:58:06,301 - Epoch: [2][   20/   37]    Overall Loss 0.724053    Objective Loss 0.724053                                        LR 0.000060    Time 0.024750    
2023-01-06 12:58:06,530 - Epoch: [2][   30/   37]    Overall Loss 0.720358    Objective Loss 0.720358                                        LR 0.000060    Time 0.024084    
2023-01-06 12:58:06,671 - Epoch: [2][   37/   37]    Overall Loss 0.718865    Objective Loss 0.718865    Top1 58.368201    LR 0.000060    Time 0.023324    
2023-01-06 12:58:06,748 - --- validate (epoch=2)-----------
2023-01-06 12:58:06,748 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:06,924 - Epoch: [2][    5/    5]    Loss 0.714172    Top1 59.064885    
2023-01-06 12:58:06,981 - ==> Top1: 59.065    Loss: 0.714

2023-01-06 12:58:06,981 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:06,982 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 2]
2023-01-06 12:58:06,982 - Saving checkpoint to: logs/2023.01.06-125753/checkpoint.pth.tar
2023-01-06 12:58:07,003 - 

2023-01-06 12:58:07,003 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:07,322 - Epoch: [3][   10/   37]    Overall Loss 0.714179    Objective Loss 0.714179                                        LR 0.000060    Time 0.031821    
2023-01-06 12:58:07,517 - Epoch: [3][   20/   37]    Overall Loss 0.711646    Objective Loss 0.711646                                        LR 0.000060    Time 0.025610    
2023-01-06 12:58:07,754 - Epoch: [3][   30/   37]    Overall Loss 0.711819    Objective Loss 0.711819                                        LR 0.000060    Time 0.024948    
2023-01-06 12:58:07,894 - Epoch: [3][   37/   37]    Overall Loss 0.709644    Objective Loss 0.709644    Top1 58.786611    LR 0.000060    Time 0.024019    
2023-01-06 12:58:07,967 - --- validate (epoch=3)-----------
2023-01-06 12:58:07,967 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:08,159 - Epoch: [3][    5/    5]    Loss 0.695764    Top1 59.064885    
2023-01-06 12:58:08,225 - ==> Top1: 59.065    Loss: 0.696

2023-01-06 12:58:08,225 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:08,227 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 3]
2023-01-06 12:58:08,227 - Saving checkpoint to: logs/2023.01.06-125753/checkpoint.pth.tar
2023-01-06 12:58:08,251 - 

2023-01-06 12:58:08,251 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:08,588 - Epoch: [4][   10/   37]    Overall Loss 0.708368    Objective Loss 0.708368                                        LR 0.000060    Time 0.033565    
2023-01-06 12:58:08,790 - Epoch: [4][   20/   37]    Overall Loss 0.706902    Objective Loss 0.706902                                        LR 0.000060    Time 0.026877    
2023-01-06 12:58:09,014 - Epoch: [4][   30/   37]    Overall Loss 0.705176    Objective Loss 0.705176                                        LR 0.000060    Time 0.025315    
2023-01-06 12:58:09,143 - Epoch: [4][   37/   37]    Overall Loss 0.704607    Objective Loss 0.704607    Top1 55.439331    LR 0.000060    Time 0.023996    
2023-01-06 12:58:09,213 - --- validate (epoch=4)-----------
2023-01-06 12:58:09,213 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:09,395 - Epoch: [4][    5/    5]    Loss 0.687093    Top1 59.064885    
2023-01-06 12:58:09,452 - ==> Top1: 59.065    Loss: 0.687

2023-01-06 12:58:09,452 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:09,454 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 4]
2023-01-06 12:58:09,454 - Saving checkpoint to: logs/2023.01.06-125753/checkpoint.pth.tar
2023-01-06 12:58:09,474 - 

2023-01-06 12:58:09,475 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:09,831 - Epoch: [5][   10/   37]    Overall Loss 0.707732    Objective Loss 0.707732                                        LR 0.000060    Time 0.035494    
2023-01-06 12:58:10,054 - Epoch: [5][   20/   37]    Overall Loss 0.705319    Objective Loss 0.705319                                        LR 0.000060    Time 0.028827    
2023-01-06 12:58:10,279 - Epoch: [5][   30/   37]    Overall Loss 0.702863    Objective Loss 0.702863                                        LR 0.000060    Time 0.026705    
2023-01-06 12:58:10,422 - Epoch: [5][   37/   37]    Overall Loss 0.701157    Objective Loss 0.701157    Top1 58.158996    LR 0.000060    Time 0.025522    
2023-01-06 12:58:10,491 - --- validate (epoch=5)-----------
2023-01-06 12:58:10,491 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:10,692 - Epoch: [5][    5/    5]    Loss 0.683069    Top1 59.064885    
2023-01-06 12:58:10,754 - ==> Top1: 59.065    Loss: 0.683

2023-01-06 12:58:10,754 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:10,755 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 5]
2023-01-06 12:58:10,755 - Saving checkpoint to: logs/2023.01.06-125753/checkpoint.pth.tar
2023-01-06 12:58:10,786 - 

2023-01-06 12:58:10,786 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:11,140 - Epoch: [6][   10/   37]    Overall Loss 0.700131    Objective Loss 0.700131                                        LR 0.000060    Time 0.035322    
2023-01-06 12:58:11,370 - Epoch: [6][   20/   37]    Overall Loss 0.697331    Objective Loss 0.697331                                        LR 0.000060    Time 0.029109    
2023-01-06 12:58:11,573 - Epoch: [6][   30/   37]    Overall Loss 0.698165    Objective Loss 0.698165                                        LR 0.000060    Time 0.026154    
2023-01-06 12:58:11,689 - Epoch: [6][   37/   37]    Overall Loss 0.698776    Objective Loss 0.698776    Top1 52.719665    LR 0.000060    Time 0.024358    
2023-01-06 12:58:11,757 - --- validate (epoch=6)-----------
2023-01-06 12:58:11,757 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:11,939 - Epoch: [6][    5/    5]    Loss 0.692008    Top1 59.064885    
2023-01-06 12:58:11,995 - ==> Top1: 59.065    Loss: 0.692

2023-01-06 12:58:11,995 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:11,997 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 6]
2023-01-06 12:58:11,997 - Saving checkpoint to: logs/2023.01.06-125753/checkpoint.pth.tar
2023-01-06 12:58:12,028 - 

2023-01-06 12:58:12,028 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:12,339 - Epoch: [7][   10/   37]    Overall Loss 0.700052    Objective Loss 0.700052                                        LR 0.000060    Time 0.030989    
2023-01-06 12:58:12,524 - Epoch: [7][   20/   37]    Overall Loss 0.698617    Objective Loss 0.698617                                        LR 0.000060    Time 0.024744    
2023-01-06 12:58:12,741 - Epoch: [7][   30/   37]    Overall Loss 0.697802    Objective Loss 0.697802                                        LR 0.000060    Time 0.023694    
2023-01-06 12:58:12,883 - Epoch: [7][   37/   37]    Overall Loss 0.696643    Objective Loss 0.696643    Top1 59.623431    LR 0.000060    Time 0.023057    
2023-01-06 12:58:12,949 - --- validate (epoch=7)-----------
2023-01-06 12:58:12,949 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:13,131 - Epoch: [7][    5/    5]    Loss 0.687499    Top1 59.064885    
2023-01-06 12:58:13,190 - ==> Top1: 59.065    Loss: 0.687

2023-01-06 12:58:13,190 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:13,191 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 7]
2023-01-06 12:58:13,191 - Saving checkpoint to: logs/2023.01.06-125753/checkpoint.pth.tar
2023-01-06 12:58:13,222 - 

2023-01-06 12:58:13,222 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:13,741 - Epoch: [8][   10/   37]    Overall Loss 0.697371    Objective Loss 0.697371                                        LR 0.000060    Time 0.051784    
2023-01-06 12:58:13,974 - Epoch: [8][   20/   37]    Overall Loss 0.695623    Objective Loss 0.695623                                        LR 0.000060    Time 0.037496    
2023-01-06 12:58:14,206 - Epoch: [8][   30/   37]    Overall Loss 0.695394    Objective Loss 0.695394                                        LR 0.000060    Time 0.032713    
2023-01-06 12:58:14,348 - Epoch: [8][   37/   37]    Overall Loss 0.695039    Objective Loss 0.695039    Top1 56.066946    LR 0.000060    Time 0.030345    
2023-01-06 12:58:14,413 - --- validate (epoch=8)-----------
2023-01-06 12:58:14,413 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:14,604 - Epoch: [8][    5/    5]    Loss 0.699711    Top1 59.064885    
2023-01-06 12:58:14,657 - ==> Top1: 59.065    Loss: 0.700

2023-01-06 12:58:14,658 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:14,659 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 8]
2023-01-06 12:58:14,659 - Saving checkpoint to: logs/2023.01.06-125753/checkpoint.pth.tar
2023-01-06 12:58:14,690 - 

2023-01-06 12:58:14,691 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:15,020 - Epoch: [9][   10/   37]    Overall Loss 0.692803    Objective Loss 0.692803                                        LR 0.000060    Time 0.032807    
2023-01-06 12:58:15,228 - Epoch: [9][   20/   37]    Overall Loss 0.695260    Objective Loss 0.695260                                        LR 0.000060    Time 0.026802    
2023-01-06 12:58:15,458 - Epoch: [9][   30/   37]    Overall Loss 0.694790    Objective Loss 0.694790                                        LR 0.000060    Time 0.025505    
2023-01-06 12:58:15,599 - Epoch: [9][   37/   37]    Overall Loss 0.693955    Objective Loss 0.693955    Top1 55.230126    LR 0.000060    Time 0.024502    
2023-01-06 12:58:15,669 - --- validate (epoch=9)-----------
2023-01-06 12:58:15,669 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:15,852 - Epoch: [9][    5/    5]    Loss 0.694260    Top1 59.064885    
2023-01-06 12:58:15,910 - ==> Top1: 59.065    Loss: 0.694

2023-01-06 12:58:15,910 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:15,912 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 9]
2023-01-06 12:58:15,912 - Saving checkpoint to: logs/2023.01.06-125753/checkpoint.pth.tar
2023-01-06 12:58:15,952 - 

2023-01-06 12:58:15,952 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:16,370 - Epoch: [10][   10/   37]    Overall Loss 0.879605    Objective Loss 0.879605                                        LR 0.000060    Time 0.041664    
2023-01-06 12:58:16,623 - Epoch: [10][   20/   37]    Overall Loss 0.801118    Objective Loss 0.801118                                        LR 0.000060    Time 0.033475    
2023-01-06 12:58:16,877 - Epoch: [10][   30/   37]    Overall Loss 0.763138    Objective Loss 0.763138                                        LR 0.000060    Time 0.030762    
2023-01-06 12:58:17,027 - Epoch: [10][   37/   37]    Overall Loss 0.747991    Objective Loss 0.747991    Top1 60.251046    LR 0.000060    Time 0.029011    
2023-01-06 12:58:17,097 - --- validate (epoch=10)-----------
2023-01-06 12:58:17,098 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:17,300 - Epoch: [10][    5/    5]    Loss 0.680576    Top1 59.064885    
2023-01-06 12:58:17,368 - ==> Top1: 59.065    Loss: 0.681

2023-01-06 12:58:17,368 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:17,370 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 10]
2023-01-06 12:58:17,370 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:17,382 - 

2023-01-06 12:58:17,382 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:17,791 - Epoch: [11][   10/   37]    Overall Loss 0.686967    Objective Loss 0.686967                                        LR 0.000060    Time 0.040816    
2023-01-06 12:58:18,034 - Epoch: [11][   20/   37]    Overall Loss 0.683248    Objective Loss 0.683248                                        LR 0.000060    Time 0.032541    
2023-01-06 12:58:18,280 - Epoch: [11][   30/   37]    Overall Loss 0.684322    Objective Loss 0.684322                                        LR 0.000060    Time 0.029891    
2023-01-06 12:58:18,433 - Epoch: [11][   37/   37]    Overall Loss 0.683733    Objective Loss 0.683733    Top1 58.158996    LR 0.000060    Time 0.028358    
2023-01-06 12:58:18,502 - --- validate (epoch=11)-----------
2023-01-06 12:58:18,503 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:18,714 - Epoch: [11][    5/    5]    Loss 0.678111    Top1 59.064885    
2023-01-06 12:58:18,793 - ==> Top1: 59.065    Loss: 0.678

2023-01-06 12:58:18,793 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:18,794 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 11]
2023-01-06 12:58:18,794 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:18,819 - 

2023-01-06 12:58:18,819 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:19,216 - Epoch: [12][   10/   37]    Overall Loss 0.684531    Objective Loss 0.684531                                        LR 0.000060    Time 0.039573    
2023-01-06 12:58:19,459 - Epoch: [12][   20/   37]    Overall Loss 0.683608    Objective Loss 0.683608                                        LR 0.000060    Time 0.031938    
2023-01-06 12:58:19,707 - Epoch: [12][   30/   37]    Overall Loss 0.684174    Objective Loss 0.684174                                        LR 0.000060    Time 0.029543    
2023-01-06 12:58:19,860 - Epoch: [12][   37/   37]    Overall Loss 0.683874    Objective Loss 0.683874    Top1 56.903766    LR 0.000060    Time 0.028070    
2023-01-06 12:58:19,919 - --- validate (epoch=12)-----------
2023-01-06 12:58:19,919 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:20,127 - Epoch: [12][    5/    5]    Loss 0.682143    Top1 59.064885    
2023-01-06 12:58:20,194 - ==> Top1: 59.065    Loss: 0.682

2023-01-06 12:58:20,194 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:20,196 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 12]
2023-01-06 12:58:20,196 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:20,227 - 

2023-01-06 12:58:20,227 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:20,651 - Epoch: [13][   10/   37]    Overall Loss 0.684291    Objective Loss 0.684291                                        LR 0.000060    Time 0.042271    
2023-01-06 12:58:20,900 - Epoch: [13][   20/   37]    Overall Loss 0.683027    Objective Loss 0.683027                                        LR 0.000060    Time 0.033571    
2023-01-06 12:58:21,149 - Epoch: [13][   30/   37]    Overall Loss 0.682647    Objective Loss 0.682647                                        LR 0.000060    Time 0.030654    
2023-01-06 12:58:21,301 - Epoch: [13][   37/   37]    Overall Loss 0.683576    Objective Loss 0.683576    Top1 57.531381    LR 0.000060    Time 0.028958    
2023-01-06 12:58:21,371 - --- validate (epoch=13)-----------
2023-01-06 12:58:21,371 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:21,577 - Epoch: [13][    5/    5]    Loss 0.673098    Top1 59.064885    
2023-01-06 12:58:21,629 - ==> Top1: 59.065    Loss: 0.673

2023-01-06 12:58:21,629 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:21,630 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 13]
2023-01-06 12:58:21,630 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:21,658 - 

2023-01-06 12:58:21,658 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:22,066 - Epoch: [14][   10/   37]    Overall Loss 0.683586    Objective Loss 0.683586                                        LR 0.000060    Time 0.040641    
2023-01-06 12:58:22,307 - Epoch: [14][   20/   37]    Overall Loss 0.685736    Objective Loss 0.685736                                        LR 0.000060    Time 0.032390    
2023-01-06 12:58:22,549 - Epoch: [14][   30/   37]    Overall Loss 0.684546    Objective Loss 0.684546                                        LR 0.000060    Time 0.029619    
2023-01-06 12:58:22,699 - Epoch: [14][   37/   37]    Overall Loss 0.683598    Objective Loss 0.683598    Top1 58.786611    LR 0.000060    Time 0.028076    
2023-01-06 12:58:22,781 - --- validate (epoch=14)-----------
2023-01-06 12:58:22,781 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:22,997 - Epoch: [14][    5/    5]    Loss 0.671444    Top1 59.064885    
2023-01-06 12:58:23,062 - ==> Top1: 59.065    Loss: 0.671

2023-01-06 12:58:23,063 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:23,064 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 14]
2023-01-06 12:58:23,064 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:23,095 - 

2023-01-06 12:58:23,095 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:23,503 - Epoch: [15][   10/   37]    Overall Loss 0.677470    Objective Loss 0.677470                                        LR 0.000060    Time 0.040639    
2023-01-06 12:58:23,762 - Epoch: [15][   20/   37]    Overall Loss 0.683306    Objective Loss 0.683306                                        LR 0.000060    Time 0.033285    
2023-01-06 12:58:24,017 - Epoch: [15][   30/   37]    Overall Loss 0.684377    Objective Loss 0.684377                                        LR 0.000060    Time 0.030679    
2023-01-06 12:58:24,168 - Epoch: [15][   37/   37]    Overall Loss 0.683725    Objective Loss 0.683725    Top1 56.485356    LR 0.000060    Time 0.028940    
2023-01-06 12:58:24,233 - --- validate (epoch=15)-----------
2023-01-06 12:58:24,233 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:24,441 - Epoch: [15][    5/    5]    Loss 0.679862    Top1 59.064885    
2023-01-06 12:58:24,503 - ==> Top1: 59.065    Loss: 0.680

2023-01-06 12:58:24,503 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:24,505 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 15]
2023-01-06 12:58:24,505 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:24,533 - 

2023-01-06 12:58:24,534 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:24,934 - Epoch: [16][   10/   37]    Overall Loss 0.684353    Objective Loss 0.684353                                        LR 0.000060    Time 0.040005    
2023-01-06 12:58:25,182 - Epoch: [16][   20/   37]    Overall Loss 0.682798    Objective Loss 0.682798                                        LR 0.000060    Time 0.032383    
2023-01-06 12:58:25,431 - Epoch: [16][   30/   37]    Overall Loss 0.682869    Objective Loss 0.682869                                        LR 0.000060    Time 0.029807    
2023-01-06 12:58:25,583 - Epoch: [16][   37/   37]    Overall Loss 0.683530    Objective Loss 0.683530    Top1 54.393305    LR 0.000060    Time 0.028269    
2023-01-06 12:58:25,652 - --- validate (epoch=16)-----------
2023-01-06 12:58:25,652 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:25,862 - Epoch: [16][    5/    5]    Loss 0.674529    Top1 59.064885    
2023-01-06 12:58:25,922 - ==> Top1: 59.065    Loss: 0.675

2023-01-06 12:58:25,923 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:25,924 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 16]
2023-01-06 12:58:25,924 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:25,948 - 

2023-01-06 12:58:25,948 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:26,342 - Epoch: [17][   10/   37]    Overall Loss 0.684196    Objective Loss 0.684196                                        LR 0.000060    Time 0.039345    
2023-01-06 12:58:26,590 - Epoch: [17][   20/   37]    Overall Loss 0.682839    Objective Loss 0.682839                                        LR 0.000060    Time 0.032054    
2023-01-06 12:58:26,838 - Epoch: [17][   30/   37]    Overall Loss 0.683869    Objective Loss 0.683869                                        LR 0.000060    Time 0.029602    
2023-01-06 12:58:26,990 - Epoch: [17][   37/   37]    Overall Loss 0.683450    Objective Loss 0.683450    Top1 57.740586    LR 0.000060    Time 0.028105    
2023-01-06 12:58:27,058 - --- validate (epoch=17)-----------
2023-01-06 12:58:27,058 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:27,261 - Epoch: [17][    5/    5]    Loss 0.675090    Top1 59.064885    
2023-01-06 12:58:27,323 - ==> Top1: 59.065    Loss: 0.675

2023-01-06 12:58:27,323 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:27,325 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 17]
2023-01-06 12:58:27,325 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:27,348 - 

2023-01-06 12:58:27,348 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:27,752 - Epoch: [18][   10/   37]    Overall Loss 0.680293    Objective Loss 0.680293                                        LR 0.000060    Time 0.040305    
2023-01-06 12:58:27,993 - Epoch: [18][   20/   37]    Overall Loss 0.683659    Objective Loss 0.683659                                        LR 0.000060    Time 0.032199    
2023-01-06 12:58:28,251 - Epoch: [18][   30/   37]    Overall Loss 0.683347    Objective Loss 0.683347                                        LR 0.000060    Time 0.030053    
2023-01-06 12:58:28,403 - Epoch: [18][   37/   37]    Overall Loss 0.684063    Objective Loss 0.684063    Top1 57.322176    LR 0.000060    Time 0.028446    
2023-01-06 12:58:28,463 - --- validate (epoch=18)-----------
2023-01-06 12:58:28,463 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:28,674 - Epoch: [18][    5/    5]    Loss 0.666687    Top1 59.064885    
2023-01-06 12:58:28,731 - ==> Top1: 59.065    Loss: 0.667

2023-01-06 12:58:28,731 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:28,733 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 18]
2023-01-06 12:58:28,733 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:28,761 - 

2023-01-06 12:58:28,761 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:29,151 - Epoch: [19][   10/   37]    Overall Loss 0.684421    Objective Loss 0.684421                                        LR 0.000060    Time 0.038904    
2023-01-06 12:58:29,372 - Epoch: [19][   20/   37]    Overall Loss 0.682265    Objective Loss 0.682265                                        LR 0.000060    Time 0.030479    
2023-01-06 12:58:29,586 - Epoch: [19][   30/   37]    Overall Loss 0.683469    Objective Loss 0.683469                                        LR 0.000060    Time 0.027447    
2023-01-06 12:58:29,729 - Epoch: [19][   37/   37]    Overall Loss 0.683650    Objective Loss 0.683650    Top1 53.765690    LR 0.000060    Time 0.026113    
2023-01-06 12:58:29,802 - --- validate (epoch=19)-----------
2023-01-06 12:58:29,803 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:30,005 - Epoch: [19][    5/    5]    Loss 0.683995    Top1 59.064885    
2023-01-06 12:58:30,060 - ==> Top1: 59.065    Loss: 0.684

2023-01-06 12:58:30,060 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:30,061 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 19]
2023-01-06 12:58:30,061 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:30,089 - 

2023-01-06 12:58:30,089 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:30,477 - Epoch: [20][   10/   37]    Overall Loss 0.685168    Objective Loss 0.685168                                        LR 0.000060    Time 0.038642    
2023-01-06 12:58:30,689 - Epoch: [20][   20/   37]    Overall Loss 0.683933    Objective Loss 0.683933                                        LR 0.000060    Time 0.029922    
2023-01-06 12:58:30,900 - Epoch: [20][   30/   37]    Overall Loss 0.683623    Objective Loss 0.683623                                        LR 0.000060    Time 0.026965    
2023-01-06 12:58:31,038 - Epoch: [20][   37/   37]    Overall Loss 0.683729    Objective Loss 0.683729    Top1 58.368201    LR 0.000060    Time 0.025575    
2023-01-06 12:58:31,104 - --- validate (epoch=20)-----------
2023-01-06 12:58:31,104 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:31,307 - Epoch: [20][    5/    5]    Loss 0.677586    Top1 59.064885    
2023-01-06 12:58:31,374 - ==> Top1: 59.065    Loss: 0.678

2023-01-06 12:58:31,374 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:31,376 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 20]
2023-01-06 12:58:31,376 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:31,406 - 

2023-01-06 12:58:31,406 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:31,807 - Epoch: [21][   10/   37]    Overall Loss 0.682037    Objective Loss 0.682037                                        LR 0.000060    Time 0.039998    
2023-01-06 12:58:32,041 - Epoch: [21][   20/   37]    Overall Loss 0.685289    Objective Loss 0.685289                                        LR 0.000060    Time 0.031665    
2023-01-06 12:58:32,268 - Epoch: [21][   30/   37]    Overall Loss 0.683521    Objective Loss 0.683521                                        LR 0.000060    Time 0.028680    
2023-01-06 12:58:32,408 - Epoch: [21][   37/   37]    Overall Loss 0.683818    Objective Loss 0.683818    Top1 54.602510    LR 0.000060    Time 0.027010    
2023-01-06 12:58:32,475 - --- validate (epoch=21)-----------
2023-01-06 12:58:32,475 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:32,683 - Epoch: [21][    5/    5]    Loss 0.674288    Top1 59.064885    
2023-01-06 12:58:32,742 - ==> Top1: 59.065    Loss: 0.674

2023-01-06 12:58:32,743 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:32,744 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 21]
2023-01-06 12:58:32,744 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:32,772 - 

2023-01-06 12:58:32,773 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:33,172 - Epoch: [22][   10/   37]    Overall Loss 0.685368    Objective Loss 0.685368                                        LR 0.000060    Time 0.039861    
2023-01-06 12:58:33,410 - Epoch: [22][   20/   37]    Overall Loss 0.684279    Objective Loss 0.684279                                        LR 0.000060    Time 0.031801    
2023-01-06 12:58:33,622 - Epoch: [22][   30/   37]    Overall Loss 0.683806    Objective Loss 0.683806                                        LR 0.000060    Time 0.028264    
2023-01-06 12:58:33,769 - Epoch: [22][   37/   37]    Overall Loss 0.683914    Objective Loss 0.683914    Top1 54.602510    LR 0.000060    Time 0.026868    
2023-01-06 12:58:33,851 - --- validate (epoch=22)-----------
2023-01-06 12:58:33,851 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:34,062 - Epoch: [22][    5/    5]    Loss 0.681933    Top1 59.064885    
2023-01-06 12:58:34,135 - ==> Top1: 59.065    Loss: 0.682

2023-01-06 12:58:34,135 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:34,136 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 22]
2023-01-06 12:58:34,136 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:34,161 - 

2023-01-06 12:58:34,161 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:34,563 - Epoch: [23][   10/   37]    Overall Loss 0.684082    Objective Loss 0.684082                                        LR 0.000060    Time 0.040111    
2023-01-06 12:58:34,818 - Epoch: [23][   20/   37]    Overall Loss 0.683266    Objective Loss 0.683266                                        LR 0.000060    Time 0.032821    
2023-01-06 12:58:35,073 - Epoch: [23][   30/   37]    Overall Loss 0.683624    Objective Loss 0.683624                                        LR 0.000060    Time 0.030375    
2023-01-06 12:58:35,227 - Epoch: [23][   37/   37]    Overall Loss 0.683169    Objective Loss 0.683169    Top1 59.205021    LR 0.000060    Time 0.028777    
2023-01-06 12:58:35,296 - --- validate (epoch=23)-----------
2023-01-06 12:58:35,296 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:35,498 - Epoch: [23][    5/    5]    Loss 0.673325    Top1 59.064885    
2023-01-06 12:58:35,559 - ==> Top1: 59.065    Loss: 0.673

2023-01-06 12:58:35,559 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:35,561 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 23]
2023-01-06 12:58:35,561 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:35,592 - 

2023-01-06 12:58:35,592 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:36,126 - Epoch: [24][   10/   37]    Overall Loss 0.677721    Objective Loss 0.677721                                        LR 0.000060    Time 0.053302    
2023-01-06 12:58:36,376 - Epoch: [24][   20/   37]    Overall Loss 0.680852    Objective Loss 0.680852                                        LR 0.000060    Time 0.039130    
2023-01-06 12:58:36,624 - Epoch: [24][   30/   37]    Overall Loss 0.682509    Objective Loss 0.682509                                        LR 0.000060    Time 0.034363    
2023-01-06 12:58:36,779 - Epoch: [24][   37/   37]    Overall Loss 0.682343    Objective Loss 0.682343    Top1 57.322176    LR 0.000060    Time 0.032025    
2023-01-06 12:58:36,842 - --- validate (epoch=24)-----------
2023-01-06 12:58:36,843 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:37,048 - Epoch: [24][    5/    5]    Loss 0.675057    Top1 59.064885    
2023-01-06 12:58:37,111 - ==> Top1: 59.065    Loss: 0.675

2023-01-06 12:58:37,111 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:37,113 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 24]
2023-01-06 12:58:37,113 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:37,141 - 

2023-01-06 12:58:37,141 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:37,569 - Epoch: [25][   10/   37]    Overall Loss 0.681037    Objective Loss 0.681037                                        LR 0.000060    Time 0.042761    
2023-01-06 12:58:37,811 - Epoch: [25][   20/   37]    Overall Loss 0.680847    Objective Loss 0.680847                                        LR 0.000060    Time 0.033415    
2023-01-06 12:58:38,062 - Epoch: [25][   30/   37]    Overall Loss 0.679313    Objective Loss 0.679313                                        LR 0.000060    Time 0.030653    
2023-01-06 12:58:38,214 - Epoch: [25][   37/   37]    Overall Loss 0.679860    Objective Loss 0.679860    Top1 54.393305    LR 0.000060    Time 0.028943    
2023-01-06 12:58:38,279 - --- validate (epoch=25)-----------
2023-01-06 12:58:38,279 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:38,482 - Epoch: [25][    5/    5]    Loss 0.670935    Top1 59.064885    
2023-01-06 12:58:38,545 - ==> Top1: 59.065    Loss: 0.671

2023-01-06 12:58:38,545 - ==> Confusion:
[[  0 429   0]
 [  0 619   0]
 [  0   0   0]]

2023-01-06 12:58:38,546 - ==> Best [Top1: 59.065   Sparsity:0.00   Params: 360896 on epoch: 25]
2023-01-06 12:58:38,547 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:38,577 - 

2023-01-06 12:58:38,577 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:38,956 - Epoch: [26][   10/   37]    Overall Loss 0.675236    Objective Loss 0.675236                                        LR 0.000060    Time 0.037782    
2023-01-06 12:58:39,160 - Epoch: [26][   20/   37]    Overall Loss 0.672736    Objective Loss 0.672736                                        LR 0.000060    Time 0.029080    
2023-01-06 12:58:39,400 - Epoch: [26][   30/   37]    Overall Loss 0.665887    Objective Loss 0.665887                                        LR 0.000060    Time 0.027368    
2023-01-06 12:58:39,547 - Epoch: [26][   37/   37]    Overall Loss 0.662660    Objective Loss 0.662660    Top1 61.087866    LR 0.000060    Time 0.026139    
2023-01-06 12:58:39,618 - --- validate (epoch=26)-----------
2023-01-06 12:58:39,618 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:39,822 - Epoch: [26][    5/    5]    Loss 0.636533    Top1 63.931298    
2023-01-06 12:58:39,888 - ==> Top1: 63.931    Loss: 0.637

2023-01-06 12:58:39,889 - ==> Confusion:
[[ 76 353   0]
 [ 25 594   0]
 [  0   0   0]]

2023-01-06 12:58:39,890 - ==> Best [Top1: 63.931   Sparsity:0.00   Params: 360896 on epoch: 26]
2023-01-06 12:58:39,890 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:39,918 - 

2023-01-06 12:58:39,918 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:40,324 - Epoch: [27][   10/   37]    Overall Loss 0.623119    Objective Loss 0.623119                                        LR 0.000060    Time 0.040463    
2023-01-06 12:58:40,573 - Epoch: [27][   20/   37]    Overall Loss 0.613571    Objective Loss 0.613571                                        LR 0.000060    Time 0.032666    
2023-01-06 12:58:40,821 - Epoch: [27][   30/   37]    Overall Loss 0.606204    Objective Loss 0.606204                                        LR 0.000060    Time 0.030046    
2023-01-06 12:58:40,978 - Epoch: [27][   37/   37]    Overall Loss 0.601776    Objective Loss 0.601776    Top1 67.782427    LR 0.000060    Time 0.028581    
2023-01-06 12:58:41,049 - --- validate (epoch=27)-----------
2023-01-06 12:58:41,049 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:41,258 - Epoch: [27][    5/    5]    Loss 0.586395    Top1 66.030534    
2023-01-06 12:58:41,322 - ==> Top1: 66.031    Loss: 0.586

2023-01-06 12:58:41,322 - ==> Confusion:
[[127 302   0]
 [ 54 565   0]
 [  0   0   0]]

2023-01-06 12:58:41,324 - ==> Best [Top1: 66.031   Sparsity:0.00   Params: 360896 on epoch: 27]
2023-01-06 12:58:41,324 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:41,355 - 

2023-01-06 12:58:41,356 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:41,750 - Epoch: [28][   10/   37]    Overall Loss 0.578347    Objective Loss 0.578347                                        LR 0.000060    Time 0.039373    
2023-01-06 12:58:41,987 - Epoch: [28][   20/   37]    Overall Loss 0.578908    Objective Loss 0.578908                                        LR 0.000060    Time 0.031493    
2023-01-06 12:58:42,227 - Epoch: [28][   30/   37]    Overall Loss 0.575570    Objective Loss 0.575570                                        LR 0.000060    Time 0.028990    
2023-01-06 12:58:42,374 - Epoch: [28][   37/   37]    Overall Loss 0.574705    Objective Loss 0.574705    Top1 68.828452    LR 0.000060    Time 0.027469    
2023-01-06 12:58:42,446 - --- validate (epoch=28)-----------
2023-01-06 12:58:42,446 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:42,652 - Epoch: [28][    5/    5]    Loss 0.555265    Top1 67.938931    
2023-01-06 12:58:42,718 - ==> Top1: 67.939    Loss: 0.555

2023-01-06 12:58:42,719 - ==> Confusion:
[[298 131   0]
 [205 414   0]
 [  0   0   0]]

2023-01-06 12:58:42,720 - ==> Best [Top1: 67.939   Sparsity:0.00   Params: 360896 on epoch: 28]
2023-01-06 12:58:42,720 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:42,751 - 

2023-01-06 12:58:42,751 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:43,130 - Epoch: [29][   10/   37]    Overall Loss 0.565727    Objective Loss 0.565727                                        LR 0.000060    Time 0.037791    
2023-01-06 12:58:43,347 - Epoch: [29][   20/   37]    Overall Loss 0.569680    Objective Loss 0.569680                                        LR 0.000060    Time 0.029739    
2023-01-06 12:58:43,578 - Epoch: [29][   30/   37]    Overall Loss 0.568069    Objective Loss 0.568069                                        LR 0.000060    Time 0.027438    
2023-01-06 12:58:43,727 - Epoch: [29][   37/   37]    Overall Loss 0.564771    Objective Loss 0.564771    Top1 74.267782    LR 0.000060    Time 0.026287    
2023-01-06 12:58:43,791 - --- validate (epoch=29)-----------
2023-01-06 12:58:43,792 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:44,002 - Epoch: [29][    5/    5]    Loss 0.549718    Top1 68.416031    
2023-01-06 12:58:44,060 - ==> Top1: 68.416    Loss: 0.550

2023-01-06 12:58:44,061 - ==> Confusion:
[[346  83   0]
 [248 371   0]
 [  0   0   0]]

2023-01-06 12:58:44,062 - ==> Best [Top1: 68.416   Sparsity:0.00   Params: 360896 on epoch: 29]
2023-01-06 12:58:44,062 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:44,083 - 

2023-01-06 12:58:44,083 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:44,475 - Epoch: [30][   10/   37]    Overall Loss 0.552743    Objective Loss 0.552743                                        LR 0.000060    Time 0.039097    
2023-01-06 12:58:44,696 - Epoch: [30][   20/   37]    Overall Loss 0.551101    Objective Loss 0.551101                                        LR 0.000060    Time 0.030572    
2023-01-06 12:58:44,926 - Epoch: [30][   30/   37]    Overall Loss 0.550941    Objective Loss 0.550941                                        LR 0.000060    Time 0.028047    
2023-01-06 12:58:45,069 - Epoch: [30][   37/   37]    Overall Loss 0.556529    Objective Loss 0.556529    Top1 65.271967    LR 0.000060    Time 0.026583    
2023-01-06 12:58:45,139 - --- validate (epoch=30)-----------
2023-01-06 12:58:45,139 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:45,346 - Epoch: [30][    5/    5]    Loss 0.525579    Top1 71.755725    
2023-01-06 12:58:45,412 - ==> Top1: 71.756    Loss: 0.526

2023-01-06 12:58:45,412 - ==> Confusion:
[[318 111   0]
 [185 434   0]
 [  0   0   0]]

2023-01-06 12:58:45,413 - ==> Best [Top1: 71.756   Sparsity:0.00   Params: 360896 on epoch: 30]
2023-01-06 12:58:45,413 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:45,443 - 

2023-01-06 12:58:45,443 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:45,839 - Epoch: [31][   10/   37]    Overall Loss 0.552537    Objective Loss 0.552537                                        LR 0.000060    Time 0.039481    
2023-01-06 12:58:46,063 - Epoch: [31][   20/   37]    Overall Loss 0.550759    Objective Loss 0.550759                                        LR 0.000060    Time 0.030927    
2023-01-06 12:58:46,292 - Epoch: [31][   30/   37]    Overall Loss 0.556382    Objective Loss 0.556382                                        LR 0.000060    Time 0.028251    
2023-01-06 12:58:46,431 - Epoch: [31][   37/   37]    Overall Loss 0.551355    Objective Loss 0.551355    Top1 73.430962    LR 0.000060    Time 0.026659    
2023-01-06 12:58:46,507 - --- validate (epoch=31)-----------
2023-01-06 12:58:46,508 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:46,713 - Epoch: [31][    5/    5]    Loss 0.539584    Top1 70.801527    
2023-01-06 12:58:46,775 - ==> Top1: 70.802    Loss: 0.540

2023-01-06 12:58:46,775 - ==> Confusion:
[[195 234   0]
 [ 72 547   0]
 [  0   0   0]]

2023-01-06 12:58:46,777 - ==> Best [Top1: 71.756   Sparsity:0.00   Params: 360896 on epoch: 30]
2023-01-06 12:58:46,777 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:46,797 - 

2023-01-06 12:58:46,797 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:47,171 - Epoch: [32][   10/   37]    Overall Loss 0.542174    Objective Loss 0.542174                                        LR 0.000060    Time 0.037317    
2023-01-06 12:58:47,381 - Epoch: [32][   20/   37]    Overall Loss 0.540485    Objective Loss 0.540485                                        LR 0.000060    Time 0.029136    
2023-01-06 12:58:47,621 - Epoch: [32][   30/   37]    Overall Loss 0.540222    Objective Loss 0.540222                                        LR 0.000060    Time 0.027407    
2023-01-06 12:58:47,765 - Epoch: [32][   37/   37]    Overall Loss 0.543953    Objective Loss 0.543953    Top1 72.803347    LR 0.000060    Time 0.026110    
2023-01-06 12:58:47,843 - --- validate (epoch=32)-----------
2023-01-06 12:58:47,843 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:48,055 - Epoch: [32][    5/    5]    Loss 0.517171    Top1 72.328244    
2023-01-06 12:58:48,118 - ==> Top1: 72.328    Loss: 0.517

2023-01-06 12:58:48,119 - ==> Confusion:
[[229 200   0]
 [ 90 529   0]
 [  0   0   0]]

2023-01-06 12:58:48,120 - ==> Best [Top1: 72.328   Sparsity:0.00   Params: 360896 on epoch: 32]
2023-01-06 12:58:48,120 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:48,144 - 

2023-01-06 12:58:48,144 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:48,531 - Epoch: [33][   10/   37]    Overall Loss 0.549892    Objective Loss 0.549892                                        LR 0.000060    Time 0.038593    
2023-01-06 12:58:48,756 - Epoch: [33][   20/   37]    Overall Loss 0.543034    Objective Loss 0.543034                                        LR 0.000060    Time 0.030506    
2023-01-06 12:58:48,997 - Epoch: [33][   30/   37]    Overall Loss 0.537400    Objective Loss 0.537400                                        LR 0.000060    Time 0.028373    
2023-01-06 12:58:49,132 - Epoch: [33][   37/   37]    Overall Loss 0.537629    Objective Loss 0.537629    Top1 70.292887    LR 0.000060    Time 0.026656    
2023-01-06 12:58:49,198 - --- validate (epoch=33)-----------
2023-01-06 12:58:49,198 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:49,409 - Epoch: [33][    5/    5]    Loss 0.503131    Top1 73.568702    
2023-01-06 12:58:49,473 - ==> Top1: 73.569    Loss: 0.503

2023-01-06 12:58:49,474 - ==> Confusion:
[[281 148   0]
 [129 490   0]
 [  0   0   0]]

2023-01-06 12:58:49,475 - ==> Best [Top1: 73.569   Sparsity:0.00   Params: 360896 on epoch: 33]
2023-01-06 12:58:49,475 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:49,503 - 

2023-01-06 12:58:49,503 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:49,907 - Epoch: [34][   10/   37]    Overall Loss 0.523792    Objective Loss 0.523792                                        LR 0.000060    Time 0.040272    
2023-01-06 12:58:50,141 - Epoch: [34][   20/   37]    Overall Loss 0.532883    Objective Loss 0.532883                                        LR 0.000060    Time 0.031833    
2023-01-06 12:58:50,384 - Epoch: [34][   30/   37]    Overall Loss 0.529574    Objective Loss 0.529574                                        LR 0.000060    Time 0.029314    
2023-01-06 12:58:50,537 - Epoch: [34][   37/   37]    Overall Loss 0.524244    Objective Loss 0.524244    Top1 75.523013    LR 0.000060    Time 0.027877    
2023-01-06 12:58:50,603 - --- validate (epoch=34)-----------
2023-01-06 12:58:50,603 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:50,813 - Epoch: [34][    5/    5]    Loss 0.494045    Top1 75.095420    
2023-01-06 12:58:50,876 - ==> Top1: 75.095    Loss: 0.494

2023-01-06 12:58:50,877 - ==> Confusion:
[[307 122   0]
 [139 480   0]
 [  0   0   0]]

2023-01-06 12:58:50,878 - ==> Best [Top1: 75.095   Sparsity:0.00   Params: 360896 on epoch: 34]
2023-01-06 12:58:50,878 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:50,906 - 

2023-01-06 12:58:50,906 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:51,289 - Epoch: [35][   10/   37]    Overall Loss 0.512682    Objective Loss 0.512682                                        LR 0.000060    Time 0.038223    
2023-01-06 12:58:51,525 - Epoch: [35][   20/   37]    Overall Loss 0.507756    Objective Loss 0.507756                                        LR 0.000060    Time 0.030864    
2023-01-06 12:58:51,755 - Epoch: [35][   30/   37]    Overall Loss 0.510794    Objective Loss 0.510794                                        LR 0.000060    Time 0.028220    
2023-01-06 12:58:51,898 - Epoch: [35][   37/   37]    Overall Loss 0.511649    Objective Loss 0.511649    Top1 70.502092    LR 0.000060    Time 0.026744    
2023-01-06 12:58:51,981 - --- validate (epoch=35)-----------
2023-01-06 12:58:51,981 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:52,200 - Epoch: [35][    5/    5]    Loss 0.500089    Top1 74.618321    
2023-01-06 12:58:52,273 - ==> Top1: 74.618    Loss: 0.500

2023-01-06 12:58:52,273 - ==> Confusion:
[[313 116   0]
 [150 469   0]
 [  0   0   0]]

2023-01-06 12:58:52,274 - ==> Best [Top1: 75.095   Sparsity:0.00   Params: 360896 on epoch: 34]
2023-01-06 12:58:52,274 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:52,295 - 

2023-01-06 12:58:52,295 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:52,692 - Epoch: [36][   10/   37]    Overall Loss 0.509041    Objective Loss 0.509041                                        LR 0.000060    Time 0.039640    
2023-01-06 12:58:52,930 - Epoch: [36][   20/   37]    Overall Loss 0.504782    Objective Loss 0.504782                                        LR 0.000060    Time 0.031685    
2023-01-06 12:58:53,172 - Epoch: [36][   30/   37]    Overall Loss 0.505477    Objective Loss 0.505477                                        LR 0.000060    Time 0.029187    
2023-01-06 12:58:53,327 - Epoch: [36][   37/   37]    Overall Loss 0.504855    Objective Loss 0.504855    Top1 74.895397    LR 0.000060    Time 0.027861    
2023-01-06 12:58:53,415 - --- validate (epoch=36)-----------
2023-01-06 12:58:53,416 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:53,621 - Epoch: [36][    5/    5]    Loss 0.491954    Top1 75.763359    
2023-01-06 12:58:53,682 - ==> Top1: 75.763    Loss: 0.492

2023-01-06 12:58:53,682 - ==> Confusion:
[[337  92   0]
 [162 457   0]
 [  0   0   0]]

2023-01-06 12:58:53,684 - ==> Best [Top1: 75.763   Sparsity:0.00   Params: 360896 on epoch: 36]
2023-01-06 12:58:53,684 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:53,714 - 

2023-01-06 12:58:53,715 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:54,098 - Epoch: [37][   10/   37]    Overall Loss 0.492491    Objective Loss 0.492491                                        LR 0.000060    Time 0.038257    
2023-01-06 12:58:54,327 - Epoch: [37][   20/   37]    Overall Loss 0.489672    Objective Loss 0.489672                                        LR 0.000060    Time 0.030500    
2023-01-06 12:58:54,579 - Epoch: [37][   30/   37]    Overall Loss 0.498878    Objective Loss 0.498878                                        LR 0.000060    Time 0.028716    
2023-01-06 12:58:54,734 - Epoch: [37][   37/   37]    Overall Loss 0.503209    Objective Loss 0.503209    Top1 73.640167    LR 0.000060    Time 0.027465    
2023-01-06 12:58:54,803 - --- validate (epoch=37)-----------
2023-01-06 12:58:54,803 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:55,010 - Epoch: [37][    5/    5]    Loss 0.481433    Top1 72.805344    
2023-01-06 12:58:55,067 - ==> Top1: 72.805    Loss: 0.481

2023-01-06 12:58:55,067 - ==> Confusion:
[[186 243   0]
 [ 42 577   0]
 [  0   0   0]]

2023-01-06 12:58:55,069 - ==> Best [Top1: 75.763   Sparsity:0.00   Params: 360896 on epoch: 36]
2023-01-06 12:58:55,069 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:55,078 - 

2023-01-06 12:58:55,079 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:55,470 - Epoch: [38][   10/   37]    Overall Loss 0.506529    Objective Loss 0.506529                                        LR 0.000060    Time 0.039045    
2023-01-06 12:58:55,719 - Epoch: [38][   20/   37]    Overall Loss 0.497773    Objective Loss 0.497773                                        LR 0.000060    Time 0.031962    
2023-01-06 12:58:55,954 - Epoch: [38][   30/   37]    Overall Loss 0.490829    Objective Loss 0.490829                                        LR 0.000060    Time 0.029128    
2023-01-06 12:58:56,106 - Epoch: [38][   37/   37]    Overall Loss 0.490369    Objective Loss 0.490369    Top1 74.058577    LR 0.000060    Time 0.027709    
2023-01-06 12:58:56,180 - --- validate (epoch=38)-----------
2023-01-06 12:58:56,180 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:56,384 - Epoch: [38][    5/    5]    Loss 0.507969    Top1 77.290076    
2023-01-06 12:58:56,448 - ==> Top1: 77.290    Loss: 0.508

2023-01-06 12:58:56,448 - ==> Confusion:
[[355  74   0]
 [164 455   0]
 [  0   0   0]]

2023-01-06 12:58:56,450 - ==> Best [Top1: 77.290   Sparsity:0.00   Params: 360896 on epoch: 38]
2023-01-06 12:58:56,450 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:56,469 - 

2023-01-06 12:58:56,469 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:56,993 - Epoch: [39][   10/   37]    Overall Loss 0.480399    Objective Loss 0.480399                                        LR 0.000060    Time 0.052247    
2023-01-06 12:58:57,216 - Epoch: [39][   20/   37]    Overall Loss 0.497315    Objective Loss 0.497315                                        LR 0.000060    Time 0.037267    
2023-01-06 12:58:57,455 - Epoch: [39][   30/   37]    Overall Loss 0.494822    Objective Loss 0.494822                                        LR 0.000060    Time 0.032807    
2023-01-06 12:58:57,604 - Epoch: [39][   37/   37]    Overall Loss 0.489083    Objective Loss 0.489083    Top1 75.523013    LR 0.000060    Time 0.030613    
2023-01-06 12:58:57,675 - --- validate (epoch=39)-----------
2023-01-06 12:58:57,675 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:57,883 - Epoch: [39][    5/    5]    Loss 0.502520    Top1 76.812977    
2023-01-06 12:58:57,948 - ==> Top1: 76.813    Loss: 0.503

2023-01-06 12:58:57,948 - ==> Confusion:
[[341  88   0]
 [155 464   0]
 [  0   0   0]]

2023-01-06 12:58:57,949 - ==> Best [Top1: 77.290   Sparsity:0.00   Params: 360896 on epoch: 38]
2023-01-06 12:58:57,949 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:57,969 - 

2023-01-06 12:58:57,970 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:58,386 - Epoch: [40][   10/   37]    Overall Loss 0.465880    Objective Loss 0.465880                                        LR 0.000036    Time 0.041571    
2023-01-06 12:58:58,634 - Epoch: [40][   20/   37]    Overall Loss 0.478582    Objective Loss 0.478582                                        LR 0.000036    Time 0.033155    
2023-01-06 12:58:58,886 - Epoch: [40][   30/   37]    Overall Loss 0.475356    Objective Loss 0.475356                                        LR 0.000036    Time 0.030491    
2023-01-06 12:58:59,040 - Epoch: [40][   37/   37]    Overall Loss 0.471597    Objective Loss 0.471597    Top1 78.242678    LR 0.000036    Time 0.028880    
2023-01-06 12:58:59,107 - --- validate (epoch=40)-----------
2023-01-06 12:58:59,107 - 1048 samples (256 per mini-batch)
2023-01-06 12:58:59,314 - Epoch: [40][    5/    5]    Loss 0.470862    Top1 77.671756    
2023-01-06 12:58:59,374 - ==> Top1: 77.672    Loss: 0.471

2023-01-06 12:58:59,375 - ==> Confusion:
[[294 135   0]
 [ 99 520   0]
 [  0   0   0]]

2023-01-06 12:58:59,376 - ==> Best [Top1: 77.672   Sparsity:0.00   Params: 360896 on epoch: 40]
2023-01-06 12:58:59,376 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:58:59,407 - 

2023-01-06 12:58:59,407 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:58:59,806 - Epoch: [41][   10/   37]    Overall Loss 0.462802    Objective Loss 0.462802                                        LR 0.000036    Time 0.039825    
2023-01-06 12:59:00,048 - Epoch: [41][   20/   37]    Overall Loss 0.468984    Objective Loss 0.468984                                        LR 0.000036    Time 0.031976    
2023-01-06 12:59:00,296 - Epoch: [41][   30/   37]    Overall Loss 0.461222    Objective Loss 0.461222                                        LR 0.000036    Time 0.029589    
2023-01-06 12:59:00,450 - Epoch: [41][   37/   37]    Overall Loss 0.464163    Objective Loss 0.464163    Top1 75.941423    LR 0.000036    Time 0.028137    
2023-01-06 12:59:00,539 - --- validate (epoch=41)-----------
2023-01-06 12:59:00,540 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:00,743 - Epoch: [41][    5/    5]    Loss 0.442945    Top1 77.862595    
2023-01-06 12:59:00,803 - ==> Top1: 77.863    Loss: 0.443

2023-01-06 12:59:00,803 - ==> Confusion:
[[359  70   0]
 [162 457   0]
 [  0   0   0]]

2023-01-06 12:59:00,804 - ==> Best [Top1: 77.863   Sparsity:0.00   Params: 360896 on epoch: 41]
2023-01-06 12:59:00,804 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:00,825 - 

2023-01-06 12:59:00,825 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:01,232 - Epoch: [42][   10/   37]    Overall Loss 0.466638    Objective Loss 0.466638                                        LR 0.000036    Time 0.040640    
2023-01-06 12:59:01,477 - Epoch: [42][   20/   37]    Overall Loss 0.468610    Objective Loss 0.468610                                        LR 0.000036    Time 0.032514    
2023-01-06 12:59:01,721 - Epoch: [42][   30/   37]    Overall Loss 0.460141    Objective Loss 0.460141                                        LR 0.000036    Time 0.029821    
2023-01-06 12:59:01,874 - Epoch: [42][   37/   37]    Overall Loss 0.459501    Objective Loss 0.459501    Top1 79.288703    LR 0.000036    Time 0.028302    
2023-01-06 12:59:01,948 - --- validate (epoch=42)-----------
2023-01-06 12:59:01,948 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:02,157 - Epoch: [42][    5/    5]    Loss 0.469936    Top1 78.625954    
2023-01-06 12:59:02,217 - ==> Top1: 78.626    Loss: 0.470

2023-01-06 12:59:02,217 - ==> Confusion:
[[348  81   0]
 [143 476   0]
 [  0   0   0]]

2023-01-06 12:59:02,218 - ==> Best [Top1: 78.626   Sparsity:0.00   Params: 360896 on epoch: 42]
2023-01-06 12:59:02,219 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:02,249 - 

2023-01-06 12:59:02,249 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:02,633 - Epoch: [43][   10/   37]    Overall Loss 0.468009    Objective Loss 0.468009                                        LR 0.000036    Time 0.038309    
2023-01-06 12:59:02,870 - Epoch: [43][   20/   37]    Overall Loss 0.458608    Objective Loss 0.458608                                        LR 0.000036    Time 0.030970    
2023-01-06 12:59:03,113 - Epoch: [43][   30/   37]    Overall Loss 0.461578    Objective Loss 0.461578                                        LR 0.000036    Time 0.028738    
2023-01-06 12:59:03,262 - Epoch: [43][   37/   37]    Overall Loss 0.458650    Objective Loss 0.458650    Top1 79.707113    LR 0.000036    Time 0.027325    
2023-01-06 12:59:03,325 - --- validate (epoch=43)-----------
2023-01-06 12:59:03,325 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:03,535 - Epoch: [43][    5/    5]    Loss 0.441771    Top1 79.293893    
2023-01-06 12:59:03,596 - ==> Top1: 79.294    Loss: 0.442

2023-01-06 12:59:03,597 - ==> Confusion:
[[331  98   0]
 [119 500   0]
 [  0   0   0]]

2023-01-06 12:59:03,598 - ==> Best [Top1: 79.294   Sparsity:0.00   Params: 360896 on epoch: 43]
2023-01-06 12:59:03,598 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:03,629 - 

2023-01-06 12:59:03,629 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:04,024 - Epoch: [44][   10/   37]    Overall Loss 0.446545    Objective Loss 0.446545                                        LR 0.000036    Time 0.039406    
2023-01-06 12:59:04,268 - Epoch: [44][   20/   37]    Overall Loss 0.452852    Objective Loss 0.452852                                        LR 0.000036    Time 0.031884    
2023-01-06 12:59:04,517 - Epoch: [44][   30/   37]    Overall Loss 0.449907    Objective Loss 0.449907                                        LR 0.000036    Time 0.029548    
2023-01-06 12:59:04,669 - Epoch: [44][   37/   37]    Overall Loss 0.452209    Objective Loss 0.452209    Top1 80.543933    LR 0.000036    Time 0.028053    
2023-01-06 12:59:04,737 - --- validate (epoch=44)-----------
2023-01-06 12:59:04,737 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:04,949 - Epoch: [44][    5/    5]    Loss 0.437482    Top1 79.007634    
2023-01-06 12:59:05,007 - ==> Top1: 79.008    Loss: 0.437

2023-01-06 12:59:05,007 - ==> Confusion:
[[345  84   0]
 [136 483   0]
 [  0   0   0]]

2023-01-06 12:59:05,009 - ==> Best [Top1: 79.294   Sparsity:0.00   Params: 360896 on epoch: 43]
2023-01-06 12:59:05,009 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:05,019 - 

2023-01-06 12:59:05,019 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:05,427 - Epoch: [45][   10/   37]    Overall Loss 0.458174    Objective Loss 0.458174                                        LR 0.000036    Time 0.040738    
2023-01-06 12:59:05,682 - Epoch: [45][   20/   37]    Overall Loss 0.449714    Objective Loss 0.449714                                        LR 0.000036    Time 0.033110    
2023-01-06 12:59:05,930 - Epoch: [45][   30/   37]    Overall Loss 0.449783    Objective Loss 0.449783                                        LR 0.000036    Time 0.030322    
2023-01-06 12:59:06,083 - Epoch: [45][   37/   37]    Overall Loss 0.450758    Objective Loss 0.450758    Top1 79.288703    LR 0.000036    Time 0.028718    
2023-01-06 12:59:06,166 - --- validate (epoch=45)-----------
2023-01-06 12:59:06,166 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:06,380 - Epoch: [45][    5/    5]    Loss 0.448228    Top1 76.049618    
2023-01-06 12:59:06,440 - ==> Top1: 76.050    Loss: 0.448

2023-01-06 12:59:06,440 - ==> Confusion:
[[234 195   0]
 [ 56 563   0]
 [  0   0   0]]

2023-01-06 12:59:06,441 - ==> Best [Top1: 79.294   Sparsity:0.00   Params: 360896 on epoch: 43]
2023-01-06 12:59:06,441 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:06,461 - 

2023-01-06 12:59:06,462 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:06,864 - Epoch: [46][   10/   37]    Overall Loss 0.451287    Objective Loss 0.451287                                        LR 0.000036    Time 0.040127    
2023-01-06 12:59:07,097 - Epoch: [46][   20/   37]    Overall Loss 0.459817    Objective Loss 0.459817                                        LR 0.000036    Time 0.031711    
2023-01-06 12:59:07,347 - Epoch: [46][   30/   37]    Overall Loss 0.454121    Objective Loss 0.454121                                        LR 0.000036    Time 0.029480    
2023-01-06 12:59:07,501 - Epoch: [46][   37/   37]    Overall Loss 0.453604    Objective Loss 0.453604    Top1 77.615063    LR 0.000036    Time 0.028038    
2023-01-06 12:59:07,569 - --- validate (epoch=46)-----------
2023-01-06 12:59:07,570 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:07,774 - Epoch: [46][    5/    5]    Loss 0.447548    Top1 78.816794    
2023-01-06 12:59:07,831 - ==> Top1: 78.817    Loss: 0.448

2023-01-06 12:59:07,831 - ==> Confusion:
[[349  80   0]
 [142 477   0]
 [  0   0   0]]

2023-01-06 12:59:07,833 - ==> Best [Top1: 79.294   Sparsity:0.00   Params: 360896 on epoch: 43]
2023-01-06 12:59:07,833 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:07,853 - 

2023-01-06 12:59:07,853 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:08,252 - Epoch: [47][   10/   37]    Overall Loss 0.454096    Objective Loss 0.454096                                        LR 0.000036    Time 0.039795    
2023-01-06 12:59:08,493 - Epoch: [47][   20/   37]    Overall Loss 0.450226    Objective Loss 0.450226                                        LR 0.000036    Time 0.031943    
2023-01-06 12:59:08,747 - Epoch: [47][   30/   37]    Overall Loss 0.443495    Objective Loss 0.443495                                        LR 0.000036    Time 0.029752    
2023-01-06 12:59:08,899 - Epoch: [47][   37/   37]    Overall Loss 0.442109    Objective Loss 0.442109    Top1 81.171548    LR 0.000036    Time 0.028210    
2023-01-06 12:59:08,960 - --- validate (epoch=47)-----------
2023-01-06 12:59:08,960 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:09,171 - Epoch: [47][    5/    5]    Loss 0.414483    Top1 77.958015    
2023-01-06 12:59:09,235 - ==> Top1: 77.958    Loss: 0.414

2023-01-06 12:59:09,236 - ==> Confusion:
[[344  85   0]
 [146 473   0]
 [  0   0   0]]

2023-01-06 12:59:09,237 - ==> Best [Top1: 79.294   Sparsity:0.00   Params: 360896 on epoch: 43]
2023-01-06 12:59:09,237 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:09,257 - 

2023-01-06 12:59:09,258 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:09,642 - Epoch: [48][   10/   37]    Overall Loss 0.438720    Objective Loss 0.438720                                        LR 0.000036    Time 0.038377    
2023-01-06 12:59:09,881 - Epoch: [48][   20/   37]    Overall Loss 0.433151    Objective Loss 0.433151                                        LR 0.000036    Time 0.031121    
2023-01-06 12:59:10,138 - Epoch: [48][   30/   37]    Overall Loss 0.438923    Objective Loss 0.438923                                        LR 0.000036    Time 0.029272    
2023-01-06 12:59:10,291 - Epoch: [48][   37/   37]    Overall Loss 0.438140    Objective Loss 0.438140    Top1 77.405858    LR 0.000036    Time 0.027861    
2023-01-06 12:59:10,365 - --- validate (epoch=48)-----------
2023-01-06 12:59:10,365 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:10,579 - Epoch: [48][    5/    5]    Loss 0.415611    Top1 79.389313    
2023-01-06 12:59:10,646 - ==> Top1: 79.389    Loss: 0.416

2023-01-06 12:59:10,646 - ==> Confusion:
[[305 124   0]
 [ 92 527   0]
 [  0   0   0]]

2023-01-06 12:59:10,648 - ==> Best [Top1: 79.389   Sparsity:0.00   Params: 360896 on epoch: 48]
2023-01-06 12:59:10,648 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:10,678 - 

2023-01-06 12:59:10,679 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:11,070 - Epoch: [49][   10/   37]    Overall Loss 0.462587    Objective Loss 0.462587                                        LR 0.000036    Time 0.039089    
2023-01-06 12:59:11,289 - Epoch: [49][   20/   37]    Overall Loss 0.446058    Objective Loss 0.446058                                        LR 0.000036    Time 0.030488    
2023-01-06 12:59:11,546 - Epoch: [49][   30/   37]    Overall Loss 0.439451    Objective Loss 0.439451                                        LR 0.000036    Time 0.028862    
2023-01-06 12:59:11,702 - Epoch: [49][   37/   37]    Overall Loss 0.443515    Objective Loss 0.443515    Top1 81.171548    LR 0.000036    Time 0.027625    
2023-01-06 12:59:11,760 - --- validate (epoch=49)-----------
2023-01-06 12:59:11,760 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:11,967 - Epoch: [49][    5/    5]    Loss 0.444656    Top1 78.625954    
2023-01-06 12:59:12,029 - ==> Top1: 78.626    Loss: 0.445

2023-01-06 12:59:12,030 - ==> Confusion:
[[357  72   0]
 [152 467   0]
 [  0   0   0]]

2023-01-06 12:59:12,031 - ==> Best [Top1: 79.389   Sparsity:0.00   Params: 360896 on epoch: 48]
2023-01-06 12:59:12,031 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:12,051 - 

2023-01-06 12:59:12,051 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:12,450 - Epoch: [50][   10/   37]    Overall Loss 0.439757    Objective Loss 0.439757                                        LR 0.000036    Time 0.039801    
2023-01-06 12:59:12,690 - Epoch: [50][   20/   37]    Overall Loss 0.437105    Objective Loss 0.437105                                        LR 0.000036    Time 0.031888    
2023-01-06 12:59:12,944 - Epoch: [50][   30/   37]    Overall Loss 0.437856    Objective Loss 0.437856                                        LR 0.000036    Time 0.029684    
2023-01-06 12:59:13,098 - Epoch: [50][   37/   37]    Overall Loss 0.435433    Objective Loss 0.435433    Top1 81.589958    LR 0.000036    Time 0.028209    
2023-01-06 12:59:13,158 - --- validate (epoch=50)-----------
2023-01-06 12:59:13,158 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:13,366 - Epoch: [50][    5/    5]    Loss 0.432458    Top1 81.297710    
2023-01-06 12:59:13,443 - ==> Top1: 81.298    Loss: 0.432

2023-01-06 12:59:13,443 - ==> Confusion:
[[314 115   0]
 [ 81 538   0]
 [  0   0   0]]

2023-01-06 12:59:13,444 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 360896 on epoch: 50]
2023-01-06 12:59:13,444 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:13,476 - 

2023-01-06 12:59:13,476 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:13,893 - Epoch: [51][   10/   37]    Overall Loss 0.424644    Objective Loss 0.424644                                        LR 0.000036    Time 0.041640    
2023-01-06 12:59:14,141 - Epoch: [51][   20/   37]    Overall Loss 0.424422    Objective Loss 0.424422                                        LR 0.000036    Time 0.033210    
2023-01-06 12:59:14,383 - Epoch: [51][   30/   37]    Overall Loss 0.431552    Objective Loss 0.431552                                        LR 0.000036    Time 0.030170    
2023-01-06 12:59:14,536 - Epoch: [51][   37/   37]    Overall Loss 0.431782    Objective Loss 0.431782    Top1 82.008368    LR 0.000036    Time 0.028593    
2023-01-06 12:59:14,604 - --- validate (epoch=51)-----------
2023-01-06 12:59:14,604 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:14,810 - Epoch: [51][    5/    5]    Loss 0.427663    Top1 79.484733    
2023-01-06 12:59:14,870 - ==> Top1: 79.485    Loss: 0.428

2023-01-06 12:59:14,870 - ==> Confusion:
[[338  91   0]
 [124 495   0]
 [  0   0   0]]

2023-01-06 12:59:14,872 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 360896 on epoch: 50]
2023-01-06 12:59:14,872 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:14,881 - 

2023-01-06 12:59:14,882 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:15,298 - Epoch: [52][   10/   37]    Overall Loss 0.430445    Objective Loss 0.430445                                        LR 0.000036    Time 0.041556    
2023-01-06 12:59:15,538 - Epoch: [52][   20/   37]    Overall Loss 0.425617    Objective Loss 0.425617                                        LR 0.000036    Time 0.032779    
2023-01-06 12:59:15,777 - Epoch: [52][   30/   37]    Overall Loss 0.426005    Objective Loss 0.426005                                        LR 0.000036    Time 0.029792    
2023-01-06 12:59:15,930 - Epoch: [52][   37/   37]    Overall Loss 0.425426    Objective Loss 0.425426    Top1 80.334728    LR 0.000036    Time 0.028281    
2023-01-06 12:59:16,013 - --- validate (epoch=52)-----------
2023-01-06 12:59:16,013 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:16,218 - Epoch: [52][    5/    5]    Loss 0.440156    Top1 79.007634    
2023-01-06 12:59:16,283 - ==> Top1: 79.008    Loss: 0.440

2023-01-06 12:59:16,283 - ==> Confusion:
[[298 131   0]
 [ 89 530   0]
 [  0   0   0]]

2023-01-06 12:59:16,284 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 360896 on epoch: 50]
2023-01-06 12:59:16,284 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:16,295 - 

2023-01-06 12:59:16,295 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:16,686 - Epoch: [53][   10/   37]    Overall Loss 0.432463    Objective Loss 0.432463                                        LR 0.000036    Time 0.038973    
2023-01-06 12:59:16,929 - Epoch: [53][   20/   37]    Overall Loss 0.427391    Objective Loss 0.427391                                        LR 0.000036    Time 0.031648    
2023-01-06 12:59:17,187 - Epoch: [53][   30/   37]    Overall Loss 0.431831    Objective Loss 0.431831                                        LR 0.000036    Time 0.029689    
2023-01-06 12:59:17,339 - Epoch: [53][   37/   37]    Overall Loss 0.427502    Objective Loss 0.427502    Top1 78.870293    LR 0.000036    Time 0.028154    
2023-01-06 12:59:17,405 - --- validate (epoch=53)-----------
2023-01-06 12:59:17,405 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:17,839 - Epoch: [53][    5/    5]    Loss 0.418719    Top1 80.057252    
2023-01-06 12:59:17,908 - ==> Top1: 80.057    Loss: 0.419

2023-01-06 12:59:17,908 - ==> Confusion:
[[317 112   0]
 [ 97 522   0]
 [  0   0   0]]

2023-01-06 12:59:17,909 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 360896 on epoch: 50]
2023-01-06 12:59:17,910 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:17,930 - 

2023-01-06 12:59:17,930 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:18,320 - Epoch: [54][   10/   37]    Overall Loss 0.413998    Objective Loss 0.413998                                        LR 0.000036    Time 0.038968    
2023-01-06 12:59:18,527 - Epoch: [54][   20/   37]    Overall Loss 0.415147    Objective Loss 0.415147                                        LR 0.000036    Time 0.029803    
2023-01-06 12:59:18,736 - Epoch: [54][   30/   37]    Overall Loss 0.423292    Objective Loss 0.423292                                        LR 0.000036    Time 0.026831    
2023-01-06 12:59:18,871 - Epoch: [54][   37/   37]    Overall Loss 0.422470    Objective Loss 0.422470    Top1 80.753138    LR 0.000036    Time 0.025386    
2023-01-06 12:59:18,936 - --- validate (epoch=54)-----------
2023-01-06 12:59:18,936 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:19,147 - Epoch: [54][    5/    5]    Loss 0.395237    Top1 79.866412    
2023-01-06 12:59:19,216 - ==> Top1: 79.866    Loss: 0.395

2023-01-06 12:59:19,216 - ==> Confusion:
[[293 136   0]
 [ 75 544   0]
 [  0   0   0]]

2023-01-06 12:59:19,218 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 360896 on epoch: 50]
2023-01-06 12:59:19,218 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:19,238 - 

2023-01-06 12:59:19,238 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:19,607 - Epoch: [55][   10/   37]    Overall Loss 0.409096    Objective Loss 0.409096                                        LR 0.000036    Time 0.036832    
2023-01-06 12:59:19,811 - Epoch: [55][   20/   37]    Overall Loss 0.414970    Objective Loss 0.414970                                        LR 0.000036    Time 0.028581    
2023-01-06 12:59:20,018 - Epoch: [55][   30/   37]    Overall Loss 0.418729    Objective Loss 0.418729                                        LR 0.000036    Time 0.025943    
2023-01-06 12:59:20,153 - Epoch: [55][   37/   37]    Overall Loss 0.418432    Objective Loss 0.418432    Top1 79.707113    LR 0.000036    Time 0.024679    
2023-01-06 12:59:20,228 - --- validate (epoch=55)-----------
2023-01-06 12:59:20,229 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:20,436 - Epoch: [55][    5/    5]    Loss 0.386661    Top1 80.438931    
2023-01-06 12:59:20,509 - ==> Top1: 80.439    Loss: 0.387

2023-01-06 12:59:20,509 - ==> Confusion:
[[315 114   0]
 [ 91 528   0]
 [  0   0   0]]

2023-01-06 12:59:20,511 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 360896 on epoch: 50]
2023-01-06 12:59:20,511 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:20,531 - 

2023-01-06 12:59:20,531 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:20,919 - Epoch: [56][   10/   37]    Overall Loss 0.426402    Objective Loss 0.426402                                        LR 0.000036    Time 0.038666    
2023-01-06 12:59:21,142 - Epoch: [56][   20/   37]    Overall Loss 0.423030    Objective Loss 0.423030                                        LR 0.000036    Time 0.030467    
2023-01-06 12:59:21,357 - Epoch: [56][   30/   37]    Overall Loss 0.421739    Objective Loss 0.421739                                        LR 0.000036    Time 0.027480    
2023-01-06 12:59:21,504 - Epoch: [56][   37/   37]    Overall Loss 0.418836    Objective Loss 0.418836    Top1 79.707113    LR 0.000036    Time 0.026249    
2023-01-06 12:59:21,571 - --- validate (epoch=56)-----------
2023-01-06 12:59:21,571 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:21,777 - Epoch: [56][    5/    5]    Loss 0.424760    Top1 79.961832    
2023-01-06 12:59:21,834 - ==> Top1: 79.962    Loss: 0.425

2023-01-06 12:59:21,834 - ==> Confusion:
[[329 100   0]
 [110 509   0]
 [  0   0   0]]

2023-01-06 12:59:21,835 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 360896 on epoch: 50]
2023-01-06 12:59:21,835 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:21,855 - 

2023-01-06 12:59:21,856 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:22,263 - Epoch: [57][   10/   37]    Overall Loss 0.413793    Objective Loss 0.413793                                        LR 0.000036    Time 0.040684    
2023-01-06 12:59:22,503 - Epoch: [57][   20/   37]    Overall Loss 0.419643    Objective Loss 0.419643                                        LR 0.000036    Time 0.032296    
2023-01-06 12:59:22,750 - Epoch: [57][   30/   37]    Overall Loss 0.412678    Objective Loss 0.412678                                        LR 0.000036    Time 0.029765    
2023-01-06 12:59:22,906 - Epoch: [57][   37/   37]    Overall Loss 0.413101    Objective Loss 0.413101    Top1 80.334728    LR 0.000036    Time 0.028337    
2023-01-06 12:59:22,980 - --- validate (epoch=57)-----------
2023-01-06 12:59:22,980 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:23,203 - Epoch: [57][    5/    5]    Loss 0.433891    Top1 79.389313    
2023-01-06 12:59:23,265 - ==> Top1: 79.389    Loss: 0.434

2023-01-06 12:59:23,265 - ==> Confusion:
[[294 135   0]
 [ 81 538   0]
 [  0   0   0]]

2023-01-06 12:59:23,266 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 360896 on epoch: 50]
2023-01-06 12:59:23,266 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:23,287 - 

2023-01-06 12:59:23,287 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:23,677 - Epoch: [58][   10/   37]    Overall Loss 0.410184    Objective Loss 0.410184                                        LR 0.000036    Time 0.038906    
2023-01-06 12:59:23,890 - Epoch: [58][   20/   37]    Overall Loss 0.413373    Objective Loss 0.413373                                        LR 0.000036    Time 0.030089    
2023-01-06 12:59:24,114 - Epoch: [58][   30/   37]    Overall Loss 0.413039    Objective Loss 0.413039                                        LR 0.000036    Time 0.027514    
2023-01-06 12:59:24,262 - Epoch: [58][   37/   37]    Overall Loss 0.411729    Objective Loss 0.411729    Top1 79.497908    LR 0.000036    Time 0.026306    
2023-01-06 12:59:24,321 - --- validate (epoch=58)-----------
2023-01-06 12:59:24,322 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:24,533 - Epoch: [58][    5/    5]    Loss 0.401893    Top1 80.725191    
2023-01-06 12:59:24,603 - ==> Top1: 80.725    Loss: 0.402

2023-01-06 12:59:24,604 - ==> Confusion:
[[324 105   0]
 [ 97 522   0]
 [  0   0   0]]

2023-01-06 12:59:24,605 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 360896 on epoch: 50]
2023-01-06 12:59:24,605 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:24,625 - 

2023-01-06 12:59:24,625 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:25,034 - Epoch: [59][   10/   37]    Overall Loss 0.414750    Objective Loss 0.414750                                        LR 0.000036    Time 0.040800    
2023-01-06 12:59:25,265 - Epoch: [59][   20/   37]    Overall Loss 0.411485    Objective Loss 0.411485                                        LR 0.000036    Time 0.031930    
2023-01-06 12:59:25,499 - Epoch: [59][   30/   37]    Overall Loss 0.415403    Objective Loss 0.415403                                        LR 0.000036    Time 0.029060    
2023-01-06 12:59:25,644 - Epoch: [59][   37/   37]    Overall Loss 0.413220    Objective Loss 0.413220    Top1 82.845188    LR 0.000036    Time 0.027480    
2023-01-06 12:59:25,716 - --- validate (epoch=59)-----------
2023-01-06 12:59:25,716 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:25,924 - Epoch: [59][    5/    5]    Loss 0.422551    Top1 78.912214    
2023-01-06 12:59:25,978 - ==> Top1: 78.912    Loss: 0.423

2023-01-06 12:59:25,979 - ==> Confusion:
[[361  68   0]
 [153 466   0]
 [  0   0   0]]

2023-01-06 12:59:25,980 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 360896 on epoch: 50]
2023-01-06 12:59:25,980 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:26,000 - 

2023-01-06 12:59:26,001 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:26,398 - Epoch: [60][   10/   37]    Overall Loss 0.394826    Objective Loss 0.394826                                        LR 0.000036    Time 0.039633    
2023-01-06 12:59:26,622 - Epoch: [60][   20/   37]    Overall Loss 0.404078    Objective Loss 0.404078                                        LR 0.000036    Time 0.031024    
2023-01-06 12:59:26,856 - Epoch: [60][   30/   37]    Overall Loss 0.408019    Objective Loss 0.408019                                        LR 0.000036    Time 0.028473    
2023-01-06 12:59:27,002 - Epoch: [60][   37/   37]    Overall Loss 0.410410    Objective Loss 0.410410    Top1 78.661088    LR 0.000036    Time 0.027022    
2023-01-06 12:59:27,073 - --- validate (epoch=60)-----------
2023-01-06 12:59:27,073 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:27,283 - Epoch: [60][    5/    5]    Loss 0.409262    Top1 81.011450    
2023-01-06 12:59:27,347 - ==> Top1: 81.011    Loss: 0.409

2023-01-06 12:59:27,347 - ==> Confusion:
[[355  74   0]
 [125 494   0]
 [  0   0   0]]

2023-01-06 12:59:27,348 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 360896 on epoch: 50]
2023-01-06 12:59:27,348 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:27,358 - 

2023-01-06 12:59:27,358 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:27,763 - Epoch: [61][   10/   37]    Overall Loss 0.402022    Objective Loss 0.402022                                        LR 0.000036    Time 0.040390    
2023-01-06 12:59:27,998 - Epoch: [61][   20/   37]    Overall Loss 0.403338    Objective Loss 0.403338                                        LR 0.000036    Time 0.031898    
2023-01-06 12:59:28,232 - Epoch: [61][   30/   37]    Overall Loss 0.407515    Objective Loss 0.407515                                        LR 0.000036    Time 0.029045    
2023-01-06 12:59:28,380 - Epoch: [61][   37/   37]    Overall Loss 0.406283    Objective Loss 0.406283    Top1 80.334728    LR 0.000036    Time 0.027553    
2023-01-06 12:59:28,439 - --- validate (epoch=61)-----------
2023-01-06 12:59:28,439 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:28,649 - Epoch: [61][    5/    5]    Loss 0.424116    Top1 80.629771    
2023-01-06 12:59:28,716 - ==> Top1: 80.630    Loss: 0.424

2023-01-06 12:59:28,717 - ==> Confusion:
[[299 130   0]
 [ 73 546   0]
 [  0   0   0]]

2023-01-06 12:59:28,718 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 360896 on epoch: 50]
2023-01-06 12:59:28,718 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:28,738 - 

2023-01-06 12:59:28,738 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:29,118 - Epoch: [62][   10/   37]    Overall Loss 0.409129    Objective Loss 0.409129                                        LR 0.000036    Time 0.037855    
2023-01-06 12:59:29,341 - Epoch: [62][   20/   37]    Overall Loss 0.404589    Objective Loss 0.404589                                        LR 0.000036    Time 0.030087    
2023-01-06 12:59:29,581 - Epoch: [62][   30/   37]    Overall Loss 0.403818    Objective Loss 0.403818                                        LR 0.000036    Time 0.028022    
2023-01-06 12:59:29,725 - Epoch: [62][   37/   37]    Overall Loss 0.403276    Objective Loss 0.403276    Top1 80.334728    LR 0.000036    Time 0.026616    
2023-01-06 12:59:29,789 - --- validate (epoch=62)-----------
2023-01-06 12:59:29,790 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:30,006 - Epoch: [62][    5/    5]    Loss 0.382977    Top1 79.675573    
2023-01-06 12:59:30,069 - ==> Top1: 79.676    Loss: 0.383

2023-01-06 12:59:30,070 - ==> Confusion:
[[287 142   0]
 [ 71 548   0]
 [  0   0   0]]

2023-01-06 12:59:30,071 - ==> Best [Top1: 81.298   Sparsity:0.00   Params: 360896 on epoch: 50]
2023-01-06 12:59:30,071 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:30,081 - 

2023-01-06 12:59:30,081 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:30,476 - Epoch: [63][   10/   37]    Overall Loss 0.407941    Objective Loss 0.407941                                        LR 0.000036    Time 0.039438    
2023-01-06 12:59:30,704 - Epoch: [63][   20/   37]    Overall Loss 0.403770    Objective Loss 0.403770                                        LR 0.000036    Time 0.031104    
2023-01-06 12:59:30,947 - Epoch: [63][   30/   37]    Overall Loss 0.400805    Objective Loss 0.400805                                        LR 0.000036    Time 0.028821    
2023-01-06 12:59:31,096 - Epoch: [63][   37/   37]    Overall Loss 0.400499    Objective Loss 0.400499    Top1 82.845188    LR 0.000036    Time 0.027388    
2023-01-06 12:59:31,154 - --- validate (epoch=63)-----------
2023-01-06 12:59:31,155 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:31,359 - Epoch: [63][    5/    5]    Loss 0.420557    Top1 81.774809    
2023-01-06 12:59:31,426 - ==> Top1: 81.775    Loss: 0.421

2023-01-06 12:59:31,427 - ==> Confusion:
[[356  73   0]
 [118 501   0]
 [  0   0   0]]

2023-01-06 12:59:31,428 - ==> Best [Top1: 81.775   Sparsity:0.00   Params: 360896 on epoch: 63]
2023-01-06 12:59:31,428 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:31,456 - 

2023-01-06 12:59:31,457 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:31,862 - Epoch: [64][   10/   37]    Overall Loss 0.403885    Objective Loss 0.403885                                        LR 0.000036    Time 0.040481    
2023-01-06 12:59:32,099 - Epoch: [64][   20/   37]    Overall Loss 0.395707    Objective Loss 0.395707                                        LR 0.000036    Time 0.032070    
2023-01-06 12:59:32,330 - Epoch: [64][   30/   37]    Overall Loss 0.391459    Objective Loss 0.391459                                        LR 0.000036    Time 0.029059    
2023-01-06 12:59:32,478 - Epoch: [64][   37/   37]    Overall Loss 0.395187    Objective Loss 0.395187    Top1 80.962343    LR 0.000036    Time 0.027558    
2023-01-06 12:59:32,548 - --- validate (epoch=64)-----------
2023-01-06 12:59:32,548 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:32,758 - Epoch: [64][    5/    5]    Loss 0.394252    Top1 80.534351    
2023-01-06 12:59:32,820 - ==> Top1: 80.534    Loss: 0.394

2023-01-06 12:59:32,821 - ==> Confusion:
[[318 111   0]
 [ 93 526   0]
 [  0   0   0]]

2023-01-06 12:59:32,822 - ==> Best [Top1: 81.775   Sparsity:0.00   Params: 360896 on epoch: 63]
2023-01-06 12:59:32,822 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:32,842 - 

2023-01-06 12:59:32,842 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:33,225 - Epoch: [65][   10/   37]    Overall Loss 0.395656    Objective Loss 0.395656                                        LR 0.000036    Time 0.038231    
2023-01-06 12:59:33,456 - Epoch: [65][   20/   37]    Overall Loss 0.397047    Objective Loss 0.397047                                        LR 0.000036    Time 0.030609    
2023-01-06 12:59:33,686 - Epoch: [65][   30/   37]    Overall Loss 0.406522    Objective Loss 0.406522                                        LR 0.000036    Time 0.028075    
2023-01-06 12:59:33,830 - Epoch: [65][   37/   37]    Overall Loss 0.402507    Objective Loss 0.402507    Top1 82.845188    LR 0.000036    Time 0.026648    
2023-01-06 12:59:33,898 - --- validate (epoch=65)-----------
2023-01-06 12:59:33,899 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:34,104 - Epoch: [65][    5/    5]    Loss 0.400520    Top1 80.725191    
2023-01-06 12:59:34,164 - ==> Top1: 80.725    Loss: 0.401

2023-01-06 12:59:34,164 - ==> Confusion:
[[282 147   0]
 [ 55 564   0]
 [  0   0   0]]

2023-01-06 12:59:34,166 - ==> Best [Top1: 81.775   Sparsity:0.00   Params: 360896 on epoch: 63]
2023-01-06 12:59:34,166 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:34,186 - 

2023-01-06 12:59:34,186 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:34,583 - Epoch: [66][   10/   37]    Overall Loss 0.391780    Objective Loss 0.391780                                        LR 0.000036    Time 0.039598    
2023-01-06 12:59:34,814 - Epoch: [66][   20/   37]    Overall Loss 0.397878    Objective Loss 0.397878                                        LR 0.000036    Time 0.031327    
2023-01-06 12:59:35,044 - Epoch: [66][   30/   37]    Overall Loss 0.397580    Objective Loss 0.397580                                        LR 0.000036    Time 0.028517    
2023-01-06 12:59:35,189 - Epoch: [66][   37/   37]    Overall Loss 0.399373    Objective Loss 0.399373    Top1 78.242678    LR 0.000036    Time 0.027057    
2023-01-06 12:59:35,262 - --- validate (epoch=66)-----------
2023-01-06 12:59:35,262 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:35,473 - Epoch: [66][    5/    5]    Loss 0.429545    Top1 81.202290    
2023-01-06 12:59:35,525 - ==> Top1: 81.202    Loss: 0.430

2023-01-06 12:59:35,525 - ==> Confusion:
[[366  63   0]
 [134 485   0]
 [  0   0   0]]

2023-01-06 12:59:35,526 - ==> Best [Top1: 81.775   Sparsity:0.00   Params: 360896 on epoch: 63]
2023-01-06 12:59:35,526 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:35,547 - 

2023-01-06 12:59:35,547 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:35,974 - Epoch: [67][   10/   37]    Overall Loss 0.399509    Objective Loss 0.399509                                        LR 0.000036    Time 0.042636    
2023-01-06 12:59:36,209 - Epoch: [67][   20/   37]    Overall Loss 0.405003    Objective Loss 0.405003                                        LR 0.000036    Time 0.033019    
2023-01-06 12:59:36,448 - Epoch: [67][   30/   37]    Overall Loss 0.400724    Objective Loss 0.400724                                        LR 0.000036    Time 0.029988    
2023-01-06 12:59:36,595 - Epoch: [67][   37/   37]    Overall Loss 0.400195    Objective Loss 0.400195    Top1 78.870293    LR 0.000036    Time 0.028264    
2023-01-06 12:59:36,662 - --- validate (epoch=67)-----------
2023-01-06 12:59:36,662 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:36,866 - Epoch: [67][    5/    5]    Loss 0.389760    Top1 82.251908    
2023-01-06 12:59:36,925 - ==> Top1: 82.252    Loss: 0.390

2023-01-06 12:59:36,925 - ==> Confusion:
[[351  78   0]
 [108 511   0]
 [  0   0   0]]

2023-01-06 12:59:36,926 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:36,927 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:36,951 - 

2023-01-06 12:59:36,951 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:37,478 - Epoch: [68][   10/   37]    Overall Loss 0.398026    Objective Loss 0.398026                                        LR 0.000036    Time 0.052623    
2023-01-06 12:59:37,706 - Epoch: [68][   20/   37]    Overall Loss 0.391296    Objective Loss 0.391296                                        LR 0.000036    Time 0.037667    
2023-01-06 12:59:37,937 - Epoch: [68][   30/   37]    Overall Loss 0.388229    Objective Loss 0.388229                                        LR 0.000036    Time 0.032822    
2023-01-06 12:59:38,081 - Epoch: [68][   37/   37]    Overall Loss 0.390128    Objective Loss 0.390128    Top1 83.472803    LR 0.000036    Time 0.030489    
2023-01-06 12:59:38,153 - --- validate (epoch=68)-----------
2023-01-06 12:59:38,153 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:38,364 - Epoch: [68][    5/    5]    Loss 0.389558    Top1 81.583969    
2023-01-06 12:59:38,441 - ==> Top1: 81.584    Loss: 0.390

2023-01-06 12:59:38,441 - ==> Confusion:
[[311 118   0]
 [ 75 544   0]
 [  0   0   0]]

2023-01-06 12:59:38,443 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:38,443 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:38,463 - 

2023-01-06 12:59:38,463 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:38,859 - Epoch: [69][   10/   37]    Overall Loss 0.386171    Objective Loss 0.386171                                        LR 0.000036    Time 0.039506    
2023-01-06 12:59:39,089 - Epoch: [69][   20/   37]    Overall Loss 0.388858    Objective Loss 0.388858                                        LR 0.000036    Time 0.031208    
2023-01-06 12:59:39,327 - Epoch: [69][   30/   37]    Overall Loss 0.391592    Objective Loss 0.391592                                        LR 0.000036    Time 0.028737    
2023-01-06 12:59:39,479 - Epoch: [69][   37/   37]    Overall Loss 0.393090    Objective Loss 0.393090    Top1 81.380753    LR 0.000036    Time 0.027408    
2023-01-06 12:59:39,542 - --- validate (epoch=69)-----------
2023-01-06 12:59:39,542 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:39,750 - Epoch: [69][    5/    5]    Loss 0.402785    Top1 81.393130    
2023-01-06 12:59:39,817 - ==> Top1: 81.393    Loss: 0.403

2023-01-06 12:59:39,817 - ==> Confusion:
[[347  82   0]
 [113 506   0]
 [  0   0   0]]

2023-01-06 12:59:39,818 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:39,819 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:39,839 - 

2023-01-06 12:59:39,839 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:40,223 - Epoch: [70][   10/   37]    Overall Loss 0.401625    Objective Loss 0.401625                                        LR 0.000022    Time 0.038340    
2023-01-06 12:59:40,430 - Epoch: [70][   20/   37]    Overall Loss 0.394121    Objective Loss 0.394121                                        LR 0.000022    Time 0.029496    
2023-01-06 12:59:40,643 - Epoch: [70][   30/   37]    Overall Loss 0.388602    Objective Loss 0.388602                                        LR 0.000022    Time 0.026753    
2023-01-06 12:59:40,787 - Epoch: [70][   37/   37]    Overall Loss 0.385864    Objective Loss 0.385864    Top1 78.451883    LR 0.000022    Time 0.025577    
2023-01-06 12:59:40,850 - --- validate (epoch=70)-----------
2023-01-06 12:59:40,850 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:41,055 - Epoch: [70][    5/    5]    Loss 0.395903    Top1 80.248092    
2023-01-06 12:59:41,117 - ==> Top1: 80.248    Loss: 0.396

2023-01-06 12:59:41,117 - ==> Confusion:
[[344  85   0]
 [122 497   0]
 [  0   0   0]]

2023-01-06 12:59:41,119 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:41,119 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:41,128 - 

2023-01-06 12:59:41,128 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:41,544 - Epoch: [71][   10/   37]    Overall Loss 0.379854    Objective Loss 0.379854                                        LR 0.000022    Time 0.041425    
2023-01-06 12:59:41,796 - Epoch: [71][   20/   37]    Overall Loss 0.383939    Objective Loss 0.383939                                        LR 0.000022    Time 0.033333    
2023-01-06 12:59:42,045 - Epoch: [71][   30/   37]    Overall Loss 0.379312    Objective Loss 0.379312                                        LR 0.000022    Time 0.030499    
2023-01-06 12:59:42,200 - Epoch: [71][   37/   37]    Overall Loss 0.382404    Objective Loss 0.382404    Top1 81.589958    LR 0.000022    Time 0.028910    
2023-01-06 12:59:42,282 - --- validate (epoch=71)-----------
2023-01-06 12:59:42,282 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:42,497 - Epoch: [71][    5/    5]    Loss 0.402832    Top1 81.297710    
2023-01-06 12:59:42,564 - ==> Top1: 81.298    Loss: 0.403

2023-01-06 12:59:42,564 - ==> Confusion:
[[359  70   0]
 [126 493   0]
 [  0   0   0]]

2023-01-06 12:59:42,566 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:42,566 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:42,586 - 

2023-01-06 12:59:42,587 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:43,003 - Epoch: [72][   10/   37]    Overall Loss 0.368791    Objective Loss 0.368791                                        LR 0.000022    Time 0.041593    
2023-01-06 12:59:43,255 - Epoch: [72][   20/   37]    Overall Loss 0.380707    Objective Loss 0.380707                                        LR 0.000022    Time 0.033336    
2023-01-06 12:59:43,505 - Epoch: [72][   30/   37]    Overall Loss 0.380616    Objective Loss 0.380616                                        LR 0.000022    Time 0.030568    
2023-01-06 12:59:43,660 - Epoch: [72][   37/   37]    Overall Loss 0.381213    Objective Loss 0.381213    Top1 83.891213    LR 0.000022    Time 0.028963    
2023-01-06 12:59:43,723 - --- validate (epoch=72)-----------
2023-01-06 12:59:43,724 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:43,930 - Epoch: [72][    5/    5]    Loss 0.371682    Top1 81.106870    
2023-01-06 12:59:43,995 - ==> Top1: 81.107    Loss: 0.372

2023-01-06 12:59:43,996 - ==> Confusion:
[[365  64   0]
 [134 485   0]
 [  0   0   0]]

2023-01-06 12:59:43,997 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:43,997 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:44,017 - 

2023-01-06 12:59:44,017 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:44,409 - Epoch: [73][   10/   37]    Overall Loss 0.376096    Objective Loss 0.376096                                        LR 0.000022    Time 0.039023    
2023-01-06 12:59:44,639 - Epoch: [73][   20/   37]    Overall Loss 0.371023    Objective Loss 0.371023                                        LR 0.000022    Time 0.031039    
2023-01-06 12:59:44,880 - Epoch: [73][   30/   37]    Overall Loss 0.370737    Objective Loss 0.370737                                        LR 0.000022    Time 0.028704    
2023-01-06 12:59:45,037 - Epoch: [73][   37/   37]    Overall Loss 0.376579    Objective Loss 0.376579    Top1 82.426778    LR 0.000022    Time 0.027495    
2023-01-06 12:59:45,109 - --- validate (epoch=73)-----------
2023-01-06 12:59:45,109 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:45,320 - Epoch: [73][    5/    5]    Loss 0.365569    Top1 81.965649    
2023-01-06 12:59:45,380 - ==> Top1: 81.966    Loss: 0.366

2023-01-06 12:59:45,380 - ==> Confusion:
[[347  82   0]
 [107 512   0]
 [  0   0   0]]

2023-01-06 12:59:45,381 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:45,381 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:45,402 - 

2023-01-06 12:59:45,402 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:45,798 - Epoch: [74][   10/   37]    Overall Loss 0.371677    Objective Loss 0.371677                                        LR 0.000022    Time 0.039551    
2023-01-06 12:59:46,025 - Epoch: [74][   20/   37]    Overall Loss 0.374613    Objective Loss 0.374613                                        LR 0.000022    Time 0.031092    
2023-01-06 12:59:46,244 - Epoch: [74][   30/   37]    Overall Loss 0.376785    Objective Loss 0.376785                                        LR 0.000022    Time 0.028024    
2023-01-06 12:59:46,380 - Epoch: [74][   37/   37]    Overall Loss 0.376765    Objective Loss 0.376765    Top1 83.472803    LR 0.000022    Time 0.026398    
2023-01-06 12:59:46,451 - --- validate (epoch=74)-----------
2023-01-06 12:59:46,451 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:46,662 - Epoch: [74][    5/    5]    Loss 0.398392    Top1 80.629771    
2023-01-06 12:59:46,728 - ==> Top1: 80.630    Loss: 0.398

2023-01-06 12:59:46,729 - ==> Confusion:
[[369  60   0]
 [143 476   0]
 [  0   0   0]]

2023-01-06 12:59:46,730 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:46,730 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:46,750 - 

2023-01-06 12:59:46,750 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:47,132 - Epoch: [75][   10/   37]    Overall Loss 0.366116    Objective Loss 0.366116                                        LR 0.000022    Time 0.038103    
2023-01-06 12:59:47,351 - Epoch: [75][   20/   37]    Overall Loss 0.373770    Objective Loss 0.373770                                        LR 0.000022    Time 0.030003    
2023-01-06 12:59:47,581 - Epoch: [75][   30/   37]    Overall Loss 0.378461    Objective Loss 0.378461                                        LR 0.000022    Time 0.027659    
2023-01-06 12:59:47,729 - Epoch: [75][   37/   37]    Overall Loss 0.374612    Objective Loss 0.374612    Top1 81.799163    LR 0.000022    Time 0.026403    
2023-01-06 12:59:47,796 - --- validate (epoch=75)-----------
2023-01-06 12:59:47,796 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:48,001 - Epoch: [75][    5/    5]    Loss 0.401980    Top1 82.061069    
2023-01-06 12:59:48,065 - ==> Top1: 82.061    Loss: 0.402

2023-01-06 12:59:48,065 - ==> Confusion:
[[340  89   0]
 [ 99 520   0]
 [  0   0   0]]

2023-01-06 12:59:48,067 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:48,067 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:48,087 - 

2023-01-06 12:59:48,087 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:48,474 - Epoch: [76][   10/   37]    Overall Loss 0.375456    Objective Loss 0.375456                                        LR 0.000022    Time 0.038656    
2023-01-06 12:59:48,702 - Epoch: [76][   20/   37]    Overall Loss 0.382518    Objective Loss 0.382518                                        LR 0.000022    Time 0.030709    
2023-01-06 12:59:48,938 - Epoch: [76][   30/   37]    Overall Loss 0.375811    Objective Loss 0.375811                                        LR 0.000022    Time 0.028324    
2023-01-06 12:59:49,089 - Epoch: [76][   37/   37]    Overall Loss 0.375880    Objective Loss 0.375880    Top1 81.589958    LR 0.000022    Time 0.027046    
2023-01-06 12:59:49,159 - --- validate (epoch=76)-----------
2023-01-06 12:59:49,159 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:49,368 - Epoch: [76][    5/    5]    Loss 0.383757    Top1 81.202290    
2023-01-06 12:59:49,421 - ==> Top1: 81.202    Loss: 0.384

2023-01-06 12:59:49,421 - ==> Confusion:
[[363  66   0]
 [131 488   0]
 [  0   0   0]]

2023-01-06 12:59:49,423 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:49,423 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:49,433 - 

2023-01-06 12:59:49,433 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:49,814 - Epoch: [77][   10/   37]    Overall Loss 0.359507    Objective Loss 0.359507                                        LR 0.000022    Time 0.038096    
2023-01-06 12:59:50,036 - Epoch: [77][   20/   37]    Overall Loss 0.370320    Objective Loss 0.370320                                        LR 0.000022    Time 0.030113    
2023-01-06 12:59:50,274 - Epoch: [77][   30/   37]    Overall Loss 0.376122    Objective Loss 0.376122                                        LR 0.000022    Time 0.027998    
2023-01-06 12:59:50,428 - Epoch: [77][   37/   37]    Overall Loss 0.373663    Objective Loss 0.373663    Top1 85.146444    LR 0.000022    Time 0.026843    
2023-01-06 12:59:50,493 - --- validate (epoch=77)-----------
2023-01-06 12:59:50,493 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:50,703 - Epoch: [77][    5/    5]    Loss 0.401227    Top1 81.965649    
2023-01-06 12:59:50,762 - ==> Top1: 81.966    Loss: 0.401

2023-01-06 12:59:50,762 - ==> Confusion:
[[359  70   0]
 [119 500   0]
 [  0   0   0]]

2023-01-06 12:59:50,764 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:50,764 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:50,784 - 

2023-01-06 12:59:50,784 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:51,166 - Epoch: [78][   10/   37]    Overall Loss 0.391227    Objective Loss 0.391227                                        LR 0.000022    Time 0.038163    
2023-01-06 12:59:51,374 - Epoch: [78][   20/   37]    Overall Loss 0.381723    Objective Loss 0.381723                                        LR 0.000022    Time 0.029453    
2023-01-06 12:59:51,601 - Epoch: [78][   30/   37]    Overall Loss 0.377253    Objective Loss 0.377253                                        LR 0.000022    Time 0.027204    
2023-01-06 12:59:51,755 - Epoch: [78][   37/   37]    Overall Loss 0.379441    Objective Loss 0.379441    Top1 85.146444    LR 0.000022    Time 0.026196    
2023-01-06 12:59:51,823 - --- validate (epoch=78)-----------
2023-01-06 12:59:51,824 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:52,046 - Epoch: [78][    5/    5]    Loss 0.384651    Top1 81.583969    
2023-01-06 12:59:52,114 - ==> Top1: 81.584    Loss: 0.385

2023-01-06 12:59:52,114 - ==> Confusion:
[[338  91   0]
 [102 517   0]
 [  0   0   0]]

2023-01-06 12:59:52,116 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:52,116 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:52,136 - 

2023-01-06 12:59:52,136 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:52,510 - Epoch: [79][   10/   37]    Overall Loss 0.386254    Objective Loss 0.386254                                        LR 0.000022    Time 0.037289    
2023-01-06 12:59:52,720 - Epoch: [79][   20/   37]    Overall Loss 0.391861    Objective Loss 0.391861                                        LR 0.000022    Time 0.029144    
2023-01-06 12:59:52,935 - Epoch: [79][   30/   37]    Overall Loss 0.384946    Objective Loss 0.384946                                        LR 0.000022    Time 0.026585    
2023-01-06 12:59:53,081 - Epoch: [79][   37/   37]    Overall Loss 0.381935    Objective Loss 0.381935    Top1 83.263598    LR 0.000022    Time 0.025493    
2023-01-06 12:59:53,163 - --- validate (epoch=79)-----------
2023-01-06 12:59:53,163 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:53,385 - Epoch: [79][    5/    5]    Loss 0.402290    Top1 81.774809    
2023-01-06 12:59:53,448 - ==> Top1: 81.775    Loss: 0.402

2023-01-06 12:59:53,448 - ==> Confusion:
[[364  65   0]
 [126 493   0]
 [  0   0   0]]

2023-01-06 12:59:53,450 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:53,450 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:53,470 - 

2023-01-06 12:59:53,470 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:53,868 - Epoch: [80][   10/   37]    Overall Loss 0.380787    Objective Loss 0.380787                                        LR 0.000022    Time 0.039673    
2023-01-06 12:59:54,107 - Epoch: [80][   20/   37]    Overall Loss 0.370542    Objective Loss 0.370542                                        LR 0.000022    Time 0.031781    
2023-01-06 12:59:54,357 - Epoch: [80][   30/   37]    Overall Loss 0.369952    Objective Loss 0.369952                                        LR 0.000022    Time 0.029498    
2023-01-06 12:59:54,511 - Epoch: [80][   37/   37]    Overall Loss 0.375777    Objective Loss 0.375777    Top1 81.799163    LR 0.000022    Time 0.028096    
2023-01-06 12:59:54,576 - --- validate (epoch=80)-----------
2023-01-06 12:59:54,576 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:54,784 - Epoch: [80][    5/    5]    Loss 0.385188    Top1 81.583969    
2023-01-06 12:59:54,836 - ==> Top1: 81.584    Loss: 0.385

2023-01-06 12:59:54,837 - ==> Confusion:
[[326 103   0]
 [ 90 529   0]
 [  0   0   0]]

2023-01-06 12:59:54,838 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:54,838 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:54,848 - 

2023-01-06 12:59:54,848 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:55,228 - Epoch: [81][   10/   37]    Overall Loss 0.369556    Objective Loss 0.369556                                        LR 0.000022    Time 0.037957    
2023-01-06 12:59:55,448 - Epoch: [81][   20/   37]    Overall Loss 0.368980    Objective Loss 0.368980                                        LR 0.000022    Time 0.029970    
2023-01-06 12:59:55,684 - Epoch: [81][   30/   37]    Overall Loss 0.367362    Objective Loss 0.367362                                        LR 0.000022    Time 0.027829    
2023-01-06 12:59:55,830 - Epoch: [81][   37/   37]    Overall Loss 0.370541    Objective Loss 0.370541    Top1 78.033473    LR 0.000022    Time 0.026500    
2023-01-06 12:59:55,902 - --- validate (epoch=81)-----------
2023-01-06 12:59:55,902 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:56,115 - Epoch: [81][    5/    5]    Loss 0.397284    Top1 81.774809    
2023-01-06 12:59:56,176 - ==> Top1: 81.775    Loss: 0.397

2023-01-06 12:59:56,176 - ==> Confusion:
[[369  60   0]
 [131 488   0]
 [  0   0   0]]

2023-01-06 12:59:56,177 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:56,177 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:56,198 - 

2023-01-06 12:59:56,198 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:56,582 - Epoch: [82][   10/   37]    Overall Loss 0.364306    Objective Loss 0.364306                                        LR 0.000022    Time 0.038288    
2023-01-06 12:59:56,791 - Epoch: [82][   20/   37]    Overall Loss 0.368709    Objective Loss 0.368709                                        LR 0.000022    Time 0.029592    
2023-01-06 12:59:57,007 - Epoch: [82][   30/   37]    Overall Loss 0.370630    Objective Loss 0.370630                                        LR 0.000022    Time 0.026930    
2023-01-06 12:59:57,160 - Epoch: [82][   37/   37]    Overall Loss 0.368954    Objective Loss 0.368954    Top1 83.263598    LR 0.000022    Time 0.025945    
2023-01-06 12:59:57,225 - --- validate (epoch=82)-----------
2023-01-06 12:59:57,225 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:57,429 - Epoch: [82][    5/    5]    Loss 0.385872    Top1 81.965649    
2023-01-06 12:59:57,490 - ==> Top1: 81.966    Loss: 0.386

2023-01-06 12:59:57,490 - ==> Confusion:
[[326 103   0]
 [ 86 533   0]
 [  0   0   0]]

2023-01-06 12:59:57,492 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:57,492 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:57,512 - 

2023-01-06 12:59:57,512 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:57,898 - Epoch: [83][   10/   37]    Overall Loss 0.373769    Objective Loss 0.373769                                        LR 0.000022    Time 0.038509    
2023-01-06 12:59:58,117 - Epoch: [83][   20/   37]    Overall Loss 0.366293    Objective Loss 0.366293                                        LR 0.000022    Time 0.030205    
2023-01-06 12:59:58,356 - Epoch: [83][   30/   37]    Overall Loss 0.367242    Objective Loss 0.367242                                        LR 0.000022    Time 0.028067    
2023-01-06 12:59:58,504 - Epoch: [83][   37/   37]    Overall Loss 0.370032    Objective Loss 0.370032    Top1 84.518828    LR 0.000022    Time 0.026751    
2023-01-06 12:59:58,586 - --- validate (epoch=83)-----------
2023-01-06 12:59:58,586 - 1048 samples (256 per mini-batch)
2023-01-06 12:59:58,928 - Epoch: [83][    5/    5]    Loss 0.374216    Top1 81.870229    
2023-01-06 12:59:58,995 - ==> Top1: 81.870    Loss: 0.374

2023-01-06 12:59:58,996 - ==> Confusion:
[[338  91   0]
 [ 99 520   0]
 [  0   0   0]]

2023-01-06 12:59:58,997 - ==> Best [Top1: 82.252   Sparsity:0.00   Params: 360896 on epoch: 67]
2023-01-06 12:59:58,997 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 12:59:59,017 - 

2023-01-06 12:59:59,017 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 12:59:59,405 - Epoch: [84][   10/   37]    Overall Loss 0.366968    Objective Loss 0.366968                                        LR 0.000022    Time 0.038681    
2023-01-06 12:59:59,626 - Epoch: [84][   20/   37]    Overall Loss 0.363600    Objective Loss 0.363600                                        LR 0.000022    Time 0.030389    
2023-01-06 12:59:59,853 - Epoch: [84][   30/   37]    Overall Loss 0.367434    Objective Loss 0.367434                                        LR 0.000022    Time 0.027798    
2023-01-06 13:00:00,000 - Epoch: [84][   37/   37]    Overall Loss 0.368122    Objective Loss 0.368122    Top1 80.543933    LR 0.000022    Time 0.026512    
2023-01-06 13:00:00,072 - --- validate (epoch=84)-----------
2023-01-06 13:00:00,073 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:00,279 - Epoch: [84][    5/    5]    Loss 0.375919    Top1 82.347328    
2023-01-06 13:00:00,345 - ==> Top1: 82.347    Loss: 0.376

2023-01-06 13:00:00,345 - ==> Confusion:
[[350  79   0]
 [106 513   0]
 [  0   0   0]]

2023-01-06 13:00:00,347 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 360896 on epoch: 84]
2023-01-06 13:00:00,347 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:00,375 - 

2023-01-06 13:00:00,375 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:00,766 - Epoch: [85][   10/   37]    Overall Loss 0.379554    Objective Loss 0.379554                                        LR 0.000022    Time 0.039004    
2023-01-06 13:00:00,991 - Epoch: [85][   20/   37]    Overall Loss 0.373459    Objective Loss 0.373459                                        LR 0.000022    Time 0.030741    
2023-01-06 13:00:01,216 - Epoch: [85][   30/   37]    Overall Loss 0.367383    Objective Loss 0.367383                                        LR 0.000022    Time 0.027962    
2023-01-06 13:00:01,364 - Epoch: [85][   37/   37]    Overall Loss 0.368580    Objective Loss 0.368580    Top1 82.426778    LR 0.000022    Time 0.026680    
2023-01-06 13:00:01,432 - --- validate (epoch=85)-----------
2023-01-06 13:00:01,432 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:01,638 - Epoch: [85][    5/    5]    Loss 0.376600    Top1 81.870229    
2023-01-06 13:00:01,707 - ==> Top1: 81.870    Loss: 0.377

2023-01-06 13:00:01,707 - ==> Confusion:
[[366  63   0]
 [127 492   0]
 [  0   0   0]]

2023-01-06 13:00:01,709 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 360896 on epoch: 84]
2023-01-06 13:00:01,709 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:01,733 - 

2023-01-06 13:00:01,733 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:02,140 - Epoch: [86][   10/   37]    Overall Loss 0.357816    Objective Loss 0.357816                                        LR 0.000022    Time 0.040592    
2023-01-06 13:00:02,392 - Epoch: [86][   20/   37]    Overall Loss 0.363394    Objective Loss 0.363394                                        LR 0.000022    Time 0.032835    
2023-01-06 13:00:02,651 - Epoch: [86][   30/   37]    Overall Loss 0.363598    Objective Loss 0.363598                                        LR 0.000022    Time 0.030535    
2023-01-06 13:00:02,801 - Epoch: [86][   37/   37]    Overall Loss 0.366672    Objective Loss 0.366672    Top1 84.100418    LR 0.000022    Time 0.028794    
2023-01-06 13:00:02,876 - --- validate (epoch=86)-----------
2023-01-06 13:00:02,876 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:03,100 - Epoch: [86][    5/    5]    Loss 0.414759    Top1 81.870229    
2023-01-06 13:00:03,166 - ==> Top1: 81.870    Loss: 0.415

2023-01-06 13:00:03,166 - ==> Confusion:
[[363  66   0]
 [124 495   0]
 [  0   0   0]]

2023-01-06 13:00:03,167 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 360896 on epoch: 84]
2023-01-06 13:00:03,167 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:03,177 - 

2023-01-06 13:00:03,177 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:03,586 - Epoch: [87][   10/   37]    Overall Loss 0.369033    Objective Loss 0.369033                                        LR 0.000022    Time 0.040741    
2023-01-06 13:00:03,827 - Epoch: [87][   20/   37]    Overall Loss 0.365533    Objective Loss 0.365533                                        LR 0.000022    Time 0.032431    
2023-01-06 13:00:04,067 - Epoch: [87][   30/   37]    Overall Loss 0.364999    Objective Loss 0.364999                                        LR 0.000022    Time 0.029600    
2023-01-06 13:00:04,214 - Epoch: [87][   37/   37]    Overall Loss 0.369699    Objective Loss 0.369699    Top1 79.497908    LR 0.000022    Time 0.027954    
2023-01-06 13:00:04,292 - --- validate (epoch=87)-----------
2023-01-06 13:00:04,293 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:04,499 - Epoch: [87][    5/    5]    Loss 0.380708    Top1 80.820611    
2023-01-06 13:00:04,571 - ==> Top1: 80.821    Loss: 0.381

2023-01-06 13:00:04,572 - ==> Confusion:
[[376  53   0]
 [148 471   0]
 [  0   0   0]]

2023-01-06 13:00:04,573 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 360896 on epoch: 84]
2023-01-06 13:00:04,573 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:04,594 - 

2023-01-06 13:00:04,594 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:04,999 - Epoch: [88][   10/   37]    Overall Loss 0.373184    Objective Loss 0.373184                                        LR 0.000022    Time 0.040404    
2023-01-06 13:00:05,233 - Epoch: [88][   20/   37]    Overall Loss 0.363169    Objective Loss 0.363169                                        LR 0.000022    Time 0.031928    
2023-01-06 13:00:05,472 - Epoch: [88][   30/   37]    Overall Loss 0.363523    Objective Loss 0.363523                                        LR 0.000022    Time 0.029244    
2023-01-06 13:00:05,615 - Epoch: [88][   37/   37]    Overall Loss 0.368174    Objective Loss 0.368174    Top1 82.635983    LR 0.000022    Time 0.027563    
2023-01-06 13:00:05,687 - --- validate (epoch=88)-----------
2023-01-06 13:00:05,688 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:05,899 - Epoch: [88][    5/    5]    Loss 0.409680    Top1 81.870229    
2023-01-06 13:00:05,952 - ==> Top1: 81.870    Loss: 0.410

2023-01-06 13:00:05,952 - ==> Confusion:
[[336  93   0]
 [ 97 522   0]
 [  0   0   0]]

2023-01-06 13:00:05,954 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 360896 on epoch: 84]
2023-01-06 13:00:05,954 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:05,974 - 

2023-01-06 13:00:05,974 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:06,354 - Epoch: [89][   10/   37]    Overall Loss 0.371734    Objective Loss 0.371734                                        LR 0.000022    Time 0.037931    
2023-01-06 13:00:06,586 - Epoch: [89][   20/   37]    Overall Loss 0.371274    Objective Loss 0.371274                                        LR 0.000022    Time 0.030552    
2023-01-06 13:00:06,842 - Epoch: [89][   30/   37]    Overall Loss 0.368612    Objective Loss 0.368612                                        LR 0.000022    Time 0.028855    
2023-01-06 13:00:06,994 - Epoch: [89][   37/   37]    Overall Loss 0.369533    Objective Loss 0.369533    Top1 82.008368    LR 0.000022    Time 0.027491    
2023-01-06 13:00:07,077 - --- validate (epoch=89)-----------
2023-01-06 13:00:07,077 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:07,288 - Epoch: [89][    5/    5]    Loss 0.391252    Top1 81.583969    
2023-01-06 13:00:07,346 - ==> Top1: 81.584    Loss: 0.391

2023-01-06 13:00:07,347 - ==> Confusion:
[[375  54   0]
 [139 480   0]
 [  0   0   0]]

2023-01-06 13:00:07,348 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 360896 on epoch: 84]
2023-01-06 13:00:07,348 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:07,358 - 

2023-01-06 13:00:07,358 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:07,747 - Epoch: [90][   10/   37]    Overall Loss 0.362198    Objective Loss 0.362198                                        LR 0.000022    Time 0.038816    
2023-01-06 13:00:07,952 - Epoch: [90][   20/   37]    Overall Loss 0.366258    Objective Loss 0.366258                                        LR 0.000022    Time 0.029635    
2023-01-06 13:00:08,168 - Epoch: [90][   30/   37]    Overall Loss 0.369117    Objective Loss 0.369117                                        LR 0.000022    Time 0.026920    
2023-01-06 13:00:08,304 - Epoch: [90][   37/   37]    Overall Loss 0.364171    Objective Loss 0.364171    Top1 84.937238    LR 0.000022    Time 0.025515    
2023-01-06 13:00:08,384 - --- validate (epoch=90)-----------
2023-01-06 13:00:08,385 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:08,594 - Epoch: [90][    5/    5]    Loss 0.369462    Top1 81.679389    
2023-01-06 13:00:08,647 - ==> Top1: 81.679    Loss: 0.369

2023-01-06 13:00:08,648 - ==> Confusion:
[[353  76   0]
 [116 503   0]
 [  0   0   0]]

2023-01-06 13:00:08,649 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 360896 on epoch: 84]
2023-01-06 13:00:08,649 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:08,670 - 

2023-01-06 13:00:08,670 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:09,047 - Epoch: [91][   10/   37]    Overall Loss 0.365693    Objective Loss 0.365693                                        LR 0.000022    Time 0.037663    
2023-01-06 13:00:09,255 - Epoch: [91][   20/   37]    Overall Loss 0.368544    Objective Loss 0.368544                                        LR 0.000022    Time 0.029196    
2023-01-06 13:00:09,464 - Epoch: [91][   30/   37]    Overall Loss 0.365028    Objective Loss 0.365028                                        LR 0.000022    Time 0.026427    
2023-01-06 13:00:09,608 - Epoch: [91][   37/   37]    Overall Loss 0.363119    Objective Loss 0.363119    Top1 84.100418    LR 0.000022    Time 0.025302    
2023-01-06 13:00:09,677 - --- validate (epoch=91)-----------
2023-01-06 13:00:09,677 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:09,888 - Epoch: [91][    5/    5]    Loss 0.412825    Top1 82.251908    
2023-01-06 13:00:09,943 - ==> Top1: 82.252    Loss: 0.413

2023-01-06 13:00:09,943 - ==> Confusion:
[[344  85   0]
 [101 518   0]
 [  0   0   0]]

2023-01-06 13:00:09,944 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 360896 on epoch: 84]
2023-01-06 13:00:09,945 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:09,965 - 

2023-01-06 13:00:09,965 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:10,363 - Epoch: [92][   10/   37]    Overall Loss 0.361345    Objective Loss 0.361345                                        LR 0.000022    Time 0.039747    
2023-01-06 13:00:10,617 - Epoch: [92][   20/   37]    Overall Loss 0.367237    Objective Loss 0.367237                                        LR 0.000022    Time 0.032526    
2023-01-06 13:00:10,868 - Epoch: [92][   30/   37]    Overall Loss 0.364494    Objective Loss 0.364494                                        LR 0.000022    Time 0.030036    
2023-01-06 13:00:11,001 - Epoch: [92][   37/   37]    Overall Loss 0.361277    Objective Loss 0.361277    Top1 87.656904    LR 0.000022    Time 0.027955    
2023-01-06 13:00:11,081 - --- validate (epoch=92)-----------
2023-01-06 13:00:11,081 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:11,296 - Epoch: [92][    5/    5]    Loss 0.458612    Top1 81.774809    
2023-01-06 13:00:11,357 - ==> Top1: 81.775    Loss: 0.459

2023-01-06 13:00:11,358 - ==> Confusion:
[[364  65   0]
 [126 493   0]
 [  0   0   0]]

2023-01-06 13:00:11,359 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 360896 on epoch: 84]
2023-01-06 13:00:11,359 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:11,369 - 

2023-01-06 13:00:11,369 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:11,786 - Epoch: [93][   10/   37]    Overall Loss 0.365772    Objective Loss 0.365772                                        LR 0.000022    Time 0.041653    
2023-01-06 13:00:12,017 - Epoch: [93][   20/   37]    Overall Loss 0.362908    Objective Loss 0.362908                                        LR 0.000022    Time 0.032331    
2023-01-06 13:00:12,244 - Epoch: [93][   30/   37]    Overall Loss 0.362353    Objective Loss 0.362353                                        LR 0.000022    Time 0.029116    
2023-01-06 13:00:12,388 - Epoch: [93][   37/   37]    Overall Loss 0.359891    Objective Loss 0.359891    Top1 84.937238    LR 0.000022    Time 0.027502    
2023-01-06 13:00:12,462 - --- validate (epoch=93)-----------
2023-01-06 13:00:12,462 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:12,668 - Epoch: [93][    5/    5]    Loss 0.438202    Top1 80.916031    
2023-01-06 13:00:12,739 - ==> Top1: 80.916    Loss: 0.438

2023-01-06 13:00:12,739 - ==> Confusion:
[[370  59   0]
 [141 478   0]
 [  0   0   0]]

2023-01-06 13:00:12,741 - ==> Best [Top1: 82.347   Sparsity:0.00   Params: 360896 on epoch: 84]
2023-01-06 13:00:12,741 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:12,761 - 

2023-01-06 13:00:12,761 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:13,142 - Epoch: [94][   10/   37]    Overall Loss 0.362945    Objective Loss 0.362945                                        LR 0.000022    Time 0.038035    
2023-01-06 13:00:13,356 - Epoch: [94][   20/   37]    Overall Loss 0.360824    Objective Loss 0.360824                                        LR 0.000022    Time 0.029691    
2023-01-06 13:00:13,569 - Epoch: [94][   30/   37]    Overall Loss 0.358597    Objective Loss 0.358597                                        LR 0.000022    Time 0.026888    
2023-01-06 13:00:13,714 - Epoch: [94][   37/   37]    Overall Loss 0.357347    Objective Loss 0.357347    Top1 82.845188    LR 0.000022    Time 0.025704    
2023-01-06 13:00:13,782 - --- validate (epoch=94)-----------
2023-01-06 13:00:13,783 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:13,987 - Epoch: [94][    5/    5]    Loss 0.373941    Top1 82.919847    
2023-01-06 13:00:14,056 - ==> Top1: 82.920    Loss: 0.374

2023-01-06 13:00:14,056 - ==> Confusion:
[[361  68   0]
 [111 508   0]
 [  0   0   0]]

2023-01-06 13:00:14,058 - ==> Best [Top1: 82.920   Sparsity:0.00   Params: 360896 on epoch: 94]
2023-01-06 13:00:14,058 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:14,083 - 

2023-01-06 13:00:14,083 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:14,491 - Epoch: [95][   10/   37]    Overall Loss 0.337874    Objective Loss 0.337874                                        LR 0.000022    Time 0.040630    
2023-01-06 13:00:14,746 - Epoch: [95][   20/   37]    Overall Loss 0.344976    Objective Loss 0.344976                                        LR 0.000022    Time 0.033054    
2023-01-06 13:00:14,998 - Epoch: [95][   30/   37]    Overall Loss 0.351150    Objective Loss 0.351150                                        LR 0.000022    Time 0.030427    
2023-01-06 13:00:15,153 - Epoch: [95][   37/   37]    Overall Loss 0.355916    Objective Loss 0.355916    Top1 82.426778    LR 0.000022    Time 0.028861    
2023-01-06 13:00:15,226 - --- validate (epoch=95)-----------
2023-01-06 13:00:15,226 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:15,434 - Epoch: [95][    5/    5]    Loss 0.380117    Top1 83.015267    
2023-01-06 13:00:15,491 - ==> Top1: 83.015    Loss: 0.380

2023-01-06 13:00:15,491 - ==> Confusion:
[[318 111   0]
 [ 67 552   0]
 [  0   0   0]]

2023-01-06 13:00:15,493 - ==> Best [Top1: 83.015   Sparsity:0.00   Params: 360896 on epoch: 95]
2023-01-06 13:00:15,493 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:15,523 - 

2023-01-06 13:00:15,524 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:15,916 - Epoch: [96][   10/   37]    Overall Loss 0.355851    Objective Loss 0.355851                                        LR 0.000022    Time 0.039126    
2023-01-06 13:00:16,126 - Epoch: [96][   20/   37]    Overall Loss 0.358054    Objective Loss 0.358054                                        LR 0.000022    Time 0.030059    
2023-01-06 13:00:16,362 - Epoch: [96][   30/   37]    Overall Loss 0.354641    Objective Loss 0.354641                                        LR 0.000022    Time 0.027901    
2023-01-06 13:00:16,510 - Epoch: [96][   37/   37]    Overall Loss 0.355042    Objective Loss 0.355042    Top1 84.937238    LR 0.000022    Time 0.026609    
2023-01-06 13:00:16,582 - --- validate (epoch=96)-----------
2023-01-06 13:00:16,583 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:16,794 - Epoch: [96][    5/    5]    Loss 0.362885    Top1 83.492366    
2023-01-06 13:00:16,861 - ==> Top1: 83.492    Loss: 0.363

2023-01-06 13:00:16,862 - ==> Confusion:
[[358  71   0]
 [102 517   0]
 [  0   0   0]]

2023-01-06 13:00:16,863 - ==> Best [Top1: 83.492   Sparsity:0.00   Params: 360896 on epoch: 96]
2023-01-06 13:00:16,863 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:16,885 - 

2023-01-06 13:00:16,885 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:17,292 - Epoch: [97][   10/   37]    Overall Loss 0.348619    Objective Loss 0.348619                                        LR 0.000022    Time 0.040616    
2023-01-06 13:00:17,533 - Epoch: [97][   20/   37]    Overall Loss 0.358023    Objective Loss 0.358023                                        LR 0.000022    Time 0.032364    
2023-01-06 13:00:17,785 - Epoch: [97][   30/   37]    Overall Loss 0.358438    Objective Loss 0.358438                                        LR 0.000022    Time 0.029942    
2023-01-06 13:00:17,938 - Epoch: [97][   37/   37]    Overall Loss 0.358019    Objective Loss 0.358019    Top1 85.774059    LR 0.000022    Time 0.028416    
2023-01-06 13:00:18,017 - --- validate (epoch=97)-----------
2023-01-06 13:00:18,017 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:18,235 - Epoch: [97][    5/    5]    Loss 0.362741    Top1 83.778626    
2023-01-06 13:00:18,304 - ==> Top1: 83.779    Loss: 0.363

2023-01-06 13:00:18,304 - ==> Confusion:
[[343  86   0]
 [ 84 535   0]
 [  0   0   0]]

2023-01-06 13:00:18,306 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 360896 on epoch: 97]
2023-01-06 13:00:18,306 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:18,337 - 

2023-01-06 13:00:18,337 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:18,719 - Epoch: [98][   10/   37]    Overall Loss 0.343893    Objective Loss 0.343893                                        LR 0.000022    Time 0.038135    
2023-01-06 13:00:18,924 - Epoch: [98][   20/   37]    Overall Loss 0.359563    Objective Loss 0.359563                                        LR 0.000022    Time 0.029281    
2023-01-06 13:00:19,133 - Epoch: [98][   30/   37]    Overall Loss 0.358141    Objective Loss 0.358141                                        LR 0.000022    Time 0.026401    
2023-01-06 13:00:19,275 - Epoch: [98][   37/   37]    Overall Loss 0.357936    Objective Loss 0.357936    Top1 85.983264    LR 0.000022    Time 0.025236    
2023-01-06 13:00:19,338 - --- validate (epoch=98)-----------
2023-01-06 13:00:19,338 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:19,545 - Epoch: [98][    5/    5]    Loss 0.392147    Top1 82.919847    
2023-01-06 13:00:19,611 - ==> Top1: 82.920    Loss: 0.392

2023-01-06 13:00:19,611 - ==> Confusion:
[[364  65   0]
 [114 505   0]
 [  0   0   0]]

2023-01-06 13:00:19,613 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 360896 on epoch: 97]
2023-01-06 13:00:19,613 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:19,633 - 

2023-01-06 13:00:19,633 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:20,160 - Epoch: [99][   10/   37]    Overall Loss 0.366821    Objective Loss 0.366821                                        LR 0.000022    Time 0.052624    
2023-01-06 13:00:20,412 - Epoch: [99][   20/   37]    Overall Loss 0.365674    Objective Loss 0.365674                                        LR 0.000022    Time 0.038871    
2023-01-06 13:00:20,660 - Epoch: [99][   30/   37]    Overall Loss 0.365272    Objective Loss 0.365272                                        LR 0.000022    Time 0.034104    
2023-01-06 13:00:20,813 - Epoch: [99][   37/   37]    Overall Loss 0.362224    Objective Loss 0.362224    Top1 88.075314    LR 0.000022    Time 0.031783    
2023-01-06 13:00:20,901 - --- validate (epoch=99)-----------
2023-01-06 13:00:20,901 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:21,113 - Epoch: [99][    5/    5]    Loss 0.351489    Top1 83.492366    
2023-01-06 13:00:21,181 - ==> Top1: 83.492    Loss: 0.351

2023-01-06 13:00:21,182 - ==> Confusion:
[[325 104   0]
 [ 69 550   0]
 [  0   0   0]]

2023-01-06 13:00:21,183 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 360896 on epoch: 97]
2023-01-06 13:00:21,183 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:21,203 - 

2023-01-06 13:00:21,203 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:21,618 - Epoch: [100][   10/   37]    Overall Loss 0.348276    Objective Loss 0.348276                                        LR 0.000013    Time 0.041365    
2023-01-06 13:00:21,868 - Epoch: [100][   20/   37]    Overall Loss 0.351822    Objective Loss 0.351822                                        LR 0.000013    Time 0.033185    
2023-01-06 13:00:22,116 - Epoch: [100][   30/   37]    Overall Loss 0.355836    Objective Loss 0.355836                                        LR 0.000013    Time 0.030347    
2023-01-06 13:00:22,270 - Epoch: [100][   37/   37]    Overall Loss 0.357145    Objective Loss 0.357145    Top1 80.543933    LR 0.000013    Time 0.028782    
2023-01-06 13:00:22,341 - --- validate (epoch=100)-----------
2023-01-06 13:00:22,342 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:22,555 - Epoch: [100][    5/    5]    Loss 0.379518    Top1 83.778626    
2023-01-06 13:00:22,630 - ==> Top1: 83.779    Loss: 0.380

2023-01-06 13:00:22,631 - ==> Confusion:
[[337  92   0]
 [ 78 541   0]
 [  0   0   0]]

2023-01-06 13:00:22,632 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 360896 on epoch: 100]
2023-01-06 13:00:22,632 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:22,656 - 

2023-01-06 13:00:22,657 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:23,046 - Epoch: [101][   10/   37]    Overall Loss 0.345433    Objective Loss 0.345433                                        LR 0.000013    Time 0.038841    
2023-01-06 13:00:23,288 - Epoch: [101][   20/   37]    Overall Loss 0.354382    Objective Loss 0.354382                                        LR 0.000013    Time 0.031490    
2023-01-06 13:00:23,538 - Epoch: [101][   30/   37]    Overall Loss 0.355773    Objective Loss 0.355773                                        LR 0.000013    Time 0.029268    
2023-01-06 13:00:23,691 - Epoch: [101][   37/   37]    Overall Loss 0.353115    Objective Loss 0.353115    Top1 83.891213    LR 0.000013    Time 0.027856    
2023-01-06 13:00:23,760 - --- validate (epoch=101)-----------
2023-01-06 13:00:23,761 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:23,973 - Epoch: [101][    5/    5]    Loss 0.400013    Top1 82.538168    
2023-01-06 13:00:24,028 - ==> Top1: 82.538    Loss: 0.400

2023-01-06 13:00:24,028 - ==> Confusion:
[[358  71   0]
 [112 507   0]
 [  0   0   0]]

2023-01-06 13:00:24,030 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 360896 on epoch: 100]
2023-01-06 13:00:24,030 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:24,051 - 

2023-01-06 13:00:24,051 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:24,459 - Epoch: [102][   10/   37]    Overall Loss 0.353426    Objective Loss 0.353426                                        LR 0.000013    Time 0.040738    
2023-01-06 13:00:24,699 - Epoch: [102][   20/   37]    Overall Loss 0.356235    Objective Loss 0.356235                                        LR 0.000013    Time 0.032339    
2023-01-06 13:00:24,951 - Epoch: [102][   30/   37]    Overall Loss 0.352452    Objective Loss 0.352452                                        LR 0.000013    Time 0.029888    
2023-01-06 13:00:25,103 - Epoch: [102][   37/   37]    Overall Loss 0.352497    Objective Loss 0.352497    Top1 82.008368    LR 0.000013    Time 0.028341    
2023-01-06 13:00:25,168 - --- validate (epoch=102)-----------
2023-01-06 13:00:25,169 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:25,385 - Epoch: [102][    5/    5]    Loss 0.384170    Top1 82.538168    
2023-01-06 13:00:25,453 - ==> Top1: 82.538    Loss: 0.384

2023-01-06 13:00:25,453 - ==> Confusion:
[[348  81   0]
 [102 517   0]
 [  0   0   0]]

2023-01-06 13:00:25,455 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 360896 on epoch: 100]
2023-01-06 13:00:25,455 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:25,475 - 

2023-01-06 13:00:25,475 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:25,897 - Epoch: [103][   10/   37]    Overall Loss 0.367625    Objective Loss 0.367625                                        LR 0.000013    Time 0.042144    
2023-01-06 13:00:26,142 - Epoch: [103][   20/   37]    Overall Loss 0.358630    Objective Loss 0.358630                                        LR 0.000013    Time 0.033280    
2023-01-06 13:00:26,385 - Epoch: [103][   30/   37]    Overall Loss 0.354964    Objective Loss 0.354964                                        LR 0.000013    Time 0.030254    
2023-01-06 13:00:26,538 - Epoch: [103][   37/   37]    Overall Loss 0.354590    Objective Loss 0.354590    Top1 83.682008    LR 0.000013    Time 0.028661    
2023-01-06 13:00:26,604 - --- validate (epoch=103)-----------
2023-01-06 13:00:26,604 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:26,812 - Epoch: [103][    5/    5]    Loss 0.387556    Top1 82.824427    
2023-01-06 13:00:26,884 - ==> Top1: 82.824    Loss: 0.388

2023-01-06 13:00:26,884 - ==> Confusion:
[[352  77   0]
 [103 516   0]
 [  0   0   0]]

2023-01-06 13:00:26,886 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 360896 on epoch: 100]
2023-01-06 13:00:26,886 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:26,896 - 

2023-01-06 13:00:26,896 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:27,286 - Epoch: [104][   10/   37]    Overall Loss 0.367325    Objective Loss 0.367325                                        LR 0.000013    Time 0.038900    
2023-01-06 13:00:27,519 - Epoch: [104][   20/   37]    Overall Loss 0.359453    Objective Loss 0.359453                                        LR 0.000013    Time 0.031093    
2023-01-06 13:00:27,771 - Epoch: [104][   30/   37]    Overall Loss 0.354879    Objective Loss 0.354879                                        LR 0.000013    Time 0.029063    
2023-01-06 13:00:27,922 - Epoch: [104][   37/   37]    Overall Loss 0.353250    Objective Loss 0.353250    Top1 87.029289    LR 0.000013    Time 0.027632    
2023-01-06 13:00:27,985 - --- validate (epoch=104)-----------
2023-01-06 13:00:27,986 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:28,196 - Epoch: [104][    5/    5]    Loss 0.406327    Top1 82.538168    
2023-01-06 13:00:28,255 - ==> Top1: 82.538    Loss: 0.406

2023-01-06 13:00:28,255 - ==> Confusion:
[[330  99   0]
 [ 84 535   0]
 [  0   0   0]]

2023-01-06 13:00:28,257 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 360896 on epoch: 100]
2023-01-06 13:00:28,257 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:28,266 - 

2023-01-06 13:00:28,267 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:28,674 - Epoch: [105][   10/   37]    Overall Loss 0.363965    Objective Loss 0.363965                                        LR 0.000013    Time 0.040700    
2023-01-06 13:00:28,920 - Epoch: [105][   20/   37]    Overall Loss 0.355449    Objective Loss 0.355449                                        LR 0.000013    Time 0.032591    
2023-01-06 13:00:29,161 - Epoch: [105][   30/   37]    Overall Loss 0.350928    Objective Loss 0.350928                                        LR 0.000013    Time 0.029758    
2023-01-06 13:00:29,312 - Epoch: [105][   37/   37]    Overall Loss 0.350671    Objective Loss 0.350671    Top1 81.589958    LR 0.000013    Time 0.028204    
2023-01-06 13:00:29,375 - --- validate (epoch=105)-----------
2023-01-06 13:00:29,375 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:29,588 - Epoch: [105][    5/    5]    Loss 0.355954    Top1 83.110687    
2023-01-06 13:00:29,657 - ==> Top1: 83.111    Loss: 0.356

2023-01-06 13:00:29,658 - ==> Confusion:
[[353  76   0]
 [101 518   0]
 [  0   0   0]]

2023-01-06 13:00:29,659 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 360896 on epoch: 100]
2023-01-06 13:00:29,659 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:29,680 - 

2023-01-06 13:00:29,680 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:30,082 - Epoch: [106][   10/   37]    Overall Loss 0.338458    Objective Loss 0.338458                                        LR 0.000013    Time 0.040077    
2023-01-06 13:00:30,336 - Epoch: [106][   20/   37]    Overall Loss 0.349402    Objective Loss 0.349402                                        LR 0.000013    Time 0.032747    
2023-01-06 13:00:30,586 - Epoch: [106][   30/   37]    Overall Loss 0.347187    Objective Loss 0.347187                                        LR 0.000013    Time 0.030122    
2023-01-06 13:00:30,740 - Epoch: [106][   37/   37]    Overall Loss 0.350611    Objective Loss 0.350611    Top1 82.217573    LR 0.000013    Time 0.028601    
2023-01-06 13:00:30,827 - --- validate (epoch=106)-----------
2023-01-06 13:00:30,827 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:31,035 - Epoch: [106][    5/    5]    Loss 0.385388    Top1 82.251908    
2023-01-06 13:00:31,100 - ==> Top1: 82.252    Loss: 0.385

2023-01-06 13:00:31,100 - ==> Confusion:
[[325 104   0]
 [ 82 537   0]
 [  0   0   0]]

2023-01-06 13:00:31,102 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 360896 on epoch: 100]
2023-01-06 13:00:31,102 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:31,122 - 

2023-01-06 13:00:31,122 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:31,527 - Epoch: [107][   10/   37]    Overall Loss 0.366832    Objective Loss 0.366832                                        LR 0.000013    Time 0.040497    
2023-01-06 13:00:31,768 - Epoch: [107][   20/   37]    Overall Loss 0.360689    Objective Loss 0.360689                                        LR 0.000013    Time 0.032250    
2023-01-06 13:00:32,015 - Epoch: [107][   30/   37]    Overall Loss 0.362451    Objective Loss 0.362451                                        LR 0.000013    Time 0.029729    
2023-01-06 13:00:32,168 - Epoch: [107][   37/   37]    Overall Loss 0.358320    Objective Loss 0.358320    Top1 84.728033    LR 0.000013    Time 0.028224    
2023-01-06 13:00:32,242 - --- validate (epoch=107)-----------
2023-01-06 13:00:32,243 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:32,453 - Epoch: [107][    5/    5]    Loss 0.369816    Top1 82.442748    
2023-01-06 13:00:32,512 - ==> Top1: 82.443    Loss: 0.370

2023-01-06 13:00:32,512 - ==> Confusion:
[[341  88   0]
 [ 96 523   0]
 [  0   0   0]]

2023-01-06 13:00:32,514 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 360896 on epoch: 100]
2023-01-06 13:00:32,514 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:32,534 - 

2023-01-06 13:00:32,534 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:32,914 - Epoch: [108][   10/   37]    Overall Loss 0.356283    Objective Loss 0.356283                                        LR 0.000013    Time 0.037876    
2023-01-06 13:00:33,136 - Epoch: [108][   20/   37]    Overall Loss 0.353952    Objective Loss 0.353952                                        LR 0.000013    Time 0.030043    
2023-01-06 13:00:33,378 - Epoch: [108][   30/   37]    Overall Loss 0.352371    Objective Loss 0.352371                                        LR 0.000013    Time 0.028056    
2023-01-06 13:00:33,530 - Epoch: [108][   37/   37]    Overall Loss 0.350816    Objective Loss 0.350816    Top1 82.426778    LR 0.000013    Time 0.026843    
2023-01-06 13:00:33,594 - --- validate (epoch=108)-----------
2023-01-06 13:00:33,594 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:33,806 - Epoch: [108][    5/    5]    Loss 0.368623    Top1 82.919847    
2023-01-06 13:00:33,869 - ==> Top1: 82.920    Loss: 0.369

2023-01-06 13:00:33,869 - ==> Confusion:
[[365  64   0]
 [115 504   0]
 [  0   0   0]]

2023-01-06 13:00:33,871 - ==> Best [Top1: 83.779   Sparsity:0.00   Params: 360896 on epoch: 100]
2023-01-06 13:00:33,871 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:33,891 - 

2023-01-06 13:00:33,891 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:34,313 - Epoch: [109][   10/   37]    Overall Loss 0.355390    Objective Loss 0.355390                                        LR 0.000013    Time 0.042064    
2023-01-06 13:00:34,567 - Epoch: [109][   20/   37]    Overall Loss 0.347412    Objective Loss 0.347412                                        LR 0.000013    Time 0.033733    
2023-01-06 13:00:34,820 - Epoch: [109][   30/   37]    Overall Loss 0.345637    Objective Loss 0.345637                                        LR 0.000013    Time 0.030891    
2023-01-06 13:00:34,971 - Epoch: [109][   37/   37]    Overall Loss 0.348045    Objective Loss 0.348045    Top1 84.728033    LR 0.000013    Time 0.029132    
2023-01-06 13:00:35,042 - --- validate (epoch=109)-----------
2023-01-06 13:00:35,042 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:35,251 - Epoch: [109][    5/    5]    Loss 0.376860    Top1 83.874046    
2023-01-06 13:00:35,312 - ==> Top1: 83.874    Loss: 0.377

2023-01-06 13:00:35,312 - ==> Confusion:
[[356  73   0]
 [ 96 523   0]
 [  0   0   0]]

2023-01-06 13:00:35,314 - ==> Best [Top1: 83.874   Sparsity:0.00   Params: 360896 on epoch: 109]
2023-01-06 13:00:35,314 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:35,344 - 

2023-01-06 13:00:35,345 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:35,769 - Epoch: [110][   10/   37]    Overall Loss 0.352919    Objective Loss 0.352919                                        LR 0.000013    Time 0.042325    
2023-01-06 13:00:36,033 - Epoch: [110][   20/   37]    Overall Loss 0.356467    Objective Loss 0.356467                                        LR 0.000013    Time 0.034379    
2023-01-06 13:00:36,277 - Epoch: [110][   30/   37]    Overall Loss 0.352839    Objective Loss 0.352839                                        LR 0.000013    Time 0.031012    
2023-01-06 13:00:36,430 - Epoch: [110][   37/   37]    Overall Loss 0.350794    Objective Loss 0.350794    Top1 85.774059    LR 0.000013    Time 0.029278    
2023-01-06 13:00:36,502 - --- validate (epoch=110)-----------
2023-01-06 13:00:36,502 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:36,713 - Epoch: [110][    5/    5]    Loss 0.456115    Top1 82.824427    
2023-01-06 13:00:36,772 - ==> Top1: 82.824    Loss: 0.456

2023-01-06 13:00:36,772 - ==> Confusion:
[[345  84   0]
 [ 96 523   0]
 [  0   0   0]]

2023-01-06 13:00:36,773 - ==> Best [Top1: 83.874   Sparsity:0.00   Params: 360896 on epoch: 109]
2023-01-06 13:00:36,773 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:36,783 - 

2023-01-06 13:00:36,784 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:37,189 - Epoch: [111][   10/   37]    Overall Loss 0.340680    Objective Loss 0.340680                                        LR 0.000013    Time 0.040458    
2023-01-06 13:00:37,426 - Epoch: [111][   20/   37]    Overall Loss 0.342591    Objective Loss 0.342591                                        LR 0.000013    Time 0.032055    
2023-01-06 13:00:37,669 - Epoch: [111][   30/   37]    Overall Loss 0.344328    Objective Loss 0.344328                                        LR 0.000013    Time 0.029387    
2023-01-06 13:00:37,823 - Epoch: [111][   37/   37]    Overall Loss 0.346600    Objective Loss 0.346600    Top1 83.682008    LR 0.000013    Time 0.027981    
2023-01-06 13:00:37,885 - --- validate (epoch=111)-----------
2023-01-06 13:00:37,886 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:38,098 - Epoch: [111][    5/    5]    Loss 0.428843    Top1 82.442748    
2023-01-06 13:00:38,170 - ==> Top1: 82.443    Loss: 0.429

2023-01-06 13:00:38,170 - ==> Confusion:
[[361  68   0]
 [116 503   0]
 [  0   0   0]]

2023-01-06 13:00:38,172 - ==> Best [Top1: 83.874   Sparsity:0.00   Params: 360896 on epoch: 109]
2023-01-06 13:00:38,172 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:38,189 - 

2023-01-06 13:00:38,189 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:38,596 - Epoch: [112][   10/   37]    Overall Loss 0.351861    Objective Loss 0.351861                                        LR 0.000013    Time 0.040583    
2023-01-06 13:00:38,839 - Epoch: [112][   20/   37]    Overall Loss 0.347877    Objective Loss 0.347877                                        LR 0.000013    Time 0.032436    
2023-01-06 13:00:39,083 - Epoch: [112][   30/   37]    Overall Loss 0.350121    Objective Loss 0.350121                                        LR 0.000013    Time 0.029738    
2023-01-06 13:00:39,235 - Epoch: [112][   37/   37]    Overall Loss 0.349387    Objective Loss 0.349387    Top1 83.054393    LR 0.000013    Time 0.028214    
2023-01-06 13:00:39,303 - --- validate (epoch=112)-----------
2023-01-06 13:00:39,303 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:39,515 - Epoch: [112][    5/    5]    Loss 0.388231    Top1 82.347328    
2023-01-06 13:00:39,582 - ==> Top1: 82.347    Loss: 0.388

2023-01-06 13:00:39,582 - ==> Confusion:
[[374  55   0]
 [130 489   0]
 [  0   0   0]]

2023-01-06 13:00:39,584 - ==> Best [Top1: 83.874   Sparsity:0.00   Params: 360896 on epoch: 109]
2023-01-06 13:00:39,584 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:39,604 - 

2023-01-06 13:00:39,604 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:40,002 - Epoch: [113][   10/   37]    Overall Loss 0.362902    Objective Loss 0.362902                                        LR 0.000013    Time 0.039789    
2023-01-06 13:00:40,252 - Epoch: [113][   20/   37]    Overall Loss 0.351843    Objective Loss 0.351843                                        LR 0.000013    Time 0.032362    
2023-01-06 13:00:40,501 - Epoch: [113][   30/   37]    Overall Loss 0.352271    Objective Loss 0.352271                                        LR 0.000013    Time 0.029810    
2023-01-06 13:00:40,654 - Epoch: [113][   37/   37]    Overall Loss 0.349127    Objective Loss 0.349127    Top1 83.682008    LR 0.000013    Time 0.028305    
2023-01-06 13:00:40,731 - --- validate (epoch=113)-----------
2023-01-06 13:00:40,731 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:41,201 - Epoch: [113][    5/    5]    Loss 0.368642    Top1 83.110687    
2023-01-06 13:00:41,268 - ==> Top1: 83.111    Loss: 0.369

2023-01-06 13:00:41,268 - ==> Confusion:
[[340  89   0]
 [ 88 531   0]
 [  0   0   0]]

2023-01-06 13:00:41,270 - ==> Best [Top1: 83.874   Sparsity:0.00   Params: 360896 on epoch: 109]
2023-01-06 13:00:41,271 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:41,298 - 

2023-01-06 13:00:41,298 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:41,727 - Epoch: [114][   10/   37]    Overall Loss 0.354001    Objective Loss 0.354001                                        LR 0.000013    Time 0.042772    
2023-01-06 13:00:41,980 - Epoch: [114][   20/   37]    Overall Loss 0.352304    Objective Loss 0.352304                                        LR 0.000013    Time 0.033987    
2023-01-06 13:00:42,226 - Epoch: [114][   30/   37]    Overall Loss 0.352074    Objective Loss 0.352074                                        LR 0.000013    Time 0.030852    
2023-01-06 13:00:42,377 - Epoch: [114][   37/   37]    Overall Loss 0.352330    Objective Loss 0.352330    Top1 84.937238    LR 0.000013    Time 0.029103    
2023-01-06 13:00:42,445 - --- validate (epoch=114)-----------
2023-01-06 13:00:42,445 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:42,652 - Epoch: [114][    5/    5]    Loss 0.366904    Top1 81.011450    
2023-01-06 13:00:42,722 - ==> Top1: 81.011    Loss: 0.367

2023-01-06 13:00:42,723 - ==> Confusion:
[[373  56   0]
 [143 476   0]
 [  0   0   0]]

2023-01-06 13:00:42,724 - ==> Best [Top1: 83.874   Sparsity:0.00   Params: 360896 on epoch: 109]
2023-01-06 13:00:42,724 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:42,745 - 

2023-01-06 13:00:42,745 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:43,152 - Epoch: [115][   10/   37]    Overall Loss 0.339582    Objective Loss 0.339582                                        LR 0.000013    Time 0.040659    
2023-01-06 13:00:43,406 - Epoch: [115][   20/   37]    Overall Loss 0.344817    Objective Loss 0.344817                                        LR 0.000013    Time 0.032988    
2023-01-06 13:00:43,654 - Epoch: [115][   30/   37]    Overall Loss 0.347058    Objective Loss 0.347058                                        LR 0.000013    Time 0.030253    
2023-01-06 13:00:43,808 - Epoch: [115][   37/   37]    Overall Loss 0.348531    Objective Loss 0.348531    Top1 84.518828    LR 0.000013    Time 0.028694    
2023-01-06 13:00:43,875 - --- validate (epoch=115)-----------
2023-01-06 13:00:43,876 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:44,085 - Epoch: [115][    5/    5]    Loss 0.431935    Top1 82.061069    
2023-01-06 13:00:44,155 - ==> Top1: 82.061    Loss: 0.432

2023-01-06 13:00:44,155 - ==> Confusion:
[[349  80   0]
 [108 511   0]
 [  0   0   0]]

2023-01-06 13:00:44,157 - ==> Best [Top1: 83.874   Sparsity:0.00   Params: 360896 on epoch: 109]
2023-01-06 13:00:44,157 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:44,177 - 

2023-01-06 13:00:44,177 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:44,587 - Epoch: [116][   10/   37]    Overall Loss 0.342152    Objective Loss 0.342152                                        LR 0.000013    Time 0.040890    
2023-01-06 13:00:44,834 - Epoch: [116][   20/   37]    Overall Loss 0.344287    Objective Loss 0.344287                                        LR 0.000013    Time 0.032764    
2023-01-06 13:00:45,081 - Epoch: [116][   30/   37]    Overall Loss 0.344530    Objective Loss 0.344530                                        LR 0.000013    Time 0.030017    
2023-01-06 13:00:45,231 - Epoch: [116][   37/   37]    Overall Loss 0.348466    Objective Loss 0.348466    Top1 82.845188    LR 0.000013    Time 0.028396    
2023-01-06 13:00:45,303 - --- validate (epoch=116)-----------
2023-01-06 13:00:45,303 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:45,513 - Epoch: [116][    5/    5]    Loss 0.418780    Top1 81.965649    
2023-01-06 13:00:45,580 - ==> Top1: 81.966    Loss: 0.419

2023-01-06 13:00:45,581 - ==> Confusion:
[[356  73   0]
 [116 503   0]
 [  0   0   0]]

2023-01-06 13:00:45,582 - ==> Best [Top1: 83.874   Sparsity:0.00   Params: 360896 on epoch: 109]
2023-01-06 13:00:45,582 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:45,602 - 

2023-01-06 13:00:45,602 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:46,015 - Epoch: [117][   10/   37]    Overall Loss 0.376202    Objective Loss 0.376202                                        LR 0.000013    Time 0.041257    
2023-01-06 13:00:46,272 - Epoch: [117][   20/   37]    Overall Loss 0.364395    Objective Loss 0.364395                                        LR 0.000013    Time 0.033419    
2023-01-06 13:00:46,522 - Epoch: [117][   30/   37]    Overall Loss 0.348825    Objective Loss 0.348825                                        LR 0.000013    Time 0.030616    
2023-01-06 13:00:46,674 - Epoch: [117][   37/   37]    Overall Loss 0.348071    Objective Loss 0.348071    Top1 81.589958    LR 0.000013    Time 0.028918    
2023-01-06 13:00:46,740 - --- validate (epoch=117)-----------
2023-01-06 13:00:46,741 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:46,948 - Epoch: [117][    5/    5]    Loss 0.361050    Top1 82.824427    
2023-01-06 13:00:47,011 - ==> Top1: 82.824    Loss: 0.361

2023-01-06 13:00:47,012 - ==> Confusion:
[[350  79   0]
 [101 518   0]
 [  0   0   0]]

2023-01-06 13:00:47,014 - ==> Best [Top1: 83.874   Sparsity:0.00   Params: 360896 on epoch: 109]
2023-01-06 13:00:47,014 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:47,038 - 

2023-01-06 13:00:47,038 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:47,455 - Epoch: [118][   10/   37]    Overall Loss 0.350819    Objective Loss 0.350819                                        LR 0.000013    Time 0.041565    
2023-01-06 13:00:47,690 - Epoch: [118][   20/   37]    Overall Loss 0.344844    Objective Loss 0.344844                                        LR 0.000013    Time 0.032542    
2023-01-06 13:00:47,927 - Epoch: [118][   30/   37]    Overall Loss 0.342091    Objective Loss 0.342091                                        LR 0.000013    Time 0.029568    
2023-01-06 13:00:48,078 - Epoch: [118][   37/   37]    Overall Loss 0.345400    Objective Loss 0.345400    Top1 82.635983    LR 0.000013    Time 0.028070    
2023-01-06 13:00:48,147 - --- validate (epoch=118)-----------
2023-01-06 13:00:48,147 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:48,356 - Epoch: [118][    5/    5]    Loss 0.372662    Top1 83.015267    
2023-01-06 13:00:48,425 - ==> Top1: 83.015    Loss: 0.373

2023-01-06 13:00:48,425 - ==> Confusion:
[[370  59   0]
 [119 500   0]
 [  0   0   0]]

2023-01-06 13:00:48,427 - ==> Best [Top1: 83.874   Sparsity:0.00   Params: 360896 on epoch: 109]
2023-01-06 13:00:48,427 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:48,436 - 

2023-01-06 13:00:48,437 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:48,839 - Epoch: [119][   10/   37]    Overall Loss 0.345957    Objective Loss 0.345957                                        LR 0.000013    Time 0.040186    
2023-01-06 13:00:49,093 - Epoch: [119][   20/   37]    Overall Loss 0.350176    Objective Loss 0.350176                                        LR 0.000013    Time 0.032761    
2023-01-06 13:00:49,343 - Epoch: [119][   30/   37]    Overall Loss 0.350210    Objective Loss 0.350210                                        LR 0.000013    Time 0.030151    
2023-01-06 13:00:49,495 - Epoch: [119][   37/   37]    Overall Loss 0.344139    Objective Loss 0.344139    Top1 85.983264    LR 0.000013    Time 0.028558    
2023-01-06 13:00:49,577 - --- validate (epoch=119)-----------
2023-01-06 13:00:49,577 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:49,802 - Epoch: [119][    5/    5]    Loss 0.391522    Top1 83.969466    
2023-01-06 13:00:49,867 - ==> Top1: 83.969    Loss: 0.392

2023-01-06 13:00:49,867 - ==> Confusion:
[[336  93   0]
 [ 75 544   0]
 [  0   0   0]]

2023-01-06 13:00:49,869 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 360896 on epoch: 119]
2023-01-06 13:00:49,869 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:49,900 - 

2023-01-06 13:00:49,901 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:50,317 - Epoch: [120][   10/   37]    Overall Loss 0.348277    Objective Loss 0.348277                                        LR 0.000013    Time 0.041518    
2023-01-06 13:00:50,559 - Epoch: [120][   20/   37]    Overall Loss 0.339905    Objective Loss 0.339905                                        LR 0.000013    Time 0.032853    
2023-01-06 13:00:50,806 - Epoch: [120][   30/   37]    Overall Loss 0.342609    Objective Loss 0.342609                                        LR 0.000013    Time 0.030079    
2023-01-06 13:00:50,958 - Epoch: [120][   37/   37]    Overall Loss 0.346680    Objective Loss 0.346680    Top1 83.682008    LR 0.000013    Time 0.028511    
2023-01-06 13:00:51,027 - --- validate (epoch=120)-----------
2023-01-06 13:00:51,027 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:51,239 - Epoch: [120][    5/    5]    Loss 0.395457    Top1 83.492366    
2023-01-06 13:00:51,300 - ==> Top1: 83.492    Loss: 0.395

2023-01-06 13:00:51,301 - ==> Confusion:
[[358  71   0]
 [102 517   0]
 [  0   0   0]]

2023-01-06 13:00:51,302 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 360896 on epoch: 119]
2023-01-06 13:00:51,302 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:51,323 - 

2023-01-06 13:00:51,323 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:51,738 - Epoch: [121][   10/   37]    Overall Loss 0.345309    Objective Loss 0.345309                                        LR 0.000013    Time 0.041433    
2023-01-06 13:00:51,992 - Epoch: [121][   20/   37]    Overall Loss 0.341582    Objective Loss 0.341582                                        LR 0.000013    Time 0.033389    
2023-01-06 13:00:52,239 - Epoch: [121][   30/   37]    Overall Loss 0.343198    Objective Loss 0.343198                                        LR 0.000013    Time 0.030461    
2023-01-06 13:00:52,391 - Epoch: [121][   37/   37]    Overall Loss 0.341847    Objective Loss 0.341847    Top1 82.635983    LR 0.000013    Time 0.028806    
2023-01-06 13:00:52,476 - --- validate (epoch=121)-----------
2023-01-06 13:00:52,476 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:52,690 - Epoch: [121][    5/    5]    Loss 0.348865    Top1 83.683206    
2023-01-06 13:00:52,760 - ==> Top1: 83.683    Loss: 0.349

2023-01-06 13:00:52,760 - ==> Confusion:
[[351  78   0]
 [ 93 526   0]
 [  0   0   0]]

2023-01-06 13:00:52,762 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 360896 on epoch: 119]
2023-01-06 13:00:52,762 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:52,782 - 

2023-01-06 13:00:52,782 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:53,196 - Epoch: [122][   10/   37]    Overall Loss 0.348181    Objective Loss 0.348181                                        LR 0.000013    Time 0.041356    
2023-01-06 13:00:53,442 - Epoch: [122][   20/   37]    Overall Loss 0.336100    Objective Loss 0.336100                                        LR 0.000013    Time 0.032923    
2023-01-06 13:00:53,688 - Epoch: [122][   30/   37]    Overall Loss 0.340442    Objective Loss 0.340442                                        LR 0.000013    Time 0.030161    
2023-01-06 13:00:53,841 - Epoch: [122][   37/   37]    Overall Loss 0.341403    Objective Loss 0.341403    Top1 82.426778    LR 0.000013    Time 0.028580    
2023-01-06 13:00:53,909 - --- validate (epoch=122)-----------
2023-01-06 13:00:53,909 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:54,118 - Epoch: [122][    5/    5]    Loss 0.349560    Top1 83.110687    
2023-01-06 13:00:54,181 - ==> Top1: 83.111    Loss: 0.350

2023-01-06 13:00:54,182 - ==> Confusion:
[[336  93   0]
 [ 84 535   0]
 [  0   0   0]]

2023-01-06 13:00:54,183 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 360896 on epoch: 119]
2023-01-06 13:00:54,183 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:54,193 - 

2023-01-06 13:00:54,193 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:54,592 - Epoch: [123][   10/   37]    Overall Loss 0.348135    Objective Loss 0.348135                                        LR 0.000013    Time 0.039852    
2023-01-06 13:00:54,841 - Epoch: [123][   20/   37]    Overall Loss 0.349445    Objective Loss 0.349445                                        LR 0.000013    Time 0.032355    
2023-01-06 13:00:55,093 - Epoch: [123][   30/   37]    Overall Loss 0.344506    Objective Loss 0.344506                                        LR 0.000013    Time 0.029944    
2023-01-06 13:00:55,247 - Epoch: [123][   37/   37]    Overall Loss 0.343481    Objective Loss 0.343481    Top1 87.029289    LR 0.000013    Time 0.028435    
2023-01-06 13:00:55,314 - --- validate (epoch=123)-----------
2023-01-06 13:00:55,315 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:55,530 - Epoch: [123][    5/    5]    Loss 0.387455    Top1 82.919847    
2023-01-06 13:00:55,584 - ==> Top1: 82.920    Loss: 0.387

2023-01-06 13:00:55,585 - ==> Confusion:
[[364  65   0]
 [114 505   0]
 [  0   0   0]]

2023-01-06 13:00:55,586 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 360896 on epoch: 119]
2023-01-06 13:00:55,586 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:55,607 - 

2023-01-06 13:00:55,607 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:56,012 - Epoch: [124][   10/   37]    Overall Loss 0.344556    Objective Loss 0.344556                                        LR 0.000013    Time 0.040390    
2023-01-06 13:00:56,256 - Epoch: [124][   20/   37]    Overall Loss 0.337642    Objective Loss 0.337642                                        LR 0.000013    Time 0.032409    
2023-01-06 13:00:56,499 - Epoch: [124][   30/   37]    Overall Loss 0.339491    Objective Loss 0.339491                                        LR 0.000013    Time 0.029698    
2023-01-06 13:00:56,653 - Epoch: [124][   37/   37]    Overall Loss 0.339546    Objective Loss 0.339546    Top1 85.355649    LR 0.000013    Time 0.028227    
2023-01-06 13:00:56,727 - --- validate (epoch=124)-----------
2023-01-06 13:00:56,727 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:56,933 - Epoch: [124][    5/    5]    Loss 0.354913    Top1 82.061069    
2023-01-06 13:00:56,988 - ==> Top1: 82.061    Loss: 0.355

2023-01-06 13:00:56,988 - ==> Confusion:
[[316 113   0]
 [ 75 544   0]
 [  0   0   0]]

2023-01-06 13:00:56,990 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 360896 on epoch: 119]
2023-01-06 13:00:56,990 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:57,010 - 

2023-01-06 13:00:57,010 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:57,407 - Epoch: [125][   10/   37]    Overall Loss 0.351710    Objective Loss 0.351710                                        LR 0.000013    Time 0.039609    
2023-01-06 13:00:57,667 - Epoch: [125][   20/   37]    Overall Loss 0.349927    Objective Loss 0.349927                                        LR 0.000013    Time 0.032767    
2023-01-06 13:00:57,920 - Epoch: [125][   30/   37]    Overall Loss 0.346342    Objective Loss 0.346342                                        LR 0.000013    Time 0.030278    
2023-01-06 13:00:58,074 - Epoch: [125][   37/   37]    Overall Loss 0.344700    Objective Loss 0.344700    Top1 84.728033    LR 0.000013    Time 0.028702    
2023-01-06 13:00:58,144 - --- validate (epoch=125)-----------
2023-01-06 13:00:58,144 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:58,365 - Epoch: [125][    5/    5]    Loss 0.381216    Top1 83.110687    
2023-01-06 13:00:58,432 - ==> Top1: 83.111    Loss: 0.381

2023-01-06 13:00:58,432 - ==> Confusion:
[[329 100   0]
 [ 77 542   0]
 [  0   0   0]]

2023-01-06 13:00:58,434 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 360896 on epoch: 119]
2023-01-06 13:00:58,434 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:58,454 - 

2023-01-06 13:00:58,454 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:00:58,958 - Epoch: [126][   10/   37]    Overall Loss 0.325893    Objective Loss 0.325893                                        LR 0.000013    Time 0.050292    
2023-01-06 13:00:59,199 - Epoch: [126][   20/   37]    Overall Loss 0.335390    Objective Loss 0.335390                                        LR 0.000013    Time 0.037187    
2023-01-06 13:00:59,446 - Epoch: [126][   30/   37]    Overall Loss 0.341600    Objective Loss 0.341600                                        LR 0.000013    Time 0.033004    
2023-01-06 13:00:59,600 - Epoch: [126][   37/   37]    Overall Loss 0.343450    Objective Loss 0.343450    Top1 82.845188    LR 0.000013    Time 0.030931    
2023-01-06 13:00:59,669 - --- validate (epoch=126)-----------
2023-01-06 13:00:59,669 - 1048 samples (256 per mini-batch)
2023-01-06 13:00:59,880 - Epoch: [126][    5/    5]    Loss 0.379282    Top1 82.729008    
2023-01-06 13:00:59,942 - ==> Top1: 82.729    Loss: 0.379

2023-01-06 13:00:59,942 - ==> Confusion:
[[341  88   0]
 [ 93 526   0]
 [  0   0   0]]

2023-01-06 13:00:59,944 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 360896 on epoch: 119]
2023-01-06 13:00:59,944 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:00:59,964 - 

2023-01-06 13:00:59,964 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:00,372 - Epoch: [127][   10/   37]    Overall Loss 0.346891    Objective Loss 0.346891                                        LR 0.000013    Time 0.040760    
2023-01-06 13:01:00,618 - Epoch: [127][   20/   37]    Overall Loss 0.338737    Objective Loss 0.338737                                        LR 0.000013    Time 0.032621    
2023-01-06 13:01:00,871 - Epoch: [127][   30/   37]    Overall Loss 0.344306    Objective Loss 0.344306                                        LR 0.000013    Time 0.030174    
2023-01-06 13:01:01,017 - Epoch: [127][   37/   37]    Overall Loss 0.345116    Objective Loss 0.345116    Top1 84.937238    LR 0.000013    Time 0.028415    
2023-01-06 13:01:01,087 - --- validate (epoch=127)-----------
2023-01-06 13:01:01,087 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:01,298 - Epoch: [127][    5/    5]    Loss 0.375052    Top1 83.206107    
2023-01-06 13:01:01,360 - ==> Top1: 83.206    Loss: 0.375

2023-01-06 13:01:01,360 - ==> Confusion:
[[370  59   0]
 [117 502   0]
 [  0   0   0]]

2023-01-06 13:01:01,361 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 360896 on epoch: 119]
2023-01-06 13:01:01,362 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:01,382 - 

2023-01-06 13:01:01,382 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:01,765 - Epoch: [128][   10/   37]    Overall Loss 0.327505    Objective Loss 0.327505                                        LR 0.000013    Time 0.038269    
2023-01-06 13:01:02,001 - Epoch: [128][   20/   37]    Overall Loss 0.333572    Objective Loss 0.333572                                        LR 0.000013    Time 0.030911    
2023-01-06 13:01:02,244 - Epoch: [128][   30/   37]    Overall Loss 0.345711    Objective Loss 0.345711                                        LR 0.000013    Time 0.028684    
2023-01-06 13:01:02,397 - Epoch: [128][   37/   37]    Overall Loss 0.342402    Objective Loss 0.342402    Top1 85.774059    LR 0.000013    Time 0.027403    
2023-01-06 13:01:02,464 - --- validate (epoch=128)-----------
2023-01-06 13:01:02,465 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:02,672 - Epoch: [128][    5/    5]    Loss 0.381226    Top1 83.110687    
2023-01-06 13:01:02,723 - ==> Top1: 83.111    Loss: 0.381

2023-01-06 13:01:02,723 - ==> Confusion:
[[365  64   0]
 [113 506   0]
 [  0   0   0]]

2023-01-06 13:01:02,725 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 360896 on epoch: 119]
2023-01-06 13:01:02,725 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:02,745 - 

2023-01-06 13:01:02,745 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:03,148 - Epoch: [129][   10/   37]    Overall Loss 0.337345    Objective Loss 0.337345                                        LR 0.000013    Time 0.040251    
2023-01-06 13:01:03,387 - Epoch: [129][   20/   37]    Overall Loss 0.337347    Objective Loss 0.337347                                        LR 0.000013    Time 0.032037    
2023-01-06 13:01:03,634 - Epoch: [129][   30/   37]    Overall Loss 0.340222    Objective Loss 0.340222                                        LR 0.000013    Time 0.029587    
2023-01-06 13:01:03,787 - Epoch: [129][   37/   37]    Overall Loss 0.340035    Objective Loss 0.340035    Top1 82.635983    LR 0.000013    Time 0.028120    
2023-01-06 13:01:03,859 - --- validate (epoch=129)-----------
2023-01-06 13:01:03,859 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:04,062 - Epoch: [129][    5/    5]    Loss 0.355952    Top1 83.969466    
2023-01-06 13:01:04,121 - ==> Top1: 83.969    Loss: 0.356

2023-01-06 13:01:04,121 - ==> Confusion:
[[356  73   0]
 [ 95 524   0]
 [  0   0   0]]

2023-01-06 13:01:04,123 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 360896 on epoch: 129]
2023-01-06 13:01:04,123 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:04,147 - 

2023-01-06 13:01:04,147 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:04,523 - Epoch: [130][   10/   37]    Overall Loss 0.346822    Objective Loss 0.346822                                        LR 0.000013    Time 0.037512    
2023-01-06 13:01:04,730 - Epoch: [130][   20/   37]    Overall Loss 0.336548    Objective Loss 0.336548                                        LR 0.000013    Time 0.029110    
2023-01-06 13:01:04,958 - Epoch: [130][   30/   37]    Overall Loss 0.342419    Objective Loss 0.342419                                        LR 0.000013    Time 0.026992    
2023-01-06 13:01:05,111 - Epoch: [130][   37/   37]    Overall Loss 0.344252    Objective Loss 0.344252    Top1 88.075314    LR 0.000013    Time 0.026008    
2023-01-06 13:01:05,176 - --- validate (epoch=130)-----------
2023-01-06 13:01:05,176 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:05,386 - Epoch: [130][    5/    5]    Loss 0.361480    Top1 83.778626    
2023-01-06 13:01:05,454 - ==> Top1: 83.779    Loss: 0.361

2023-01-06 13:01:05,454 - ==> Confusion:
[[336  93   0]
 [ 77 542   0]
 [  0   0   0]]

2023-01-06 13:01:05,456 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 360896 on epoch: 129]
2023-01-06 13:01:05,456 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:05,466 - 

2023-01-06 13:01:05,466 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:05,873 - Epoch: [131][   10/   37]    Overall Loss 0.349590    Objective Loss 0.349590                                        LR 0.000013    Time 0.040650    
2023-01-06 13:01:06,119 - Epoch: [131][   20/   37]    Overall Loss 0.344936    Objective Loss 0.344936                                        LR 0.000013    Time 0.032607    
2023-01-06 13:01:06,367 - Epoch: [131][   30/   37]    Overall Loss 0.343798    Objective Loss 0.343798                                        LR 0.000013    Time 0.029983    
2023-01-06 13:01:06,520 - Epoch: [131][   37/   37]    Overall Loss 0.342156    Objective Loss 0.342156    Top1 85.983264    LR 0.000013    Time 0.028446    
2023-01-06 13:01:06,586 - --- validate (epoch=131)-----------
2023-01-06 13:01:06,587 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:06,797 - Epoch: [131][    5/    5]    Loss 0.369107    Top1 82.251908    
2023-01-06 13:01:06,866 - ==> Top1: 82.252    Loss: 0.369

2023-01-06 13:01:06,866 - ==> Confusion:
[[368  61   0]
 [125 494   0]
 [  0   0   0]]

2023-01-06 13:01:06,868 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 360896 on epoch: 129]
2023-01-06 13:01:06,868 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:06,888 - 

2023-01-06 13:01:06,888 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:07,280 - Epoch: [132][   10/   37]    Overall Loss 0.335471    Objective Loss 0.335471                                        LR 0.000013    Time 0.039082    
2023-01-06 13:01:07,517 - Epoch: [132][   20/   37]    Overall Loss 0.341246    Objective Loss 0.341246                                        LR 0.000013    Time 0.031377    
2023-01-06 13:01:07,767 - Epoch: [132][   30/   37]    Overall Loss 0.339400    Objective Loss 0.339400                                        LR 0.000013    Time 0.029267    
2023-01-06 13:01:07,920 - Epoch: [132][   37/   37]    Overall Loss 0.337505    Objective Loss 0.337505    Top1 87.029289    LR 0.000013    Time 0.027858    
2023-01-06 13:01:07,985 - --- validate (epoch=132)-----------
2023-01-06 13:01:07,985 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:08,193 - Epoch: [132][    5/    5]    Loss 0.358099    Top1 82.347328    
2023-01-06 13:01:08,266 - ==> Top1: 82.347    Loss: 0.358

2023-01-06 13:01:08,266 - ==> Confusion:
[[361  68   0]
 [117 502   0]
 [  0   0   0]]

2023-01-06 13:01:08,268 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 360896 on epoch: 129]
2023-01-06 13:01:08,268 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:08,288 - 

2023-01-06 13:01:08,288 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:08,695 - Epoch: [133][   10/   37]    Overall Loss 0.333421    Objective Loss 0.333421                                        LR 0.000013    Time 0.040635    
2023-01-06 13:01:08,934 - Epoch: [133][   20/   37]    Overall Loss 0.340671    Objective Loss 0.340671                                        LR 0.000013    Time 0.032257    
2023-01-06 13:01:09,179 - Epoch: [133][   30/   37]    Overall Loss 0.340563    Objective Loss 0.340563                                        LR 0.000013    Time 0.029658    
2023-01-06 13:01:09,333 - Epoch: [133][   37/   37]    Overall Loss 0.338262    Objective Loss 0.338262    Top1 85.146444    LR 0.000013    Time 0.028189    
2023-01-06 13:01:09,406 - --- validate (epoch=133)-----------
2023-01-06 13:01:09,407 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:09,625 - Epoch: [133][    5/    5]    Loss 0.423539    Top1 82.729008    
2023-01-06 13:01:09,692 - ==> Top1: 82.729    Loss: 0.424

2023-01-06 13:01:09,692 - ==> Confusion:
[[311 118   0]
 [ 63 556   0]
 [  0   0   0]]

2023-01-06 13:01:09,694 - ==> Best [Top1: 83.969   Sparsity:0.00   Params: 360896 on epoch: 129]
2023-01-06 13:01:09,694 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:09,703 - 

2023-01-06 13:01:09,703 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:10,108 - Epoch: [134][   10/   37]    Overall Loss 0.334638    Objective Loss 0.334638                                        LR 0.000013    Time 0.040378    
2023-01-06 13:01:10,346 - Epoch: [134][   20/   37]    Overall Loss 0.334224    Objective Loss 0.334224                                        LR 0.000013    Time 0.032047    
2023-01-06 13:01:10,594 - Epoch: [134][   30/   37]    Overall Loss 0.334465    Objective Loss 0.334465                                        LR 0.000013    Time 0.029588    
2023-01-06 13:01:10,740 - Epoch: [134][   37/   37]    Overall Loss 0.338629    Objective Loss 0.338629    Top1 82.635983    LR 0.000013    Time 0.027928    
2023-01-06 13:01:10,826 - --- validate (epoch=134)-----------
2023-01-06 13:01:10,826 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:11,029 - Epoch: [134][    5/    5]    Loss 0.345828    Top1 84.064885    
2023-01-06 13:01:11,102 - ==> Top1: 84.065    Loss: 0.346

2023-01-06 13:01:11,102 - ==> Confusion:
[[365  64   0]
 [103 516   0]
 [  0   0   0]]

2023-01-06 13:01:11,104 - ==> Best [Top1: 84.065   Sparsity:0.00   Params: 360896 on epoch: 134]
2023-01-06 13:01:11,104 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:11,135 - 

2023-01-06 13:01:11,135 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:11,541 - Epoch: [135][   10/   37]    Overall Loss 0.327855    Objective Loss 0.327855                                        LR 0.000013    Time 0.040552    
2023-01-06 13:01:11,791 - Epoch: [135][   20/   37]    Overall Loss 0.330365    Objective Loss 0.330365                                        LR 0.000013    Time 0.032739    
2023-01-06 13:01:12,044 - Epoch: [135][   30/   37]    Overall Loss 0.333025    Objective Loss 0.333025                                        LR 0.000013    Time 0.030266    
2023-01-06 13:01:12,200 - Epoch: [135][   37/   37]    Overall Loss 0.336873    Objective Loss 0.336873    Top1 83.263598    LR 0.000013    Time 0.028727    
2023-01-06 13:01:12,275 - --- validate (epoch=135)-----------
2023-01-06 13:01:12,276 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:12,488 - Epoch: [135][    5/    5]    Loss 0.366568    Top1 83.683206    
2023-01-06 13:01:12,555 - ==> Top1: 83.683    Loss: 0.367

2023-01-06 13:01:12,555 - ==> Confusion:
[[337  92   0]
 [ 79 540   0]
 [  0   0   0]]

2023-01-06 13:01:12,557 - ==> Best [Top1: 84.065   Sparsity:0.00   Params: 360896 on epoch: 134]
2023-01-06 13:01:12,557 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:12,577 - 

2023-01-06 13:01:12,577 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:12,984 - Epoch: [136][   10/   37]    Overall Loss 0.351244    Objective Loss 0.351244                                        LR 0.000013    Time 0.040572    
2023-01-06 13:01:13,237 - Epoch: [136][   20/   37]    Overall Loss 0.329251    Objective Loss 0.329251                                        LR 0.000013    Time 0.032915    
2023-01-06 13:01:13,484 - Epoch: [136][   30/   37]    Overall Loss 0.333561    Objective Loss 0.333561                                        LR 0.000013    Time 0.030180    
2023-01-06 13:01:13,637 - Epoch: [136][   37/   37]    Overall Loss 0.334855    Objective Loss 0.334855    Top1 86.401674    LR 0.000013    Time 0.028603    
2023-01-06 13:01:13,709 - --- validate (epoch=136)-----------
2023-01-06 13:01:13,709 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:13,916 - Epoch: [136][    5/    5]    Loss 0.332338    Top1 84.351145    
2023-01-06 13:01:13,988 - ==> Top1: 84.351    Loss: 0.332

2023-01-06 13:01:13,988 - ==> Confusion:
[[348  81   0]
 [ 83 536   0]
 [  0   0   0]]

2023-01-06 13:01:13,990 - ==> Best [Top1: 84.351   Sparsity:0.00   Params: 360896 on epoch: 136]
2023-01-06 13:01:13,990 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:14,020 - 

2023-01-06 13:01:14,021 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:14,413 - Epoch: [137][   10/   37]    Overall Loss 0.342735    Objective Loss 0.342735                                        LR 0.000013    Time 0.039115    
2023-01-06 13:01:14,660 - Epoch: [137][   20/   37]    Overall Loss 0.338401    Objective Loss 0.338401                                        LR 0.000013    Time 0.031928    
2023-01-06 13:01:14,897 - Epoch: [137][   30/   37]    Overall Loss 0.337074    Objective Loss 0.337074                                        LR 0.000013    Time 0.029144    
2023-01-06 13:01:15,051 - Epoch: [137][   37/   37]    Overall Loss 0.333821    Objective Loss 0.333821    Top1 86.820084    LR 0.000013    Time 0.027793    
2023-01-06 13:01:15,114 - --- validate (epoch=137)-----------
2023-01-06 13:01:15,114 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:15,328 - Epoch: [137][    5/    5]    Loss 0.358819    Top1 83.301527    
2023-01-06 13:01:15,385 - ==> Top1: 83.302    Loss: 0.359

2023-01-06 13:01:15,386 - ==> Confusion:
[[343  86   0]
 [ 89 530   0]
 [  0   0   0]]

2023-01-06 13:01:15,387 - ==> Best [Top1: 84.351   Sparsity:0.00   Params: 360896 on epoch: 136]
2023-01-06 13:01:15,387 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:15,408 - 

2023-01-06 13:01:15,408 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:15,821 - Epoch: [138][   10/   37]    Overall Loss 0.343129    Objective Loss 0.343129                                        LR 0.000013    Time 0.041177    
2023-01-06 13:01:16,077 - Epoch: [138][   20/   37]    Overall Loss 0.334312    Objective Loss 0.334312                                        LR 0.000013    Time 0.033383    
2023-01-06 13:01:16,332 - Epoch: [138][   30/   37]    Overall Loss 0.336217    Objective Loss 0.336217                                        LR 0.000013    Time 0.030738    
2023-01-06 13:01:16,485 - Epoch: [138][   37/   37]    Overall Loss 0.336847    Objective Loss 0.336847    Top1 82.008368    LR 0.000013    Time 0.029066    
2023-01-06 13:01:16,546 - --- validate (epoch=138)-----------
2023-01-06 13:01:16,546 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:16,752 - Epoch: [138][    5/    5]    Loss 0.350189    Top1 84.541985    
2023-01-06 13:01:16,816 - ==> Top1: 84.542    Loss: 0.350

2023-01-06 13:01:16,816 - ==> Confusion:
[[347  82   0]
 [ 80 539   0]
 [  0   0   0]]

2023-01-06 13:01:16,818 - ==> Best [Top1: 84.542   Sparsity:0.00   Params: 360896 on epoch: 138]
2023-01-06 13:01:16,818 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:16,849 - 

2023-01-06 13:01:16,849 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:17,250 - Epoch: [139][   10/   37]    Overall Loss 0.356700    Objective Loss 0.356700                                        LR 0.000013    Time 0.040011    
2023-01-06 13:01:17,498 - Epoch: [139][   20/   37]    Overall Loss 0.346179    Objective Loss 0.346179                                        LR 0.000013    Time 0.032397    
2023-01-06 13:01:17,755 - Epoch: [139][   30/   37]    Overall Loss 0.340901    Objective Loss 0.340901                                        LR 0.000013    Time 0.030076    
2023-01-06 13:01:17,907 - Epoch: [139][   37/   37]    Overall Loss 0.336519    Objective Loss 0.336519    Top1 86.820084    LR 0.000013    Time 0.028487    
2023-01-06 13:01:17,976 - --- validate (epoch=139)-----------
2023-01-06 13:01:17,976 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:18,186 - Epoch: [139][    5/    5]    Loss 0.341063    Top1 83.396947    
2023-01-06 13:01:18,253 - ==> Top1: 83.397    Loss: 0.341

2023-01-06 13:01:18,253 - ==> Confusion:
[[363  66   0]
 [108 511   0]
 [  0   0   0]]

2023-01-06 13:01:18,255 - ==> Best [Top1: 84.542   Sparsity:0.00   Params: 360896 on epoch: 138]
2023-01-06 13:01:18,255 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:18,275 - 

2023-01-06 13:01:18,276 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:18,673 - Epoch: [140][   10/   37]    Overall Loss 0.351172    Objective Loss 0.351172                                        LR 0.000008    Time 0.039652    
2023-01-06 13:01:18,920 - Epoch: [140][   20/   37]    Overall Loss 0.337364    Objective Loss 0.337364                                        LR 0.000008    Time 0.032144    
2023-01-06 13:01:19,174 - Epoch: [140][   30/   37]    Overall Loss 0.333652    Objective Loss 0.333652                                        LR 0.000008    Time 0.029892    
2023-01-06 13:01:19,326 - Epoch: [140][   37/   37]    Overall Loss 0.331417    Objective Loss 0.331417    Top1 86.192469    LR 0.000008    Time 0.028331    
2023-01-06 13:01:19,397 - --- validate (epoch=140)-----------
2023-01-06 13:01:19,398 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:19,609 - Epoch: [140][    5/    5]    Loss 0.375403    Top1 83.778626    
2023-01-06 13:01:19,676 - ==> Top1: 83.779    Loss: 0.375

2023-01-06 13:01:19,677 - ==> Confusion:
[[353  76   0]
 [ 94 525   0]
 [  0   0   0]]

2023-01-06 13:01:19,678 - ==> Best [Top1: 84.542   Sparsity:0.00   Params: 360896 on epoch: 138]
2023-01-06 13:01:19,678 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:19,696 - 

2023-01-06 13:01:19,696 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:20,104 - Epoch: [141][   10/   37]    Overall Loss 0.326202    Objective Loss 0.326202                                        LR 0.000008    Time 0.040673    
2023-01-06 13:01:20,339 - Epoch: [141][   20/   37]    Overall Loss 0.335302    Objective Loss 0.335302                                        LR 0.000008    Time 0.032083    
2023-01-06 13:01:20,585 - Epoch: [141][   30/   37]    Overall Loss 0.329442    Objective Loss 0.329442                                        LR 0.000008    Time 0.029501    
2023-01-06 13:01:20,736 - Epoch: [141][   37/   37]    Overall Loss 0.331165    Objective Loss 0.331165    Top1 82.217573    LR 0.000008    Time 0.028012    
2023-01-06 13:01:20,807 - --- validate (epoch=141)-----------
2023-01-06 13:01:20,808 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:21,013 - Epoch: [141][    5/    5]    Loss 0.361172    Top1 83.015267    
2023-01-06 13:01:21,072 - ==> Top1: 83.015    Loss: 0.361

2023-01-06 13:01:21,073 - ==> Confusion:
[[369  60   0]
 [118 501   0]
 [  0   0   0]]

2023-01-06 13:01:21,074 - ==> Best [Top1: 84.542   Sparsity:0.00   Params: 360896 on epoch: 138]
2023-01-06 13:01:21,074 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:21,094 - 

2023-01-06 13:01:21,094 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:21,470 - Epoch: [142][   10/   37]    Overall Loss 0.329830    Objective Loss 0.329830                                        LR 0.000008    Time 0.037441    
2023-01-06 13:01:21,696 - Epoch: [142][   20/   37]    Overall Loss 0.335475    Objective Loss 0.335475                                        LR 0.000008    Time 0.030031    
2023-01-06 13:01:21,947 - Epoch: [142][   30/   37]    Overall Loss 0.332438    Objective Loss 0.332438                                        LR 0.000008    Time 0.028353    
2023-01-06 13:01:22,099 - Epoch: [142][   37/   37]    Overall Loss 0.332044    Objective Loss 0.332044    Top1 83.263598    LR 0.000008    Time 0.027091    
2023-01-06 13:01:22,172 - --- validate (epoch=142)-----------
2023-01-06 13:01:22,172 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:22,380 - Epoch: [142][    5/    5]    Loss 0.365802    Top1 83.969466    
2023-01-06 13:01:22,443 - ==> Top1: 83.969    Loss: 0.366

2023-01-06 13:01:22,443 - ==> Confusion:
[[338  91   0]
 [ 77 542   0]
 [  0   0   0]]

2023-01-06 13:01:22,445 - ==> Best [Top1: 84.542   Sparsity:0.00   Params: 360896 on epoch: 138]
2023-01-06 13:01:22,445 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:22,465 - 

2023-01-06 13:01:22,466 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:22,988 - Epoch: [143][   10/   37]    Overall Loss 0.316246    Objective Loss 0.316246                                        LR 0.000008    Time 0.052128    
2023-01-06 13:01:23,232 - Epoch: [143][   20/   37]    Overall Loss 0.318547    Objective Loss 0.318547                                        LR 0.000008    Time 0.038235    
2023-01-06 13:01:23,476 - Epoch: [143][   30/   37]    Overall Loss 0.324214    Objective Loss 0.324214                                        LR 0.000008    Time 0.033597    
2023-01-06 13:01:23,628 - Epoch: [143][   37/   37]    Overall Loss 0.330468    Objective Loss 0.330468    Top1 84.728033    LR 0.000008    Time 0.031326    
2023-01-06 13:01:23,699 - --- validate (epoch=143)-----------
2023-01-06 13:01:23,700 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:23,913 - Epoch: [143][    5/    5]    Loss 0.369376    Top1 83.492366    
2023-01-06 13:01:23,976 - ==> Top1: 83.492    Loss: 0.369

2023-01-06 13:01:23,976 - ==> Confusion:
[[372  57   0]
 [116 503   0]
 [  0   0   0]]

2023-01-06 13:01:23,978 - ==> Best [Top1: 84.542   Sparsity:0.00   Params: 360896 on epoch: 138]
2023-01-06 13:01:23,978 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:23,998 - 

2023-01-06 13:01:23,998 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:24,399 - Epoch: [144][   10/   37]    Overall Loss 0.327363    Objective Loss 0.327363                                        LR 0.000008    Time 0.040034    
2023-01-06 13:01:24,663 - Epoch: [144][   20/   37]    Overall Loss 0.331545    Objective Loss 0.331545                                        LR 0.000008    Time 0.033168    
2023-01-06 13:01:24,924 - Epoch: [144][   30/   37]    Overall Loss 0.330245    Objective Loss 0.330245                                        LR 0.000008    Time 0.030806    
2023-01-06 13:01:25,077 - Epoch: [144][   37/   37]    Overall Loss 0.332270    Objective Loss 0.332270    Top1 84.309623    LR 0.000008    Time 0.029118    
2023-01-06 13:01:25,147 - --- validate (epoch=144)-----------
2023-01-06 13:01:25,148 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:25,362 - Epoch: [144][    5/    5]    Loss 0.367978    Top1 83.110687    
2023-01-06 13:01:25,418 - ==> Top1: 83.111    Loss: 0.368

2023-01-06 13:01:25,419 - ==> Confusion:
[[331  98   0]
 [ 79 540   0]
 [  0   0   0]]

2023-01-06 13:01:25,420 - ==> Best [Top1: 84.542   Sparsity:0.00   Params: 360896 on epoch: 138]
2023-01-06 13:01:25,420 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:25,430 - 

2023-01-06 13:01:25,430 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:25,855 - Epoch: [145][   10/   37]    Overall Loss 0.339805    Objective Loss 0.339805                                        LR 0.000008    Time 0.042341    
2023-01-06 13:01:26,098 - Epoch: [145][   20/   37]    Overall Loss 0.334991    Objective Loss 0.334991                                        LR 0.000008    Time 0.033332    
2023-01-06 13:01:26,343 - Epoch: [145][   30/   37]    Overall Loss 0.331537    Objective Loss 0.331537                                        LR 0.000008    Time 0.030317    
2023-01-06 13:01:26,495 - Epoch: [145][   37/   37]    Overall Loss 0.333429    Objective Loss 0.333429    Top1 81.380753    LR 0.000008    Time 0.028663    
2023-01-06 13:01:26,555 - --- validate (epoch=145)-----------
2023-01-06 13:01:26,555 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:26,769 - Epoch: [145][    5/    5]    Loss 0.407418    Top1 82.538168    
2023-01-06 13:01:26,825 - ==> Top1: 82.538    Loss: 0.407

2023-01-06 13:01:26,825 - ==> Confusion:
[[374  55   0]
 [128 491   0]
 [  0   0   0]]

2023-01-06 13:01:26,827 - ==> Best [Top1: 84.542   Sparsity:0.00   Params: 360896 on epoch: 138]
2023-01-06 13:01:26,827 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:26,847 - 

2023-01-06 13:01:26,848 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:27,265 - Epoch: [146][   10/   37]    Overall Loss 0.342730    Objective Loss 0.342730                                        LR 0.000008    Time 0.041679    
2023-01-06 13:01:27,519 - Epoch: [146][   20/   37]    Overall Loss 0.342768    Objective Loss 0.342768                                        LR 0.000008    Time 0.033530    
2023-01-06 13:01:27,766 - Epoch: [146][   30/   37]    Overall Loss 0.337901    Objective Loss 0.337901                                        LR 0.000008    Time 0.030527    
2023-01-06 13:01:27,917 - Epoch: [146][   37/   37]    Overall Loss 0.335237    Objective Loss 0.335237    Top1 87.238494    LR 0.000008    Time 0.028846    
2023-01-06 13:01:27,989 - --- validate (epoch=146)-----------
2023-01-06 13:01:27,989 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:28,197 - Epoch: [146][    5/    5]    Loss 0.374993    Top1 83.015267    
2023-01-06 13:01:28,255 - ==> Top1: 83.015    Loss: 0.375

2023-01-06 13:01:28,255 - ==> Confusion:
[[343  86   0]
 [ 92 527   0]
 [  0   0   0]]

2023-01-06 13:01:28,257 - ==> Best [Top1: 84.542   Sparsity:0.00   Params: 360896 on epoch: 138]
2023-01-06 13:01:28,257 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:28,277 - 

2023-01-06 13:01:28,277 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:28,706 - Epoch: [147][   10/   37]    Overall Loss 0.331748    Objective Loss 0.331748                                        LR 0.000008    Time 0.042757    
2023-01-06 13:01:28,964 - Epoch: [147][   20/   37]    Overall Loss 0.326724    Objective Loss 0.326724                                        LR 0.000008    Time 0.034265    
2023-01-06 13:01:29,212 - Epoch: [147][   30/   37]    Overall Loss 0.332936    Objective Loss 0.332936                                        LR 0.000008    Time 0.031097    
2023-01-06 13:01:29,363 - Epoch: [147][   37/   37]    Overall Loss 0.332453    Objective Loss 0.332453    Top1 86.401674    LR 0.000008    Time 0.029291    
2023-01-06 13:01:29,432 - --- validate (epoch=147)-----------
2023-01-06 13:01:29,432 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:29,640 - Epoch: [147][    5/    5]    Loss 0.360717    Top1 83.587786    
2023-01-06 13:01:29,703 - ==> Top1: 83.588    Loss: 0.361

2023-01-06 13:01:29,703 - ==> Confusion:
[[361  68   0]
 [104 515   0]
 [  0   0   0]]

2023-01-06 13:01:29,705 - ==> Best [Top1: 84.542   Sparsity:0.00   Params: 360896 on epoch: 138]
2023-01-06 13:01:29,705 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:29,715 - 

2023-01-06 13:01:29,715 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:30,117 - Epoch: [148][   10/   37]    Overall Loss 0.336221    Objective Loss 0.336221                                        LR 0.000008    Time 0.040195    
2023-01-06 13:01:30,357 - Epoch: [148][   20/   37]    Overall Loss 0.336642    Objective Loss 0.336642                                        LR 0.000008    Time 0.032068    
2023-01-06 13:01:30,610 - Epoch: [148][   30/   37]    Overall Loss 0.328395    Objective Loss 0.328395                                        LR 0.000008    Time 0.029789    
2023-01-06 13:01:30,762 - Epoch: [148][   37/   37]    Overall Loss 0.331249    Objective Loss 0.331249    Top1 85.564854    LR 0.000008    Time 0.028248    
2023-01-06 13:01:30,827 - --- validate (epoch=148)-----------
2023-01-06 13:01:30,827 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:31,035 - Epoch: [148][    5/    5]    Loss 0.349568    Top1 84.732824    
2023-01-06 13:01:31,106 - ==> Top1: 84.733    Loss: 0.350

2023-01-06 13:01:31,106 - ==> Confusion:
[[365  64   0]
 [ 96 523   0]
 [  0   0   0]]

2023-01-06 13:01:31,107 - ==> Best [Top1: 84.733   Sparsity:0.00   Params: 360896 on epoch: 148]
2023-01-06 13:01:31,107 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:31,138 - 

2023-01-06 13:01:31,139 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:31,521 - Epoch: [149][   10/   37]    Overall Loss 0.338808    Objective Loss 0.338808                                        LR 0.000008    Time 0.038204    
2023-01-06 13:01:31,760 - Epoch: [149][   20/   37]    Overall Loss 0.336073    Objective Loss 0.336073                                        LR 0.000008    Time 0.030994    
2023-01-06 13:01:32,009 - Epoch: [149][   30/   37]    Overall Loss 0.331996    Objective Loss 0.331996                                        LR 0.000008    Time 0.028944    
2023-01-06 13:01:32,160 - Epoch: [149][   37/   37]    Overall Loss 0.333076    Objective Loss 0.333076    Top1 81.380753    LR 0.000008    Time 0.027559    
2023-01-06 13:01:32,226 - --- validate (epoch=149)-----------
2023-01-06 13:01:32,226 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:32,433 - Epoch: [149][    5/    5]    Loss 0.356241    Top1 83.969466    
2023-01-06 13:01:32,511 - ==> Top1: 83.969    Loss: 0.356

2023-01-06 13:01:32,511 - ==> Confusion:
[[360  69   0]
 [ 99 520   0]
 [  0   0   0]]

2023-01-06 13:01:32,512 - ==> Best [Top1: 84.733   Sparsity:0.00   Params: 360896 on epoch: 148]
2023-01-06 13:01:32,513 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:32,533 - 

2023-01-06 13:01:32,533 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:32,949 - Epoch: [150][   10/   37]    Overall Loss 0.326788    Objective Loss 0.326788                                        LR 0.000008    Time 0.041454    
2023-01-06 13:01:33,197 - Epoch: [150][   20/   37]    Overall Loss 0.331639    Objective Loss 0.331639                                        LR 0.000008    Time 0.033063    
2023-01-06 13:01:33,453 - Epoch: [150][   30/   37]    Overall Loss 0.332116    Objective Loss 0.332116                                        LR 0.000008    Time 0.030560    
2023-01-06 13:01:33,606 - Epoch: [150][   37/   37]    Overall Loss 0.333689    Objective Loss 0.333689    Top1 85.355649    LR 0.000008    Time 0.028916    
2023-01-06 13:01:33,683 - --- validate (epoch=150)-----------
2023-01-06 13:01:33,683 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:33,896 - Epoch: [150][    5/    5]    Loss 0.345051    Top1 83.110687    
2023-01-06 13:01:33,950 - ==> Top1: 83.111    Loss: 0.345

2023-01-06 13:01:33,951 - ==> Confusion:
[[357  72   0]
 [105 514   0]
 [  0   0   0]]

2023-01-06 13:01:33,952 - ==> Best [Top1: 84.733   Sparsity:0.00   Params: 360896 on epoch: 148]
2023-01-06 13:01:33,952 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:33,973 - 

2023-01-06 13:01:33,973 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:34,372 - Epoch: [151][   10/   37]    Overall Loss 0.334244    Objective Loss 0.334244                                        LR 0.000008    Time 0.039732    
2023-01-06 13:01:34,613 - Epoch: [151][   20/   37]    Overall Loss 0.336848    Objective Loss 0.336848                                        LR 0.000008    Time 0.031926    
2023-01-06 13:01:34,864 - Epoch: [151][   30/   37]    Overall Loss 0.331964    Objective Loss 0.331964                                        LR 0.000008    Time 0.029622    
2023-01-06 13:01:35,016 - Epoch: [151][   37/   37]    Overall Loss 0.331245    Objective Loss 0.331245    Top1 82.845188    LR 0.000008    Time 0.028132    
2023-01-06 13:01:35,092 - --- validate (epoch=151)-----------
2023-01-06 13:01:35,092 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:35,313 - Epoch: [151][    5/    5]    Loss 0.359148    Top1 83.587786    
2023-01-06 13:01:35,374 - ==> Top1: 83.588    Loss: 0.359

2023-01-06 13:01:35,375 - ==> Confusion:
[[345  84   0]
 [ 88 531   0]
 [  0   0   0]]

2023-01-06 13:01:35,376 - ==> Best [Top1: 84.733   Sparsity:0.00   Params: 360896 on epoch: 148]
2023-01-06 13:01:35,376 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:35,386 - 

2023-01-06 13:01:35,386 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:35,797 - Epoch: [152][   10/   37]    Overall Loss 0.336161    Objective Loss 0.336161                                        LR 0.000008    Time 0.040977    
2023-01-06 13:01:36,062 - Epoch: [152][   20/   37]    Overall Loss 0.330751    Objective Loss 0.330751                                        LR 0.000008    Time 0.033724    
2023-01-06 13:01:36,315 - Epoch: [152][   30/   37]    Overall Loss 0.333893    Objective Loss 0.333893                                        LR 0.000008    Time 0.030913    
2023-01-06 13:01:36,468 - Epoch: [152][   37/   37]    Overall Loss 0.330807    Objective Loss 0.330807    Top1 85.146444    LR 0.000008    Time 0.029182    
2023-01-06 13:01:36,532 - --- validate (epoch=152)-----------
2023-01-06 13:01:36,532 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:36,742 - Epoch: [152][    5/    5]    Loss 0.408507    Top1 83.492366    
2023-01-06 13:01:36,810 - ==> Top1: 83.492    Loss: 0.409

2023-01-06 13:01:36,810 - ==> Confusion:
[[367  62   0]
 [111 508   0]
 [  0   0   0]]

2023-01-06 13:01:36,811 - ==> Best [Top1: 84.733   Sparsity:0.00   Params: 360896 on epoch: 148]
2023-01-06 13:01:36,812 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:36,832 - 

2023-01-06 13:01:36,832 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:37,232 - Epoch: [153][   10/   37]    Overall Loss 0.338819    Objective Loss 0.338819                                        LR 0.000008    Time 0.039907    
2023-01-06 13:01:37,469 - Epoch: [153][   20/   37]    Overall Loss 0.327105    Objective Loss 0.327105                                        LR 0.000008    Time 0.031821    
2023-01-06 13:01:37,714 - Epoch: [153][   30/   37]    Overall Loss 0.329219    Objective Loss 0.329219                                        LR 0.000008    Time 0.029363    
2023-01-06 13:01:37,861 - Epoch: [153][   37/   37]    Overall Loss 0.329838    Objective Loss 0.329838    Top1 86.820084    LR 0.000008    Time 0.027766    
2023-01-06 13:01:37,932 - --- validate (epoch=153)-----------
2023-01-06 13:01:37,932 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:38,146 - Epoch: [153][    5/    5]    Loss 0.366573    Top1 83.683206    
2023-01-06 13:01:38,214 - ==> Top1: 83.683    Loss: 0.367

2023-01-06 13:01:38,214 - ==> Confusion:
[[351  78   0]
 [ 93 526   0]
 [  0   0   0]]

2023-01-06 13:01:38,216 - ==> Best [Top1: 84.733   Sparsity:0.00   Params: 360896 on epoch: 148]
2023-01-06 13:01:38,216 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:38,236 - 

2023-01-06 13:01:38,236 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:38,617 - Epoch: [154][   10/   37]    Overall Loss 0.348093    Objective Loss 0.348093                                        LR 0.000008    Time 0.037967    
2023-01-06 13:01:38,821 - Epoch: [154][   20/   37]    Overall Loss 0.350548    Objective Loss 0.350548                                        LR 0.000008    Time 0.029164    
2023-01-06 13:01:39,055 - Epoch: [154][   30/   37]    Overall Loss 0.342491    Objective Loss 0.342491                                        LR 0.000008    Time 0.027243    
2023-01-06 13:01:39,210 - Epoch: [154][   37/   37]    Overall Loss 0.335740    Objective Loss 0.335740    Top1 86.610879    LR 0.000008    Time 0.026270    
2023-01-06 13:01:39,275 - --- validate (epoch=154)-----------
2023-01-06 13:01:39,275 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:39,487 - Epoch: [154][    5/    5]    Loss 0.370762    Top1 83.778626    
2023-01-06 13:01:39,547 - ==> Top1: 83.779    Loss: 0.371

2023-01-06 13:01:39,547 - ==> Confusion:
[[369  60   0]
 [110 509   0]
 [  0   0   0]]

2023-01-06 13:01:39,549 - ==> Best [Top1: 84.733   Sparsity:0.00   Params: 360896 on epoch: 148]
2023-01-06 13:01:39,549 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:39,569 - 

2023-01-06 13:01:39,569 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:39,973 - Epoch: [155][   10/   37]    Overall Loss 0.334992    Objective Loss 0.334992                                        LR 0.000008    Time 0.040328    
2023-01-06 13:01:40,206 - Epoch: [155][   20/   37]    Overall Loss 0.326272    Objective Loss 0.326272                                        LR 0.000008    Time 0.031806    
2023-01-06 13:01:40,442 - Epoch: [155][   30/   37]    Overall Loss 0.330308    Objective Loss 0.330308                                        LR 0.000008    Time 0.029043    
2023-01-06 13:01:40,596 - Epoch: [155][   37/   37]    Overall Loss 0.330048    Objective Loss 0.330048    Top1 84.518828    LR 0.000008    Time 0.027696    
2023-01-06 13:01:40,666 - --- validate (epoch=155)-----------
2023-01-06 13:01:40,666 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:40,877 - Epoch: [155][    5/    5]    Loss 0.347151    Top1 85.114504    
2023-01-06 13:01:40,929 - ==> Top1: 85.115    Loss: 0.347

2023-01-06 13:01:40,930 - ==> Confusion:
[[357  72   0]
 [ 84 535   0]
 [  0   0   0]]

2023-01-06 13:01:40,931 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 360896 on epoch: 155]
2023-01-06 13:01:40,931 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:40,955 - 

2023-01-06 13:01:40,955 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:41,362 - Epoch: [156][   10/   37]    Overall Loss 0.333122    Objective Loss 0.333122                                        LR 0.000008    Time 0.040673    
2023-01-06 13:01:41,614 - Epoch: [156][   20/   37]    Overall Loss 0.332565    Objective Loss 0.332565                                        LR 0.000008    Time 0.032886    
2023-01-06 13:01:41,867 - Epoch: [156][   30/   37]    Overall Loss 0.332758    Objective Loss 0.332758                                        LR 0.000008    Time 0.030332    
2023-01-06 13:01:42,022 - Epoch: [156][   37/   37]    Overall Loss 0.329494    Objective Loss 0.329494    Top1 84.728033    LR 0.000008    Time 0.028791    
2023-01-06 13:01:42,099 - --- validate (epoch=156)-----------
2023-01-06 13:01:42,099 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:42,305 - Epoch: [156][    5/    5]    Loss 0.338890    Top1 84.064885    
2023-01-06 13:01:42,364 - ==> Top1: 84.065    Loss: 0.339

2023-01-06 13:01:42,365 - ==> Confusion:
[[365  64   0]
 [103 516   0]
 [  0   0   0]]

2023-01-06 13:01:42,366 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 360896 on epoch: 155]
2023-01-06 13:01:42,366 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:42,376 - 

2023-01-06 13:01:42,376 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:42,756 - Epoch: [157][   10/   37]    Overall Loss 0.314350    Objective Loss 0.314350                                        LR 0.000008    Time 0.037869    
2023-01-06 13:01:42,983 - Epoch: [157][   20/   37]    Overall Loss 0.331568    Objective Loss 0.331568                                        LR 0.000008    Time 0.030209    
2023-01-06 13:01:43,229 - Epoch: [157][   30/   37]    Overall Loss 0.331945    Objective Loss 0.331945                                        LR 0.000008    Time 0.028336    
2023-01-06 13:01:43,383 - Epoch: [157][   37/   37]    Overall Loss 0.331666    Objective Loss 0.331666    Top1 85.146444    LR 0.000008    Time 0.027132    
2023-01-06 13:01:43,449 - --- validate (epoch=157)-----------
2023-01-06 13:01:43,449 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:43,657 - Epoch: [157][    5/    5]    Loss 0.369727    Top1 83.301527    
2023-01-06 13:01:43,721 - ==> Top1: 83.302    Loss: 0.370

2023-01-06 13:01:43,721 - ==> Confusion:
[[357  72   0]
 [103 516   0]
 [  0   0   0]]

2023-01-06 13:01:43,723 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 360896 on epoch: 155]
2023-01-06 13:01:43,723 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:43,732 - 

2023-01-06 13:01:43,733 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:44,115 - Epoch: [158][   10/   37]    Overall Loss 0.337768    Objective Loss 0.337768                                        LR 0.000008    Time 0.038135    
2023-01-06 13:01:44,346 - Epoch: [158][   20/   37]    Overall Loss 0.329885    Objective Loss 0.329885                                        LR 0.000008    Time 0.030597    
2023-01-06 13:01:44,601 - Epoch: [158][   30/   37]    Overall Loss 0.327334    Objective Loss 0.327334                                        LR 0.000008    Time 0.028862    
2023-01-06 13:01:44,752 - Epoch: [158][   37/   37]    Overall Loss 0.331443    Objective Loss 0.331443    Top1 82.217573    LR 0.000008    Time 0.027481    
2023-01-06 13:01:44,819 - --- validate (epoch=158)-----------
2023-01-06 13:01:44,819 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:45,048 - Epoch: [158][    5/    5]    Loss 0.419199    Top1 83.110687    
2023-01-06 13:01:45,103 - ==> Top1: 83.111    Loss: 0.419

2023-01-06 13:01:45,103 - ==> Confusion:
[[378  51   0]
 [126 493   0]
 [  0   0   0]]

2023-01-06 13:01:45,105 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 360896 on epoch: 155]
2023-01-06 13:01:45,105 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:45,115 - 

2023-01-06 13:01:45,115 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:45,521 - Epoch: [159][   10/   37]    Overall Loss 0.322762    Objective Loss 0.322762                                        LR 0.000008    Time 0.040543    
2023-01-06 13:01:45,734 - Epoch: [159][   20/   37]    Overall Loss 0.325139    Objective Loss 0.325139                                        LR 0.000008    Time 0.030891    
2023-01-06 13:01:45,946 - Epoch: [159][   30/   37]    Overall Loss 0.331098    Objective Loss 0.331098                                        LR 0.000008    Time 0.027654    
2023-01-06 13:01:46,094 - Epoch: [159][   37/   37]    Overall Loss 0.330720    Objective Loss 0.330720    Top1 83.472803    LR 0.000008    Time 0.026408    
2023-01-06 13:01:46,173 - --- validate (epoch=159)-----------
2023-01-06 13:01:46,173 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:46,387 - Epoch: [159][    5/    5]    Loss 0.378245    Top1 82.729008    
2023-01-06 13:01:46,463 - ==> Top1: 82.729    Loss: 0.378

2023-01-06 13:01:46,463 - ==> Confusion:
[[362  67   0]
 [114 505   0]
 [  0   0   0]]

2023-01-06 13:01:46,464 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 360896 on epoch: 155]
2023-01-06 13:01:46,464 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:46,484 - 

2023-01-06 13:01:46,485 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:47,004 - Epoch: [160][   10/   37]    Overall Loss 0.328770    Objective Loss 0.328770                                        LR 0.000008    Time 0.051821    
2023-01-06 13:01:47,246 - Epoch: [160][   20/   37]    Overall Loss 0.336284    Objective Loss 0.336284                                        LR 0.000008    Time 0.038025    
2023-01-06 13:01:47,498 - Epoch: [160][   30/   37]    Overall Loss 0.334818    Objective Loss 0.334818                                        LR 0.000008    Time 0.033746    
2023-01-06 13:01:47,646 - Epoch: [160][   37/   37]    Overall Loss 0.330125    Objective Loss 0.330125    Top1 84.100418    LR 0.000008    Time 0.031352    
2023-01-06 13:01:47,719 - --- validate (epoch=160)-----------
2023-01-06 13:01:47,719 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:47,926 - Epoch: [160][    5/    5]    Loss 0.365534    Top1 83.969466    
2023-01-06 13:01:47,993 - ==> Top1: 83.969    Loss: 0.366

2023-01-06 13:01:47,993 - ==> Confusion:
[[352  77   0]
 [ 91 528   0]
 [  0   0   0]]

2023-01-06 13:01:47,994 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 360896 on epoch: 155]
2023-01-06 13:01:47,995 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:48,015 - 

2023-01-06 13:01:48,015 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:48,407 - Epoch: [161][   10/   37]    Overall Loss 0.318308    Objective Loss 0.318308                                        LR 0.000008    Time 0.039143    
2023-01-06 13:01:48,625 - Epoch: [161][   20/   37]    Overall Loss 0.331694    Objective Loss 0.331694                                        LR 0.000008    Time 0.030430    
2023-01-06 13:01:48,848 - Epoch: [161][   30/   37]    Overall Loss 0.334136    Objective Loss 0.334136                                        LR 0.000008    Time 0.027710    
2023-01-06 13:01:49,002 - Epoch: [161][   37/   37]    Overall Loss 0.330566    Objective Loss 0.330566    Top1 86.820084    LR 0.000008    Time 0.026634    
2023-01-06 13:01:49,083 - --- validate (epoch=161)-----------
2023-01-06 13:01:49,083 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:49,297 - Epoch: [161][    5/    5]    Loss 0.366870    Top1 85.209924    
2023-01-06 13:01:49,366 - ==> Top1: 85.210    Loss: 0.367

2023-01-06 13:01:49,367 - ==> Confusion:
[[361  68   0]
 [ 87 532   0]
 [  0   0   0]]

2023-01-06 13:01:49,369 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:01:49,369 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:49,395 - 

2023-01-06 13:01:49,395 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:49,782 - Epoch: [162][   10/   37]    Overall Loss 0.343300    Objective Loss 0.343300                                        LR 0.000008    Time 0.038530    
2023-01-06 13:01:50,024 - Epoch: [162][   20/   37]    Overall Loss 0.338757    Objective Loss 0.338757                                        LR 0.000008    Time 0.031362    
2023-01-06 13:01:50,236 - Epoch: [162][   30/   37]    Overall Loss 0.334750    Objective Loss 0.334750                                        LR 0.000008    Time 0.027960    
2023-01-06 13:01:50,383 - Epoch: [162][   37/   37]    Overall Loss 0.331383    Objective Loss 0.331383    Top1 83.472803    LR 0.000008    Time 0.026653    
2023-01-06 13:01:50,460 - --- validate (epoch=162)-----------
2023-01-06 13:01:50,461 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:50,674 - Epoch: [162][    5/    5]    Loss 0.345608    Top1 84.828244    
2023-01-06 13:01:50,733 - ==> Top1: 84.828    Loss: 0.346

2023-01-06 13:01:50,733 - ==> Confusion:
[[361  68   0]
 [ 91 528   0]
 [  0   0   0]]

2023-01-06 13:01:50,735 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:01:50,735 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:50,755 - 

2023-01-06 13:01:50,755 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:51,163 - Epoch: [163][   10/   37]    Overall Loss 0.329379    Objective Loss 0.329379                                        LR 0.000008    Time 0.040701    
2023-01-06 13:01:51,413 - Epoch: [163][   20/   37]    Overall Loss 0.330345    Objective Loss 0.330345                                        LR 0.000008    Time 0.032813    
2023-01-06 13:01:51,661 - Epoch: [163][   30/   37]    Overall Loss 0.327651    Objective Loss 0.327651                                        LR 0.000008    Time 0.030123    
2023-01-06 13:01:51,817 - Epoch: [163][   37/   37]    Overall Loss 0.329169    Objective Loss 0.329169    Top1 83.472803    LR 0.000008    Time 0.028637    
2023-01-06 13:01:51,878 - --- validate (epoch=163)-----------
2023-01-06 13:01:51,878 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:52,097 - Epoch: [163][    5/    5]    Loss 0.373132    Top1 83.492366    
2023-01-06 13:01:52,164 - ==> Top1: 83.492    Loss: 0.373

2023-01-06 13:01:52,164 - ==> Confusion:
[[348  81   0]
 [ 92 527   0]
 [  0   0   0]]

2023-01-06 13:01:52,166 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:01:52,166 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:52,186 - 

2023-01-06 13:01:52,186 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:52,570 - Epoch: [164][   10/   37]    Overall Loss 0.326521    Objective Loss 0.326521                                        LR 0.000008    Time 0.038329    
2023-01-06 13:01:52,785 - Epoch: [164][   20/   37]    Overall Loss 0.324658    Objective Loss 0.324658                                        LR 0.000008    Time 0.029864    
2023-01-06 13:01:53,000 - Epoch: [164][   30/   37]    Overall Loss 0.328205    Objective Loss 0.328205                                        LR 0.000008    Time 0.027080    
2023-01-06 13:01:53,149 - Epoch: [164][   37/   37]    Overall Loss 0.330482    Objective Loss 0.330482    Top1 83.891213    LR 0.000008    Time 0.025966    
2023-01-06 13:01:53,215 - --- validate (epoch=164)-----------
2023-01-06 13:01:53,215 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:53,426 - Epoch: [164][    5/    5]    Loss 0.368213    Top1 82.824427    
2023-01-06 13:01:53,479 - ==> Top1: 82.824    Loss: 0.368

2023-01-06 13:01:53,479 - ==> Confusion:
[[331  98   0]
 [ 82 537   0]
 [  0   0   0]]

2023-01-06 13:01:53,481 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:01:53,481 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:53,503 - 

2023-01-06 13:01:53,503 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:53,876 - Epoch: [165][   10/   37]    Overall Loss 0.336316    Objective Loss 0.336316                                        LR 0.000008    Time 0.037202    
2023-01-06 13:01:54,104 - Epoch: [165][   20/   37]    Overall Loss 0.329917    Objective Loss 0.329917                                        LR 0.000008    Time 0.029967    
2023-01-06 13:01:54,345 - Epoch: [165][   30/   37]    Overall Loss 0.332121    Objective Loss 0.332121                                        LR 0.000008    Time 0.028008    
2023-01-06 13:01:54,501 - Epoch: [165][   37/   37]    Overall Loss 0.329129    Objective Loss 0.329129    Top1 84.100418    LR 0.000008    Time 0.026905    
2023-01-06 13:01:54,574 - --- validate (epoch=165)-----------
2023-01-06 13:01:54,575 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:54,787 - Epoch: [165][    5/    5]    Loss 0.360959    Top1 82.156489    
2023-01-06 13:01:54,851 - ==> Top1: 82.156    Loss: 0.361

2023-01-06 13:01:54,852 - ==> Confusion:
[[381  48   0]
 [139 480   0]
 [  0   0   0]]

2023-01-06 13:01:54,853 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:01:54,853 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:54,874 - 

2023-01-06 13:01:54,874 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:55,281 - Epoch: [166][   10/   37]    Overall Loss 0.325263    Objective Loss 0.325263                                        LR 0.000008    Time 0.040608    
2023-01-06 13:01:55,520 - Epoch: [166][   20/   37]    Overall Loss 0.331104    Objective Loss 0.331104                                        LR 0.000008    Time 0.032258    
2023-01-06 13:01:55,730 - Epoch: [166][   30/   37]    Overall Loss 0.331345    Objective Loss 0.331345                                        LR 0.000008    Time 0.028485    
2023-01-06 13:01:55,865 - Epoch: [166][   37/   37]    Overall Loss 0.330375    Objective Loss 0.330375    Top1 84.100418    LR 0.000008    Time 0.026752    
2023-01-06 13:01:55,947 - --- validate (epoch=166)-----------
2023-01-06 13:01:55,947 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:56,156 - Epoch: [166][    5/    5]    Loss 0.408786    Top1 83.301527    
2023-01-06 13:01:56,216 - ==> Top1: 83.302    Loss: 0.409

2023-01-06 13:01:56,216 - ==> Confusion:
[[364  65   0]
 [110 509   0]
 [  0   0   0]]

2023-01-06 13:01:56,218 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:01:56,218 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:56,238 - 

2023-01-06 13:01:56,238 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:56,647 - Epoch: [167][   10/   37]    Overall Loss 0.323124    Objective Loss 0.323124                                        LR 0.000008    Time 0.040732    
2023-01-06 13:01:56,884 - Epoch: [167][   20/   37]    Overall Loss 0.316434    Objective Loss 0.316434                                        LR 0.000008    Time 0.032219    
2023-01-06 13:01:57,127 - Epoch: [167][   30/   37]    Overall Loss 0.325588    Objective Loss 0.325588                                        LR 0.000008    Time 0.029579    
2023-01-06 13:01:57,275 - Epoch: [167][   37/   37]    Overall Loss 0.330213    Objective Loss 0.330213    Top1 82.635983    LR 0.000008    Time 0.027953    
2023-01-06 13:01:57,339 - --- validate (epoch=167)-----------
2023-01-06 13:01:57,340 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:57,553 - Epoch: [167][    5/    5]    Loss 0.343235    Top1 83.492366    
2023-01-06 13:01:57,608 - ==> Top1: 83.492    Loss: 0.343

2023-01-06 13:01:57,608 - ==> Confusion:
[[346  83   0]
 [ 90 529   0]
 [  0   0   0]]

2023-01-06 13:01:57,609 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:01:57,610 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:57,630 - 

2023-01-06 13:01:57,630 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:58,001 - Epoch: [168][   10/   37]    Overall Loss 0.340495    Objective Loss 0.340495                                        LR 0.000008    Time 0.037073    
2023-01-06 13:01:58,209 - Epoch: [168][   20/   37]    Overall Loss 0.332911    Objective Loss 0.332911                                        LR 0.000008    Time 0.028907    
2023-01-06 13:01:58,425 - Epoch: [168][   30/   37]    Overall Loss 0.329646    Objective Loss 0.329646                                        LR 0.000008    Time 0.026436    
2023-01-06 13:01:58,561 - Epoch: [168][   37/   37]    Overall Loss 0.329557    Objective Loss 0.329557    Top1 85.146444    LR 0.000008    Time 0.025104    
2023-01-06 13:01:58,642 - --- validate (epoch=168)-----------
2023-01-06 13:01:58,642 - 1048 samples (256 per mini-batch)
2023-01-06 13:01:58,855 - Epoch: [168][    5/    5]    Loss 0.375897    Top1 83.778626    
2023-01-06 13:01:58,929 - ==> Top1: 83.779    Loss: 0.376

2023-01-06 13:01:58,930 - ==> Confusion:
[[360  69   0]
 [101 518   0]
 [  0   0   0]]

2023-01-06 13:01:58,931 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:01:58,931 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:01:58,941 - 

2023-01-06 13:01:58,941 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:01:59,345 - Epoch: [169][   10/   37]    Overall Loss 0.327207    Objective Loss 0.327207                                        LR 0.000008    Time 0.040354    
2023-01-06 13:01:59,595 - Epoch: [169][   20/   37]    Overall Loss 0.326956    Objective Loss 0.326956                                        LR 0.000008    Time 0.032623    
2023-01-06 13:01:59,847 - Epoch: [169][   30/   37]    Overall Loss 0.333738    Objective Loss 0.333738                                        LR 0.000008    Time 0.030129    
2023-01-06 13:02:00,002 - Epoch: [169][   37/   37]    Overall Loss 0.329857    Objective Loss 0.329857    Top1 87.238494    LR 0.000008    Time 0.028631    
2023-01-06 13:02:00,070 - --- validate (epoch=169)-----------
2023-01-06 13:02:00,070 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:00,281 - Epoch: [169][    5/    5]    Loss 0.386215    Top1 84.064885    
2023-01-06 13:02:00,333 - ==> Top1: 84.065    Loss: 0.386

2023-01-06 13:02:00,333 - ==> Confusion:
[[358  71   0]
 [ 96 523   0]
 [  0   0   0]]

2023-01-06 13:02:00,335 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:00,335 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:00,345 - 

2023-01-06 13:02:00,345 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:00,754 - Epoch: [170][   10/   37]    Overall Loss 0.342083    Objective Loss 0.342083                                        LR 0.000008    Time 0.040790    
2023-01-06 13:02:00,976 - Epoch: [170][   20/   37]    Overall Loss 0.340580    Objective Loss 0.340580                                        LR 0.000008    Time 0.031477    
2023-01-06 13:02:01,216 - Epoch: [170][   30/   37]    Overall Loss 0.332769    Objective Loss 0.332769                                        LR 0.000008    Time 0.028911    
2023-01-06 13:02:01,370 - Epoch: [170][   37/   37]    Overall Loss 0.327848    Objective Loss 0.327848    Top1 85.774059    LR 0.000008    Time 0.027618    
2023-01-06 13:02:01,437 - --- validate (epoch=170)-----------
2023-01-06 13:02:01,437 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:01,646 - Epoch: [170][    5/    5]    Loss 0.341318    Top1 82.919847    
2023-01-06 13:02:01,710 - ==> Top1: 82.920    Loss: 0.341

2023-01-06 13:02:01,711 - ==> Confusion:
[[331  98   0]
 [ 81 538   0]
 [  0   0   0]]

2023-01-06 13:02:01,712 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:01,712 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:01,732 - 

2023-01-06 13:02:01,733 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:02,151 - Epoch: [171][   10/   37]    Overall Loss 0.326508    Objective Loss 0.326508                                        LR 0.000008    Time 0.041808    
2023-01-06 13:02:02,397 - Epoch: [171][   20/   37]    Overall Loss 0.332193    Objective Loss 0.332193                                        LR 0.000008    Time 0.033148    
2023-01-06 13:02:02,611 - Epoch: [171][   30/   37]    Overall Loss 0.331126    Objective Loss 0.331126                                        LR 0.000008    Time 0.029218    
2023-01-06 13:02:02,753 - Epoch: [171][   37/   37]    Overall Loss 0.327797    Objective Loss 0.327797    Top1 87.447699    LR 0.000008    Time 0.027542    
2023-01-06 13:02:02,818 - --- validate (epoch=171)-----------
2023-01-06 13:02:02,818 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:03,024 - Epoch: [171][    5/    5]    Loss 0.344566    Top1 82.919847    
2023-01-06 13:02:03,091 - ==> Top1: 82.920    Loss: 0.345

2023-01-06 13:02:03,091 - ==> Confusion:
[[350  79   0]
 [100 519   0]
 [  0   0   0]]

2023-01-06 13:02:03,093 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:03,093 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:03,113 - 

2023-01-06 13:02:03,113 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:03,513 - Epoch: [172][   10/   37]    Overall Loss 0.345184    Objective Loss 0.345184                                        LR 0.000008    Time 0.039905    
2023-01-06 13:02:03,731 - Epoch: [172][   20/   37]    Overall Loss 0.338815    Objective Loss 0.338815                                        LR 0.000008    Time 0.030852    
2023-01-06 13:02:03,955 - Epoch: [172][   30/   37]    Overall Loss 0.331812    Objective Loss 0.331812                                        LR 0.000008    Time 0.028022    
2023-01-06 13:02:04,100 - Epoch: [172][   37/   37]    Overall Loss 0.331032    Objective Loss 0.331032    Top1 83.472803    LR 0.000008    Time 0.026615    
2023-01-06 13:02:04,167 - --- validate (epoch=172)-----------
2023-01-06 13:02:04,167 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:04,379 - Epoch: [172][    5/    5]    Loss 0.370113    Top1 84.732824    
2023-01-06 13:02:04,442 - ==> Top1: 84.733    Loss: 0.370

2023-01-06 13:02:04,442 - ==> Confusion:
[[358  71   0]
 [ 89 530   0]
 [  0   0   0]]

2023-01-06 13:02:04,444 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:04,444 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:04,454 - 

2023-01-06 13:02:04,454 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:04,863 - Epoch: [173][   10/   37]    Overall Loss 0.327745    Objective Loss 0.327745                                        LR 0.000008    Time 0.040811    
2023-01-06 13:02:05,112 - Epoch: [173][   20/   37]    Overall Loss 0.328263    Objective Loss 0.328263                                        LR 0.000008    Time 0.032838    
2023-01-06 13:02:05,373 - Epoch: [173][   30/   37]    Overall Loss 0.325526    Objective Loss 0.325526                                        LR 0.000008    Time 0.030586    
2023-01-06 13:02:05,527 - Epoch: [173][   37/   37]    Overall Loss 0.326929    Objective Loss 0.326929    Top1 84.937238    LR 0.000008    Time 0.028936    
2023-01-06 13:02:05,601 - --- validate (epoch=173)-----------
2023-01-06 13:02:05,601 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:05,813 - Epoch: [173][    5/    5]    Loss 0.351222    Top1 83.492366    
2023-01-06 13:02:05,875 - ==> Top1: 83.492    Loss: 0.351

2023-01-06 13:02:05,876 - ==> Confusion:
[[359  70   0]
 [103 516   0]
 [  0   0   0]]

2023-01-06 13:02:05,877 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:05,877 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:05,897 - 

2023-01-06 13:02:05,898 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:06,288 - Epoch: [174][   10/   37]    Overall Loss 0.334112    Objective Loss 0.334112                                        LR 0.000008    Time 0.038950    
2023-01-06 13:02:06,535 - Epoch: [174][   20/   37]    Overall Loss 0.332933    Objective Loss 0.332933                                        LR 0.000008    Time 0.031808    
2023-01-06 13:02:06,768 - Epoch: [174][   30/   37]    Overall Loss 0.329814    Objective Loss 0.329814                                        LR 0.000008    Time 0.028963    
2023-01-06 13:02:06,917 - Epoch: [174][   37/   37]    Overall Loss 0.328590    Objective Loss 0.328590    Top1 85.983264    LR 0.000008    Time 0.027512    
2023-01-06 13:02:06,981 - --- validate (epoch=174)-----------
2023-01-06 13:02:06,981 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:07,193 - Epoch: [174][    5/    5]    Loss 0.450163    Top1 82.061069    
2023-01-06 13:02:07,259 - ==> Top1: 82.061    Loss: 0.450

2023-01-06 13:02:07,259 - ==> Confusion:
[[375  54   0]
 [134 485   0]
 [  0   0   0]]

2023-01-06 13:02:07,261 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:07,261 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:07,281 - 

2023-01-06 13:02:07,281 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:07,690 - Epoch: [175][   10/   37]    Overall Loss 0.334752    Objective Loss 0.334752                                        LR 0.000008    Time 0.040769    
2023-01-06 13:02:07,940 - Epoch: [175][   20/   37]    Overall Loss 0.330475    Objective Loss 0.330475                                        LR 0.000008    Time 0.032883    
2023-01-06 13:02:08,184 - Epoch: [175][   30/   37]    Overall Loss 0.326673    Objective Loss 0.326673                                        LR 0.000008    Time 0.030029    
2023-01-06 13:02:08,318 - Epoch: [175][   37/   37]    Overall Loss 0.330377    Objective Loss 0.330377    Top1 86.192469    LR 0.000008    Time 0.027971    
2023-01-06 13:02:08,392 - --- validate (epoch=175)-----------
2023-01-06 13:02:08,392 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:08,600 - Epoch: [175][    5/    5]    Loss 0.340276    Top1 84.064885    
2023-01-06 13:02:08,672 - ==> Top1: 84.065    Loss: 0.340

2023-01-06 13:02:08,672 - ==> Confusion:
[[356  73   0]
 [ 94 525   0]
 [  0   0   0]]

2023-01-06 13:02:08,674 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:08,674 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:08,695 - 

2023-01-06 13:02:08,695 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:09,203 - Epoch: [176][   10/   37]    Overall Loss 0.332737    Objective Loss 0.332737                                        LR 0.000008    Time 0.050697    
2023-01-06 13:02:09,429 - Epoch: [176][   20/   37]    Overall Loss 0.326263    Objective Loss 0.326263                                        LR 0.000008    Time 0.036638    
2023-01-06 13:02:09,691 - Epoch: [176][   30/   37]    Overall Loss 0.326272    Objective Loss 0.326272                                        LR 0.000008    Time 0.033161    
2023-01-06 13:02:09,825 - Epoch: [176][   37/   37]    Overall Loss 0.330797    Objective Loss 0.330797    Top1 83.682008    LR 0.000008    Time 0.030505    
2023-01-06 13:02:09,907 - --- validate (epoch=176)-----------
2023-01-06 13:02:09,907 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:10,117 - Epoch: [176][    5/    5]    Loss 0.339960    Top1 83.969466    
2023-01-06 13:02:10,175 - ==> Top1: 83.969    Loss: 0.340

2023-01-06 13:02:10,176 - ==> Confusion:
[[345  84   0]
 [ 84 535   0]
 [  0   0   0]]

2023-01-06 13:02:10,177 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:10,177 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:10,197 - 

2023-01-06 13:02:10,197 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:10,594 - Epoch: [177][   10/   37]    Overall Loss 0.336605    Objective Loss 0.336605                                        LR 0.000008    Time 0.039639    
2023-01-06 13:02:10,829 - Epoch: [177][   20/   37]    Overall Loss 0.332064    Objective Loss 0.332064                                        LR 0.000008    Time 0.031570    
2023-01-06 13:02:11,065 - Epoch: [177][   30/   37]    Overall Loss 0.328948    Objective Loss 0.328948                                        LR 0.000008    Time 0.028908    
2023-01-06 13:02:11,217 - Epoch: [177][   37/   37]    Overall Loss 0.329714    Objective Loss 0.329714    Top1 86.820084    LR 0.000008    Time 0.027538    
2023-01-06 13:02:11,286 - --- validate (epoch=177)-----------
2023-01-06 13:02:11,286 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:11,492 - Epoch: [177][    5/    5]    Loss 0.394709    Top1 82.061069    
2023-01-06 13:02:11,558 - ==> Top1: 82.061    Loss: 0.395

2023-01-06 13:02:11,558 - ==> Confusion:
[[378  51   0]
 [137 482   0]
 [  0   0   0]]

2023-01-06 13:02:11,559 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:11,560 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:11,569 - 

2023-01-06 13:02:11,569 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:11,949 - Epoch: [178][   10/   37]    Overall Loss 0.329235    Objective Loss 0.329235                                        LR 0.000008    Time 0.037904    
2023-01-06 13:02:12,189 - Epoch: [178][   20/   37]    Overall Loss 0.328784    Objective Loss 0.328784                                        LR 0.000008    Time 0.030927    
2023-01-06 13:02:12,445 - Epoch: [178][   30/   37]    Overall Loss 0.329019    Objective Loss 0.329019                                        LR 0.000008    Time 0.029153    
2023-01-06 13:02:12,599 - Epoch: [178][   37/   37]    Overall Loss 0.327848    Objective Loss 0.327848    Top1 83.891213    LR 0.000008    Time 0.027787    
2023-01-06 13:02:12,672 - --- validate (epoch=178)-----------
2023-01-06 13:02:12,672 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:12,878 - Epoch: [178][    5/    5]    Loss 0.349901    Top1 83.683206    
2023-01-06 13:02:12,936 - ==> Top1: 83.683    Loss: 0.350

2023-01-06 13:02:12,936 - ==> Confusion:
[[328 101   0]
 [ 70 549   0]
 [  0   0   0]]

2023-01-06 13:02:12,938 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:12,938 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:12,948 - 

2023-01-06 13:02:12,948 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:13,344 - Epoch: [179][   10/   37]    Overall Loss 0.323847    Objective Loss 0.323847                                        LR 0.000008    Time 0.039555    
2023-01-06 13:02:13,587 - Epoch: [179][   20/   37]    Overall Loss 0.322342    Objective Loss 0.322342                                        LR 0.000008    Time 0.031879    
2023-01-06 13:02:13,832 - Epoch: [179][   30/   37]    Overall Loss 0.322106    Objective Loss 0.322106                                        LR 0.000008    Time 0.029412    
2023-01-06 13:02:13,985 - Epoch: [179][   37/   37]    Overall Loss 0.327589    Objective Loss 0.327589    Top1 85.146444    LR 0.000008    Time 0.027973    
2023-01-06 13:02:14,053 - --- validate (epoch=179)-----------
2023-01-06 13:02:14,053 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:14,258 - Epoch: [179][    5/    5]    Loss 0.383937    Top1 82.251908    
2023-01-06 13:02:14,315 - ==> Top1: 82.252    Loss: 0.384

2023-01-06 13:02:14,316 - ==> Confusion:
[[368  61   0]
 [125 494   0]
 [  0   0   0]]

2023-01-06 13:02:14,317 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:14,317 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:14,337 - 

2023-01-06 13:02:14,337 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:14,737 - Epoch: [180][   10/   37]    Overall Loss 0.338259    Objective Loss 0.338259                                        LR 0.000005    Time 0.039865    
2023-01-06 13:02:14,965 - Epoch: [180][   20/   37]    Overall Loss 0.336506    Objective Loss 0.336506                                        LR 0.000005    Time 0.031324    
2023-01-06 13:02:15,179 - Epoch: [180][   30/   37]    Overall Loss 0.326625    Objective Loss 0.326625                                        LR 0.000005    Time 0.028021    
2023-01-06 13:02:15,319 - Epoch: [180][   37/   37]    Overall Loss 0.328654    Objective Loss 0.328654    Top1 87.866109    LR 0.000005    Time 0.026477    
2023-01-06 13:02:15,393 - --- validate (epoch=180)-----------
2023-01-06 13:02:15,394 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:15,603 - Epoch: [180][    5/    5]    Loss 0.397422    Top1 83.015267    
2023-01-06 13:02:15,661 - ==> Top1: 83.015    Loss: 0.397

2023-01-06 13:02:15,661 - ==> Confusion:
[[377  52   0]
 [126 493   0]
 [  0   0   0]]

2023-01-06 13:02:15,663 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:15,663 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:15,672 - 

2023-01-06 13:02:15,673 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:16,073 - Epoch: [181][   10/   37]    Overall Loss 0.329070    Objective Loss 0.329070                                        LR 0.000005    Time 0.039921    
2023-01-06 13:02:16,322 - Epoch: [181][   20/   37]    Overall Loss 0.332721    Objective Loss 0.332721                                        LR 0.000005    Time 0.032423    
2023-01-06 13:02:16,582 - Epoch: [181][   30/   37]    Overall Loss 0.327942    Objective Loss 0.327942                                        LR 0.000005    Time 0.030253    
2023-01-06 13:02:16,728 - Epoch: [181][   37/   37]    Overall Loss 0.327915    Objective Loss 0.327915    Top1 84.518828    LR 0.000005    Time 0.028480    
2023-01-06 13:02:16,795 - --- validate (epoch=181)-----------
2023-01-06 13:02:16,795 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:17,009 - Epoch: [181][    5/    5]    Loss 0.369704    Top1 84.255725    
2023-01-06 13:02:17,075 - ==> Top1: 84.256    Loss: 0.370

2023-01-06 13:02:17,076 - ==> Confusion:
[[351  78   0]
 [ 87 532   0]
 [  0   0   0]]

2023-01-06 13:02:17,077 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:17,077 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:17,087 - 

2023-01-06 13:02:17,087 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:17,489 - Epoch: [182][   10/   37]    Overall Loss 0.316717    Objective Loss 0.316717                                        LR 0.000005    Time 0.040124    
2023-01-06 13:02:17,701 - Epoch: [182][   20/   37]    Overall Loss 0.323316    Objective Loss 0.323316                                        LR 0.000005    Time 0.030612    
2023-01-06 13:02:17,915 - Epoch: [182][   30/   37]    Overall Loss 0.326536    Objective Loss 0.326536                                        LR 0.000005    Time 0.027541    
2023-01-06 13:02:18,052 - Epoch: [182][   37/   37]    Overall Loss 0.328203    Objective Loss 0.328203    Top1 82.635983    LR 0.000005    Time 0.026038    
2023-01-06 13:02:18,118 - --- validate (epoch=182)-----------
2023-01-06 13:02:18,119 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:18,327 - Epoch: [182][    5/    5]    Loss 0.357618    Top1 82.729008    
2023-01-06 13:02:18,398 - ==> Top1: 82.729    Loss: 0.358

2023-01-06 13:02:18,398 - ==> Confusion:
[[368  61   0]
 [120 499   0]
 [  0   0   0]]

2023-01-06 13:02:18,400 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:18,400 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:18,420 - 

2023-01-06 13:02:18,420 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:18,806 - Epoch: [183][   10/   37]    Overall Loss 0.326352    Objective Loss 0.326352                                        LR 0.000005    Time 0.038484    
2023-01-06 13:02:19,016 - Epoch: [183][   20/   37]    Overall Loss 0.319451    Objective Loss 0.319451                                        LR 0.000005    Time 0.029716    
2023-01-06 13:02:19,264 - Epoch: [183][   30/   37]    Overall Loss 0.322624    Objective Loss 0.322624                                        LR 0.000005    Time 0.028073    
2023-01-06 13:02:19,419 - Epoch: [183][   37/   37]    Overall Loss 0.324704    Objective Loss 0.324704    Top1 85.774059    LR 0.000005    Time 0.026934    
2023-01-06 13:02:19,495 - --- validate (epoch=183)-----------
2023-01-06 13:02:19,495 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:19,708 - Epoch: [183][    5/    5]    Loss 0.380445    Top1 82.729008    
2023-01-06 13:02:19,775 - ==> Top1: 82.729    Loss: 0.380

2023-01-06 13:02:19,776 - ==> Confusion:
[[353  76   0]
 [105 514   0]
 [  0   0   0]]

2023-01-06 13:02:19,777 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:19,777 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:19,787 - 

2023-01-06 13:02:19,787 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:20,193 - Epoch: [184][   10/   37]    Overall Loss 0.338284    Objective Loss 0.338284                                        LR 0.000005    Time 0.040447    
2023-01-06 13:02:20,428 - Epoch: [184][   20/   37]    Overall Loss 0.321921    Objective Loss 0.321921                                        LR 0.000005    Time 0.031974    
2023-01-06 13:02:20,657 - Epoch: [184][   30/   37]    Overall Loss 0.326208    Objective Loss 0.326208                                        LR 0.000005    Time 0.028947    
2023-01-06 13:02:20,798 - Epoch: [184][   37/   37]    Overall Loss 0.325781    Objective Loss 0.325781    Top1 83.472803    LR 0.000005    Time 0.027260    
2023-01-06 13:02:20,863 - --- validate (epoch=184)-----------
2023-01-06 13:02:20,863 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:21,072 - Epoch: [184][    5/    5]    Loss 0.358591    Top1 83.683206    
2023-01-06 13:02:21,141 - ==> Top1: 83.683    Loss: 0.359

2023-01-06 13:02:21,142 - ==> Confusion:
[[361  68   0]
 [103 516   0]
 [  0   0   0]]

2023-01-06 13:02:21,143 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:21,143 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:21,164 - 

2023-01-06 13:02:21,164 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:21,565 - Epoch: [185][   10/   37]    Overall Loss 0.334768    Objective Loss 0.334768                                        LR 0.000005    Time 0.040016    
2023-01-06 13:02:21,809 - Epoch: [185][   20/   37]    Overall Loss 0.329379    Objective Loss 0.329379                                        LR 0.000005    Time 0.032199    
2023-01-06 13:02:22,036 - Epoch: [185][   30/   37]    Overall Loss 0.326375    Objective Loss 0.326375                                        LR 0.000005    Time 0.029020    
2023-01-06 13:02:22,173 - Epoch: [185][   37/   37]    Overall Loss 0.325777    Objective Loss 0.325777    Top1 85.146444    LR 0.000005    Time 0.027212    
2023-01-06 13:02:22,253 - --- validate (epoch=185)-----------
2023-01-06 13:02:22,253 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:22,458 - Epoch: [185][    5/    5]    Loss 0.378053    Top1 84.255725    
2023-01-06 13:02:22,513 - ==> Top1: 84.256    Loss: 0.378

2023-01-06 13:02:22,513 - ==> Confusion:
[[331  98   0]
 [ 67 552   0]
 [  0   0   0]]

2023-01-06 13:02:22,516 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:22,516 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:22,536 - 

2023-01-06 13:02:22,536 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:22,935 - Epoch: [186][   10/   37]    Overall Loss 0.336122    Objective Loss 0.336122                                        LR 0.000005    Time 0.039821    
2023-01-06 13:02:23,171 - Epoch: [186][   20/   37]    Overall Loss 0.333215    Objective Loss 0.333215                                        LR 0.000005    Time 0.031697    
2023-01-06 13:02:23,418 - Epoch: [186][   30/   37]    Overall Loss 0.328456    Objective Loss 0.328456                                        LR 0.000005    Time 0.029333    
2023-01-06 13:02:23,574 - Epoch: [186][   37/   37]    Overall Loss 0.326666    Objective Loss 0.326666    Top1 83.891213    LR 0.000005    Time 0.027998    
2023-01-06 13:02:23,643 - --- validate (epoch=186)-----------
2023-01-06 13:02:23,643 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:23,856 - Epoch: [186][    5/    5]    Loss 0.356771    Top1 83.015267    
2023-01-06 13:02:23,930 - ==> Top1: 83.015    Loss: 0.357

2023-01-06 13:02:23,930 - ==> Confusion:
[[353  76   0]
 [102 517   0]
 [  0   0   0]]

2023-01-06 13:02:23,932 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:23,932 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:23,952 - 

2023-01-06 13:02:23,952 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:24,364 - Epoch: [187][   10/   37]    Overall Loss 0.319017    Objective Loss 0.319017                                        LR 0.000005    Time 0.041123    
2023-01-06 13:02:24,608 - Epoch: [187][   20/   37]    Overall Loss 0.323506    Objective Loss 0.323506                                        LR 0.000005    Time 0.032742    
2023-01-06 13:02:24,862 - Epoch: [187][   30/   37]    Overall Loss 0.322958    Objective Loss 0.322958                                        LR 0.000005    Time 0.030292    
2023-01-06 13:02:25,020 - Epoch: [187][   37/   37]    Overall Loss 0.325968    Objective Loss 0.325968    Top1 84.518828    LR 0.000005    Time 0.028814    
2023-01-06 13:02:25,091 - --- validate (epoch=187)-----------
2023-01-06 13:02:25,091 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:25,299 - Epoch: [187][    5/    5]    Loss 0.340996    Top1 83.110687    
2023-01-06 13:02:25,368 - ==> Top1: 83.111    Loss: 0.341

2023-01-06 13:02:25,368 - ==> Confusion:
[[357  72   0]
 [105 514   0]
 [  0   0   0]]

2023-01-06 13:02:25,370 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:25,370 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:25,380 - 

2023-01-06 13:02:25,380 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:25,766 - Epoch: [188][   10/   37]    Overall Loss 0.324744    Objective Loss 0.324744                                        LR 0.000005    Time 0.038474    
2023-01-06 13:02:26,013 - Epoch: [188][   20/   37]    Overall Loss 0.331722    Objective Loss 0.331722                                        LR 0.000005    Time 0.031575    
2023-01-06 13:02:26,258 - Epoch: [188][   30/   37]    Overall Loss 0.324751    Objective Loss 0.324751                                        LR 0.000005    Time 0.029220    
2023-01-06 13:02:26,411 - Epoch: [188][   37/   37]    Overall Loss 0.324323    Objective Loss 0.324323    Top1 85.774059    LR 0.000005    Time 0.027809    
2023-01-06 13:02:26,493 - --- validate (epoch=188)-----------
2023-01-06 13:02:26,493 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:26,700 - Epoch: [188][    5/    5]    Loss 0.368933    Top1 83.683206    
2023-01-06 13:02:26,776 - ==> Top1: 83.683    Loss: 0.369

2023-01-06 13:02:26,777 - ==> Confusion:
[[358  71   0]
 [100 519   0]
 [  0   0   0]]

2023-01-06 13:02:26,778 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:26,778 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:26,798 - 

2023-01-06 13:02:26,799 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:27,201 - Epoch: [189][   10/   37]    Overall Loss 0.327429    Objective Loss 0.327429                                        LR 0.000005    Time 0.040165    
2023-01-06 13:02:27,425 - Epoch: [189][   20/   37]    Overall Loss 0.328211    Objective Loss 0.328211                                        LR 0.000005    Time 0.031247    
2023-01-06 13:02:27,666 - Epoch: [189][   30/   37]    Overall Loss 0.325202    Objective Loss 0.325202                                        LR 0.000005    Time 0.028871    
2023-01-06 13:02:27,818 - Epoch: [189][   37/   37]    Overall Loss 0.325467    Objective Loss 0.325467    Top1 83.891213    LR 0.000005    Time 0.027517    
2023-01-06 13:02:27,895 - --- validate (epoch=189)-----------
2023-01-06 13:02:27,895 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:28,105 - Epoch: [189][    5/    5]    Loss 0.373566    Top1 83.396947    
2023-01-06 13:02:28,167 - ==> Top1: 83.397    Loss: 0.374

2023-01-06 13:02:28,168 - ==> Confusion:
[[340  89   0]
 [ 85 534   0]
 [  0   0   0]]

2023-01-06 13:02:28,169 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:28,169 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:28,179 - 

2023-01-06 13:02:28,179 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:28,592 - Epoch: [190][   10/   37]    Overall Loss 0.322207    Objective Loss 0.322207                                        LR 0.000003    Time 0.041241    
2023-01-06 13:02:28,826 - Epoch: [190][   20/   37]    Overall Loss 0.326312    Objective Loss 0.326312                                        LR 0.000003    Time 0.032269    
2023-01-06 13:02:29,042 - Epoch: [190][   30/   37]    Overall Loss 0.328599    Objective Loss 0.328599                                        LR 0.000003    Time 0.028706    
2023-01-06 13:02:29,187 - Epoch: [190][   37/   37]    Overall Loss 0.322634    Objective Loss 0.322634    Top1 88.912134    LR 0.000003    Time 0.027184    
2023-01-06 13:02:29,255 - --- validate (epoch=190)-----------
2023-01-06 13:02:29,255 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:29,466 - Epoch: [190][    5/    5]    Loss 0.359780    Top1 83.396947    
2023-01-06 13:02:29,523 - ==> Top1: 83.397    Loss: 0.360

2023-01-06 13:02:29,523 - ==> Confusion:
[[361  68   0]
 [106 513   0]
 [  0   0   0]]

2023-01-06 13:02:29,525 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:29,525 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:29,546 - 

2023-01-06 13:02:29,546 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:29,948 - Epoch: [191][   10/   37]    Overall Loss 0.316548    Objective Loss 0.316548                                        LR 0.000003    Time 0.040172    
2023-01-06 13:02:30,199 - Epoch: [191][   20/   37]    Overall Loss 0.323163    Objective Loss 0.323163                                        LR 0.000003    Time 0.032588    
2023-01-06 13:02:30,452 - Epoch: [191][   30/   37]    Overall Loss 0.321497    Objective Loss 0.321497                                        LR 0.000003    Time 0.030143    
2023-01-06 13:02:30,603 - Epoch: [191][   37/   37]    Overall Loss 0.322683    Objective Loss 0.322683    Top1 80.543933    LR 0.000003    Time 0.028520    
2023-01-06 13:02:30,679 - --- validate (epoch=191)-----------
2023-01-06 13:02:30,679 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:30,896 - Epoch: [191][    5/    5]    Loss 0.347885    Top1 83.015267    
2023-01-06 13:02:30,951 - ==> Top1: 83.015    Loss: 0.348

2023-01-06 13:02:30,951 - ==> Confusion:
[[368  61   0]
 [117 502   0]
 [  0   0   0]]

2023-01-06 13:02:30,953 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:30,953 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:30,963 - 

2023-01-06 13:02:30,963 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:31,359 - Epoch: [192][   10/   37]    Overall Loss 0.320205    Objective Loss 0.320205                                        LR 0.000003    Time 0.039505    
2023-01-06 13:02:31,599 - Epoch: [192][   20/   37]    Overall Loss 0.319856    Objective Loss 0.319856                                        LR 0.000003    Time 0.031721    
2023-01-06 13:02:31,842 - Epoch: [192][   30/   37]    Overall Loss 0.323541    Objective Loss 0.323541                                        LR 0.000003    Time 0.029257    
2023-01-06 13:02:31,997 - Epoch: [192][   37/   37]    Overall Loss 0.324113    Objective Loss 0.324113    Top1 83.891213    LR 0.000003    Time 0.027906    
2023-01-06 13:02:32,070 - --- validate (epoch=192)-----------
2023-01-06 13:02:32,070 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:32,277 - Epoch: [192][    5/    5]    Loss 0.363561    Top1 82.729008    
2023-01-06 13:02:32,329 - ==> Top1: 82.729    Loss: 0.364

2023-01-06 13:02:32,329 - ==> Confusion:
[[345  84   0]
 [ 97 522   0]
 [  0   0   0]]

2023-01-06 13:02:32,331 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:32,331 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:32,351 - 

2023-01-06 13:02:32,352 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:32,871 - Epoch: [193][   10/   37]    Overall Loss 0.319008    Objective Loss 0.319008                                        LR 0.000003    Time 0.051882    
2023-01-06 13:02:33,119 - Epoch: [193][   20/   37]    Overall Loss 0.323759    Objective Loss 0.323759                                        LR 0.000003    Time 0.038319    
2023-01-06 13:02:33,360 - Epoch: [193][   30/   37]    Overall Loss 0.325919    Objective Loss 0.325919                                        LR 0.000003    Time 0.033572    
2023-01-06 13:02:33,498 - Epoch: [193][   37/   37]    Overall Loss 0.323721    Objective Loss 0.323721    Top1 85.146444    LR 0.000003    Time 0.030944    
2023-01-06 13:02:33,574 - --- validate (epoch=193)-----------
2023-01-06 13:02:33,574 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:33,784 - Epoch: [193][    5/    5]    Loss 0.389342    Top1 83.683206    
2023-01-06 13:02:33,847 - ==> Top1: 83.683    Loss: 0.389

2023-01-06 13:02:33,848 - ==> Confusion:
[[363  66   0]
 [105 514   0]
 [  0   0   0]]

2023-01-06 13:02:33,849 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:33,849 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:33,870 - 

2023-01-06 13:02:33,870 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:34,249 - Epoch: [194][   10/   37]    Overall Loss 0.303712    Objective Loss 0.303712                                        LR 0.000003    Time 0.037832    
2023-01-06 13:02:34,469 - Epoch: [194][   20/   37]    Overall Loss 0.314687    Objective Loss 0.314687                                        LR 0.000003    Time 0.029878    
2023-01-06 13:02:34,686 - Epoch: [194][   30/   37]    Overall Loss 0.317064    Objective Loss 0.317064                                        LR 0.000003    Time 0.027124    
2023-01-06 13:02:34,832 - Epoch: [194][   37/   37]    Overall Loss 0.321770    Objective Loss 0.321770    Top1 85.564854    LR 0.000003    Time 0.025943    
2023-01-06 13:02:34,896 - --- validate (epoch=194)-----------
2023-01-06 13:02:34,897 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:35,114 - Epoch: [194][    5/    5]    Loss 0.421346    Top1 83.301527    
2023-01-06 13:02:35,186 - ==> Top1: 83.302    Loss: 0.421

2023-01-06 13:02:35,187 - ==> Confusion:
[[367  62   0]
 [113 506   0]
 [  0   0   0]]

2023-01-06 13:02:35,188 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:35,188 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:35,199 - 

2023-01-06 13:02:35,199 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:35,588 - Epoch: [195][   10/   37]    Overall Loss 0.311843    Objective Loss 0.311843                                        LR 0.000003    Time 0.038825    
2023-01-06 13:02:35,827 - Epoch: [195][   20/   37]    Overall Loss 0.318223    Objective Loss 0.318223                                        LR 0.000003    Time 0.031299    
2023-01-06 13:02:36,058 - Epoch: [195][   30/   37]    Overall Loss 0.323485    Objective Loss 0.323485                                        LR 0.000003    Time 0.028562    
2023-01-06 13:02:36,203 - Epoch: [195][   37/   37]    Overall Loss 0.321842    Objective Loss 0.321842    Top1 86.192469    LR 0.000003    Time 0.027079    
2023-01-06 13:02:36,271 - --- validate (epoch=195)-----------
2023-01-06 13:02:36,271 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:36,479 - Epoch: [195][    5/    5]    Loss 0.353617    Top1 82.729008    
2023-01-06 13:02:36,551 - ==> Top1: 82.729    Loss: 0.354

2023-01-06 13:02:36,552 - ==> Confusion:
[[367  62   0]
 [119 500   0]
 [  0   0   0]]

2023-01-06 13:02:36,553 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:36,553 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:36,574 - 

2023-01-06 13:02:36,574 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:36,956 - Epoch: [196][   10/   37]    Overall Loss 0.322073    Objective Loss 0.322073                                        LR 0.000003    Time 0.038163    
2023-01-06 13:02:37,196 - Epoch: [196][   20/   37]    Overall Loss 0.325234    Objective Loss 0.325234                                        LR 0.000003    Time 0.030943    
2023-01-06 13:02:37,438 - Epoch: [196][   30/   37]    Overall Loss 0.322392    Objective Loss 0.322392                                        LR 0.000003    Time 0.028689    
2023-01-06 13:02:37,592 - Epoch: [196][   37/   37]    Overall Loss 0.323227    Objective Loss 0.323227    Top1 85.774059    LR 0.000003    Time 0.027410    
2023-01-06 13:02:37,665 - --- validate (epoch=196)-----------
2023-01-06 13:02:37,665 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:37,873 - Epoch: [196][    5/    5]    Loss 0.359094    Top1 84.351145    
2023-01-06 13:02:37,940 - ==> Top1: 84.351    Loss: 0.359

2023-01-06 13:02:37,940 - ==> Confusion:
[[359  70   0]
 [ 94 525   0]
 [  0   0   0]]

2023-01-06 13:02:37,942 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:37,942 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:37,962 - 

2023-01-06 13:02:37,962 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:38,386 - Epoch: [197][   10/   37]    Overall Loss 0.325610    Objective Loss 0.325610                                        LR 0.000003    Time 0.042355    
2023-01-06 13:02:38,636 - Epoch: [197][   20/   37]    Overall Loss 0.328374    Objective Loss 0.328374                                        LR 0.000003    Time 0.033638    
2023-01-06 13:02:38,889 - Epoch: [197][   30/   37]    Overall Loss 0.321061    Objective Loss 0.321061                                        LR 0.000003    Time 0.030861    
2023-01-06 13:02:39,043 - Epoch: [197][   37/   37]    Overall Loss 0.320168    Objective Loss 0.320168    Top1 84.518828    LR 0.000003    Time 0.029160    
2023-01-06 13:02:39,107 - --- validate (epoch=197)-----------
2023-01-06 13:02:39,107 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:39,320 - Epoch: [197][    5/    5]    Loss 0.354095    Top1 84.351145    
2023-01-06 13:02:39,390 - ==> Top1: 84.351    Loss: 0.354

2023-01-06 13:02:39,390 - ==> Confusion:
[[352  77   0]
 [ 87 532   0]
 [  0   0   0]]

2023-01-06 13:02:39,392 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:39,392 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:39,412 - 

2023-01-06 13:02:39,412 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:39,823 - Epoch: [198][   10/   37]    Overall Loss 0.319441    Objective Loss 0.319441                                        LR 0.000003    Time 0.040937    
2023-01-06 13:02:40,074 - Epoch: [198][   20/   37]    Overall Loss 0.320679    Objective Loss 0.320679                                        LR 0.000003    Time 0.032995    
2023-01-06 13:02:40,330 - Epoch: [198][   30/   37]    Overall Loss 0.321893    Objective Loss 0.321893                                        LR 0.000003    Time 0.030488    
2023-01-06 13:02:40,482 - Epoch: [198][   37/   37]    Overall Loss 0.322445    Objective Loss 0.322445    Top1 84.309623    LR 0.000003    Time 0.028830    
2023-01-06 13:02:40,558 - --- validate (epoch=198)-----------
2023-01-06 13:02:40,558 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:40,776 - Epoch: [198][    5/    5]    Loss 0.325608    Top1 83.587786    
2023-01-06 13:02:40,837 - ==> Top1: 83.588    Loss: 0.326

2023-01-06 13:02:40,838 - ==> Confusion:
[[363  66   0]
 [106 513   0]
 [  0   0   0]]

2023-01-06 13:02:40,839 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:40,840 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:40,849 - 

2023-01-06 13:02:40,849 - Training epoch: 9438 samples (256 per mini-batch)
2023-01-06 13:02:41,267 - Epoch: [199][   10/   37]    Overall Loss 0.320592    Objective Loss 0.320592                                        LR 0.000003    Time 0.041714    
2023-01-06 13:02:41,511 - Epoch: [199][   20/   37]    Overall Loss 0.322720    Objective Loss 0.322720                                        LR 0.000003    Time 0.033005    
2023-01-06 13:02:41,752 - Epoch: [199][   30/   37]    Overall Loss 0.321852    Objective Loss 0.321852                                        LR 0.000003    Time 0.030034    
2023-01-06 13:02:41,906 - Epoch: [199][   37/   37]    Overall Loss 0.320987    Objective Loss 0.320987    Top1 84.518828    LR 0.000003    Time 0.028501    
2023-01-06 13:02:41,974 - --- validate (epoch=199)-----------
2023-01-06 13:02:41,974 - 1048 samples (256 per mini-batch)
2023-01-06 13:02:42,181 - Epoch: [199][    5/    5]    Loss 0.340183    Top1 83.874046    
2023-01-06 13:02:42,240 - ==> Top1: 83.874    Loss: 0.340

2023-01-06 13:02:42,240 - ==> Confusion:
[[352  77   0]
 [ 92 527   0]
 [  0   0   0]]

2023-01-06 13:02:42,242 - ==> Best [Top1: 85.210   Sparsity:0.00   Params: 360896 on epoch: 161]
2023-01-06 13:02:42,242 - Saving checkpoint to: logs/2023.01.06-125753/qat_checkpoint.pth.tar
2023-01-06 13:02:42,263 - --- test ---------------------
2023-01-06 13:02:42,263 - 1317 samples (256 per mini-batch)
2023-01-06 13:02:42,493 - Test: [    6/    6]    Loss 0.393888    Top1 82.308276    
2023-01-06 13:02:42,549 - ==> Top1: 82.308    Loss: 0.394

2023-01-06 13:02:42,549 - ==> Confusion:
[[443 118   0]
 [115 641   0]
 [  0   0   0]]

2023-01-06 13:02:42,560 - 
2023-01-06 13:02:42,560 - Log file for this run: /home/ubuntumaschin/KeyWordSpotting_on_MAX78000/ai8x-training/logs/2023.01.06-125753/2023.01.06-125753.log
