2022-12-15 14:58:48,465 - Log file for this run: /home/ubuntumaschin/KeyWordSpotting_on_MAX78000/ai8x-training/logs/2022.12.15-145848/2022.12.15-145848.log
2022-12-15 14:58:50,479 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2022-12-15 14:58:50,480 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}
2022-12-15 15:01:42,289 - Dataset sizes:
	training=18864
	validation=2096
	test=3935
2022-12-15 15:01:42,290 - Reading compression schedule from: policies/schedule.yaml
2022-12-15 15:01:42,293 - 

2022-12-15 15:01:42,293 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:01:42,897 - Epoch: [0][   10/   74]    Overall Loss 3.310018    Objective Loss 3.310018                                        LR 0.001000    Time 0.060246    
2022-12-15 15:01:43,087 - Epoch: [0][   20/   74]    Overall Loss 3.200365    Objective Loss 3.200365                                        LR 0.001000    Time 0.039596    
2022-12-15 15:01:43,302 - Epoch: [0][   30/   74]    Overall Loss 3.134987    Objective Loss 3.134987                                        LR 0.001000    Time 0.033553    
2022-12-15 15:01:43,509 - Epoch: [0][   40/   74]    Overall Loss 3.100075    Objective Loss 3.100075                                        LR 0.001000    Time 0.030339    
2022-12-15 15:01:43,736 - Epoch: [0][   50/   74]    Overall Loss 3.077675    Objective Loss 3.077675                                        LR 0.001000    Time 0.028798    
2022-12-15 15:01:43,904 - Epoch: [0][   60/   74]    Overall Loss 3.060561    Objective Loss 3.060561                                        LR 0.001000    Time 0.026792    
2022-12-15 15:01:44,073 - Epoch: [0][   70/   74]    Overall Loss 3.045491    Objective Loss 3.045491                                        LR 0.001000    Time 0.025373    
2022-12-15 15:01:44,138 - Epoch: [0][   74/   74]    Overall Loss 3.043424    Objective Loss 3.043424    Top1 8.101852    Top5 43.055556    LR 0.001000    Time 0.024884    
2022-12-15 15:01:44,196 - --- validate (epoch=0)-----------
2022-12-15 15:01:44,197 - 2096 samples (256 per mini-batch)
2022-12-15 15:01:44,414 - Epoch: [0][    9/    9]    Loss 3.004551    Top1 8.206107    Top5 41.841603    
2022-12-15 15:01:44,460 - ==> Top1: 8.206    Top5: 41.842    Loss: 3.005

2022-12-15 15:01:44,462 - ==> Confusion:
[[  0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:01:44,463 - ==> Best [Top1: 8.206   Top5: 41.842   Sparsity:0.00   Params: 364480 on epoch: 0]
2022-12-15 15:01:44,464 - Saving checkpoint to: logs/2022.12.15-145848/checkpoint.pth.tar
2022-12-15 15:01:44,476 - 

2022-12-15 15:01:44,476 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:01:44,824 - Epoch: [1][   10/   74]    Overall Loss 2.995374    Objective Loss 2.995374                                        LR 0.001000    Time 0.034688    
2022-12-15 15:01:45,022 - Epoch: [1][   20/   74]    Overall Loss 2.977283    Objective Loss 2.977283                                        LR 0.001000    Time 0.027221    
2022-12-15 15:01:45,247 - Epoch: [1][   30/   74]    Overall Loss 2.976203    Objective Loss 2.976203                                        LR 0.001000    Time 0.025660    
2022-12-15 15:01:45,478 - Epoch: [1][   40/   74]    Overall Loss 2.975079    Objective Loss 2.975079                                        LR 0.001000    Time 0.024991    
2022-12-15 15:01:45,711 - Epoch: [1][   50/   74]    Overall Loss 2.978791    Objective Loss 2.978791                                        LR 0.001000    Time 0.024656    
2022-12-15 15:01:45,943 - Epoch: [1][   60/   74]    Overall Loss 2.976360    Objective Loss 2.976360                                        LR 0.001000    Time 0.024393    
2022-12-15 15:01:46,162 - Epoch: [1][   70/   74]    Overall Loss 2.980077    Objective Loss 2.980077                                        LR 0.001000    Time 0.024032    
2022-12-15 15:01:46,236 - Epoch: [1][   74/   74]    Overall Loss 2.980210    Objective Loss 2.980210    Top1 9.259259    Top5 43.518519    LR 0.001000    Time 0.023735    
2022-12-15 15:01:46,307 - --- validate (epoch=1)-----------
2022-12-15 15:01:46,307 - 2096 samples (256 per mini-batch)
2022-12-15 15:01:46,526 - Epoch: [1][    9/    9]    Loss 2.994342    Top1 7.538168    Top5 41.841603    
2022-12-15 15:01:46,575 - ==> Top1: 7.538    Top5: 41.842    Loss: 2.994

2022-12-15 15:01:46,577 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:01:46,579 - ==> Best [Top1: 8.206   Top5: 41.842   Sparsity:0.00   Params: 364480 on epoch: 0]
2022-12-15 15:01:46,579 - Saving checkpoint to: logs/2022.12.15-145848/checkpoint.pth.tar
2022-12-15 15:01:46,597 - 

2022-12-15 15:01:46,597 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:01:47,083 - Epoch: [2][   10/   74]    Overall Loss 2.972573    Objective Loss 2.972573                                        LR 0.001000    Time 0.048500    
2022-12-15 15:01:47,271 - Epoch: [2][   20/   74]    Overall Loss 2.969944    Objective Loss 2.969944                                        LR 0.001000    Time 0.033654    
2022-12-15 15:01:47,478 - Epoch: [2][   30/   74]    Overall Loss 2.972074    Objective Loss 2.972074                                        LR 0.001000    Time 0.029308    
2022-12-15 15:01:47,699 - Epoch: [2][   40/   74]    Overall Loss 2.979843    Objective Loss 2.979843                                        LR 0.001000    Time 0.027489    
2022-12-15 15:01:47,908 - Epoch: [2][   50/   74]    Overall Loss 2.980903    Objective Loss 2.980903                                        LR 0.001000    Time 0.026168    
2022-12-15 15:01:48,109 - Epoch: [2][   60/   74]    Overall Loss 2.980092    Objective Loss 2.980092                                        LR 0.001000    Time 0.025156    
2022-12-15 15:01:48,298 - Epoch: [2][   70/   74]    Overall Loss 2.980776    Objective Loss 2.980776                                        LR 0.001000    Time 0.024250    
2022-12-15 15:01:48,368 - Epoch: [2][   74/   74]    Overall Loss 2.979120    Objective Loss 2.979120    Top1 11.342593    Top5 45.833333    LR 0.001000    Time 0.023886    
2022-12-15 15:01:48,431 - --- validate (epoch=2)-----------
2022-12-15 15:01:48,432 - 2096 samples (256 per mini-batch)
2022-12-15 15:01:48,664 - Epoch: [2][    9/    9]    Loss 2.994791    Top1 7.538168    Top5 41.841603    
2022-12-15 15:01:48,712 - ==> Top1: 7.538    Top5: 41.842    Loss: 2.995

2022-12-15 15:01:48,714 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:01:48,716 - ==> Best [Top1: 8.206   Top5: 41.842   Sparsity:0.00   Params: 364480 on epoch: 0]
2022-12-15 15:01:48,716 - Saving checkpoint to: logs/2022.12.15-145848/checkpoint.pth.tar
2022-12-15 15:01:48,737 - 

2022-12-15 15:01:48,737 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:01:49,064 - Epoch: [3][   10/   74]    Overall Loss 2.964344    Objective Loss 2.964344                                        LR 0.001000    Time 0.032610    
2022-12-15 15:01:49,218 - Epoch: [3][   20/   74]    Overall Loss 2.956321    Objective Loss 2.956321                                        LR 0.001000    Time 0.023967    
2022-12-15 15:01:49,371 - Epoch: [3][   30/   74]    Overall Loss 2.964190    Objective Loss 2.964190                                        LR 0.001000    Time 0.021036    
2022-12-15 15:01:49,523 - Epoch: [3][   40/   74]    Overall Loss 2.964972    Objective Loss 2.964972                                        LR 0.001000    Time 0.019588    
2022-12-15 15:01:49,676 - Epoch: [3][   50/   74]    Overall Loss 2.974054    Objective Loss 2.974054                                        LR 0.001000    Time 0.018707    
2022-12-15 15:01:49,838 - Epoch: [3][   60/   74]    Overall Loss 2.976110    Objective Loss 2.976110                                        LR 0.001000    Time 0.018296    
2022-12-15 15:01:50,005 - Epoch: [3][   70/   74]    Overall Loss 2.976256    Objective Loss 2.976256                                        LR 0.001000    Time 0.018060    
2022-12-15 15:01:50,071 - Epoch: [3][   74/   74]    Overall Loss 2.977978    Objective Loss 2.977978    Top1 6.481481    Top5 42.592593    LR 0.001000    Time 0.017967    
2022-12-15 15:01:50,150 - --- validate (epoch=3)-----------
2022-12-15 15:01:50,150 - 2096 samples (256 per mini-batch)
2022-12-15 15:01:50,375 - Epoch: [3][    9/    9]    Loss 3.026824    Top1 9.017176    Top5 41.841603    
2022-12-15 15:01:50,442 - ==> Top1: 9.017    Top5: 41.842    Loss: 3.027

2022-12-15 15:01:50,444 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:01:50,445 - ==> Best [Top1: 9.017   Top5: 41.842   Sparsity:0.00   Params: 364480 on epoch: 3]
2022-12-15 15:01:50,445 - Saving checkpoint to: logs/2022.12.15-145848/checkpoint.pth.tar
2022-12-15 15:01:50,466 - 

2022-12-15 15:01:50,466 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:01:50,841 - Epoch: [4][   10/   74]    Overall Loss 2.992181    Objective Loss 2.992181                                        LR 0.001000    Time 0.037418    
2022-12-15 15:01:51,062 - Epoch: [4][   20/   74]    Overall Loss 2.990908    Objective Loss 2.990908                                        LR 0.001000    Time 0.029740    
2022-12-15 15:01:51,295 - Epoch: [4][   30/   74]    Overall Loss 2.986253    Objective Loss 2.986253                                        LR 0.001000    Time 0.027552    
2022-12-15 15:01:51,542 - Epoch: [4][   40/   74]    Overall Loss 2.983541    Objective Loss 2.983541                                        LR 0.001000    Time 0.026833    
2022-12-15 15:01:51,784 - Epoch: [4][   50/   74]    Overall Loss 2.982715    Objective Loss 2.982715                                        LR 0.001000    Time 0.026300    
2022-12-15 15:01:52,029 - Epoch: [4][   60/   74]    Overall Loss 2.980076    Objective Loss 2.980076                                        LR 0.001000    Time 0.025989    
2022-12-15 15:01:52,258 - Epoch: [4][   70/   74]    Overall Loss 2.978275    Objective Loss 2.978275                                        LR 0.001000    Time 0.025535    
2022-12-15 15:01:52,336 - Epoch: [4][   74/   74]    Overall Loss 2.979599    Objective Loss 2.979599    Top1 7.175926    Top5 40.972222    LR 0.001000    Time 0.025213    
2022-12-15 15:01:52,402 - --- validate (epoch=4)-----------
2022-12-15 15:01:52,402 - 2096 samples (256 per mini-batch)
2022-12-15 15:01:52,635 - Epoch: [4][    9/    9]    Loss 2.993106    Top1 8.492366    Top5 41.125954    
2022-12-15 15:01:52,680 - ==> Top1: 8.492    Top5: 41.126    Loss: 2.993

2022-12-15 15:01:52,682 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:01:52,683 - ==> Best [Top1: 9.017   Top5: 41.842   Sparsity:0.00   Params: 364480 on epoch: 3]
2022-12-15 15:01:52,683 - Saving checkpoint to: logs/2022.12.15-145848/checkpoint.pth.tar
2022-12-15 15:01:52,703 - 

2022-12-15 15:01:52,704 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:01:53,030 - Epoch: [5][   10/   74]    Overall Loss 2.978608    Objective Loss 2.978608                                        LR 0.001000    Time 0.032516    
2022-12-15 15:01:53,191 - Epoch: [5][   20/   74]    Overall Loss 2.979421    Objective Loss 2.979421                                        LR 0.001000    Time 0.024249    
2022-12-15 15:01:53,361 - Epoch: [5][   30/   74]    Overall Loss 2.978127    Objective Loss 2.978127                                        LR 0.001000    Time 0.021836    
2022-12-15 15:01:53,525 - Epoch: [5][   40/   74]    Overall Loss 2.983421    Objective Loss 2.983421                                        LR 0.001000    Time 0.020468    
2022-12-15 15:01:53,692 - Epoch: [5][   50/   74]    Overall Loss 2.979010    Objective Loss 2.979010                                        LR 0.001000    Time 0.019710    
2022-12-15 15:01:53,859 - Epoch: [5][   60/   74]    Overall Loss 2.976903    Objective Loss 2.976903                                        LR 0.001000    Time 0.019194    
2022-12-15 15:01:54,025 - Epoch: [5][   70/   74]    Overall Loss 2.977609    Objective Loss 2.977609                                        LR 0.001000    Time 0.018816    
2022-12-15 15:01:54,092 - Epoch: [5][   74/   74]    Overall Loss 2.980683    Objective Loss 2.980683    Top1 6.250000    Top5 38.425926    LR 0.001000    Time 0.018704    
2022-12-15 15:01:54,149 - --- validate (epoch=5)-----------
2022-12-15 15:01:54,149 - 2096 samples (256 per mini-batch)
2022-12-15 15:01:54,371 - Epoch: [5][    9/    9]    Loss 3.017936    Top1 7.538168    Top5 40.696565    
2022-12-15 15:01:54,432 - ==> Top1: 7.538    Top5: 40.697    Loss: 3.018

2022-12-15 15:01:54,434 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:01:54,435 - ==> Best [Top1: 9.017   Top5: 41.842   Sparsity:0.00   Params: 364480 on epoch: 3]
2022-12-15 15:01:54,435 - Saving checkpoint to: logs/2022.12.15-145848/checkpoint.pth.tar
2022-12-15 15:01:54,456 - 

2022-12-15 15:01:54,456 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:01:54,795 - Epoch: [6][   10/   74]    Overall Loss 2.967702    Objective Loss 2.967702                                        LR 0.001000    Time 0.033860    
2022-12-15 15:01:54,958 - Epoch: [6][   20/   74]    Overall Loss 2.982856    Objective Loss 2.982856                                        LR 0.001000    Time 0.025040    
2022-12-15 15:01:55,170 - Epoch: [6][   30/   74]    Overall Loss 2.988092    Objective Loss 2.988092                                        LR 0.001000    Time 0.023752    
2022-12-15 15:01:55,418 - Epoch: [6][   40/   74]    Overall Loss 2.988942    Objective Loss 2.988942                                        LR 0.001000    Time 0.023967    
2022-12-15 15:01:55,672 - Epoch: [6][   50/   74]    Overall Loss 2.982060    Objective Loss 2.982060                                        LR 0.001000    Time 0.024250    
2022-12-15 15:01:55,913 - Epoch: [6][   60/   74]    Overall Loss 2.981005    Objective Loss 2.981005                                        LR 0.001000    Time 0.024221    
2022-12-15 15:01:56,147 - Epoch: [6][   70/   74]    Overall Loss 2.979409    Objective Loss 2.979409                                        LR 0.001000    Time 0.024094    
2022-12-15 15:01:56,225 - Epoch: [6][   74/   74]    Overall Loss 2.979960    Objective Loss 2.979960    Top1 6.944444    Top5 40.740741    LR 0.001000    Time 0.023848    
2022-12-15 15:01:56,287 - --- validate (epoch=6)-----------
2022-12-15 15:01:56,288 - 2096 samples (256 per mini-batch)
2022-12-15 15:01:56,511 - Epoch: [6][    9/    9]    Loss 2.995085    Top1 8.206107    Top5 41.841603    
2022-12-15 15:01:56,563 - ==> Top1: 8.206    Top5: 41.842    Loss: 2.995

2022-12-15 15:01:56,565 - ==> Confusion:
[[  0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:01:56,567 - ==> Best [Top1: 9.017   Top5: 41.842   Sparsity:0.00   Params: 364480 on epoch: 3]
2022-12-15 15:01:56,567 - Saving checkpoint to: logs/2022.12.15-145848/checkpoint.pth.tar
2022-12-15 15:01:56,578 - 

2022-12-15 15:01:56,578 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:01:56,936 - Epoch: [7][   10/   74]    Overall Loss 2.997184    Objective Loss 2.997184                                        LR 0.001000    Time 0.035712    
2022-12-15 15:01:57,117 - Epoch: [7][   20/   74]    Overall Loss 2.984252    Objective Loss 2.984252                                        LR 0.001000    Time 0.026872    
2022-12-15 15:01:57,317 - Epoch: [7][   30/   74]    Overall Loss 2.979708    Objective Loss 2.979708                                        LR 0.001000    Time 0.024567    
2022-12-15 15:01:57,490 - Epoch: [7][   40/   74]    Overall Loss 2.979707    Objective Loss 2.979707                                        LR 0.001000    Time 0.022746    
2022-12-15 15:01:57,705 - Epoch: [7][   50/   74]    Overall Loss 2.977443    Objective Loss 2.977443                                        LR 0.001000    Time 0.022493    
2022-12-15 15:01:57,963 - Epoch: [7][   60/   74]    Overall Loss 2.980496    Objective Loss 2.980496                                        LR 0.001000    Time 0.023021    
2022-12-15 15:01:58,199 - Epoch: [7][   70/   74]    Overall Loss 2.980272    Objective Loss 2.980272                                        LR 0.001000    Time 0.023082    
2022-12-15 15:01:58,274 - Epoch: [7][   74/   74]    Overall Loss 2.980761    Objective Loss 2.980761    Top1 8.564815    Top5 42.824074    LR 0.001000    Time 0.022838    
2022-12-15 15:01:58,338 - --- validate (epoch=7)-----------
2022-12-15 15:01:58,338 - 2096 samples (256 per mini-batch)
2022-12-15 15:01:58,571 - Epoch: [7][    9/    9]    Loss 2.993561    Top1 9.017176    Top5 41.507634    
2022-12-15 15:01:58,628 - ==> Top1: 9.017    Top5: 41.508    Loss: 2.994

2022-12-15 15:01:58,630 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  19   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:01:58,631 - ==> Best [Top1: 9.017   Top5: 41.842   Sparsity:0.00   Params: 364480 on epoch: 3]
2022-12-15 15:01:58,631 - Saving checkpoint to: logs/2022.12.15-145848/checkpoint.pth.tar
2022-12-15 15:01:58,642 - 

2022-12-15 15:01:58,643 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:01:58,981 - Epoch: [8][   10/   74]    Overall Loss 3.007877    Objective Loss 3.007877                                        LR 0.001000    Time 0.033720    
2022-12-15 15:01:59,139 - Epoch: [8][   20/   74]    Overall Loss 2.992998    Objective Loss 2.992998                                        LR 0.001000    Time 0.024770    
2022-12-15 15:01:59,307 - Epoch: [8][   30/   74]    Overall Loss 2.994094    Objective Loss 2.994094                                        LR 0.001000    Time 0.022101    
2022-12-15 15:01:59,478 - Epoch: [8][   40/   74]    Overall Loss 2.987175    Objective Loss 2.987175                                        LR 0.001000    Time 0.020825    
2022-12-15 15:01:59,642 - Epoch: [8][   50/   74]    Overall Loss 2.983467    Objective Loss 2.983467                                        LR 0.001000    Time 0.019903    
2022-12-15 15:01:59,810 - Epoch: [8][   60/   74]    Overall Loss 2.982868    Objective Loss 2.982868                                        LR 0.001000    Time 0.019362    
2022-12-15 15:01:59,975 - Epoch: [8][   70/   74]    Overall Loss 2.981354    Objective Loss 2.981354                                        LR 0.001000    Time 0.018947    
2022-12-15 15:02:00,037 - Epoch: [8][   74/   74]    Overall Loss 2.980334    Objective Loss 2.980334    Top1 9.490741    Top5 42.824074    LR 0.001000    Time 0.018762    
2022-12-15 15:02:00,107 - --- validate (epoch=8)-----------
2022-12-15 15:02:00,107 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:00,335 - Epoch: [8][    9/    9]    Loss 2.999461    Top1 9.017176    Top5 42.175573    
2022-12-15 15:02:00,388 - ==> Top1: 9.017    Top5: 42.176    Loss: 2.999

2022-12-15 15:02:00,390 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:00,391 - ==> Best [Top1: 9.017   Top5: 42.176   Sparsity:0.00   Params: 364480 on epoch: 8]
2022-12-15 15:02:00,392 - Saving checkpoint to: logs/2022.12.15-145848/checkpoint.pth.tar
2022-12-15 15:02:00,417 - 

2022-12-15 15:02:00,417 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:00,876 - Epoch: [9][   10/   74]    Overall Loss 2.982479    Objective Loss 2.982479                                        LR 0.001000    Time 0.045863    
2022-12-15 15:02:01,050 - Epoch: [9][   20/   74]    Overall Loss 2.974631    Objective Loss 2.974631                                        LR 0.001000    Time 0.031558    
2022-12-15 15:02:01,210 - Epoch: [9][   30/   74]    Overall Loss 2.970707    Objective Loss 2.970707                                        LR 0.001000    Time 0.026374    
2022-12-15 15:02:01,378 - Epoch: [9][   40/   74]    Overall Loss 2.976099    Objective Loss 2.976099                                        LR 0.001000    Time 0.023972    
2022-12-15 15:02:01,552 - Epoch: [9][   50/   74]    Overall Loss 2.980738    Objective Loss 2.980738                                        LR 0.001000    Time 0.022643    
2022-12-15 15:02:01,722 - Epoch: [9][   60/   74]    Overall Loss 2.981137    Objective Loss 2.981137                                        LR 0.001000    Time 0.021707    
2022-12-15 15:02:01,897 - Epoch: [9][   70/   74]    Overall Loss 2.980597    Objective Loss 2.980597                                        LR 0.001000    Time 0.021097    
2022-12-15 15:02:01,958 - Epoch: [9][   74/   74]    Overall Loss 2.980202    Objective Loss 2.980202    Top1 7.175926    Top5 41.666667    LR 0.001000    Time 0.020784    
2022-12-15 15:02:02,034 - --- validate (epoch=9)-----------
2022-12-15 15:02:02,034 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:02,262 - Epoch: [9][    9/    9]    Loss 2.990609    Top1 7.538168    Top5 41.841603    
2022-12-15 15:02:02,318 - ==> Top1: 7.538    Top5: 41.842    Loss: 2.991

2022-12-15 15:02:02,319 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:02,321 - ==> Best [Top1: 9.017   Top5: 42.176   Sparsity:0.00   Params: 364480 on epoch: 8]
2022-12-15 15:02:02,321 - Saving checkpoint to: logs/2022.12.15-145848/checkpoint.pth.tar
2022-12-15 15:02:02,358 - 

2022-12-15 15:02:02,358 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:02,744 - Epoch: [10][   10/   74]    Overall Loss 3.671312    Objective Loss 3.671312                                        LR 0.001000    Time 0.038579    
2022-12-15 15:02:02,949 - Epoch: [10][   20/   74]    Overall Loss 3.409437    Objective Loss 3.409437                                        LR 0.001000    Time 0.029497    
2022-12-15 15:02:03,162 - Epoch: [10][   30/   74]    Overall Loss 3.298019    Objective Loss 3.298019                                        LR 0.001000    Time 0.026758    
2022-12-15 15:02:03,383 - Epoch: [10][   40/   74]    Overall Loss 3.233393    Objective Loss 3.233393                                        LR 0.001000    Time 0.025589    
2022-12-15 15:02:03,612 - Epoch: [10][   50/   74]    Overall Loss 3.199114    Objective Loss 3.199114                                        LR 0.001000    Time 0.025030    
2022-12-15 15:02:03,837 - Epoch: [10][   60/   74]    Overall Loss 3.164118    Objective Loss 3.164118                                        LR 0.001000    Time 0.024603    
2022-12-15 15:02:04,054 - Epoch: [10][   70/   74]    Overall Loss 3.139589    Objective Loss 3.139589                                        LR 0.001000    Time 0.024188    
2022-12-15 15:02:04,132 - Epoch: [10][   74/   74]    Overall Loss 3.133336    Objective Loss 3.133336    Top1 9.722222    Top5 41.435185    LR 0.001000    Time 0.023930    
2022-12-15 15:02:04,198 - --- validate (epoch=10)-----------
2022-12-15 15:02:04,199 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:04,473 - Epoch: [10][    9/    9]    Loss 3.007623    Top1 7.538168    Top5 40.696565    
2022-12-15 15:02:04,528 - ==> Top1: 7.538    Top5: 40.697    Loss: 3.008

2022-12-15 15:02:04,530 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:04,531 - ==> Best [Top1: 7.538   Top5: 40.697   Sparsity:0.00   Params: 364480 on epoch: 10]
2022-12-15 15:02:04,531 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:04,543 - 

2022-12-15 15:02:04,544 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:04,978 - Epoch: [11][   10/   74]    Overall Loss 2.995937    Objective Loss 2.995937                                        LR 0.001000    Time 0.043377    
2022-12-15 15:02:05,208 - Epoch: [11][   20/   74]    Overall Loss 3.005059    Objective Loss 3.005059                                        LR 0.001000    Time 0.033179    
2022-12-15 15:02:05,470 - Epoch: [11][   30/   74]    Overall Loss 3.014758    Objective Loss 3.014758                                        LR 0.001000    Time 0.030816    
2022-12-15 15:02:05,731 - Epoch: [11][   40/   74]    Overall Loss 3.040076    Objective Loss 3.040076                                        LR 0.001000    Time 0.029639    
2022-12-15 15:02:06,026 - Epoch: [11][   50/   74]    Overall Loss 3.048178    Objective Loss 3.048178                                        LR 0.001000    Time 0.029571    
2022-12-15 15:02:06,320 - Epoch: [11][   60/   74]    Overall Loss 3.043978    Objective Loss 3.043978                                        LR 0.001000    Time 0.029530    
2022-12-15 15:02:06,604 - Epoch: [11][   70/   74]    Overall Loss 3.043543    Objective Loss 3.043543                                        LR 0.001000    Time 0.029367    
2022-12-15 15:02:06,705 - Epoch: [11][   74/   74]    Overall Loss 3.044255    Objective Loss 3.044255    Top1 8.796296    Top5 39.583333    LR 0.001000    Time 0.029134    
2022-12-15 15:02:06,768 - --- validate (epoch=11)-----------
2022-12-15 15:02:06,768 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:07,034 - Epoch: [11][    9/    9]    Loss 3.023697    Top1 7.538168    Top5 41.507634    
2022-12-15 15:02:07,096 - ==> Top1: 7.538    Top5: 41.508    Loss: 3.024

2022-12-15 15:02:07,099 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:07,100 - ==> Best [Top1: 7.538   Top5: 41.508   Sparsity:0.00   Params: 364480 on epoch: 11]
2022-12-15 15:02:07,101 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:07,126 - 

2022-12-15 15:02:07,127 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:07,538 - Epoch: [12][   10/   74]    Overall Loss 3.000810    Objective Loss 3.000810                                        LR 0.001000    Time 0.041020    
2022-12-15 15:02:07,802 - Epoch: [12][   20/   74]    Overall Loss 3.019899    Objective Loss 3.019899                                        LR 0.001000    Time 0.033713    
2022-12-15 15:02:08,067 - Epoch: [12][   30/   74]    Overall Loss 3.010954    Objective Loss 3.010954                                        LR 0.001000    Time 0.031302    
2022-12-15 15:02:08,330 - Epoch: [12][   40/   74]    Overall Loss 3.017186    Objective Loss 3.017186                                        LR 0.001000    Time 0.030033    
2022-12-15 15:02:08,605 - Epoch: [12][   50/   74]    Overall Loss 3.021445    Objective Loss 3.021445                                        LR 0.001000    Time 0.029527    
2022-12-15 15:02:08,874 - Epoch: [12][   60/   74]    Overall Loss 3.019431    Objective Loss 3.019431                                        LR 0.001000    Time 0.029073    
2022-12-15 15:02:09,124 - Epoch: [12][   70/   74]    Overall Loss 3.019978    Objective Loss 3.019978                                        LR 0.001000    Time 0.028488    
2022-12-15 15:02:09,211 - Epoch: [12][   74/   74]    Overall Loss 3.021199    Objective Loss 3.021199    Top1 9.027778    Top5 40.740741    LR 0.001000    Time 0.028122    
2022-12-15 15:02:09,283 - --- validate (epoch=12)-----------
2022-12-15 15:02:09,283 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:09,563 - Epoch: [12][    9/    9]    Loss 3.037446    Top1 8.492366    Top5 37.356870    
2022-12-15 15:02:09,615 - ==> Top1: 8.492    Top5: 37.357    Loss: 3.037

2022-12-15 15:02:09,617 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:09,618 - ==> Best [Top1: 8.492   Top5: 37.357   Sparsity:0.00   Params: 364480 on epoch: 12]
2022-12-15 15:02:09,618 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:09,640 - 

2022-12-15 15:02:09,640 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:10,075 - Epoch: [13][   10/   74]    Overall Loss 3.015954    Objective Loss 3.015954                                        LR 0.001000    Time 0.043355    
2022-12-15 15:02:10,334 - Epoch: [13][   20/   74]    Overall Loss 3.016982    Objective Loss 3.016982                                        LR 0.001000    Time 0.034633    
2022-12-15 15:02:10,598 - Epoch: [13][   30/   74]    Overall Loss 3.017766    Objective Loss 3.017766                                        LR 0.001000    Time 0.031883    
2022-12-15 15:02:10,861 - Epoch: [13][   40/   74]    Overall Loss 3.015670    Objective Loss 3.015670                                        LR 0.001000    Time 0.030482    
2022-12-15 15:02:11,110 - Epoch: [13][   50/   74]    Overall Loss 3.024634    Objective Loss 3.024634                                        LR 0.001000    Time 0.029355    
2022-12-15 15:02:11,361 - Epoch: [13][   60/   74]    Overall Loss 3.023162    Objective Loss 3.023162                                        LR 0.001000    Time 0.028637    
2022-12-15 15:02:11,605 - Epoch: [13][   70/   74]    Overall Loss 3.024069    Objective Loss 3.024069                                        LR 0.001000    Time 0.028016    
2022-12-15 15:02:11,692 - Epoch: [13][   74/   74]    Overall Loss 3.019378    Objective Loss 3.019378    Top1 10.185185    Top5 45.370370    LR 0.001000    Time 0.027681    
2022-12-15 15:02:11,752 - --- validate (epoch=13)-----------
2022-12-15 15:02:11,752 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:12,019 - Epoch: [13][    9/    9]    Loss 3.033712    Top1 9.017176    Top5 39.408397    
2022-12-15 15:02:12,072 - ==> Top1: 9.017    Top5: 39.408    Loss: 3.034

2022-12-15 15:02:12,074 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:12,076 - ==> Best [Top1: 9.017   Top5: 39.408   Sparsity:0.00   Params: 364480 on epoch: 13]
2022-12-15 15:02:12,076 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:12,104 - 

2022-12-15 15:02:12,105 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:12,488 - Epoch: [14][   10/   74]    Overall Loss 2.996124    Objective Loss 2.996124                                        LR 0.001000    Time 0.038226    
2022-12-15 15:02:12,711 - Epoch: [14][   20/   74]    Overall Loss 2.997819    Objective Loss 2.997819                                        LR 0.001000    Time 0.030278    
2022-12-15 15:02:12,955 - Epoch: [14][   30/   74]    Overall Loss 3.000296    Objective Loss 3.000296                                        LR 0.001000    Time 0.028277    
2022-12-15 15:02:13,202 - Epoch: [14][   40/   74]    Overall Loss 2.991693    Objective Loss 2.991693                                        LR 0.001000    Time 0.027384    
2022-12-15 15:02:13,449 - Epoch: [14][   50/   74]    Overall Loss 2.998868    Objective Loss 2.998868                                        LR 0.001000    Time 0.026834    
2022-12-15 15:02:13,697 - Epoch: [14][   60/   74]    Overall Loss 3.000359    Objective Loss 3.000359                                        LR 0.001000    Time 0.026485    
2022-12-15 15:02:13,933 - Epoch: [14][   70/   74]    Overall Loss 3.002911    Objective Loss 3.002911                                        LR 0.001000    Time 0.026077    
2022-12-15 15:02:14,020 - Epoch: [14][   74/   74]    Overall Loss 3.006309    Objective Loss 3.006309    Top1 9.027778    Top5 36.805556    LR 0.001000    Time 0.025840    
2022-12-15 15:02:14,080 - --- validate (epoch=14)-----------
2022-12-15 15:02:14,080 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:14,354 - Epoch: [14][    9/    9]    Loss 3.038594    Top1 8.206107    Top5 41.841603    
2022-12-15 15:02:14,419 - ==> Top1: 8.206    Top5: 41.842    Loss: 3.039

2022-12-15 15:02:14,421 - ==> Confusion:
[[  0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:14,422 - ==> Best [Top1: 9.017   Top5: 39.408   Sparsity:0.00   Params: 364480 on epoch: 13]
2022-12-15 15:02:14,422 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:14,442 - 

2022-12-15 15:02:14,442 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:14,982 - Epoch: [15][   10/   74]    Overall Loss 2.996652    Objective Loss 2.996652                                        LR 0.001000    Time 0.053919    
2022-12-15 15:02:15,239 - Epoch: [15][   20/   74]    Overall Loss 3.006861    Objective Loss 3.006861                                        LR 0.001000    Time 0.039757    
2022-12-15 15:02:15,496 - Epoch: [15][   30/   74]    Overall Loss 3.003748    Objective Loss 3.003748                                        LR 0.001000    Time 0.035009    
2022-12-15 15:02:15,752 - Epoch: [15][   40/   74]    Overall Loss 3.013936    Objective Loss 3.013936                                        LR 0.001000    Time 0.032650    
2022-12-15 15:02:16,016 - Epoch: [15][   50/   74]    Overall Loss 3.009966    Objective Loss 3.009966                                        LR 0.001000    Time 0.031380    
2022-12-15 15:02:16,267 - Epoch: [15][   60/   74]    Overall Loss 3.009652    Objective Loss 3.009652                                        LR 0.001000    Time 0.030324    
2022-12-15 15:02:16,509 - Epoch: [15][   70/   74]    Overall Loss 3.009435    Objective Loss 3.009435                                        LR 0.001000    Time 0.029451    
2022-12-15 15:02:16,597 - Epoch: [15][   74/   74]    Overall Loss 3.011225    Objective Loss 3.011225    Top1 8.333333    Top5 35.416667    LR 0.001000    Time 0.029048    
2022-12-15 15:02:16,669 - --- validate (epoch=15)-----------
2022-12-15 15:02:16,670 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:16,938 - Epoch: [15][    9/    9]    Loss 3.027702    Top1 7.538168    Top5 37.833969    
2022-12-15 15:02:16,990 - ==> Top1: 7.538    Top5: 37.834    Loss: 3.028

2022-12-15 15:02:16,992 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:16,993 - ==> Best [Top1: 9.017   Top5: 39.408   Sparsity:0.00   Params: 364480 on epoch: 13]
2022-12-15 15:02:16,993 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:17,003 - 

2022-12-15 15:02:17,003 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:17,397 - Epoch: [16][   10/   74]    Overall Loss 3.005614    Objective Loss 3.005614                                        LR 0.001000    Time 0.039302    
2022-12-15 15:02:17,643 - Epoch: [16][   20/   74]    Overall Loss 3.006011    Objective Loss 3.006011                                        LR 0.001000    Time 0.031944    
2022-12-15 15:02:17,894 - Epoch: [16][   30/   74]    Overall Loss 3.003476    Objective Loss 3.003476                                        LR 0.001000    Time 0.029620    
2022-12-15 15:02:18,143 - Epoch: [16][   40/   74]    Overall Loss 3.000803    Objective Loss 3.000803                                        LR 0.001000    Time 0.028449    
2022-12-15 15:02:18,393 - Epoch: [16][   50/   74]    Overall Loss 3.007584    Objective Loss 3.007584                                        LR 0.001000    Time 0.027741    
2022-12-15 15:02:18,645 - Epoch: [16][   60/   74]    Overall Loss 3.009391    Objective Loss 3.009391                                        LR 0.001000    Time 0.027304    
2022-12-15 15:02:18,893 - Epoch: [16][   70/   74]    Overall Loss 3.008006    Objective Loss 3.008006                                        LR 0.001000    Time 0.026944    
2022-12-15 15:02:18,982 - Epoch: [16][   74/   74]    Overall Loss 3.011320    Objective Loss 3.011320    Top1 7.638889    Top5 39.351852    LR 0.001000    Time 0.026688    
2022-12-15 15:02:19,039 - --- validate (epoch=16)-----------
2022-12-15 15:02:19,039 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:19,312 - Epoch: [16][    9/    9]    Loss 3.051731    Top1 7.538168    Top5 38.549618    
2022-12-15 15:02:19,366 - ==> Top1: 7.538    Top5: 38.550    Loss: 3.052

2022-12-15 15:02:19,368 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:19,369 - ==> Best [Top1: 9.017   Top5: 39.408   Sparsity:0.00   Params: 364480 on epoch: 13]
2022-12-15 15:02:19,369 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:19,390 - 

2022-12-15 15:02:19,390 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:19,807 - Epoch: [17][   10/   74]    Overall Loss 3.030291    Objective Loss 3.030291                                        LR 0.001000    Time 0.041628    
2022-12-15 15:02:20,051 - Epoch: [17][   20/   74]    Overall Loss 3.021166    Objective Loss 3.021166                                        LR 0.001000    Time 0.032982    
2022-12-15 15:02:20,295 - Epoch: [17][   30/   74]    Overall Loss 3.019904    Objective Loss 3.019904                                        LR 0.001000    Time 0.030105    
2022-12-15 15:02:20,541 - Epoch: [17][   40/   74]    Overall Loss 3.017849    Objective Loss 3.017849                                        LR 0.001000    Time 0.028716    
2022-12-15 15:02:20,793 - Epoch: [17][   50/   74]    Overall Loss 3.018394    Objective Loss 3.018394                                        LR 0.001000    Time 0.028014    
2022-12-15 15:02:21,044 - Epoch: [17][   60/   74]    Overall Loss 3.020306    Objective Loss 3.020306                                        LR 0.001000    Time 0.027525    
2022-12-15 15:02:21,285 - Epoch: [17][   70/   74]    Overall Loss 3.020101    Objective Loss 3.020101                                        LR 0.001000    Time 0.027024    
2022-12-15 15:02:21,372 - Epoch: [17][   74/   74]    Overall Loss 3.017811    Objective Loss 3.017811    Top1 8.333333    Top5 46.759259    LR 0.001000    Time 0.026734    
2022-12-15 15:02:21,438 - --- validate (epoch=17)-----------
2022-12-15 15:02:21,438 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:21,713 - Epoch: [17][    9/    9]    Loss 3.034462    Top1 9.017176    Top5 41.507634    
2022-12-15 15:02:21,761 - ==> Top1: 9.017    Top5: 41.508    Loss: 3.034

2022-12-15 15:02:21,763 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:21,764 - ==> Best [Top1: 9.017   Top5: 41.508   Sparsity:0.00   Params: 364480 on epoch: 17]
2022-12-15 15:02:21,764 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:21,796 - 

2022-12-15 15:02:21,796 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:22,187 - Epoch: [18][   10/   74]    Overall Loss 3.012958    Objective Loss 3.012958                                        LR 0.001000    Time 0.039056    
2022-12-15 15:02:22,399 - Epoch: [18][   20/   74]    Overall Loss 3.013491    Objective Loss 3.013491                                        LR 0.001000    Time 0.030052    
2022-12-15 15:02:22,612 - Epoch: [18][   30/   74]    Overall Loss 3.005809    Objective Loss 3.005809                                        LR 0.001000    Time 0.027127    
2022-12-15 15:02:22,828 - Epoch: [18][   40/   74]    Overall Loss 3.007411    Objective Loss 3.007411                                        LR 0.001000    Time 0.025756    
2022-12-15 15:02:23,043 - Epoch: [18][   50/   74]    Overall Loss 3.004760    Objective Loss 3.004760                                        LR 0.001000    Time 0.024892    
2022-12-15 15:02:23,259 - Epoch: [18][   60/   74]    Overall Loss 3.006891    Objective Loss 3.006891                                        LR 0.001000    Time 0.024334    
2022-12-15 15:02:23,468 - Epoch: [18][   70/   74]    Overall Loss 3.007114    Objective Loss 3.007114                                        LR 0.001000    Time 0.023841    
2022-12-15 15:02:23,546 - Epoch: [18][   74/   74]    Overall Loss 3.007063    Objective Loss 3.007063    Top1 9.953704    Top5 39.351852    LR 0.001000    Time 0.023599    
2022-12-15 15:02:23,617 - --- validate (epoch=18)-----------
2022-12-15 15:02:23,617 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:23,890 - Epoch: [18][    9/    9]    Loss 3.035317    Top1 8.492366    Top5 41.125954    
2022-12-15 15:02:23,945 - ==> Top1: 8.492    Top5: 41.126    Loss: 3.035

2022-12-15 15:02:23,947 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:23,948 - ==> Best [Top1: 9.017   Top5: 41.508   Sparsity:0.00   Params: 364480 on epoch: 17]
2022-12-15 15:02:23,948 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:23,959 - 

2022-12-15 15:02:23,959 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:24,374 - Epoch: [19][   10/   74]    Overall Loss 3.009777    Objective Loss 3.009777                                        LR 0.001000    Time 0.041412    
2022-12-15 15:02:24,624 - Epoch: [19][   20/   74]    Overall Loss 3.004994    Objective Loss 3.004994                                        LR 0.001000    Time 0.033223    
2022-12-15 15:02:24,873 - Epoch: [19][   30/   74]    Overall Loss 3.005884    Objective Loss 3.005884                                        LR 0.001000    Time 0.030427    
2022-12-15 15:02:25,119 - Epoch: [19][   40/   74]    Overall Loss 3.003604    Objective Loss 3.003604                                        LR 0.001000    Time 0.028957    
2022-12-15 15:02:25,373 - Epoch: [19][   50/   74]    Overall Loss 3.002652    Objective Loss 3.002652                                        LR 0.001000    Time 0.028227    
2022-12-15 15:02:25,623 - Epoch: [19][   60/   74]    Overall Loss 3.004000    Objective Loss 3.004000                                        LR 0.001000    Time 0.027695    
2022-12-15 15:02:25,872 - Epoch: [19][   70/   74]    Overall Loss 3.003697    Objective Loss 3.003697                                        LR 0.001000    Time 0.027283    
2022-12-15 15:02:25,958 - Epoch: [19][   74/   74]    Overall Loss 3.005296    Objective Loss 3.005296    Top1 8.796296    Top5 40.046296    LR 0.001000    Time 0.026974    
2022-12-15 15:02:26,026 - --- validate (epoch=19)-----------
2022-12-15 15:02:26,026 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:26,306 - Epoch: [19][    9/    9]    Loss 2.998018    Top1 9.017176    Top5 40.076336    
2022-12-15 15:02:26,375 - ==> Top1: 9.017    Top5: 40.076    Loss: 2.998

2022-12-15 15:02:26,377 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:26,378 - ==> Best [Top1: 9.017   Top5: 41.508   Sparsity:0.00   Params: 364480 on epoch: 17]
2022-12-15 15:02:26,379 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:26,389 - 

2022-12-15 15:02:26,389 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:26,778 - Epoch: [20][   10/   74]    Overall Loss 2.993256    Objective Loss 2.993256                                        LR 0.001000    Time 0.038818    
2022-12-15 15:02:27,020 - Epoch: [20][   20/   74]    Overall Loss 3.002854    Objective Loss 3.002854                                        LR 0.001000    Time 0.031492    
2022-12-15 15:02:27,276 - Epoch: [20][   30/   74]    Overall Loss 3.011845    Objective Loss 3.011845                                        LR 0.001000    Time 0.029512    
2022-12-15 15:02:27,537 - Epoch: [20][   40/   74]    Overall Loss 3.009094    Objective Loss 3.009094                                        LR 0.001000    Time 0.028652    
2022-12-15 15:02:27,777 - Epoch: [20][   50/   74]    Overall Loss 3.009426    Objective Loss 3.009426                                        LR 0.001000    Time 0.027703    
2022-12-15 15:02:27,999 - Epoch: [20][   60/   74]    Overall Loss 3.009366    Objective Loss 3.009366                                        LR 0.001000    Time 0.026756    
2022-12-15 15:02:28,226 - Epoch: [20][   70/   74]    Overall Loss 3.011846    Objective Loss 3.011846                                        LR 0.001000    Time 0.026178    
2022-12-15 15:02:28,316 - Epoch: [20][   74/   74]    Overall Loss 3.010471    Objective Loss 3.010471    Top1 5.787037    Top5 41.203704    LR 0.001000    Time 0.025976    
2022-12-15 15:02:28,370 - --- validate (epoch=20)-----------
2022-12-15 15:02:28,371 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:28,646 - Epoch: [20][    9/    9]    Loss 3.012189    Top1 8.492366    Top5 42.175573    
2022-12-15 15:02:28,703 - ==> Top1: 8.492    Top5: 42.176    Loss: 3.012

2022-12-15 15:02:28,706 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:28,707 - ==> Best [Top1: 9.017   Top5: 41.508   Sparsity:0.00   Params: 364480 on epoch: 17]
2022-12-15 15:02:28,707 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:28,717 - 

2022-12-15 15:02:28,717 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:29,258 - Epoch: [21][   10/   74]    Overall Loss 2.996311    Objective Loss 2.996311                                        LR 0.001000    Time 0.053942    
2022-12-15 15:02:29,463 - Epoch: [21][   20/   74]    Overall Loss 3.002353    Objective Loss 3.002353                                        LR 0.001000    Time 0.037237    
2022-12-15 15:02:29,681 - Epoch: [21][   30/   74]    Overall Loss 3.009650    Objective Loss 3.009650                                        LR 0.001000    Time 0.032069    
2022-12-15 15:02:29,910 - Epoch: [21][   40/   74]    Overall Loss 3.008389    Objective Loss 3.008389                                        LR 0.001000    Time 0.029761    
2022-12-15 15:02:30,141 - Epoch: [21][   50/   74]    Overall Loss 3.011522    Objective Loss 3.011522                                        LR 0.001000    Time 0.028420    
2022-12-15 15:02:30,367 - Epoch: [21][   60/   74]    Overall Loss 3.012987    Objective Loss 3.012987                                        LR 0.001000    Time 0.027447    
2022-12-15 15:02:30,599 - Epoch: [21][   70/   74]    Overall Loss 3.011858    Objective Loss 3.011858                                        LR 0.001000    Time 0.026831    
2022-12-15 15:02:30,684 - Epoch: [21][   74/   74]    Overall Loss 3.009718    Objective Loss 3.009718    Top1 8.564815    Top5 41.435185    LR 0.001000    Time 0.026531    
2022-12-15 15:02:30,747 - --- validate (epoch=21)-----------
2022-12-15 15:02:30,748 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:31,021 - Epoch: [21][    9/    9]    Loss 3.032341    Top1 8.206107    Top5 39.312977    
2022-12-15 15:02:31,077 - ==> Top1: 8.206    Top5: 39.313    Loss: 3.032

2022-12-15 15:02:31,079 - ==> Confusion:
[[  0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:31,081 - ==> Best [Top1: 9.017   Top5: 41.508   Sparsity:0.00   Params: 364480 on epoch: 17]
2022-12-15 15:02:31,081 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:31,102 - 

2022-12-15 15:02:31,102 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:31,496 - Epoch: [22][   10/   74]    Overall Loss 3.010489    Objective Loss 3.010489                                        LR 0.001000    Time 0.039306    
2022-12-15 15:02:31,736 - Epoch: [22][   20/   74]    Overall Loss 3.001632    Objective Loss 3.001632                                        LR 0.001000    Time 0.031627    
2022-12-15 15:02:31,991 - Epoch: [22][   30/   74]    Overall Loss 2.998325    Objective Loss 2.998325                                        LR 0.001000    Time 0.029572    
2022-12-15 15:02:32,249 - Epoch: [22][   40/   74]    Overall Loss 3.001721    Objective Loss 3.001721                                        LR 0.001000    Time 0.028639    
2022-12-15 15:02:32,506 - Epoch: [22][   50/   74]    Overall Loss 3.004075    Objective Loss 3.004075                                        LR 0.001000    Time 0.028029    
2022-12-15 15:02:32,742 - Epoch: [22][   60/   74]    Overall Loss 3.000870    Objective Loss 3.000870                                        LR 0.001000    Time 0.027292    
2022-12-15 15:02:32,962 - Epoch: [22][   70/   74]    Overall Loss 3.006744    Objective Loss 3.006744                                        LR 0.001000    Time 0.026531    
2022-12-15 15:02:33,047 - Epoch: [22][   74/   74]    Overall Loss 3.008051    Objective Loss 3.008051    Top1 8.101852    Top5 41.898148    LR 0.001000    Time 0.026232    
2022-12-15 15:02:33,101 - --- validate (epoch=22)-----------
2022-12-15 15:02:33,101 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:33,379 - Epoch: [22][    9/    9]    Loss 3.063907    Top1 8.587786    Top5 40.696565    
2022-12-15 15:02:33,432 - ==> Top1: 8.588    Top5: 40.697    Loss: 3.064

2022-12-15 15:02:33,434 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0]]

2022-12-15 15:02:33,435 - ==> Best [Top1: 9.017   Top5: 41.508   Sparsity:0.00   Params: 364480 on epoch: 17]
2022-12-15 15:02:33,435 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:33,445 - 

2022-12-15 15:02:33,445 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:33,841 - Epoch: [23][   10/   74]    Overall Loss 3.002380    Objective Loss 3.002380                                        LR 0.001000    Time 0.039472    
2022-12-15 15:02:34,049 - Epoch: [23][   20/   74]    Overall Loss 3.002657    Objective Loss 3.002657                                        LR 0.001000    Time 0.030132    
2022-12-15 15:02:34,268 - Epoch: [23][   30/   74]    Overall Loss 3.011478    Objective Loss 3.011478                                        LR 0.001000    Time 0.027354    
2022-12-15 15:02:34,489 - Epoch: [23][   40/   74]    Overall Loss 3.008620    Objective Loss 3.008620                                        LR 0.001000    Time 0.026035    
2022-12-15 15:02:34,712 - Epoch: [23][   50/   74]    Overall Loss 3.009070    Objective Loss 3.009070                                        LR 0.001000    Time 0.025284    
2022-12-15 15:02:34,936 - Epoch: [23][   60/   74]    Overall Loss 3.011594    Objective Loss 3.011594                                        LR 0.001000    Time 0.024808    
2022-12-15 15:02:35,154 - Epoch: [23][   70/   74]    Overall Loss 3.012689    Objective Loss 3.012689                                        LR 0.001000    Time 0.024367    
2022-12-15 15:02:35,239 - Epoch: [23][   74/   74]    Overall Loss 3.007710    Objective Loss 3.007710    Top1 9.953704    Top5 42.129630    LR 0.001000    Time 0.024191    
2022-12-15 15:02:35,305 - --- validate (epoch=23)-----------
2022-12-15 15:02:35,305 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:35,577 - Epoch: [23][    9/    9]    Loss 3.033863    Top1 8.206107    Top5 38.454198    
2022-12-15 15:02:35,631 - ==> Top1: 8.206    Top5: 38.454    Loss: 3.034

2022-12-15 15:02:35,632 - ==> Confusion:
[[  0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:35,634 - ==> Best [Top1: 9.017   Top5: 41.508   Sparsity:0.00   Params: 364480 on epoch: 17]
2022-12-15 15:02:35,634 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:35,654 - 

2022-12-15 15:02:35,654 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:36,064 - Epoch: [24][   10/   74]    Overall Loss 3.008466    Objective Loss 3.008466                                        LR 0.001000    Time 0.040886    
2022-12-15 15:02:36,314 - Epoch: [24][   20/   74]    Overall Loss 2.996838    Objective Loss 2.996838                                        LR 0.001000    Time 0.032934    
2022-12-15 15:02:36,567 - Epoch: [24][   30/   74]    Overall Loss 3.005751    Objective Loss 3.005751                                        LR 0.001000    Time 0.030371    
2022-12-15 15:02:36,825 - Epoch: [24][   40/   74]    Overall Loss 3.001814    Objective Loss 3.001814                                        LR 0.001000    Time 0.029230    
2022-12-15 15:02:37,081 - Epoch: [24][   50/   74]    Overall Loss 3.001258    Objective Loss 3.001258                                        LR 0.001000    Time 0.028489    
2022-12-15 15:02:37,354 - Epoch: [24][   60/   74]    Overall Loss 3.004726    Objective Loss 3.004726                                        LR 0.001000    Time 0.028287    
2022-12-15 15:02:37,606 - Epoch: [24][   70/   74]    Overall Loss 3.009068    Objective Loss 3.009068                                        LR 0.001000    Time 0.027847    
2022-12-15 15:02:37,695 - Epoch: [24][   74/   74]    Overall Loss 3.009289    Objective Loss 3.009289    Top1 8.796296    Top5 39.814815    LR 0.001000    Time 0.027541    
2022-12-15 15:02:37,759 - --- validate (epoch=24)-----------
2022-12-15 15:02:37,759 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:38,042 - Epoch: [24][    9/    9]    Loss 3.036608    Top1 9.017176    Top5 40.696565    
2022-12-15 15:02:38,089 - ==> Top1: 9.017    Top5: 40.697    Loss: 3.037

2022-12-15 15:02:38,091 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  20   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:38,093 - ==> Best [Top1: 9.017   Top5: 41.508   Sparsity:0.00   Params: 364480 on epoch: 17]
2022-12-15 15:02:38,093 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:38,103 - 

2022-12-15 15:02:38,104 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:38,508 - Epoch: [25][   10/   74]    Overall Loss 2.993073    Objective Loss 2.993073                                        LR 0.001000    Time 0.040309    
2022-12-15 15:02:38,757 - Epoch: [25][   20/   74]    Overall Loss 2.989985    Objective Loss 2.989985                                        LR 0.001000    Time 0.032601    
2022-12-15 15:02:39,018 - Epoch: [25][   30/   74]    Overall Loss 2.999884    Objective Loss 2.999884                                        LR 0.001000    Time 0.030417    
2022-12-15 15:02:39,289 - Epoch: [25][   40/   74]    Overall Loss 2.999807    Objective Loss 2.999807                                        LR 0.001000    Time 0.029575    
2022-12-15 15:02:39,565 - Epoch: [25][   50/   74]    Overall Loss 3.002025    Objective Loss 3.002025                                        LR 0.001000    Time 0.029180    
2022-12-15 15:02:39,841 - Epoch: [25][   60/   74]    Overall Loss 3.003044    Objective Loss 3.003044                                        LR 0.001000    Time 0.028894    
2022-12-15 15:02:40,098 - Epoch: [25][   70/   74]    Overall Loss 3.002578    Objective Loss 3.002578                                        LR 0.001000    Time 0.028434    
2022-12-15 15:02:40,191 - Epoch: [25][   74/   74]    Overall Loss 3.003884    Objective Loss 3.003884    Top1 8.333333    Top5 36.111111    LR 0.001000    Time 0.028156    
2022-12-15 15:02:40,248 - --- validate (epoch=25)-----------
2022-12-15 15:02:40,248 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:40,522 - Epoch: [25][    9/    9]    Loss 3.021207    Top1 8.206107    Top5 39.933206    
2022-12-15 15:02:40,576 - ==> Top1: 8.206    Top5: 39.933    Loss: 3.021

2022-12-15 15:02:40,577 - ==> Confusion:
[[  0   0   0   0   0   0  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 189   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 149   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:40,579 - ==> Best [Top1: 9.017   Top5: 41.508   Sparsity:0.00   Params: 364480 on epoch: 17]
2022-12-15 15:02:40,579 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:40,600 - 

2022-12-15 15:02:40,600 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:41,010 - Epoch: [26][   10/   74]    Overall Loss 2.997426    Objective Loss 2.997426                                        LR 0.001000    Time 0.040962    
2022-12-15 15:02:41,234 - Epoch: [26][   20/   74]    Overall Loss 3.006578    Objective Loss 3.006578                                        LR 0.001000    Time 0.031637    
2022-12-15 15:02:41,459 - Epoch: [26][   30/   74]    Overall Loss 2.990153    Objective Loss 2.990153                                        LR 0.001000    Time 0.028589    
2022-12-15 15:02:41,695 - Epoch: [26][   40/   74]    Overall Loss 2.998828    Objective Loss 2.998828                                        LR 0.001000    Time 0.027336    
2022-12-15 15:02:41,910 - Epoch: [26][   50/   74]    Overall Loss 3.002077    Objective Loss 3.002077                                        LR 0.001000    Time 0.026153    
2022-12-15 15:02:42,168 - Epoch: [26][   60/   74]    Overall Loss 3.005843    Objective Loss 3.005843                                        LR 0.001000    Time 0.026095    
2022-12-15 15:02:42,411 - Epoch: [26][   70/   74]    Overall Loss 3.004741    Objective Loss 3.004741                                        LR 0.001000    Time 0.025833    
2022-12-15 15:02:42,494 - Epoch: [26][   74/   74]    Overall Loss 3.006071    Objective Loss 3.006071    Top1 6.712963    Top5 37.500000    LR 0.001000    Time 0.025548    
2022-12-15 15:02:42,556 - --- validate (epoch=26)-----------
2022-12-15 15:02:42,556 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:42,837 - Epoch: [26][    9/    9]    Loss 3.036585    Top1 8.969466    Top5 38.072519    
2022-12-15 15:02:42,891 - ==> Top1: 8.969    Top5: 38.073    Loss: 3.037

2022-12-15 15:02:42,893 - ==> Confusion:
[[  0   0   0   0   1   0   0   0   0   0   0   0   0   0  27   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 132   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 188   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 178   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0  15   0   0   0   0   0   2   3   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 148   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0  66   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:42,894 - ==> Best [Top1: 9.017   Top5: 41.508   Sparsity:0.00   Params: 364480 on epoch: 17]
2022-12-15 15:02:42,894 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:42,904 - 

2022-12-15 15:02:42,904 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:43,425 - Epoch: [27][   10/   74]    Overall Loss 3.016632    Objective Loss 3.016632                                        LR 0.001000    Time 0.051979    
2022-12-15 15:02:43,658 - Epoch: [27][   20/   74]    Overall Loss 3.008879    Objective Loss 3.008879                                        LR 0.001000    Time 0.037633    
2022-12-15 15:02:43,895 - Epoch: [27][   30/   74]    Overall Loss 2.990399    Objective Loss 2.990399                                        LR 0.001000    Time 0.032950    
2022-12-15 15:02:44,133 - Epoch: [27][   40/   74]    Overall Loss 2.989924    Objective Loss 2.989924                                        LR 0.001000    Time 0.030668    
2022-12-15 15:02:44,371 - Epoch: [27][   50/   74]    Overall Loss 2.976084    Objective Loss 2.976084                                        LR 0.001000    Time 0.029290    
2022-12-15 15:02:44,612 - Epoch: [27][   60/   74]    Overall Loss 2.940028    Objective Loss 2.940028                                        LR 0.001000    Time 0.028415    
2022-12-15 15:02:44,835 - Epoch: [27][   70/   74]    Overall Loss 2.898740    Objective Loss 2.898740                                        LR 0.001000    Time 0.027532    
2022-12-15 15:02:44,915 - Epoch: [27][   74/   74]    Overall Loss 2.878754    Objective Loss 2.878754    Top1 23.379630    Top5 66.898148    LR 0.001000    Time 0.027129    
2022-12-15 15:02:44,971 - --- validate (epoch=27)-----------
2022-12-15 15:02:44,971 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:45,246 - Epoch: [27][    9/    9]    Loss 2.596021    Top1 22.853053    Top5 65.171756    
2022-12-15 15:02:45,324 - ==> Top1: 22.853    Top5: 65.172    Loss: 2.596

2022-12-15 15:02:45,326 - ==> Confusion:
[[  0   0   0   0   0   0  12   0   0   0   0   0   0   0   4   0   0   0   1   0   0   3   0   0   0   0   1   0   0   7   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0  10   0   8   0   0   0   0   0   0   0   0  19   0]
 [  0   0   0   0   2   0  65   0   0   0   0   0   0   0   3   0   0   0   2   0   0   1   0   0   0   0   0   0   0  61   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   7   0  29   0   0   0   0   0   0   0   1   0   0   0   4   0   4   6   0   0   0   0   0   0   0 114   0]
 [  0   0   0   0   5   0   1   0   0   0   0   0   0   0   0   0   0   0  16   0   8  20   0   0   0   0   0   0   0   5   0]
 [  0   0   0   0   1   0  94   0   0   0   0   0   0   0   5   0   0   0   1   0   1   8   0   0   0   0   0   0   0  62   0]
 [  0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   3   0  10   0   0   0   0   0   0   0   0   8   0]
 [  0   0   0   0   0   0   8   0   0   0   0   0   0   0   5   0   0   0   2   0   1  12   0   0   0   0   0   0   0   5   0]
 [  0   0   0   0   3   0  12   0   0   0   0   0   0   0   0   0   0   0   2   0   1   6   0   0   0   0   0   0   0  17   0]
 [  0   0   0   0   0   0   8   0   0   0   0   0   0   0   6   0   0   0   0   0   0  21   0   0   0   0   3   1   0   1   0]
 [  0   0   0   0   0   0   5   0   0   0   0   0   0   0   6   0   0   0   0   0   0   9   0   0   0   0   1   0   0   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   8   0   4   0   0   0   0   0   0   0   0  20   0]
 [  0   0   0   0   7   0  37   0   0   0   0   0   0   0  35   0   0   0   2   0   0  70   0   2   0   0  13   1   0  22   0]
 [  0   0   0   0   0   0  11   0   0   0   0   0   0   0   1   0   0   0   1   0   0   0   0   0   0   0   0   1   0  17   0]
 [  0   0   0   0   1   1   5   0   0   0   0   0   0   0   0   0   0   0  12   0   4  25   0   0   0   0   0   1   0   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   5   0  16   0   0   0   0   0   0   0   0   0   0   0  28   0  27  12   0   0   0   0   0   0   0  70   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   5   0   1   0   0   0   0   0   0   0   0   0   0   0  25   0  47   5   0   0   0   0   0   0   0  26   0]
 [  0   0   0   0   3   0  12   0   0   0   0   0   0   0   9   0   0   0  24   0  11 111   0   0   0   0   2   0   0   6   0]
 [  0   0   0   0   0   0  10   0   0   0   0   0   0   0   2   0   0   0   0   0   0   1   0   4   0   0   1   0   0   3   0]
 [  0   0   0   0   0   0  65   0   0   0   0   0   0   0  15   0   0   0   0   0   1  12   0   0   0   0   0   1   0  55   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   2   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   1   0   4   0   0   0   0   0   0   0   1   0   0   0   0   0   0   1   0   0   0   0   0   0   0   7   0]
 [  0   0   0   0   0   0   2   0   0   0   0   0   0   0   6   0   0   0   0   0   0  39   0   0   0   0  19   0   0   2   0]
 [  0   0   0   0   4   0  19   0   0   0   0   0   0   0   1   0   0   0  15   0   5   3   0   0   0   0   0   2   0  59   0]
 [  0   0   0   0   0   0   5   0   0   0   0   0   0   0   3   0   0   0   3   0   2   9   0   0   0   0   0   0   0   4   0]
 [  0   0   0   0   9   0  11   0   0   0   0   0   0   0   0   0   0   0  12   0   7   5   0   0   0   0   0   0   0 136   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   6   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:45,328 - ==> Best [Top1: 22.853   Top5: 65.172   Sparsity:0.00   Params: 364480 on epoch: 27]
2022-12-15 15:02:45,328 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:45,349 - 

2022-12-15 15:02:45,350 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:45,739 - Epoch: [28][   10/   74]    Overall Loss 2.546150    Objective Loss 2.546150                                        LR 0.001000    Time 0.038819    
2022-12-15 15:02:45,975 - Epoch: [28][   20/   74]    Overall Loss 2.544204    Objective Loss 2.544204                                        LR 0.001000    Time 0.031179    
2022-12-15 15:02:46,224 - Epoch: [28][   30/   74]    Overall Loss 2.511767    Objective Loss 2.511767                                        LR 0.001000    Time 0.029090    
2022-12-15 15:02:46,474 - Epoch: [28][   40/   74]    Overall Loss 2.483058    Objective Loss 2.483058                                        LR 0.001000    Time 0.028040    
2022-12-15 15:02:46,707 - Epoch: [28][   50/   74]    Overall Loss 2.474468    Objective Loss 2.474468                                        LR 0.001000    Time 0.027090    
2022-12-15 15:02:46,942 - Epoch: [28][   60/   74]    Overall Loss 2.483324    Objective Loss 2.483324                                        LR 0.001000    Time 0.026483    
2022-12-15 15:02:47,166 - Epoch: [28][   70/   74]    Overall Loss 2.479862    Objective Loss 2.479862                                        LR 0.001000    Time 0.025898    
2022-12-15 15:02:47,252 - Epoch: [28][   74/   74]    Overall Loss 2.476743    Objective Loss 2.476743    Top1 28.472222    Top5 71.064815    LR 0.001000    Time 0.025656    
2022-12-15 15:02:47,319 - --- validate (epoch=28)-----------
2022-12-15 15:02:47,319 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:47,588 - Epoch: [28][    9/    9]    Loss 2.449480    Top1 27.910305    Top5 70.085878    
2022-12-15 15:02:47,638 - ==> Top1: 27.910    Top5: 70.086    Loss: 2.449

2022-12-15 15:02:47,640 - ==> Confusion:
[[  0   0   1   0   3   0  17   0   0   0   0   0   0   0   2   0   0   0   0   0   0   4   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0  12   0   3   0   0   0   0   0   0   0   0   0   0   0   5   0  10   0   0   0   0   0   0   0   0   8   0]
 [  0   0  52   0  37   0  35   0   0   0   0   0   0   0   5   0   0   0   1   0   1   0   0   2   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0   7   0  96   0  40   0   0   0   0   0   0   0   2   0   0   0   2   0   0   7   0   0   0   0   0   0   0  11   0]
 [  0   0   0   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0   4   0  25  20   0   0   0   0   0   0   0   3   0]
 [  0   0  11   0  38   0 105   0   0   0   0   0   0   0   3   0   0   0   1   0   1  10   0   2   0   0   0   0   0   1   0]
 [  0   0   0   0   5   0   2   0   0   0   0   0   0   0   0   0   0   0   2   0   8   0   0   0   0   0   0   0   0   6   0]
 [  0   0   0   0   2   0  13   0   0   0   0   0   0   0   1   0   0   0   2   0   0  15   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0  16   0  13   0   0   0   0   0   0   0   0   0   0   0   3   0   1   7   0   0   0   0   0   0   0   1   0]
 [  0   0   1   0   2   0   4   0   0   0   0   0   0   0  11   0   0   0   0   0   0  19   0   1   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   3   0   0   0   0   0   0   0   5   0   0   0   1   0   0  16   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0  16   0   2   0   0   0   0   0   0   0   0   0   0   0   2   0   9   1   0   0   0   0   0   0   0   4   0]
 [  0   0   7   0  16   0  28   0   0   0   0   0   0   0  50   0   0   0   4   0   1  76   0   1   0   0   5   0   0   1   0]
 [  0   0   1   0  12   0  12   0   0   0   0   0   0   0   1   0   0   0   2   0   0   1   0   0   0   0   0   0   0   2   0]
 [  0   0   0   0   1   0   7   0   0   0   0   0   0   0   1   0   0   0   8   0   6  29   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   3   4   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0  46   0  21   0   0   0   0   0   0   0   4   0   0   0  39   0  19  15   0   0   0   0   0   0   0  14   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0  67  11   0   0   0   0   0   0   0  12   0]
 [  0   0   0   0   4   0   4   0   0   0   0   0   0   0   9   0   0   0   5   0  17 137   0   0   0   0   0   0   0   2   0]
 [  0   0   6   0   5   0   6   0   0   0   0   0   0   0   3   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  10   0  35   0  71   0   0   0   0   0   0   0  10   0   0   0   2   0   0  20   0   1   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   7   0   6   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   2   0   0   0   0   0   0   0   6   0   0   0   0   0   0  45   0   0   0   0  13   0   0   0   0]
 [  0   0   3   0  50   0  27   0   0   0   0   0   0   0   1   0   0   0  11   0   7   2   0   0   0   0   0   0   0   7   0]
 [  0   0   0   0   3   0   8   0   0   0   0   0   0   0   0   0   0   0   4   0   1  10   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0 113   0  24   0   0   0   0   0   0   0   0   0   0   0   5   0   9   4   0   0   0   0   0   0   0  25   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   8   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:47,641 - ==> Best [Top1: 27.910   Top5: 70.086   Sparsity:0.00   Params: 364480 on epoch: 28]
2022-12-15 15:02:47,641 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:47,666 - 

2022-12-15 15:02:47,666 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:48,070 - Epoch: [29][   10/   74]    Overall Loss 2.387721    Objective Loss 2.387721                                        LR 0.001000    Time 0.040318    
2022-12-15 15:02:48,299 - Epoch: [29][   20/   74]    Overall Loss 2.366365    Objective Loss 2.366365                                        LR 0.001000    Time 0.031628    
2022-12-15 15:02:48,534 - Epoch: [29][   30/   74]    Overall Loss 2.346692    Objective Loss 2.346692                                        LR 0.001000    Time 0.028897    
2022-12-15 15:02:48,767 - Epoch: [29][   40/   74]    Overall Loss 2.333460    Objective Loss 2.333460                                        LR 0.001000    Time 0.027493    
2022-12-15 15:02:48,999 - Epoch: [29][   50/   74]    Overall Loss 2.325870    Objective Loss 2.325870                                        LR 0.001000    Time 0.026580    
2022-12-15 15:02:49,233 - Epoch: [29][   60/   74]    Overall Loss 2.313528    Objective Loss 2.313528                                        LR 0.001000    Time 0.026047    
2022-12-15 15:02:49,471 - Epoch: [29][   70/   74]    Overall Loss 2.302325    Objective Loss 2.302325                                        LR 0.001000    Time 0.025717    
2022-12-15 15:02:49,557 - Epoch: [29][   74/   74]    Overall Loss 2.301328    Objective Loss 2.301328    Top1 31.944444    Top5 73.379630    LR 0.001000    Time 0.025495    
2022-12-15 15:02:49,625 - --- validate (epoch=29)-----------
2022-12-15 15:02:49,625 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:49,892 - Epoch: [29][    9/    9]    Loss 2.268479    Top1 32.442748    Top5 72.805344    
2022-12-15 15:02:49,945 - ==> Top1: 32.443    Top5: 72.805    Loss: 2.268

2022-12-15 15:02:49,947 - ==> Confusion:
[[  0   0   1   0   1   0  14   0   0   0   0   0   0   0   6   0   0   0   3   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   4   1   0   0   0   0   0   0   0   0   0   0   0   0   9   0  13   1   0   0   0   0   0   0   0  10   0]
 [  0   0  77   0  25   0  16   0   0   0   0   0   0   0   5   0   0   0   3   0   1   1   0   0   0   0   0   0   0   6   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  14   0  28   0  22   0   0   0   0   0   0   0   6   0   0   0  22   0   3   0   0   0   0   0   0   0   0  70   0]
 [  0   0   0   0   0  22   1   0   0   0   0   0   0   0   0   0   0   0   4   0  18   7   0   0   0   0   0   0   0   3   0]
 [  0   0  17   0  28   0  72   0   0   0   0   0   0   0   9   0   0   0  20   0   0   2   0   0   0   0   0   0   0  24   0]
 [  0   0   0   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0   6   0   9   0   0   0   0   0   0   0   0   5   0]
 [  0   0   0   0   1   0   7   0   0   0   0   0   0   0  10   0   0   0  10   0   0   5   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   4   0   6   0   0   0   0   0   0   0   2   0   0   0  19   0   1   0   0   0   0   0   0   0   0   9   0]
 [  0   0   1   0   1   1   1   0   0   0   0   0   0   0  17   0   0   0   2   0   0  16   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   1   0   1   0   0   0   0   0   0   0   8   0   0   0   3   0   0  11   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   1   0   0   0   0   0   0   0   0   1   0   0   0   4   0  10   0   0   0   0   0   0   0   0  16   0]
 [  0   0   2   0   7   1  21   0   0   0   0   0   0   0  77   0   0   0  14   0   4  54   0   0   0   0   1   2   0   6   0]
 [  0   0   1   0   5   0   6   0   0   0   0   0   0   0   2   0   0   0  12   0   0   0   0   0   0   0   0   0   0   5   0]
 [  0   0   0   0   0  26   1   0   0   0   0   0   0   0   1   0   0   0  12   0   2   9   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   5   4   6   0   0   0   0   0   0   0   2   0   0   0  90   0  20   7   0   0   0   0   0   0   0  24   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   6   0  79   4   0   0   0   0   0   0   0  11   0]
 [  0   0   0   0   0  18   0   0   0   0   0   0   0   0  20   0   0   0  23   0  14 103   0   0   0   0   0   0   0   0   0]
 [  0   0   7   0   5   0   4   0   0   0   0   0   0   0   3   0   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0]
 [  0   0  20   0  15   0  45   0   0   0   0   0   0   0  18   0   0   0  20   0   0   7   0   0   0   0   0   0   0  24   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   3   0   1   0   0   0   0   0   0   0   1   0   0   0   4   0   0   1   0   0   0   0   0   0   0   4   0]
 [  0   0   0   0   1   1   1   0   0   0   0   0   0   0  32   0   0   0   3   0   0   9   0   0   0   0  21   0   0   0   0]
 [  0   0   3   0  15   3  13   0   0   0   0   0   0   0   2   0   0   0  31   0   6   2   0   0   0   0   1   0   0  32   0]
 [  0   0   0   0   1   1   6   0   0   0   0   0   0   0   4   0   0   0   7   0   1   6   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0  20   0   5   0   0   0   0   0   0   0   3   0   0   0  28   0  13   0   0   0   0   0   0   0   0 111   0]
 [  0   0   0   0   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:49,949 - ==> Best [Top1: 32.443   Top5: 72.805   Sparsity:0.00   Params: 364478 on epoch: 29]
2022-12-15 15:02:49,949 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:49,980 - 

2022-12-15 15:02:49,980 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:50,364 - Epoch: [30][   10/   74]    Overall Loss 2.214166    Objective Loss 2.214166                                        LR 0.001000    Time 0.038297    
2022-12-15 15:02:50,591 - Epoch: [30][   20/   74]    Overall Loss 2.177939    Objective Loss 2.177939                                        LR 0.001000    Time 0.030486    
2022-12-15 15:02:50,822 - Epoch: [30][   30/   74]    Overall Loss 2.187169    Objective Loss 2.187169                                        LR 0.001000    Time 0.028028    
2022-12-15 15:02:51,051 - Epoch: [30][   40/   74]    Overall Loss 2.192136    Objective Loss 2.192136                                        LR 0.001000    Time 0.026735    
2022-12-15 15:02:51,291 - Epoch: [30][   50/   74]    Overall Loss 2.194348    Objective Loss 2.194348                                        LR 0.001000    Time 0.026170    
2022-12-15 15:02:51,527 - Epoch: [30][   60/   74]    Overall Loss 2.188928    Objective Loss 2.188928                                        LR 0.001000    Time 0.025740    
2022-12-15 15:02:51,759 - Epoch: [30][   70/   74]    Overall Loss 2.177627    Objective Loss 2.177627                                        LR 0.001000    Time 0.025370    
2022-12-15 15:02:51,843 - Epoch: [30][   74/   74]    Overall Loss 2.173347    Objective Loss 2.173347    Top1 37.037037    Top5 78.703704    LR 0.001000    Time 0.025138    
2022-12-15 15:02:51,916 - --- validate (epoch=30)-----------
2022-12-15 15:02:51,917 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:52,192 - Epoch: [30][    9/    9]    Loss 2.132902    Top1 34.971374    Top5 76.288168    
2022-12-15 15:02:52,239 - ==> Top1: 34.971    Top5: 76.288    Loss: 2.133

2022-12-15 15:02:52,241 - ==> Confusion:
[[  0   0   1   0   0   0  10   0   0   0   0   0   0   0  12   0   0   0   3   0   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0  18   0   8   5   0   0   0   0   0   0   0   4   0]
 [  0   0  71   0  19   0  25   0   0   0   0   0   0   0   8   0   0   0   6   0   1   0   0   1   0   0   0   1   0   2   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0  13   0  23   0  34   0   0   0   0   0   0   0   6   0   0   0  34   0   5   2   0   0   0   0   0   0   0  48   0]
 [  0   0   0   0   0  12   1   0   0   0   0   0   0   0   1   0   0   0   3   0  14  23   0   0   0   0   0   0   0   1   0]
 [  0   0  14   0  10   0  90   0   0   0   0   0   0   0  15   0   0   0  24   0   0   2   0   0   0   0   0   0   0  17   0]
 [  0   0   0   0   2   1   2   0   0   0   0   0   0   0   0   0   0   0   3   0  13   0   0   0   0   0   0   0   0   2   0]
 [  0   0   0   0   0   0   6   0   0   0   0   0   0   0  15   0   0   0   7   0   0   5   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   9   0   0   0   0   0   0   0   2   0   0   0  24   0   0   1   0   0   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  19   0   0   0   0   0   0  18   0   0   0   0   1   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  14   0   0   0   1   0   0   8   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   1   1   0   0   0   0   0   0   0   1   0   0   0   7   0  11   0   0   0   0   0   0   0   0  11   0]
 [  0   0   1   0   6   1  15   0   0   0   0   0   0   0  91   0   0   0   9   0   1  60   0   0   0   0   2   2   0   1   0]
 [  0   0   0   0   3   0   9   0   0   0   0   0   0   0   4   0   0   0  13   0   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0  18   2   0   0   0   0   0   0   0   4   0   0   0   5   0   1  22   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   1   0   1   0   0   4   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   6   0   0   0   0   0   0   0   5   0   0   0 112   0  11  21   0   0   0   0   0   0   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1  12   0   0   0   0   0   0   0   0   0   0   0   0   5   0  71  12   0   0   0   0   0   0   0   8   0]
 [  0   0   0   0   0   4   0   0   0   0   0   0   0   0  12   0   0   0   9   0  14 139   0   0   0   0   0   0   0   0   0]
 [  0   0   8   0   5   0   2   0   0   0   0   0   0   0   5   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0  16   0  15   0  55   0   0   0   0   0   0   0  25   0   0   0  27   0   0   2   0   1   0   0   0   0   0   8   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   1   0   2   0   0   0   0   0   0   0   2   0   0   0   8   0   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   1   0   0   0   3   0   0   0   0   0   0   0  20   0   0   0   2   0   0   3   0   0   0   0  38   1   0   0   0]
 [  0   0   3   0   8   3  26   0   0   0   0   0   0   0   3   0   0   0  25   0   6  10   0   0   0   0   1   6   0  17   0]
 [  0   0   0   0   1   0   4   0   0   0   0   0   0   0   4   0   0   0   7   0   0   9   0   1   0   0   0   0   0   0   0]
 [  0   0   0   0  24   0  17   0   0   0   0   0   0   0   2   0   0   0  34   0  21   3   0   0   0   0   0   0   0  79   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   8   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:52,243 - ==> Best [Top1: 34.971   Top5: 76.288   Sparsity:0.00   Params: 364479 on epoch: 30]
2022-12-15 15:02:52,243 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:52,267 - 

2022-12-15 15:02:52,267 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:52,667 - Epoch: [31][   10/   74]    Overall Loss 2.055563    Objective Loss 2.055563                                        LR 0.001000    Time 0.039927    
2022-12-15 15:02:52,905 - Epoch: [31][   20/   74]    Overall Loss 2.079276    Objective Loss 2.079276                                        LR 0.001000    Time 0.031839    
2022-12-15 15:02:53,138 - Epoch: [31][   30/   74]    Overall Loss 2.072771    Objective Loss 2.072771                                        LR 0.001000    Time 0.028978    
2022-12-15 15:02:53,383 - Epoch: [31][   40/   74]    Overall Loss 2.072057    Objective Loss 2.072057                                        LR 0.001000    Time 0.027855    
2022-12-15 15:02:53,626 - Epoch: [31][   50/   74]    Overall Loss 2.058349    Objective Loss 2.058349                                        LR 0.001000    Time 0.027135    
2022-12-15 15:02:53,849 - Epoch: [31][   60/   74]    Overall Loss 2.051111    Objective Loss 2.051111                                        LR 0.001000    Time 0.026314    
2022-12-15 15:02:54,069 - Epoch: [31][   70/   74]    Overall Loss 2.050268    Objective Loss 2.050268                                        LR 0.001000    Time 0.025697    
2022-12-15 15:02:54,152 - Epoch: [31][   74/   74]    Overall Loss 2.047364    Objective Loss 2.047364    Top1 42.129630    Top5 79.166667    LR 0.001000    Time 0.025419    
2022-12-15 15:02:54,211 - --- validate (epoch=31)-----------
2022-12-15 15:02:54,212 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:54,482 - Epoch: [31][    9/    9]    Loss 2.048125    Top1 39.837786    Top5 77.814885    
2022-12-15 15:02:54,534 - ==> Top1: 39.838    Top5: 77.815    Loss: 2.048

2022-12-15 15:02:54,536 - ==> Confusion:
[[  0   0   1   0   2   0  11   0   0   0   0   0   0   0   9   0   0   0   2   0   0   1   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0   4   1   0   0   0   0   0   0   0   3   0]
 [  0   0  88   0  19   0  13   0   0   0   0   0   0   0   5   0   0   0   3   0   1   0   0   1   0   0   1   1   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  19   0  58   0  24   0   0   0   0   0   0   0   7   0   0   0  23   0   2   0   0   0   0   0   0   0   0  32   0]
 [  0   0   0   0   1  12   0   0   0   0   0   0   0   0   2   0   7   0   7   0  11  14   0   0   0   0   0   0   0   1   0]
 [  0   0  17   0  36   0  80   0   0   0   0   0   0   0  12   0   0   0  12   0   1   2   0   1   0   0   0   1   0  10   0]
 [  0   0   0   0   2   1   2   0   0   0   0   0   0   0   0   0   0   0   5   0  11   0   0   0   0   0   0   0   0   2   0]
 [  0   0   1   0   0   0   8   0   0   0   0   0   0   0  14   0   0   0   9   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   5   0   8   0   0   0   0   0   0   0   1   0   0   0  21   0   0   1   0   0   0   0   0   0   0   5   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  28   0   3   0   1   0   0   7   0   0   0   0   0   0   0   0   0]
 [  0   0   1   0   1   0   0   0   0   0   0   0   0   0  13   0   0   0   3   0   1   4   0   0   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   5   0   0   0   0   0   0   0   0   0   1   0   0   0   6   0  11   0   0   0   0   0   0   0   0  11   0]
 [  0   0   2   0   8   0  15   0   0   0   0   0   0   0 121   0   0   0   9   0   1  25   0   2   0   0   3   2   0   1   0]
 [  0   0   1   0   4   0  10   0   0   0   0   0   0   0   2   0   0   0   8   0   0   0   0   1   0   0   0   1   0   4   0]
 [  0   0   0   0   0   6   1   0   0   0   0   0   0   0   5   0  24   0   7   0   1   8   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0   1   0   2   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   5   0  11   0   0   0   0   0   0   0   5   0   0   0 123   0   1   7   0   0   0   0   0   0   0   6   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   5   0   0   0   0   0   0   0   0   0   0   0   0   8   0  76   5   0   0   0   0   0   0   0  14   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0  36   0   5   0  16   0  13 104   0   0   0   0   0   0   0   2   0]
 [  0   0  10   0   6   0   1   0   0   0   0   0   0   0   1   0   0   0   1   0   0   0   2   0   0   0   0   0   0   0   0]
 [  0   0  25   0  34   0  39   0   0   0   0   0   0   0  19   0   0   0  16   0   0   1   1   3   0   0   1   1   0   9   0]
 [  0   0   0   0   1   0   2   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   4   0   5   0   0   0   0   0   0   0   1   0   0   0   3   0   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   1   0   3   0   2   0   0   0   0   0   0   0   7   0   1   0   1   0   0   2   0   0   0   0  50   1   0   0   0]
 [  0   0   4   0  29   4  18   0   0   0   0   0   0   0   1   0   4   0  23   0   5   0   0   0   0   0   1   8   0  11   0]
 [  0   0   1   0   1   0   4   0   0   0   0   0   0   0   7   0   2   0   7   0   0   3   0   1   0   0   0   0   0   0   0]
 [  0   0   1   0  50   0  10   0   0   0   0   0   0   0   4   0   0   0  16   0  11   0   0   0   0   0   0   2   0  86   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1   6   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:54,537 - ==> Best [Top1: 39.838   Top5: 77.815   Sparsity:0.00   Params: 364480 on epoch: 31]
2022-12-15 15:02:54,537 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:54,558 - 

2022-12-15 15:02:54,558 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:54,974 - Epoch: [32][   10/   74]    Overall Loss 1.965444    Objective Loss 1.965444                                        LR 0.001000    Time 0.041485    
2022-12-15 15:02:55,231 - Epoch: [32][   20/   74]    Overall Loss 1.954636    Objective Loss 1.954636                                        LR 0.001000    Time 0.033589    
2022-12-15 15:02:55,497 - Epoch: [32][   30/   74]    Overall Loss 1.939113    Objective Loss 1.939113                                        LR 0.001000    Time 0.031235    
2022-12-15 15:02:55,759 - Epoch: [32][   40/   74]    Overall Loss 1.955874    Objective Loss 1.955874                                        LR 0.001000    Time 0.029975    
2022-12-15 15:02:56,023 - Epoch: [32][   50/   74]    Overall Loss 1.968994    Objective Loss 1.968994                                        LR 0.001000    Time 0.029242    
2022-12-15 15:02:56,294 - Epoch: [32][   60/   74]    Overall Loss 1.967241    Objective Loss 1.967241                                        LR 0.001000    Time 0.028881    
2022-12-15 15:02:56,551 - Epoch: [32][   70/   74]    Overall Loss 1.961585    Objective Loss 1.961585                                        LR 0.001000    Time 0.028420    
2022-12-15 15:02:56,638 - Epoch: [32][   74/   74]    Overall Loss 1.961080    Objective Loss 1.961080    Top1 40.972222    Top5 78.703704    LR 0.001000    Time 0.028052    
2022-12-15 15:02:56,702 - --- validate (epoch=32)-----------
2022-12-15 15:02:56,702 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:56,973 - Epoch: [32][    9/    9]    Loss 2.031219    Top1 40.028626    Top5 78.387405    
2022-12-15 15:02:57,028 - ==> Top1: 40.029    Top5: 78.387    Loss: 2.031

2022-12-15 15:02:57,030 - ==> Confusion:
[[  0   0   5   0   3   0   9   0   0   0   0   0   0   0   5   0   0   0   3   0   0   0   0   2   0   0   0   0   0   1   0]
 [  0   0   0   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0  26   0   4   0   0   0   0   0   0   0   0   2   0]
 [  0   0  92   0  14   0  15   0   0   0   0   0   0   0   4   0   0   0   6   0   0   0   0   0   0   0   1   0   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  11   0  33   0  33   0   0   0   0   0   0   0   6   0   0   0  24   0   0   0   0   0   0   0   0   0   0  58   0]
 [  0   0   0   0   0  12   1   0   0   0   0   0   0   0   1   0   7   0  13   0  16   4   0   0   0   0   0   0   0   1   0]
 [  0   0  14   0  19   0  90   0   0   0   0   0   0   0   7   0   0   0  25   0   0   2   0   0   0   0   0   0   0  15   0]
 [  0   0   0   0   2   0   1   1   0   0   0   0   0   0   0   0   0   0   8   0   9   0   0   0   0   0   0   0   0   2   0]
 [  0   0   0   0   0   0   8   0   0   0   0   0   0   0  10   0   0   0  14   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   4   0   7   0   0   0   0   0   0   0   1   0   0   0  25   0   0   0   0   0   0   0   0   0   0   4   0]
 [  0   0   1   0   0   0   3   0   0   0   0   0   0   0  21   0   4   0   2   0   0   8   0   0   0   0   0   1   0   0   0]
 [  0   0   1   0   1   0   0   0   0   0   0   0   0   0  13   0   0   0   6   0   0   2   0   0   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   0   1   0   0   0   0   0   0   0   0   0   0   0   7   0  12   0   0   0   0   0   0   0   0  11   0]
 [  0   0   0   0   7   0  19   0   0   0   0   0   0   0 110   0   2   0  24   0   0  21   0   2   0   0   0   3   0   1   0]
 [  0   0   0   0   4   0   9   0   0   0   0   0   0   0   0   0   0   0  16   0   0   0   0   1   0   0   0   0   0   1   0]
 [  0   0   0   0   0   3   2   0   0   0   0   0   0   0   3   0  29   0   8   0   3   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   5   0   1   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   7   0   2   0   0   0   0   0   0   0   1   0   0   0 140   0   1   3   0   0   0   0   0   0   0   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   4   0   0   0   0   0   0   0   0   0   0   4   0  11   0  68   4   0   0   0   0   0   0   0  17   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0  12   0  10   0  41   0  15  95   0   0   0   0   0   0   0   2   0]
 [  0   0  13   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   0  19   0  22   0  49   0   0   0   0   0   0   0  17   0   0   0  25   0   0   0   0   2   0   0   0   0   0  15   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   1   0   1   0   0   0   0   0   0   0   1   0   0   0   9   0   0   0   0   0   0   0   0   0   0   2   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   9   0   2   0   4   0   0   1   1   2   0   0  47   1   0   0   0]
 [  0   0   3   0  18   1  17   0   0   0   0   0   0   0   1   0   2   0  35   0   8   0   0   0   0   0   0   5   0  18   0]
 [  0   0   1   0   2   0   2   0   0   0   0   0   0   0   4   0   1   0  12   0   2   1   0   1   0   0   0   0   0   0   0]
 [  0   0   0   0  14   0   8   0   0   0   0   0   0   0   1   0   0   0  32   0  10   0   0   0   0   0   0   0   0 115   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   8   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:57,032 - ==> Best [Top1: 40.029   Top5: 78.387   Sparsity:0.00   Params: 364480 on epoch: 32]
2022-12-15 15:02:57,032 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:57,055 - 

2022-12-15 15:02:57,055 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:57,598 - Epoch: [33][   10/   74]    Overall Loss 1.883751    Objective Loss 1.883751                                        LR 0.001000    Time 0.054152    
2022-12-15 15:02:57,843 - Epoch: [33][   20/   74]    Overall Loss 1.983416    Objective Loss 1.983416                                        LR 0.001000    Time 0.039318    
2022-12-15 15:02:58,087 - Epoch: [33][   30/   74]    Overall Loss 2.031703    Objective Loss 2.031703                                        LR 0.001000    Time 0.034342    
2022-12-15 15:02:58,340 - Epoch: [33][   40/   74]    Overall Loss 2.049531    Objective Loss 2.049531                                        LR 0.001000    Time 0.032067    
2022-12-15 15:02:58,591 - Epoch: [33][   50/   74]    Overall Loss 2.055470    Objective Loss 2.055470                                        LR 0.001000    Time 0.030673    
2022-12-15 15:02:58,836 - Epoch: [33][   60/   74]    Overall Loss 2.051713    Objective Loss 2.051713                                        LR 0.001000    Time 0.029626    
2022-12-15 15:02:59,077 - Epoch: [33][   70/   74]    Overall Loss 2.046862    Objective Loss 2.046862                                        LR 0.001000    Time 0.028841    
2022-12-15 15:02:59,166 - Epoch: [33][   74/   74]    Overall Loss 2.044323    Objective Loss 2.044323    Top1 44.212963    Top5 79.398148    LR 0.001000    Time 0.028480    
2022-12-15 15:02:59,224 - --- validate (epoch=33)-----------
2022-12-15 15:02:59,225 - 2096 samples (256 per mini-batch)
2022-12-15 15:02:59,500 - Epoch: [33][    9/    9]    Loss 2.057118    Top1 41.316794    Top5 78.339695    
2022-12-15 15:02:59,560 - ==> Top1: 41.317    Top5: 78.340    Loss: 2.057

2022-12-15 15:02:59,562 - ==> Confusion:
[[  0   0   3   0   1   0   9   0   0   0   0   0   0   0   8   0   0   0   2   0   0   1   0   3   0   0   0   0   0   1   0]
 [  0   0   0   0   5   0   1   0   0   0   0   0   0   0   0   0   0   0  22   0   5   1   0   0   0   0   0   0   0   4   0]
 [  0   0 103   0   6   0  14   0   0   0   0   0   0   0   3   0   0   0   3   0   0   0   0   1   0   0   1   0   0   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  19   0  25   0  33   0   0   0   0   0   0   0   6   0   0   0  17   0   0   0   0   0   0   0   0   0   0  65   0]
 [  0   0   0   0   1   2   0   0   0   0   0   0   0   0   3   0   3   0   8   0  19  18   0   0   0   0   0   0   0   1   0]
 [  0   0  22   0  14   0  92   0   0   0   0   0   0   0  10   0   0   0   9   0   0   1   0   0   0   0   1   0   0  23   0]
 [  0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   5   0  12   0   0   0   0   0   0   0   0   4   0]
 [  0   0   1   0   0   0   8   0   0   0   0   0   0   0  12   0   0   0  11   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   4   0   7   0   0   0   0   0   0   0   2   0   0   0  20   0   0   1   0   0   0   0   0   0   0   7   0]
 [  0   0   0   0   0   0   2   0   0   0   0   0   0   0  30   0   1   0   0   0   0   6   0   0   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   3   0   0   0   0   0   0   0  14   0   0   0   3   0   0   2   0   0   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   7   0  11   0   0   0   0   0   0   0   0  14   0]
 [  0   0   2   0   7   0  16   0   0   0   0   0   0   0 127   0   0   0  11   0   0  22   0   1   0   0   0   1   0   2   0]
 [  0   0   1   0   2   0  10   0   0   0   0   0   0   0   1   0   0   0  12   0   0   0   0   1   0   0   0   0   0   4   0]
 [  0   0   0   0   1   3   1   0   0   0   0   0   0   0   7   0  23   0   6   0   3   7   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   1   0   1   0   0   0   3   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   0   8   0   0   0   0   0   0   0   3   0   0   0 130   0   0   7   0   0   0   0   0   0   0   7   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   8   0  73   8   0   0   0   0   1   0   0  18   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0  19   0   6   0  24   0  14 112   0   0   0   0   0   0   0   2   0]
 [  0   0  15   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   3   0   0   0   0   0   0   0]
 [  0   0  32   0  14   0  46   0   0   0   0   0   0   0  18   0   0   0  16   0   0   1   0   2   0   0   0   0   0  20   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   2   0   2   0   0   0   0   0   0   0   2   0   0   0   6   0   0   0   0   0   0   0   0   0   0   2   0]
 [  0   0   1   0   2   0   1   0   0   0   0   0   0   0  12   0   0   0   1   0   0   0   0   1   0   0  48   2   0   0   0]
 [  0   0   4   0  14   0  19   0   0   0   0   0   0   0   1   0   6   0  25   0   7   0   0   2   0   0   1   4   0  25   0]
 [  0   0   3   0   1   0   3   0   0   0   0   0   0   0   4   0   0   0   9   0   1   4   0   1   0   0   0   0   0   0   0]
 [  0   0   1   0  12   0  13   0   0   0   0   0   0   0   1   0   0   0  15   0  11   0   0   1   0   0   0   1   0 125   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   7   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:02:59,563 - ==> Best [Top1: 41.317   Top5: 78.340   Sparsity:0.00   Params: 364480 on epoch: 33]
2022-12-15 15:02:59,563 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:02:59,586 - 

2022-12-15 15:02:59,587 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:02:59,985 - Epoch: [34][   10/   74]    Overall Loss 1.978078    Objective Loss 1.978078                                        LR 0.001000    Time 0.039735    
2022-12-15 15:03:00,226 - Epoch: [34][   20/   74]    Overall Loss 1.952117    Objective Loss 1.952117                                        LR 0.001000    Time 0.031911    
2022-12-15 15:03:00,474 - Epoch: [34][   30/   74]    Overall Loss 1.958944    Objective Loss 1.958944                                        LR 0.001000    Time 0.029539    
2022-12-15 15:03:00,726 - Epoch: [34][   40/   74]    Overall Loss 1.961070    Objective Loss 1.961070                                        LR 0.001000    Time 0.028430    
2022-12-15 15:03:00,976 - Epoch: [34][   50/   74]    Overall Loss 1.958053    Objective Loss 1.958053                                        LR 0.001000    Time 0.027744    
2022-12-15 15:03:01,225 - Epoch: [34][   60/   74]    Overall Loss 1.952059    Objective Loss 1.952059                                        LR 0.001000    Time 0.027264    
2022-12-15 15:03:01,469 - Epoch: [34][   70/   74]    Overall Loss 1.946071    Objective Loss 1.946071                                        LR 0.001000    Time 0.026847    
2022-12-15 15:03:01,558 - Epoch: [34][   74/   74]    Overall Loss 1.943339    Objective Loss 1.943339    Top1 45.138889    Top5 81.712963    LR 0.001000    Time 0.026590    
2022-12-15 15:03:01,618 - --- validate (epoch=34)-----------
2022-12-15 15:03:01,618 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:01,893 - Epoch: [34][    9/    9]    Loss 1.970293    Top1 42.461832    Top5 79.246183    
2022-12-15 15:03:01,954 - ==> Top1: 42.462    Top5: 79.246    Loss: 1.970

2022-12-15 15:03:01,956 - ==> Confusion:
[[  0   0   1   0   1   0  10   0   0   0   0   0   0   0  10   0   0   0   1   0   0   0   0   4   0   0   0   0   0   1   0]
 [  0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0   4   1   0   0   0   0   0   0   0   5   0]
 [  0   0  98   0   8   0  11   0   0   0   0   0   0   0   5   0   0   0   3   0   0   0   0   5   0   0   1   0   0   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  17   0  28   0  44   0   0   0   0   0   0   0   6   0   0   0  14   0   1   1   0   2   0   0   0   5   0  47   0]
 [  0   0   0   0   1   8   0   0   0   0   0   0   0   0   3   0   5   0   8   0  12  15   0   0   0   0   0   0   0   3   0]
 [  0   0  14   0   9   0 103   0   0   0   0   0   0   0   8   0   0   0  10   0   0   1   0   2   0   0   1   5   0  19   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0  10   0   0   0   0   0   0   0   0   7   0]
 [  0   0   0   0   0   0   6   0   0   0   0   0   0   0  14   0   0   0  11   0   0   1   0   1   0   0   0   0   0   0   0]
 [  0   0   0   0   3   0   9   0   0   0   0   0   0   0   2   0   0   0  22   0   0   0   0   0   0   0   0   0   0   5   0]
 [  0   0   0   0   0   0   2   0   0   0   0   0   0   0  28   0   3   0   0   0   0   5   0   0   0   0   1   1   0   0   0]
 [  0   0   1   0   0   0   2   0   0   0   0   0   0   0  16   0   0   0   1   0   0   2   0   0   0   0   2   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   1   0   0   0   0   0   0   0   1   0   0   0   5   0  10   1   0   0   0   0   0   1   0  14   0]
 [  0   0   1   0   1   0  10   0   0   0   0   0   0   0 142   0   1   0   7   0   0  17   0   6   0   0   1   3   0   0   0]
 [  0   0   1   0   1   0  10   0   0   0   0   0   0   0   1   0   0   0  10   0   0   0   0   0   0   0   0   3   0   5   0]
 [  0   0   0   0   0   6   0   0   0   0   0   0   0   0  10   0  19   0   3   0   2   8   0   1   0   0   0   3   0   0   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   4   0   0   0   2   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0  11   0   0   0   0   0   0   0   5   0   0   0 126   0   0   5   0   1   0   0   0   0   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   2   0   0   0   0   0   0   0   0   1   0   1   0   6   0  63  13   0   0   0   0   0   2   0  20   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0  33   0   7   0  14   0   9 112   0   0   0   0   0   0   0   2   0]
 [  0   0  12   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   1   0   0   0   2   0   0   0]
 [  0   0  22   0  13   0  47   0   0   0   0   0   0   0  19   0   0   0  16   0   0   1   1   8   0   0   1   3   0  18   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0]
 [  0   0   0   0   0   0   2   0   0   0   0   0   0   0   2   0   0   0   7   0   0   0   0   1   0   0   0   0   0   2   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   0   0  11   0   0   0   2   0   0   0   0   1   0   0  51   2   0   0   0]
 [  0   0   1   0   9   2  23   0   0   0   0   0   0   0   1   0   0   0  23   0   9   0   0   1   0   0   1   8   0  30   0]
 [  0   0   3   0   1   0   2   0   0   0   0   0   0   0   4   0   1   0   6   0   0   7   0   2   0   0   0   0   0   0   0]
 [  0   0   0   0  14   0  17   0   0   0   0   0   0   0   3   0   0   0  10   0   8   1   0   0   0   0   0   4   0 123   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   8   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:01,958 - ==> Best [Top1: 42.462   Top5: 79.246   Sparsity:0.00   Params: 364480 on epoch: 34]
2022-12-15 15:03:01,958 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:01,982 - 

2022-12-15 15:03:01,982 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:02,372 - Epoch: [35][   10/   74]    Overall Loss 1.927255    Objective Loss 1.927255                                        LR 0.001000    Time 0.038928    
2022-12-15 15:03:02,610 - Epoch: [35][   20/   74]    Overall Loss 1.903757    Objective Loss 1.903757                                        LR 0.001000    Time 0.031332    
2022-12-15 15:03:02,856 - Epoch: [35][   30/   74]    Overall Loss 1.897181    Objective Loss 1.897181                                        LR 0.001000    Time 0.029075    
2022-12-15 15:03:03,070 - Epoch: [35][   40/   74]    Overall Loss 1.893521    Objective Loss 1.893521                                        LR 0.001000    Time 0.027137    
2022-12-15 15:03:03,283 - Epoch: [35][   50/   74]    Overall Loss 1.890454    Objective Loss 1.890454                                        LR 0.001000    Time 0.025962    
2022-12-15 15:03:03,498 - Epoch: [35][   60/   74]    Overall Loss 1.876981    Objective Loss 1.876981                                        LR 0.001000    Time 0.025204    
2022-12-15 15:03:03,708 - Epoch: [35][   70/   74]    Overall Loss 1.873241    Objective Loss 1.873241                                        LR 0.001000    Time 0.024599    
2022-12-15 15:03:03,799 - Epoch: [35][   74/   74]    Overall Loss 1.870211    Objective Loss 1.870211    Top1 42.824074    Top5 83.333333    LR 0.001000    Time 0.024495    
2022-12-15 15:03:03,874 - --- validate (epoch=35)-----------
2022-12-15 15:03:03,874 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:04,141 - Epoch: [35][    9/    9]    Loss 1.974244    Top1 41.459924    Top5 79.293893    
2022-12-15 15:03:04,195 - ==> Top1: 41.460    Top5: 79.294    Loss: 1.974

2022-12-15 15:03:04,197 - ==> Confusion:
[[  0   0   2   0   1   0   5   0   0   0   0   0   0   0   7   0   0   0   1   0   1   1   0   9   0   0   0   0   0   1   0]
 [  0   0   0   0   7   0   1   0   0   0   0   0   0   0   0   0   0   0  17   0   8   1   0   0   0   0   0   0   0   4   0]
 [  0   0 100   0  10   0  11   0   0   0   0   0   0   0   2   0   0   0   1   0   0   0   0   6   0   0   1   0   0   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  17   0  42   0  29   0   0   0   0   0   0   0   4   0   0   0   5   0   1   0   0   4   0   0   0   1   0  62   0]
 [  0   0   0   0   1  19   0   0   0   0   0   0   0   0   1   0   3   0   4   0  12   5   0   1   0   0   0   0   0   9   0]
 [  0   0  14   0  28   0 101   0   0   0   0   0   0   0   4   0   0   0   4   0   1   1   0   0   0   0   1   0   0  18   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   8   0   0   0   0   0   0   0   0  10   0]
 [  0   0   2   0   2   0  13   0   0   0   0   0   0   0   6   0   0   0   8   0   0   1   0   1   0   0   0   0   0   0   0]
 [  0   0   0   0  11   0   8   0   0   0   0   0   0   0   2   0   0   0  12   0   0   0   0   0   0   0   0   0   0   8   0]
 [  0   0   1   0   0   1   2   0   0   0   0   0   0   0  25   0   3   0   1   0   0   6   0   0   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   3   0   0   0   0   0   0   0  13   0   0   0   1   0   0   4   0   0   0   0   2   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   2   2   0   0   0   0   0   0   0   0   0   0   0   0   2   0  10   0   0   0   0   0   0   0   0  17   0]
 [  0   0   1   0   6   0  23   0   0   0   0   0   0   0 112   0   3   0   9   0   1  23   1   6   0   0   0   2   0   2   0]
 [  0   0   0   0   2   0  14   0   0   0   0   0   0   0   1   0   0   0   5   0   0   0   0   1   0   0   0   0   0   8   0]
 [  0   0   0   0   1  14   1   0   0   0   0   0   0   0   3   0  18   0   6   0   3   3   0   1   0   0   0   0   0   2   0]
 [  0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   3   0   0   0   2   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0  16   0   7   0   0   0   0   0   0   0   1   0   0   0 106   0   5   2   0   0   0   0   0   0   0  21   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   1   0   0   0   4   0  68   5   0   0   0   0   0   0   0  28   0]
 [  0   0   0   0   0  12   0   0   0   0   0   0   0   0  10   0   4   0  26   0  13 108   0   0   0   0   0   0   0   5   0]
 [  0   0  15   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   2   0   0   0   0   0   0   0]
 [  0   0  30   0  25   0  50   0   0   0   0   0   0   0  11   0   0   0   9   0   0   1   0   6   0   0   0   0   0  17   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   3   0   2   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   1   0   0   0   0   0   4   0]
 [  0   0   2   0   1   0   1   0   0   0   0   0   0   0   6   0   0   0   1   0   0   1   0   3   0   0  52   1   0   0   0]
 [  0   0   2   0  21   3  17   0   0   0   0   0   0   0   0   0   3   0  21   0   5   0   0   2   0   0   1   3   0  30   0]
 [  1   0   3   0   2   1   2   0   0   0   0   0   0   0   1   0   1   0   7   0   1   5   0   2   0   0   0   0   0   0   0]
 [  0   0   0   0  28   0   7   0   0   0   0   0   0   0   1   0   0   0   4   0   5   0   0   0   0   0   0   1   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   8   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:04,198 - ==> Best [Top1: 42.462   Top5: 79.246   Sparsity:0.00   Params: 364480 on epoch: 34]
2022-12-15 15:03:04,198 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:04,208 - 

2022-12-15 15:03:04,208 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:04,596 - Epoch: [36][   10/   74]    Overall Loss 1.891330    Objective Loss 1.891330                                        LR 0.001000    Time 0.038751    
2022-12-15 15:03:04,836 - Epoch: [36][   20/   74]    Overall Loss 1.852875    Objective Loss 1.852875                                        LR 0.001000    Time 0.031340    
2022-12-15 15:03:05,089 - Epoch: [36][   30/   74]    Overall Loss 1.841275    Objective Loss 1.841275                                        LR 0.001000    Time 0.029302    
2022-12-15 15:03:05,343 - Epoch: [36][   40/   74]    Overall Loss 1.830085    Objective Loss 1.830085                                        LR 0.001000    Time 0.028307    
2022-12-15 15:03:05,569 - Epoch: [36][   50/   74]    Overall Loss 1.826468    Objective Loss 1.826468                                        LR 0.001000    Time 0.027157    
2022-12-15 15:03:05,783 - Epoch: [36][   60/   74]    Overall Loss 1.815905    Objective Loss 1.815905                                        LR 0.001000    Time 0.026200    
2022-12-15 15:03:05,996 - Epoch: [36][   70/   74]    Overall Loss 1.811283    Objective Loss 1.811283                                        LR 0.001000    Time 0.025490    
2022-12-15 15:03:06,080 - Epoch: [36][   74/   74]    Overall Loss 1.810261    Objective Loss 1.810261    Top1 49.537037    Top5 81.712963    LR 0.001000    Time 0.025253    
2022-12-15 15:03:06,136 - --- validate (epoch=36)-----------
2022-12-15 15:03:06,136 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:06,403 - Epoch: [36][    9/    9]    Loss 1.859010    Top1 44.227099    Top5 80.868321    
2022-12-15 15:03:06,457 - ==> Top1: 44.227    Top5: 80.868    Loss: 1.859

2022-12-15 15:03:06,459 - ==> Confusion:
[[  2   0   1   0   0   0   5   0   0   0   0   0   0   0  11   0   0   0   1   0   0   0   0   7   0   0   0   0   0   1   0]
 [  0   0   0   0   3   0   1   0   0   0   0   0   0   0   1   0   0   0  24   0   4   3   0   0   0   0   0   1   0   1   0]
 [  1   0 103   0   2   0   4   0   0   0   0   0   0   0   5   0   0   0   4   0   0   0   2  10   0   0   2   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  18   0  31   0  34   0   0   0   0   0   0   0   6   0   0   0  24   0   1   2   0  12   0   0   0   5   0  32   0]
 [  0   0   0   0   1  14   0   0   0   0   0   0   0   0   3   0   6   0   7   0  10  12   0   0   0   0   1   0   0   1   0]
 [  0   0  10   0   9   0 103   0   0   0   0   0   0   0  13   0   0   0  14   0   0   1   1  12   0   0   1   1   0   7   0]
 [  0   0   0   0   2   1   0   0   0   0   0   0   0   0   0   0   1   0   8   0   6   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   0   0   4   0   0   0   0   0   0   0  12   0   0   0   9   0   0   1   0   5   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  11   0   0   0   0   0   0   0   2   0   0   0  19   0   0   0   0   3   0   0   0   0   0   6   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  28   0   3   0   0   0   0   6   0   0   0   0   0   2   0   0   0]
 [  0   0   1   0   0   0   2   0   0   0   0   0   0   0  15   0   0   0   0   0   1   5   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   4   0   0   0   0   0   0   0   0   0   1   0   0   0   7   0  12   0   0   0   0   0   0   1   0   9   0]
 [  2   0   1   0   0   0   8   0   0   0   0   0   0   0 144   0   3   0   3   0   0  20   0   5   0   0   0   3   0   0   0]
 [  1   0   0   0   0   0   9   0   0   0   0   0   0   0   2   0   0   0  13   0   0   0   0   3   0   0   0   2   0   1   0]
 [  0   0   0   0   0   4   0   0   0   0   0   0   0   0   9   0  29   0   5   0   0   3   0   0   0   0   0   2   0   0   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   4   0   0   0   0   0   0   0   2   0   0   0 126   0   2  12   0   8   0   0   0   0   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   2   0   0   0   0   0   0   0   0   1   0   3   0   4   0  69   9   0   0   0   0   0   1   0  19   0]
 [  0   0   0   0   0   6   0   0   0   0   0   0   0   0  16   0  11   0   4   0  10 128   0   0   0   0   0   1   0   2   0]
 [  0   0  15   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   1   2   2   0   0   0   0   0   0   0]
 [  4   0  22   0  11   0  44   0   0   0   0   0   0   0  18   0   0   0  10   0   0   2   1  21   0   0   2   4   0  10   0]
 [  0   0   0   0   1   0   3   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   2   0   0   0   8   0   0   0   0   1   0   0   0   0   0   2   0]
 [  0   0   2   0   0   0   0   0   0   0   0   0   0   0  13   0   0   0   0   0   0   1   0   3   0   0  48   1   0   0   0]
 [  1   0   1   0  12   0  27   0   0   0   0   0   0   0   4   0   6   0  23   0   4   0   0   5   0   0   1  13   0  11   0]
 [  0   0   2   0   1   0   2   0   0   0   0   0   0   0   5   0   1   0   5   0   0   6   0   3   0   0   1   0   0   0   0]
 [  0   0   0   0  27   0  19   0   0   0   0   0   0   0   1   0   0   0  18   0  12   2   0   2   0   0   0   5   0  94   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   7   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:06,460 - ==> Best [Top1: 44.227   Top5: 80.868   Sparsity:0.00   Params: 364480 on epoch: 36]
2022-12-15 15:03:06,460 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:06,481 - 

2022-12-15 15:03:06,482 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:06,865 - Epoch: [37][   10/   74]    Overall Loss 1.805944    Objective Loss 1.805944                                        LR 0.001000    Time 0.038295    
2022-12-15 15:03:07,085 - Epoch: [37][   20/   74]    Overall Loss 1.782678    Objective Loss 1.782678                                        LR 0.001000    Time 0.030125    
2022-12-15 15:03:07,301 - Epoch: [37][   30/   74]    Overall Loss 1.763331    Objective Loss 1.763331                                        LR 0.001000    Time 0.027246    
2022-12-15 15:03:07,521 - Epoch: [37][   40/   74]    Overall Loss 1.757670    Objective Loss 1.757670                                        LR 0.001000    Time 0.025934    
2022-12-15 15:03:07,780 - Epoch: [37][   50/   74]    Overall Loss 1.749595    Objective Loss 1.749595                                        LR 0.001000    Time 0.025918    
2022-12-15 15:03:08,007 - Epoch: [37][   60/   74]    Overall Loss 1.746743    Objective Loss 1.746743                                        LR 0.001000    Time 0.025357    
2022-12-15 15:03:08,222 - Epoch: [37][   70/   74]    Overall Loss 1.745275    Objective Loss 1.745275                                        LR 0.001000    Time 0.024809    
2022-12-15 15:03:08,302 - Epoch: [37][   74/   74]    Overall Loss 1.746856    Objective Loss 1.746856    Top1 46.527778    Top5 84.259259    LR 0.001000    Time 0.024537    
2022-12-15 15:03:08,364 - --- validate (epoch=37)-----------
2022-12-15 15:03:08,364 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:08,634 - Epoch: [37][    9/    9]    Loss 1.834640    Top1 44.799618    Top5 81.345420    
2022-12-15 15:03:08,688 - ==> Top1: 44.800    Top5: 81.345    Loss: 1.835

2022-12-15 15:03:08,690 - ==> Confusion:
[[  2   0   5   0   0   0   7   0   0   0   0   0   0   0   5   0   0   0   3   0   0   0   0   5   0   0   0   0   0   1   0]
 [  0   0   0   0   7   0   1   0   0   0   0   0   0   0   0   0   0   0  23   0   2   2   0   0   0   0   0   0   0   3   0]
 [  0   0 101   0   8   0   9   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0  11   0   0   1   0   0   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0   8   0  56   0  24   0   0   0   0   0   0   0   3   0   0   0   8   0   2   0   0   9   0   0   0   1   0  54   0]
 [  0   0   0   0   0  18   0   0   0   0   0   0   0   0   2   0   5   0   9   0  11   5   0   1   0   0   0   0   0   4   0]
 [  0   0   9   0  23   0 108   0   0   0   0   0   0   0   2   0   0   0   6   0   0   3   1   3   0   0   0   0   0  17   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   1   0   7   0   6   0   0   0   0   0   0   1   0   6   0]
 [  1   0   0   0   0   0  14   0   0   0   0   0   0   0   5   0   0   0   9   0   0   1   0   3   0   0   0   0   0   0   0]
 [  0   0   0   0   6   0  12   0   0   0   0   0   0   0   0   0   0   0  15   0   0   0   0   1   0   0   0   0   0   7   0]
 [  1   0   0   0   0   1   1   0   0   0   0   0   0   0  27   0   2   0   1   0   0   5   0   0   0   0   0   2   0   0   0]
 [  0   0   1   0   0   0   4   0   0   0   0   0   0   0  11   0   0   0   2   0   1   5   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   7   0  14   0   0   1   0   0   0   0   0  11   0]
 [  3   0   2   0   0   0  17   0   0   0   0   0   0   0 133   0   2   0   8   0   1  10   1   8   0   0   0   3   0   1   0]
 [  0   0   0   0   5   0  13   0   0   0   0   0   0   0   0   0   0   0   7   0   0   0   0   2   0   0   0   0   0   4   0]
 [  0   0   0   0   1   5   0   0   0   0   0   0   0   0   3   0  27   0   8   0   2   4   0   0   0   0   0   2   0   0   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   5   0   1   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   5   0  10   0   0   0   0   0   0   0   2   0   0   0 127   0   0   2   0   3   0   0   0   0   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   2   0   0   0   0   0   0   0   0   1   0   1   0   8   0  70   7   0   0   0   0   0   0   0  19   0]
 [  0   0   0   0   0   7   0   0   0   0   0   0   0   0  20   0   7   0  20   0  11 109   0   0   0   0   0   0   0   4   0]
 [  0   0  14   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   3   0   0   0   0   0   0   0]
 [  2   0  23   0  35   0  41   0   0   0   0   0   0   0  12   0   0   0  13   0   0   0   1   7   0   0   0   1   0  14   0]
 [  0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   3   0   3   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   1   0   0   0   0   0   3   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   3   0   0   1   0   2   0   0  50   2   0   0   0]
 [  1   0   1   0  20   3  21   0   0   0   0   0   0   0   0   0   2   0  22   0   3   0   0   4   0   0   0   6   0  25   0]
 [  0   0   3   0   1   1   5   0   0   0   0   0   0   0   1   0   1   0   7   0   0   4   0   3   0   0   0   0   0   0   0]
 [  0   0   0   0  22   0  12   0   0   0   0   0   0   0   1   0   0   0   9   0  10   0   0   1   0   0   0   0   0 125   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   8   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:08,692 - ==> Best [Top1: 44.800   Top5: 81.345   Sparsity:0.00   Params: 364480 on epoch: 37]
2022-12-15 15:03:08,692 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:08,715 - 

2022-12-15 15:03:08,715 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:09,129 - Epoch: [38][   10/   74]    Overall Loss 1.684738    Objective Loss 1.684738                                        LR 0.001000    Time 0.041271    
2022-12-15 15:03:09,359 - Epoch: [38][   20/   74]    Overall Loss 1.653320    Objective Loss 1.653320                                        LR 0.001000    Time 0.032108    
2022-12-15 15:03:09,603 - Epoch: [38][   30/   74]    Overall Loss 1.665143    Objective Loss 1.665143                                        LR 0.001000    Time 0.029532    
2022-12-15 15:03:09,853 - Epoch: [38][   40/   74]    Overall Loss 1.673444    Objective Loss 1.673444                                        LR 0.001000    Time 0.028392    
2022-12-15 15:03:10,098 - Epoch: [38][   50/   74]    Overall Loss 1.677364    Objective Loss 1.677364                                        LR 0.001000    Time 0.027609    
2022-12-15 15:03:10,364 - Epoch: [38][   60/   74]    Overall Loss 1.682393    Objective Loss 1.682393                                        LR 0.001000    Time 0.027425    
2022-12-15 15:03:10,617 - Epoch: [38][   70/   74]    Overall Loss 1.677443    Objective Loss 1.677443                                        LR 0.001000    Time 0.027112    
2022-12-15 15:03:10,706 - Epoch: [38][   74/   74]    Overall Loss 1.676398    Objective Loss 1.676398    Top1 48.379630    Top5 85.648148    LR 0.001000    Time 0.026848    
2022-12-15 15:03:10,767 - --- validate (epoch=38)-----------
2022-12-15 15:03:10,767 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:11,035 - Epoch: [38][    9/    9]    Loss 1.775486    Top1 46.469466    Top5 83.540076    
2022-12-15 15:03:11,083 - ==> Top1: 46.469    Top5: 83.540    Loss: 1.775

2022-12-15 15:03:11,085 - ==> Confusion:
[[ 10   0   2   0   0   0   4   0   0   0   0   0   0   0   6   0   0   0   2   0   0   1   0   2   0   0   0   0   0   1   0]
 [  0   0   0   0   5   0   1   0   0   0   0   0   0   0   0   0   0   0  21   0   4   1   0   0   0   0   0   1   0   5   0]
 [  3   0 113   0   6   0   5   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   3   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  14   0  45   0  27   0   0   0   0   0   0   0   5   0   0   0   6   0   0   1   0  17   0   0   0   5   0  45   0]
 [  0   0   0   0   0  20   0   0   0   0   0   0   0   0   2   0   5   0   7   0   4   9   1   0   0   0   0   1   0   6   0]
 [  0   0  14   0  14   0 106   0   0   0   0   0   0   0   3   0   0   0   8   0   0   4   0   6   0   0   1   3   0  13   0]
 [  0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   1   0   3   0   9   0   0   0   0   0   0   1   0   6   0]
 [  2   0   2   0   0   0  10   0   0   0   0   0   0   0   3   0   0   0   9   0   0   2   0   3   0   0   0   2   0   0   0]
 [  1   0   0   0   4   0  13   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   1   0   0   0   0   0   8   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  28   0   1   0   0   0   0   8   0   0   0   0   1   1   0   0   0]
 [  0   0   1   0   0   0   2   0   0   0   0   0   0   0  10   0   0   0   3   0   0   6   0   0   0   0   2   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0  12   0   0   1   0   0   0   1   0  17   0]
 [  3   0   2   0   0   0  15   0   0   0   0   0   0   0 124   0   2   0   5   0   1  25   0   6   0   0   2   3   0   1   0]
 [  0   0   0   0   3   0  12   0   0   0   0   0   0   0   0   0   0   0   8   0   0   0   0   3   0   0   0   1   0   4   0]
 [  0   0   0   0   0   8   0   0   0   0   0   0   0   0   3   0  27   0   6   0   0   5   0   0   0   0   0   2   0   1   0]
 [  0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   0   6   0  13   0   0   0   0   0   0   0   1   0   0   0 118   0   1   3   0   4   0   0   0   1   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   4   0   0   0   0   0   0   0   0   0   0   0   0   3   0  69   6   0   0   0   0   1   1   0  24   0]
 [  0   0   0   0   0   9   0   0   0   0   0   0   0   0  11   0   7   0  10   0  11 126   0   0   0   0   0   1   0   3   0]
 [  1   0  18   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]
 [  5   0  24   0  24   0  43   0   0   0   0   0   0   0   7   0   0   0   7   0   0   2   3  12   0   0   1   6   0  15   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0]
 [  1   0   0   0   1   0   6   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   0   2   0]
 [  1   0   2   0   0   0   1   0   0   0   0   0   0   0   3   0   0   0   1   0   0   1   1   0   0   0  55   3   0   0   0]
 [  3   0   2   0   9   0  23   0   0   0   0   0   0   0   1   0   7   0  16   0   4   0   0   2   0   0   1  20   0  20   0]
 [  1   0   4   0   0   1   3   0   0   0   0   0   0   0   0   0   1   0   3   0   0   8   0   4   0   0   0   1   0   0   0]
 [  0   0   0   0  13   0  17   0   0   0   0   0   0   0   0   0   0   0   9   0   6   1   0   2   0   0   0   3   0 129   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   8   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:11,086 - ==> Best [Top1: 46.469   Top5: 83.540   Sparsity:0.00   Params: 364480 on epoch: 38]
2022-12-15 15:03:11,086 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:11,110 - 

2022-12-15 15:03:11,110 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:11,491 - Epoch: [39][   10/   74]    Overall Loss 1.632602    Objective Loss 1.632602                                        LR 0.001000    Time 0.037988    
2022-12-15 15:03:11,701 - Epoch: [39][   20/   74]    Overall Loss 1.614087    Objective Loss 1.614087                                        LR 0.001000    Time 0.029505    
2022-12-15 15:03:11,917 - Epoch: [39][   30/   74]    Overall Loss 1.616199    Objective Loss 1.616199                                        LR 0.001000    Time 0.026852    
2022-12-15 15:03:12,134 - Epoch: [39][   40/   74]    Overall Loss 1.643750    Objective Loss 1.643750                                        LR 0.001000    Time 0.025557    
2022-12-15 15:03:12,362 - Epoch: [39][   50/   74]    Overall Loss 1.643799    Objective Loss 1.643799                                        LR 0.001000    Time 0.024979    
2022-12-15 15:03:12,588 - Epoch: [39][   60/   74]    Overall Loss 1.644874    Objective Loss 1.644874                                        LR 0.001000    Time 0.024585    
2022-12-15 15:03:12,808 - Epoch: [39][   70/   74]    Overall Loss 1.641362    Objective Loss 1.641362                                        LR 0.001000    Time 0.024204    
2022-12-15 15:03:12,900 - Epoch: [39][   74/   74]    Overall Loss 1.658289    Objective Loss 1.658289    Top1 47.222222    Top5 84.953704    LR 0.001000    Time 0.024143    
2022-12-15 15:03:12,957 - --- validate (epoch=39)-----------
2022-12-15 15:03:12,958 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:13,226 - Epoch: [39][    9/    9]    Loss 2.081112    Top1 47.137405    Top5 82.872137    
2022-12-15 15:03:13,282 - ==> Top1: 47.137    Top5: 82.872    Loss: 2.081

2022-12-15 15:03:13,284 - ==> Confusion:
[[  8   0   2   0   0   0   4   0   0   0   0   0   0   0   4   0   0   0   1   0   0   1   0   6   0   0   0   1   0   1   0]
 [  0   0   0   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0  15   0   8   2   0   0   0   0   0   0   0   5   0]
 [  2   0  95   0  21   0   4   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   1   5   0   0   0   1   0   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0   8   0  71   0  16   0   0   0   0   0   0   0   4   0   0   0   8   0   1   1   0   6   0   0   0   1   0  49   0]
 [  0   0   0   0   1  21   0   0   0   0   0   0   0   0   4   0   3   0   2   0   7   8   0   0   0   0   0   1   0   8   0]
 [  2   0   4   0  20   0 111   0   0   0   0   0   0   0   2   0   0   0   7   0   0   2   0   6   0   0   1   0   0  17   0]
 [  0   0   0   0   2   0   1   0   0   0   0   0   0   0   0   0   1   0   2   0   9   0   0   0   0   0   0   1   0   7   0]
 [  0   0   0   0   0   0  11   0   0   0   0   0   0   0   5   0   0   0   8   0   0   3   0   5   0   0   0   1   0   0   0]
 [  0   0   0   0   4   1   9   0   0   0   0   0   0   0   2   0   0   0  14   0   0   1   0   0   0   0   0   0   0  10   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  29   0   1   0   0   0   0   7   0   0   0   0   0   2   0   0   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  12   0   0   0   1   0   0   7   0   1   0   0   2   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0  12   0   0   0   0   0   0   1   0  16   0]
 [  1   0   1   0   1   0  14   0   0   0   0   0   0   0 137   0   3   0   1   0   1  19   0   4   0   0   0   6   0   1   0]
 [  0   0   0   0   4   0   9   0   0   0   0   0   0   0   1   0   0   0   9   0   0   0   0   1   0   0   0   3   0   4   0]
 [  0   0   0   0   1  10   0   0   0   0   0   0   0   0   6   0  24   0   5   0   0   4   0   0   0   0   0   2   0   0   0]
 [  0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0  13   1   5   0   0   0   0   0   0   0   1   0   0   0 107   0   4  14   0   1   0   0   0   0   0  12   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   5   0   0   0   0   0   0   0   0   0   0   1   0   2   0  68   7   0   0   0   0   0   0   0  25   0]
 [  0   0   0   0   0   9   0   0   0   0   0   0   0   0  16   0   5   0   4   0  12 128   0   0   0   0   0   0   0   4   0]
 [  0   0  13   0   3   0   0   0   0   0   0   0   0   0   1   0   0   0   1   0   0   0   3   0   0   0   0   0   0   0   0]
 [  4   0  15   0  43   0  29   0   0   0   0   0   0   0   9   0   0   0   9   0   0   2   4  16   0   0   1   3   0  14   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0]
 [  1   0   0   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   1   0   0   0   0   0   4   0]
 [  1   0   1   0   1   1   0   0   0   0   0   0   0   0   8   0   0   0   0   0   0   2   1   1   0   0  51   1   0   0   0]
 [  1   0   1   0  17   2  20   0   0   0   0   0   0   0   2   0   1   0  16   0   4   0   0   2   0   0   1  19   0  22   0]
 [  0   0   1   0   2   0   2   0   0   0   0   0   0   0   1   0   1   0   4   0   0   8   1   6   0   0   0   0   0   0   0]
 [  1   0   0   0  18   0  12   0   0   0   0   0   0   0   1   0   0   0   4   0   8   3   0   0   0   0   0   4   0 129   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   7   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:13,287 - ==> Best [Top1: 47.137   Top5: 82.872   Sparsity:0.00   Params: 364480 on epoch: 39]
2022-12-15 15:03:13,287 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:13,310 - 

2022-12-15 15:03:13,310 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:13,870 - Epoch: [40][   10/   74]    Overall Loss 1.979882    Objective Loss 1.979882                                        LR 0.001000    Time 0.055928    
2022-12-15 15:03:14,122 - Epoch: [40][   20/   74]    Overall Loss 1.936764    Objective Loss 1.936764                                        LR 0.001000    Time 0.040571    
2022-12-15 15:03:14,374 - Epoch: [40][   30/   74]    Overall Loss 1.905875    Objective Loss 1.905875                                        LR 0.001000    Time 0.035413    
2022-12-15 15:03:14,626 - Epoch: [40][   40/   74]    Overall Loss 1.876936    Objective Loss 1.876936                                        LR 0.001000    Time 0.032843    
2022-12-15 15:03:14,876 - Epoch: [40][   50/   74]    Overall Loss 1.856353    Objective Loss 1.856353                                        LR 0.001000    Time 0.031276    
2022-12-15 15:03:15,121 - Epoch: [40][   60/   74]    Overall Loss 1.840778    Objective Loss 1.840778                                        LR 0.001000    Time 0.030136    
2022-12-15 15:03:15,366 - Epoch: [40][   70/   74]    Overall Loss 1.829330    Objective Loss 1.829330                                        LR 0.001000    Time 0.029319    
2022-12-15 15:03:15,455 - Epoch: [40][   74/   74]    Overall Loss 1.825702    Objective Loss 1.825702    Top1 50.000000    Top5 82.638889    LR 0.001000    Time 0.028935    
2022-12-15 15:03:15,516 - --- validate (epoch=40)-----------
2022-12-15 15:03:15,516 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:15,783 - Epoch: [40][    9/    9]    Loss 1.867456    Top1 48.043893    Top5 82.061069    
2022-12-15 15:03:15,839 - ==> Top1: 48.044    Top5: 82.061    Loss: 1.867

2022-12-15 15:03:15,840 - ==> Confusion:
[[  3   0   3   0   0   0   4   0   0   0   0   0   0   0  11   0   0   0   1   0   0   0   0   5   0   0   0   0   0   1   0]
 [  0   0   0   0   3   0   2   0   0   0   0   0   0   0   0   0   0   0  23   0   2   2   0   0   0   0   0   1   0   5   0]
 [  0   0 109   0   3   0   3   0   0   0   0   0   0   0   2   0   0   0   4   0   0   0   0  11   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  19   0  40   0  24   0   0   0   0   0   0   0   7   0   0   0  13   0   0   2   0  22   0   0   0   0   0  38   0]
 [  0   0   0   0   0  10   0   0   0   0   0   0   0   0   3   0   4   0   7   0   9  15   0   1   0   0   1   1   0   4   0]
 [  1   0  13   0   1   0 117   0   0   0   0   0   0   0  13   0   0   0   8   0   0   2   0   6   0   0   1   1   0   9   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   1   0   6   0   4   0   0   0   0   0   0   1   0   9   0]
 [  0   0   1   0   0   0   7   0   0   0   0   0   0   0  11   0   0   0   7   0   0   3   0   4   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  14   0   0   0   0   0   0   0   2   0   0   0  16   0   0   1   0   2   0   0   0   0   0   6   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   0   0   0   0   0   5   0   0   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   1   0   0   0   0   0   0   0  12   0   0   0   2   0   0   6   0   0   0   0   2   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   5   0   9   0   0   0   0   0   0   1   0  17   0]
 [  2   0   1   0   0   0   7   0   0   0   0   0   0   0 152   0   1   0   1   0   0  19   0   2   0   0   2   1   0   1   0]
 [  0   0   0   0   1   0   9   0   0   0   0   0   0   0   4   0   0   0   8   0   0   0   0   6   0   0   0   1   0   2   0]
 [  0   0   0   0   0   4   0   0   0   0   0   0   0   0  10   0  27   0   3   0   0   5   0   0   0   0   0   3   0   0   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   5   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0   1   0   3   0   2   0   0   0   0   0   0   0   1   0   0   0 130   0   0   5   0   8   0   0   0   0   0   8   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   2   0   6   0  60  13   0   0   0   0   1   1   0  25   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0  12   0   6   0   8   0  10 138   0   0   0   0   0   0   0   3   0]
 [  0   0  18   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0]
 [  2   0  30   0  15   0  34   0   0   0   0   0   0   0  16   0   0   0  11   0   0   2   0  24   0   0   3   1   0  11   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   3   0   0   0   7   0   0   0   0   1   0   0   0   1   0   1   0]
 [  1   0   1   0   0   0   0   0   0   0   0   0   0   0   6   0   0   0   0   0   0   1   0   2   0   0  57   0   0   0   0]
 [  2   0   2   0   8   0  29   0   0   0   0   0   0   0   3   0   6   0  16   0   2   0   0   7   0   0   1  15   0  17   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   7   0   0   7   0   4   0   0   0   0   0   0   0]
 [  1   0   0   0  10   0  21   0   0   0   0   0   0   0   1   0   0   0  12   0   4   2   0   3   0   0   0   1   0 125   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   8   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:15,843 - ==> Best [Top1: 48.044   Top5: 82.061   Sparsity:0.00   Params: 364479 on epoch: 40]
2022-12-15 15:03:15,843 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:15,872 - 

2022-12-15 15:03:15,872 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:16,264 - Epoch: [41][   10/   74]    Overall Loss 1.693964    Objective Loss 1.693964                                        LR 0.001000    Time 0.039066    
2022-12-15 15:03:16,506 - Epoch: [41][   20/   74]    Overall Loss 1.707417    Objective Loss 1.707417                                        LR 0.001000    Time 0.031648    
2022-12-15 15:03:16,758 - Epoch: [41][   30/   74]    Overall Loss 1.709753    Objective Loss 1.709753                                        LR 0.001000    Time 0.029471    
2022-12-15 15:03:16,991 - Epoch: [41][   40/   74]    Overall Loss 1.723422    Objective Loss 1.723422                                        LR 0.001000    Time 0.027911    
2022-12-15 15:03:17,237 - Epoch: [41][   50/   74]    Overall Loss 1.708320    Objective Loss 1.708320                                        LR 0.001000    Time 0.027223    
2022-12-15 15:03:17,487 - Epoch: [41][   60/   74]    Overall Loss 1.706122    Objective Loss 1.706122                                        LR 0.001000    Time 0.026844    
2022-12-15 15:03:17,732 - Epoch: [41][   70/   74]    Overall Loss 1.700065    Objective Loss 1.700065                                        LR 0.001000    Time 0.026496    
2022-12-15 15:03:17,819 - Epoch: [41][   74/   74]    Overall Loss 1.701327    Objective Loss 1.701327    Top1 50.231481    Top5 85.416667    LR 0.001000    Time 0.026245    
2022-12-15 15:03:17,879 - --- validate (epoch=41)-----------
2022-12-15 15:03:17,879 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:18,150 - Epoch: [41][    9/    9]    Loss 1.767208    Top1 49.284351    Top5 83.540076    
2022-12-15 15:03:18,201 - ==> Top1: 49.284    Top5: 83.540    Loss: 1.767

2022-12-15 15:03:18,203 - ==> Confusion:
[[  9   0   0   0   0   0   3   0   0   0   0   0   0   0   9   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0]
 [  0   0   0   0   5   1   0   0   0   0   0   0   0   0   0   0   0   0  23   0   4   1   0   0   0   0   0   1   0   3   0]
 [  2   0 109   0   5   0   4   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   1   6   0   0   1   1   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  1   0  17   0  54   0  19   0   0   0   0   0   0   0   5   0   0   0  12   0   1   0   0  14   0   0   0   2   0  40   0]
 [  0   0   0   0   0  16   0   0   0   0   0   0   0   0   1   0   6   0   7   0   9  11   0   0   0   0   2   0   0   3   0]
 [  2   0   9   0   6   0 115   0   0   0   0   0   0   0   9   0   0   0  14   0   1   1   1   3   0   0   1   1   0   9   0]
 [  0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   1   0   4   0   4   0   0   0   0   0   0   0   0  11   0]
 [  1   0   2   0   0   0   5   0   0   0   0   0   0   0   8   0   0   0  11   0   0   2   0   4   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0  10   0   0   0   0   0   0   0   2   0   0   0  21   0   0   0   0   0   0   0   0   2   0   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   1   0   0   0   0   4   0   0   0   0   0   2   0   0   0]
 [  0   0   1   0   0   0   1   0   0   0   0   0   0   0  12   0   0   0   2   0   0   6   0   0   0   0   2   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0  14   0   0   1   0   0   0   0   0  14   0]
 [  3   0   1   0   0   0   7   0   0   0   0   0   0   0 150   0   2   0   5   0   0  17   0   4   0   0   0   0   0   0   0]
 [  1   0   0   0   2   0   8   0   0   0   0   0   0   0   1   0   0   0  12   0   0   0   0   2   0   0   0   2   0   3   0]
 [  0   0   0   0   0   7   0   0   0   0   0   0   0   0   2   0  30   0   6   0   0   4   0   0   0   0   0   3   0   0   0]
 [  0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  3   0   0   0   3   0   1   0   0   0   0   0   0   0   1   0   0   0 133   0   0   5   0   2   0   0   0   0   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   2   0   0   0   0   0   0   0   0   0   0   1   0   5   0  65  15   0   0   0   0   1   1   0  17   0]
 [  0   0   0   0   0   7   0   0   0   0   0   0   0   0  14   0   7   0   9   0  11 126   0   0   0   0   0   0   0   4   0]
 [  1   0  16   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   1   0   0   0   0   0   0   0]
 [  5   0  22   0  23   0  29   0   0   0   0   0   0   0  14   0   0   0  14   0   0   2   2  20   0   0   2   3   0  13   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   3   0]
 [  1   0   0   0   1   0   1   0   0   0   0   0   0   0   1   0   0   0   7   0   0   0   0   0   0   0   0   1   0   2   0]
 [  0   0   2   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   1   0   3   0   0  57   0   0   0   0]
 [  2   0   1   0   9   1  29   0   0   0   0   0   0   0   2   0   4   0  21   0   4   1   0   3   0   0   1  12   0  18   0]
 [  3   0   1   0   1   1   0   0   0   0   0   0   0   0   2   0   1   0   7   0   0   7   0   3   0   0   0   0   0   0   0]
 [  0   0   0   0   6   0  13   0   0   0   0   0   0   0   1   0   0   0  14   0   7   1   0   1   0   0   0   1   0 136   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   2   7   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:18,204 - ==> Best [Top1: 49.284   Top5: 83.540   Sparsity:0.00   Params: 364480 on epoch: 41]
2022-12-15 15:03:18,204 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:18,228 - 

2022-12-15 15:03:18,229 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:18,655 - Epoch: [42][   10/   74]    Overall Loss 1.612080    Objective Loss 1.612080                                        LR 0.001000    Time 0.042551    
2022-12-15 15:03:18,920 - Epoch: [42][   20/   74]    Overall Loss 1.624614    Objective Loss 1.624614                                        LR 0.001000    Time 0.034506    
2022-12-15 15:03:19,175 - Epoch: [42][   30/   74]    Overall Loss 1.619465    Objective Loss 1.619465                                        LR 0.001000    Time 0.031489    
2022-12-15 15:03:19,432 - Epoch: [42][   40/   74]    Overall Loss 1.618638    Objective Loss 1.618638                                        LR 0.001000    Time 0.030018    
2022-12-15 15:03:19,683 - Epoch: [42][   50/   74]    Overall Loss 1.623571    Objective Loss 1.623571                                        LR 0.001000    Time 0.029029    
2022-12-15 15:03:19,935 - Epoch: [42][   60/   74]    Overall Loss 1.626516    Objective Loss 1.626516                                        LR 0.001000    Time 0.028377    
2022-12-15 15:03:20,176 - Epoch: [42][   70/   74]    Overall Loss 1.620996    Objective Loss 1.620996                                        LR 0.001000    Time 0.027768    
2022-12-15 15:03:20,266 - Epoch: [42][   74/   74]    Overall Loss 1.623252    Objective Loss 1.623252    Top1 54.861111    Top5 86.111111    LR 0.001000    Time 0.027478    
2022-12-15 15:03:20,326 - --- validate (epoch=42)-----------
2022-12-15 15:03:20,326 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:20,597 - Epoch: [42][    9/    9]    Loss 1.727028    Top1 49.475191    Top5 83.778626    
2022-12-15 15:03:20,644 - ==> Top1: 49.475    Top5: 83.779    Loss: 1.727

2022-12-15 15:03:20,646 - ==> Confusion:
[[ 12   0   0   0   0   0   4   0   0   0   0   0   0   0   7   0   0   0   1   0   0   0   0   3   0   0   0   0   0   1   0]
 [  0   0   0   0   6   0   1   0   0   0   0   0   0   0   0   0   0   0  27   0   1   1   0   1   0   0   0   0   0   1   0]
 [  2   0 107   0   6   0   4   0   0   0   0   0   0   0   1   0   0   0   3   0   0   0   1   7   0   0   3   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  12   0  78   0  18   0   0   0   0   1   0   0   5   0   0   0  11   0   0   0   0  23   0   0   0   1   0  16   0]
 [  0   0   0   0   0  17   0   0   0   0   0   0   0   0   2   0   7   0  10   0   2  10   0   1   0   0   1   0   0   5   0]
 [  2   0   5   0   9   0 135   0   0   0   0   0   0   0   4   0   0   0   6   0   0   1   0   6   0   0   1   1   0   2   0]
 [  0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   1   0   7   0   2   0   0   1   0   0   0   3   0   7   0]
 [  3   0   0   0   0   0  10   0   0   0   0   3   0   0   6   0   0   0   5   0   0   1   0   4   0   0   0   1   0   0   0]
 [  2   0   0   0   1   0  16   0   0   0   0   0   0   0   1   0   0   0  13   0   0   0   0   1   0   0   0   2   0   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  36   0   1   0   0   0   0   2   0   0   0   0   0   1   0   0   0]
 [  1   0   1   0   0   0   2   0   0   0   0   0   0   0  13   0   0   0   1   0   0   4   0   0   0   0   2   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   1   0   0   0   0   0   0   0   0   0   0   0   0   5   0   9   1   0   1   0   0   0   1   0  13   0]
 [  5   0   1   0   0   0  10   0   0   0   0   0   0   0 154   0   3   0   2   0   0   9   0   2   0   0   2   1   0   0   0]
 [  3   0   0   0   1   0  12   0   0   0   0   0   0   0   1   0   0   0   8   0   0   0   0   2   0   0   0   2   0   2   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0  12   0  32   0   3   0   0   1   0   0   0   0   0   2   0   0   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  5   0   0   0   4   0   7   0   0   0   0   0   0   0   3   0   0   0 130   0   0   2   0   3   0   0   0   0   0   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   3   0   0   0   0   0   0   0   0   1   0   2   0   9   0  55  12   0   0   0   0   1   1   0  23   0]
 [  0   0   0   0   0   4   0   0   0   0   0   0   0   0  30   0   7   0  15   0   4 114   0   0   0   0   0   1   0   3   0]
 [  1   0  15   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   2   1   0   0   0   0   0   0   0]
 [  7   0  10   0  33   0  44   0   0   0   0   1   0   0   9   0   0   0  11   0   0   1   3  25   0   0   3   0   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0]
 [  1   0   0   0   1   0   3   0   0   0   0   0   0   0   0   0   0   0   7   0   0   0   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   1   0   0   4   0   0   0   0   0   0   1   1   3   0   0  56   0   0   0   0]
 [  3   0   1   0  15   0  30   0   0   0   0   0   0   0   2   0   3   0  18   0   1   0   0   4   0   0   1  17   0  13   0]
 [  3   0   1   0   1   0   2   0   0   0   0   0   0   0   6   0   2   0   7   0   0   2   0   2   0   0   0   0   0   0   0]
 [  1   0   0   0  30   0  23   0   0   0   0   0   0   0   1   0   0   0   9   0   5   1   0   3   0   0   0   4   0 103   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   8   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:20,648 - ==> Best [Top1: 49.475   Top5: 83.779   Sparsity:0.00   Params: 364480 on epoch: 42]
2022-12-15 15:03:20,648 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:20,672 - 

2022-12-15 15:03:20,672 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:21,071 - Epoch: [43][   10/   74]    Overall Loss 1.553580    Objective Loss 1.553580                                        LR 0.001000    Time 0.039811    
2022-12-15 15:03:21,318 - Epoch: [43][   20/   74]    Overall Loss 1.559899    Objective Loss 1.559899                                        LR 0.001000    Time 0.032242    
2022-12-15 15:03:21,588 - Epoch: [43][   30/   74]    Overall Loss 1.568801    Objective Loss 1.568801                                        LR 0.001000    Time 0.030472    
2022-12-15 15:03:21,867 - Epoch: [43][   40/   74]    Overall Loss 1.564650    Objective Loss 1.564650                                        LR 0.001000    Time 0.029822    
2022-12-15 15:03:22,122 - Epoch: [43][   50/   74]    Overall Loss 1.565635    Objective Loss 1.565635                                        LR 0.001000    Time 0.028953    
2022-12-15 15:03:22,383 - Epoch: [43][   60/   74]    Overall Loss 1.565493    Objective Loss 1.565493                                        LR 0.001000    Time 0.028459    
2022-12-15 15:03:22,628 - Epoch: [43][   70/   74]    Overall Loss 1.560753    Objective Loss 1.560753                                        LR 0.001000    Time 0.027889    
2022-12-15 15:03:22,709 - Epoch: [43][   74/   74]    Overall Loss 1.558491    Objective Loss 1.558491    Top1 56.944444    Top5 86.574074    LR 0.001000    Time 0.027479    
2022-12-15 15:03:22,775 - --- validate (epoch=43)-----------
2022-12-15 15:03:22,776 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:23,046 - Epoch: [43][    9/    9]    Loss 1.665058    Top1 50.906489    Top5 84.732824    
2022-12-15 15:03:23,114 - ==> Top1: 50.906    Top5: 84.733    Loss: 1.665

2022-12-15 15:03:23,115 - ==> Confusion:
[[ 13   0   0   0   0   0   4   0   0   0   0   0   0   0   5   0   0   0   0   0   0   1   0   4   0   0   0   0   0   1   0]
 [  0   0   0   0   4   1   1   0   0   0   0   0   0   0   0   0   0   0  23   0   4   1   0   0   0   0   0   1   0   3   0]
 [  1   0 105   0   8   0   2   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   1   8   0   0   4   1   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  17   0  76   0  16   0   0   0   0   1   0   0   5   0   0   0   9   0   1   1   0  10   0   0   0   2   0  27   0]
 [  0   0   0   0   0  23   0   0   0   0   0   0   0   0   3   0   5   0   4   0   5   8   0   0   0   0   2   0   0   5   0]
 [  2   0   6   0   6   0 129   0   0   0   0   0   0   0   5   0   0   0   3   0   0   1   0   5   0   0   1   3   0  11   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0   4   0   0   1   0   0   0   4   0  10   0]
 [  0   0   1   0   0   0  13   0   0   0   0   2   0   0   4   0   0   0   5   0   0   1   0   6   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0  13   0   0   0   0   0   0   0   1   0   0   0  15   0   0   1   0   2   0   0   0   3   0   6   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   2   0   0   0   0   6   0   0   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   3   0   0   0   0   1   0   0  11   0   0   0   0   0   0   6   0   0   0   0   2   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   1   1   0   0   0   0   0   0   0   0   0   0   0   3   0  11   2   0   1   0   0   0   1   0  13   0]
 [  5   0   0   0   0   1  10   0   0   0   0   1   0   0 156   0   2   0   1   0   0  10   0   2   0   0   0   1   0   0   0]
 [  1   0   0   0   2   0  12   0   0   0   0   0   0   0   1   0   0   0   5   0   0   0   0   3   0   0   0   4   0   3   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   8   0  31   0   4   0   1   3   0   0   0   0   0   3   0   0   0]
 [  0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  5   0   0   0   6   0   8   0   0   0   0   0   0   0   2   0   0   0 118   0   0   9   0   2   0   0   0   2   0   6   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   5   0   0   0   0   0   0   0   0   1   0   0   0   4   0  65  16   0   0   0   0   2   2   0  12   0]
 [  0   0   0   0   0   8   0   0   0   0   0   0   0   0  16   0  10   0   7   0   7 128   0   0   0   0   0   0   0   2   0]
 [  1   0  14   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   3   1   0   0   0   0   0   0   0]
 [  5   0  10   0  31   0  43   0   0   0   0   1   0   0   6   0   0   0   6   0   0   1   4  27   0   0   3   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   3   0]
 [  0   0   0   0   0   0   6   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   1   0   2   0]
 [  1   0   2   0   1   0   0   0   0   0   0   1   0   0   5   0   0   0   0   0   0   1   0   2   0   0  55   0   0   0   0]
 [  2   0   1   0  12   0  32   0   0   0   0   0   0   0   1   0   3   0   9   0   5   1   0   6   0   0   0  18   0  18   0]
 [  0   0   1   0   2   0   4   0   0   0   0   0   0   0   3   0   1   0   5   0   0   5   0   5   0   0   0   0   0   0   0]
 [  0   0   0   0  17   0  17   0   0   0   0   0   0   0   1   0   0   0   9   0   9   3   0   3   0   0   0   2   0 119   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   8   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:23,117 - ==> Best [Top1: 50.906   Top5: 84.733   Sparsity:0.00   Params: 364478 on epoch: 43]
2022-12-15 15:03:23,117 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:23,140 - 

2022-12-15 15:03:23,141 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:23,563 - Epoch: [44][   10/   74]    Overall Loss 1.527992    Objective Loss 1.527992                                        LR 0.001000    Time 0.042182    
2022-12-15 15:03:23,804 - Epoch: [44][   20/   74]    Overall Loss 1.524978    Objective Loss 1.524978                                        LR 0.001000    Time 0.033133    
2022-12-15 15:03:24,054 - Epoch: [44][   30/   74]    Overall Loss 1.524280    Objective Loss 1.524280                                        LR 0.001000    Time 0.030389    
2022-12-15 15:03:24,315 - Epoch: [44][   40/   74]    Overall Loss 1.520824    Objective Loss 1.520824                                        LR 0.001000    Time 0.029295    
2022-12-15 15:03:24,568 - Epoch: [44][   50/   74]    Overall Loss 1.509620    Objective Loss 1.509620                                        LR 0.001000    Time 0.028481    
2022-12-15 15:03:24,827 - Epoch: [44][   60/   74]    Overall Loss 1.505261    Objective Loss 1.505261                                        LR 0.001000    Time 0.028035    
2022-12-15 15:03:25,075 - Epoch: [44][   70/   74]    Overall Loss 1.500009    Objective Loss 1.500009                                        LR 0.001000    Time 0.027573    
2022-12-15 15:03:25,166 - Epoch: [44][   74/   74]    Overall Loss 1.505002    Objective Loss 1.505002    Top1 54.861111    Top5 87.500000    LR 0.001000    Time 0.027311    
2022-12-15 15:03:25,237 - --- validate (epoch=44)-----------
2022-12-15 15:03:25,237 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:25,512 - Epoch: [44][    9/    9]    Loss 1.650667    Top1 51.717557    Top5 84.828244    
2022-12-15 15:03:25,568 - ==> Top1: 51.718    Top5: 84.828    Loss: 1.651

2022-12-15 15:03:25,570 - ==> Confusion:
[[ 11   0   0   0   0   0   4   0   0   0   0   0   0   0   4   0   0   0   3   0   0   1   0   4   0   0   0   0   0   1   0]
 [  0   0   0   0   8   1   1   0   0   0   0   0   0   0   0   0   0   0  22   0   4   1   0   1   0   0   0   0   0   0   0]
 [  0   0 114   0  10   0   1   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   1   3   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  19   0  98   0   7   0   0   0   0   0   0   0   3   0   0   0   7   0   2   1   0  17   0   0   0   0   0  11   0]
 [  0   0   0   0   1  24   0   0   0   0   0   0   0   0   2   0   5   0   6   0   4   6   0   0   0   0   2   2   0   3   0]
 [  1   0   5   0  14   0 128   0   0   0   0   0   0   0   1   0   0   0   4   0   0   3   0   9   0   0   2   2   0   3   0]
 [  0   0   0   0   1   2   0   1   0   0   0   0   0   0   0   0   0   0   5   0   3   0   0   1   0   0   0   4   0   6   0]
 [  1   0   1   0   1   0  11   0   0   0   0   2   0   0   3   0   0   0   3   0   0   1   0   7   0   0   1   2   0   0   0]
 [  1   0   0   0   4   0  14   0   0   0   0   0   0   0   1   0   0   0  13   0   0   0   0   1   0   0   0   2   0   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  34   0   3   0   0   0   0   2   0   0   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   2   0   0   0   0   1   0   0  14   0   0   0   1   0   0   3   0   1   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0  17   0   0   1   0   0   0   0   0  10   0]
 [  4   0   1   0   0   1   9   0   0   0   0   0   0   0 149   0   2   0   0   0   0  10   0   6   0   0   4   3   0   0   0]
 [  1   0   0   0   2   0  14   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   7   0   0   0   3   0   2   0]
 [  0   0   0   0   0   5   0   0   0   0   0   0   0   0   7   0  30   0   4   0   0   3   0   0   0   0   0   3   0   0   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  3   0   0   0   9   0   5   0   0   0   0   0   0   0   1   0   0   0 124   0   0   5   0   7   0   0   0   1   0   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   2   0   0   0   0   0   0   0   0   1   0   1   0   5   0  72  10   0   0   0   0   1   1   0  13   0]
 [  0   0   0   0   2   5   0   0   0   0   0   0   0   0  18   0   8   0   8   0   9 126   0   0   0   0   0   0   0   2   0]
 [  1   0  16   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   0   0   0   0   0   0   0   0]
 [  6   0  16   0  45   0  27   0   0   0   0   1   0   0   5   0   0   0   7   0   0   1   2  31   0   0   2   2   0   4   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0]
 [  1   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   1   0   0   0   2   0   1   0]
 [  1   0   2   0   0   0   0   0   0   0   0   1   0   0   3   0   0   0   0   0   0   1   1   2   0   0  57   0   0   0   0]
 [  4   0   2   0  17   1  26   0   0   0   0   0   0   0   2   0   3   0   9   0   5   0   0   4   0   0   2  24   0   9   0]
 [  1   0   0   0   2   0   3   0   0   0   0   0   0   0   1   0   1   0   6   0   0   6   0   6   0   0   0   0   0   0   0]
 [  0   0   0   0  45   0  18   0   0   0   0   0   0   0   0   0   0   0   5   0   8   2   0   3   0   0   0   5   1  93   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   8   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:25,572 - ==> Best [Top1: 51.718   Top5: 84.828   Sparsity:0.00   Params: 364480 on epoch: 44]
2022-12-15 15:03:25,572 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:25,593 - 

2022-12-15 15:03:25,593 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:26,006 - Epoch: [45][   10/   74]    Overall Loss 1.465969    Objective Loss 1.465969                                        LR 0.001000    Time 0.041175    
2022-12-15 15:03:26,248 - Epoch: [45][   20/   74]    Overall Loss 1.484644    Objective Loss 1.484644                                        LR 0.001000    Time 0.032666    
2022-12-15 15:03:26,500 - Epoch: [45][   30/   74]    Overall Loss 1.465377    Objective Loss 1.465377                                        LR 0.001000    Time 0.030163    
2022-12-15 15:03:26,748 - Epoch: [45][   40/   74]    Overall Loss 1.449229    Objective Loss 1.449229                                        LR 0.001000    Time 0.028813    
2022-12-15 15:03:26,995 - Epoch: [45][   50/   74]    Overall Loss 1.440630    Objective Loss 1.440630                                        LR 0.001000    Time 0.027974    
2022-12-15 15:03:27,247 - Epoch: [45][   60/   74]    Overall Loss 1.442305    Objective Loss 1.442305                                        LR 0.001000    Time 0.027516    
2022-12-15 15:03:27,497 - Epoch: [45][   70/   74]    Overall Loss 1.438910    Objective Loss 1.438910                                        LR 0.001000    Time 0.027151    
2022-12-15 15:03:27,588 - Epoch: [45][   74/   74]    Overall Loss 1.436231    Objective Loss 1.436231    Top1 54.861111    Top5 87.731481    LR 0.001000    Time 0.026911    
2022-12-15 15:03:27,649 - --- validate (epoch=45)-----------
2022-12-15 15:03:27,649 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:27,936 - Epoch: [45][    9/    9]    Loss 1.568740    Top1 53.339695    Top5 86.164122    
2022-12-15 15:03:27,984 - ==> Top1: 53.340    Top5: 86.164    Loss: 1.569

2022-12-15 15:03:27,986 - ==> Confusion:
[[ 16   0   0   0   0   0   3   0   0   0   0   0   0   0   3   0   0   0   2   0   0   0   0   3   0   0   0   0   0   1   0]
 [  0   0   0   0   5   1   1   0   0   0   0   0   0   0   0   0   0   0  26   0   3   0   0   0   0   0   0   1   0   1   0]
 [  1   0 107   0  10   0   1   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   1   9   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  10   0  89   0   9   0   0   0   0   3   0   0   0   0   0   0  12   0   1   0   0  20   0   0   0   0   0  21   0]
 [  0   0   0   0   1  25   0   0   0   0   0   0   0   0   2   0   3   0   7   0   5   6   0   0   0   0   1   1   0   4   0]
 [  5   0   4   0   3   0 132   0   0   0   0   0   0   0   0   0   0   0   8   0   0   3   0   5   0   0   1   3   0   8   0]
 [  0   0   0   0   2   2   0   0   0   0   0   0   0   0   0   0   1   0   7   0   2   0   0   0   0   0   0   4   0   5   0]
 [  4   0   0   0   0   0   6   0   0   0   0   6   0   0   1   0   0   0  10   0   0   1   0   4   0   0   0   0   1   0   0]
 [  2   0   0   0   0   0  12   0   0   0   0   0   0   0   0   0   0   0  17   0   0   0   0   0   0   0   0   4   0   6   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  33   0   1   0   1   0   0   3   0   0   0   0   1   0   0   0   0]
 [  1   0   0   0   0   0   1   0   0   0   0   6   0   0   9   0   0   0   3   0   0   3   0   0   0   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   1   1   0   0   0   0   0   0   0   0   0   0   0   4   0  12   0   0   0   0   0   0   1   0  12   0]
 [  5   0   1   0   0   1   9   0   0   0   0   4   0   0 145   0   2   0   6   0   0  10   0   2   0   0   2   2   0   0   0]
 [  2   0   0   0   0   0  13   0   0   0   0   0   0   0   0   0   0   0   6   0   0   0   0   2   0   0   0   6   0   2   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   4   0  34   0   6   0   0   3   0   0   0   0   0   4   0   0   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  5   0   0   0   4   0   3   0   0   0   0   0   0   0   0   0   0   0 136   0   0   1   0   2   0   0   0   2   0   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   1   0   0   0   0   0   0   0   0   2   0   3   0   7   0  66   6   0   0   0   0   1   1   0  20   0]
 [  0   0   0   0   1   5   0   0   0   0   0   3   0   0   8   0  10   0  15   0   9 124   0   0   0   0   1   0   0   2   0]
 [  1   0  14   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   2   2   0   0   0   0   0   0   0]
 [ 10   0  10   0  29   0  36   0   0   0   0   4   0   0   2   0   0   0  18   0   0   1   2  28   0   0   2   1   0   6   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   3   0]
 [  1   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   8   0   0   0   0   0   0   0   0   1   0   1   0]
 [  1   0   1   0   1   0   0   0   0   0   0   2   0   0   2   0   0   0   0   0   0   0   0   4   0   0  57   0   0   0   0]
 [  3   0   1   0   8   0  26   0   0   0   0   0   0   0   1   0   4   0  18   0   3   0   0   1   0   0   0  29   0  14   0]
 [  3   0   0   0   0   0   2   0   0   0   0   1   0   0   2   0   2   0   7   0   0   4   0   5   0   0   0   0   0   0   0]
 [  0   0   0   0  15   0  14   0   0   0   0   0   0   0   0   0   0   0  11   0   5   1   0   3   0   0   0   9   0 122   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   8   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:27,987 - ==> Best [Top1: 53.340   Top5: 86.164   Sparsity:0.00   Params: 364480 on epoch: 45]
2022-12-15 15:03:27,987 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:28,011 - 

2022-12-15 15:03:28,011 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:28,424 - Epoch: [46][   10/   74]    Overall Loss 1.396324    Objective Loss 1.396324                                        LR 0.001000    Time 0.041196    
2022-12-15 15:03:28,682 - Epoch: [46][   20/   74]    Overall Loss 1.406990    Objective Loss 1.406990                                        LR 0.001000    Time 0.033487    
2022-12-15 15:03:28,935 - Epoch: [46][   30/   74]    Overall Loss 1.388982    Objective Loss 1.388982                                        LR 0.001000    Time 0.030736    
2022-12-15 15:03:29,193 - Epoch: [46][   40/   74]    Overall Loss 1.395054    Objective Loss 1.395054                                        LR 0.001000    Time 0.029494    
2022-12-15 15:03:29,447 - Epoch: [46][   50/   74]    Overall Loss 1.399468    Objective Loss 1.399468                                        LR 0.001000    Time 0.028672    
2022-12-15 15:03:29,702 - Epoch: [46][   60/   74]    Overall Loss 1.392745    Objective Loss 1.392745                                        LR 0.001000    Time 0.028133    
2022-12-15 15:03:29,945 - Epoch: [46][   70/   74]    Overall Loss 1.389398    Objective Loss 1.389398                                        LR 0.001000    Time 0.027581    
2022-12-15 15:03:30,033 - Epoch: [46][   74/   74]    Overall Loss 1.387764    Objective Loss 1.387764    Top1 59.722222    Top5 88.888889    LR 0.001000    Time 0.027273    
2022-12-15 15:03:30,094 - --- validate (epoch=46)-----------
2022-12-15 15:03:30,095 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:30,367 - Epoch: [46][    9/    9]    Loss 1.549653    Top1 54.007634    Top5 86.020992    
2022-12-15 15:03:30,422 - ==> Top1: 54.008    Top5: 86.021    Loss: 1.550

2022-12-15 15:03:30,425 - ==> Confusion:
[[ 10   0   0   0   0   0   4   0   0   0   0   0   0   0   7   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0]
 [  0   0   0   0   7   0   2   0   0   0   0   0   0   0   0   0   0   0  15   0   7   2   0   0   0   0   0   3   0   2   0]
 [  0   0 110   0  10   0   2   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   1   5   0   0   2   0   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  10   0 103   0   6   0   0   0   0   1   0   0   1   0   0   0   4   0   1   1   0  19   0   0   0   1   0  18   0]
 [  0   0   0   0   1  27   0   0   0   0   0   0   0   0   1   0   4   0   4   0   5   4   1   0   0   0   1   0   0   7   0]
 [  2   0   5   0   9   0 125   0   0   0   0   0   0   0   2   0   0   0   1   0   0   3   0   9   0   0   1   2   0  13   0]
 [  0   1   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   4   0   0   0   0   0   0   5   0   8   0]
 [  2   0   0   0   0   0  11   0   0   0   0   3   0   0   2   0   0   0   3   0   0   2   0   7   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0  17   0   0   0   0   0   0   0   1   0   0   0  12   0   0   0   0   0   0   0   0   2   0   8   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  32   0   1   0   0   0   0   6   0   0   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   3   0   0   0   0   4   0   0   7   0   0   0   0   0   0   7   0   0   0   0   2   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0  16   0   0   1   0   0   0   0   0  11   0]
 [  4   0   0   0   0   1   8   0   0   0   0   5   0   0 140   0   2   0   2   0   0  20   0   2   0   0   2   3   0   0   0]
 [  0   0   0   0   1   0  11   0   0   0   0   0   0   0   2   0   0   0   2   0   0   0   0   3   0   0   0   5   0   7   0]
 [  0   0   0   0   0   5   0   0   0   0   0   0   0   0   5   0  30   0   5   0   0   1   0   0   0   0   0   6   0   0   0]
 [  0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  4   1   0   0   9   1   8   0   0   0   0   0   0   0   1   0   0   0 111   0   2   7   0   2   0   0   0   4   0   8   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0  75   9   0   0   0   0   1   1   0  17   0]
 [  0   0   0   0   1   8   0   0   0   0   0   2   0   0   7   0   6   0   7   0  11 133   0   0   0   0   0   0   0   3   0]
 [  1   0  13   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   4   2   0   0   0   0   0   0   0]
 [  4   0  10   0  33   0  38   0   0   0   0   2   0   0   4   0   0   0   5   0   0   3   2  32   0   0   3   1   0  12   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0]
 [  2   0   0   0   1   0   5   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   2   0   1   0]
 [  0   0   1   0   1   0   0   0   0   0   0   2   0   0   4   0   0   0   0   0   0   1   1   3   0   0  55   0   0   0   0]
 [  0   0   1   0   8   0  22   0   0   0   0   0   0   0   0   0   2   0   8   0   4   0   0   9   0   0   0  37   0  17   0]
 [  1   0   0   0   1   0   3   0   0   0   0   2   0   0   0   0   2   0   4   0   0   6   0   5   0   0   0   2   0   0   0]
 [  0   0   0   0  12   0  13   0   0   0   0   0   0   0   0   0   0   0   4   0   4   2   0   4   0   0   0   3   2 136   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   6   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:30,428 - ==> Best [Top1: 54.008   Top5: 86.021   Sparsity:0.00   Params: 364479 on epoch: 46]
2022-12-15 15:03:30,428 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:30,459 - 

2022-12-15 15:03:30,459 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:31,021 - Epoch: [47][   10/   74]    Overall Loss 1.329130    Objective Loss 1.329130                                        LR 0.001000    Time 0.056137    
2022-12-15 15:03:31,282 - Epoch: [47][   20/   74]    Overall Loss 1.312095    Objective Loss 1.312095                                        LR 0.001000    Time 0.041079    
2022-12-15 15:03:31,541 - Epoch: [47][   30/   74]    Overall Loss 1.320327    Objective Loss 1.320327                                        LR 0.001000    Time 0.036019    
2022-12-15 15:03:31,791 - Epoch: [47][   40/   74]    Overall Loss 1.318574    Objective Loss 1.318574                                        LR 0.001000    Time 0.033247    
2022-12-15 15:03:32,036 - Epoch: [47][   50/   74]    Overall Loss 1.326316    Objective Loss 1.326316                                        LR 0.001000    Time 0.031502    
2022-12-15 15:03:32,283 - Epoch: [47][   60/   74]    Overall Loss 1.330030    Objective Loss 1.330030                                        LR 0.001000    Time 0.030360    
2022-12-15 15:03:32,524 - Epoch: [47][   70/   74]    Overall Loss 1.330847    Objective Loss 1.330847                                        LR 0.001000    Time 0.029454    
2022-12-15 15:03:32,611 - Epoch: [47][   74/   74]    Overall Loss 1.332562    Objective Loss 1.332562    Top1 59.953704    Top5 85.648148    LR 0.001000    Time 0.029038    
2022-12-15 15:03:32,670 - --- validate (epoch=47)-----------
2022-12-15 15:03:32,670 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:32,937 - Epoch: [47][    9/    9]    Loss 1.538577    Top1 55.152672    Top5 86.450382    
2022-12-15 15:03:32,999 - ==> Top1: 55.153    Top5: 86.450    Loss: 1.539

2022-12-15 15:03:33,001 - ==> Confusion:
[[ 10   0   0   0   0   0   3   0   0   0   0   0   0   0   7   0   0   0   1   0   0   1   0   4   0   0   1   0   0   1   0]
 [  0   1   0   0   6   4   2   0   0   0   0   0   0   0   0   0   0   0  15   0   4   1   0   0   0   0   0   3   0   2   0]
 [  0   0 109   0  10   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   2   7   0   0   2   1   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  10   0 101   1   3   0   0   0   0   0   0   0   5   0   0   0   5   0   1   2   1  14   0   0   3   4   0  15   0]
 [  0   0   0   0   0  34   0   0   0   0   0   0   0   0   2   0   3   0   1   0   3   6   0   0   0   0   2   1   0   3   0]
 [  1   0   4   0   5   0 123   0   0   0   0   0   0   0   6   0   0   0   2   0   0   3   0  10   0   0   3  11   0   4   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   5   0   4   0   0   0   0   0   0   7   0   5   0]
 [  1   0   0   0   0   0  10   0   0   0   0   2   0   0   4   0   0   0   5   0   0   2   0   3   0   0   2   4   0   0   0]
 [  1   0   0   0   1   0  10   0   0   0   0   0   0   0   1   0   0   0  11   0   0   1   0   0   0   0   0  11   0   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   1   0   0   0   0   4   0   0   0   0   2   0   0   0   0]
 [  1   0   0   0   0   0   3   0   0   0   0   5   0   0   7   0   0   0   0   0   0   4   1   0   0   0   3   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   1   0   0   0   0   0   1   0   0   0   0   0   0   0   0  15   1   0   0   0   0   0   4   0  11   0]
 [  2   0   0   0   0   1   8   0   0   0   0   1   0   0 155   0   3   0   0   0   0  12   0   1   0   0   3   3   0   0   0]
 [  0   0   0   0   0   0   8   0   0   0   0   0   0   0   4   0   0   0   3   0   0   2   0   3   0   0   0   9   0   2   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   6   0  32   0   3   0   0   4   0   0   0   0   0   4   0   0   0]
 [  0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  2   0   0   0   6   5   1   0   0   0   0   0   0   0   1   0   0   0 107   0   1  13   0   3   0   0   0  12   0   7   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   7   0   0   0   0   0   0   0   0   0   0   1   0   2   0  68  12   0   0   0   0   2   2   0  14   0]
 [  0   0   0   0   0  18   0   0   0   0   0   0   0   0   8   0   2   0   2   0   8 138   0   0   0   0   1   0   0   1   0]
 [  1   0   8   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   6   2   0   0   0   0   0   0   0]
 [  1   0  14   0  34   1  21   0   0   0   0   4   0   0   4   0   0   0   9   0   0   2   2  41   0   0   5   3   0   8   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   3   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   2   0   0   0   5   0   0   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   2   0   0   1   0   0   0   0   0   0   1   0   4   0   0  60   0   0   0   0]
 [  0   0   1   0   6   3  23   0   0   0   0   0   0   0   2   0   1   0   3   0   4   1   0   7   0   0   0  50   0   7   0]
 [  0   0   0   0   1   0   1   0   0   0   0   1   0   0   0   0   1   0   5   0   0   7   1   6   0   0   0   3   0   0   0]
 [  0   0   0   0   9   2  10   0   0   0   0   0   0   0   1   0   0   0   6   0  10   6   0   4   0   0   0  15   1 116   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   8   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:33,003 - ==> Best [Top1: 55.153   Top5: 86.450   Sparsity:0.00   Params: 364479 on epoch: 47]
2022-12-15 15:03:33,003 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:33,028 - 

2022-12-15 15:03:33,028 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:33,442 - Epoch: [48][   10/   74]    Overall Loss 1.291412    Objective Loss 1.291412                                        LR 0.001000    Time 0.041385    
2022-12-15 15:03:33,683 - Epoch: [48][   20/   74]    Overall Loss 1.277526    Objective Loss 1.277526                                        LR 0.001000    Time 0.032716    
2022-12-15 15:03:33,941 - Epoch: [48][   30/   74]    Overall Loss 1.281979    Objective Loss 1.281979                                        LR 0.001000    Time 0.030373    
2022-12-15 15:03:34,170 - Epoch: [48][   40/   74]    Overall Loss 1.291531    Objective Loss 1.291531                                        LR 0.001000    Time 0.028514    
2022-12-15 15:03:34,395 - Epoch: [48][   50/   74]    Overall Loss 1.297190    Objective Loss 1.297190                                        LR 0.001000    Time 0.027296    
2022-12-15 15:03:34,620 - Epoch: [48][   60/   74]    Overall Loss 1.298704    Objective Loss 1.298704                                        LR 0.001000    Time 0.026493    
2022-12-15 15:03:34,855 - Epoch: [48][   70/   74]    Overall Loss 1.293151    Objective Loss 1.293151                                        LR 0.001000    Time 0.026057    
2022-12-15 15:03:34,947 - Epoch: [48][   74/   74]    Overall Loss 1.294149    Objective Loss 1.294149    Top1 60.416667    Top5 90.046296    LR 0.001000    Time 0.025890    
2022-12-15 15:03:35,007 - --- validate (epoch=48)-----------
2022-12-15 15:03:35,007 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:35,277 - Epoch: [48][    9/    9]    Loss 1.428552    Top1 56.679389    Top5 87.786260    
2022-12-15 15:03:35,328 - ==> Top1: 56.679    Top5: 87.786    Loss: 1.429

2022-12-15 15:03:35,330 - ==> Confusion:
[[ 14   0   0   0   0   0   3   0   0   0   0   0   0   0   3   0   0   0   2   0   0   0   0   5   0   0   0   0   0   1   0]
 [  0   3   0   0   6   1   2   0   0   0   0   0   0   0   0   0   0   0  23   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0 110   0   9   0   2   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   9   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  10   0 103   0   3   0   0   0   0   0   0   0   0   0   0   0  11   0   0   2   0  21   0   0   0   3   0  12   0]
 [  0   0   1   0   1  29   0   0   0   0   0   0   0   0   2   0   5   0   7   0   3   3   0   0   0   0   1   1   0   2   0]
 [  2   0   3   0   6   0 122   0   0   0   0   0   0   0   1   0   0   0   4   0   0   1   1  14   0   0   0  10   0   8   0]
 [  0   1   0   0   1   2   0   2   0   0   0   0   0   0   0   0   0   0   5   0   5   0   0   0   0   0   0   7   0   0   0]
 [  1   0   0   0   0   0  12   0   1   0   0   2   0   0   1   0   0   0   5   0   0   1   0   7   0   0   0   1   2   0   0]
 [  2   0   0   0   0   0   8   0   0   1   0   0   0   0   0   0   0   0  17   0   0   0   0   0   0   0   0   6   0   7   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  32   0   2   0   0   0   0   3   0   0   0   0   0   2   0   0   0]
 [  1   0   0   0   0   0   3   0   1   0   0   4   0   0   8   0   0   0   0   0   0   4   1   0   0   0   2   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   4   1   0   1   0   0   0   0   0   2   0   0   0   0   2   0  13   1   0   0   0   0   0   1   1   8   0]
 [  6   0   0   0   0   1   7   0   0   0   0   2   0   0 154   0   2   0   2   0   0   6   0   2   0   0   3   4   0   0   0]
 [  2   0   0   0   0   0  10   0   0   1   0   0   0   0   0   0   0   0   6   0   0   0   0   2   0   0   0   8   0   2   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   3   0  36   0   6   0   0   3   0   0   0   0   0   2   0   0   0]
 [  0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  5   0   0   0   4   0   1   0   0   0   0   0   0   0   0   1   0   0 135   0   1   5   0   2   0   0   0   2   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   4   3   0   2   0   0   0   0   0   1   0   0   1   0   5   0  69  12   0   0   0   0   1   1   0  10   0]
 [  0   0   0   0   1   6   0   0   0   0   0   0   0   0  14   0   9   0  11   0   6 127   0   0   0   0   1   1   0   2   0]
 [  1   0  12   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   4   2   0   0   0   0   0   0   0]
 [  6   0   8   0  31   0  21   0   0   0   0   4   0   0   2   0   0   0   9   0   0   1   3  51   0   0   2   3   0   8   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   8   0   0   0   0   0   0   0   0   2   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   2   0   0   2   0   0   0   0   0   0   1   1   4   0   0  58   0   0   0   0]
 [  1   0   1   0  10   3  17   0   0   0   0   0   0   0   0   0   2   0  13   0   4   0   0   8   0   0   0  42   0   7   0]
 [  0   0   0   0   0   0   2   0   0   1   0   0   0   0   0   0   2   0   8   0   0   5   0   8   0   0   0   0   0   0   0]
 [  1   0   0   0  12   0   8   0   0   2   0   0   0   1   0   0   0   0  11   0   4   1   0   6   0   0   0  12   1 121   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   7   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:35,332 - ==> Best [Top1: 56.679   Top5: 87.786   Sparsity:0.00   Params: 364480 on epoch: 48]
2022-12-15 15:03:35,332 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:35,356 - 

2022-12-15 15:03:35,357 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:35,752 - Epoch: [49][   10/   74]    Overall Loss 1.215363    Objective Loss 1.215363                                        LR 0.001000    Time 0.039496    
2022-12-15 15:03:35,993 - Epoch: [49][   20/   74]    Overall Loss 1.213984    Objective Loss 1.213984                                        LR 0.001000    Time 0.031732    
2022-12-15 15:03:36,234 - Epoch: [49][   30/   74]    Overall Loss 1.235902    Objective Loss 1.235902                                        LR 0.001000    Time 0.029173    
2022-12-15 15:03:36,472 - Epoch: [49][   40/   74]    Overall Loss 1.239949    Objective Loss 1.239949                                        LR 0.001000    Time 0.027830    
2022-12-15 15:03:36,695 - Epoch: [49][   50/   74]    Overall Loss 1.239425    Objective Loss 1.239425                                        LR 0.001000    Time 0.026726    
2022-12-15 15:03:36,934 - Epoch: [49][   60/   74]    Overall Loss 1.238191    Objective Loss 1.238191                                        LR 0.001000    Time 0.026233    
2022-12-15 15:03:37,167 - Epoch: [49][   70/   74]    Overall Loss 1.234660    Objective Loss 1.234660                                        LR 0.001000    Time 0.025810    
2022-12-15 15:03:37,250 - Epoch: [49][   74/   74]    Overall Loss 1.233878    Objective Loss 1.233878    Top1 66.203704    Top5 91.666667    LR 0.001000    Time 0.025534    
2022-12-15 15:03:37,317 - --- validate (epoch=49)-----------
2022-12-15 15:03:37,317 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:37,588 - Epoch: [49][    9/    9]    Loss 1.450881    Top1 57.108779    Top5 89.026718    
2022-12-15 15:03:37,642 - ==> Top1: 57.109    Top5: 89.027    Loss: 1.451

2022-12-15 15:03:37,644 - ==> Confusion:
[[ 20   0   0   0   0   0   3   0   0   0   0   0   0   0   1   0   0   0   1   0   0   0   0   1   0   0   0   0   1   1   0]
 [  0   2   0   0   4   1   1   0   0   1   0   0   0   0   0   0   0   0  27   0   1   1   0   0   0   0   0   0   0   0   0]
 [  1   0 111   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   9   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1  14   0  98   0   5   0   0   0   0   0   0   0   0   0   0   0  12   0   0   2   0  20   0   0   0   1   0  12   0]
 [  0   0   0   0   0  28   0   0   0   0   0   0   0   0   3   0   6   0   7   0   4   5   0   0   0   0   1   1   0   0   0]
 [  4   0   3   0   2   0 129   0   0   0   0   0   0   0   2   0   0   0   8   0   0   0   0  10   0   0   1   2   0  11   0]
 [  0   1   0   0   0   2   0   1   0   0   0   0   0   0   0   0   1   0   5   0   5   0   0   0   0   0   0   4   0   4   0]
 [  2   0   0   0   0   0   6   0   2   0   0   5   0   0   1   0   0   0   8   0   0   1   0   6   0   0   0   1   1   0   0]
 [  0   0   0   0   0   0   8   0   0   3   0   0   0   0   1   0   0   0  18   0   0   0   0   0   0   0   0   3   0   8   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   2   0   0   0   0   6   0   0   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   2   0   0   0   0   9   0   0   4   0   0   0   1   0   0   5   1   0   0   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   1   0   0   0   0   0   0   0   3   0   0   1   0   1   0  11   1   0   0   0   0   0   3   1  10   0]
 [  4   0   0   0   0   0   6   0   0   1   0   6   0   0 152   0   1   0   4   0   0  12   0   1   0   0   0   2   0   0   0]
 [  2   0   0   0   0   0  10   0   0   3   0   0   0   0   1   2   0   0   5   0   0   0   0   2   0   0   0   4   0   2   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   3   0  34   0   6   0   0   4   0   0   0   0   1   3   0   0   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  3   1   0   0   1   0   1   0   0   1   0   0   0   0   0   1   0   0 137   0   0   6   0   1   0   0   0   2   0   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   3   3   0   0   0   0   0   0   0   0   0   0   1   0   4   0  68  15   0   0   0   0   0   2   0  10   0]
 [  0   0   0   0   1   4   0   0   0   0   0   0   0   0  12   0  10   0  12   0   7 128   0   0   0   0   1   0   0   3   0]
 [  2   0  13   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   3   2   0   0   0   0   0   0   0]
 [  6   0   9   0  24   0  26   0   0   1   0   5   0   0   1   0   0   0  13   0   0   1   3  46   0   0   2   1   0  11   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0]
 [  0   0   0   0   0   0   3   0   0   2   0   1   0   0   0   0   0   0   4   0   0   0   0   0   0   0   0   2   0   2   0]
 [  2   0   0   0   1   0   0   0   0   0   0   3   0   0   2   0   0   0   0   0   0   1   2   2   0   0  55   0   0   0   0]
 [  3   0   1   0   6   4  24   0   0   1   0   0   0   0   2   1   2   0  15   0   2   0   0   2   0   0   1  34   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   2   0   0   2   0   0   0   9   0   0   4   0   9   0   0   0   0   0   0   0]
 [  1   0   0   0   8   0   9   0   0   1   0   0   0   1   0   2   0   0  11   0   4   0   0   5   0   0   0   6   0 132   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   7   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:37,646 - ==> Best [Top1: 57.109   Top5: 89.027   Sparsity:0.00   Params: 364479 on epoch: 49]
2022-12-15 15:03:37,646 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:37,676 - 

2022-12-15 15:03:37,677 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:38,066 - Epoch: [50][   10/   74]    Overall Loss 1.197245    Objective Loss 1.197245                                        LR 0.001000    Time 0.038875    
2022-12-15 15:03:38,286 - Epoch: [50][   20/   74]    Overall Loss 1.171273    Objective Loss 1.171273                                        LR 0.001000    Time 0.030389    
2022-12-15 15:03:38,508 - Epoch: [50][   30/   74]    Overall Loss 1.192619    Objective Loss 1.192619                                        LR 0.001000    Time 0.027667    
2022-12-15 15:03:38,738 - Epoch: [50][   40/   74]    Overall Loss 1.185271    Objective Loss 1.185271                                        LR 0.001000    Time 0.026487    
2022-12-15 15:03:38,967 - Epoch: [50][   50/   74]    Overall Loss 1.187963    Objective Loss 1.187963                                        LR 0.001000    Time 0.025760    
2022-12-15 15:03:39,208 - Epoch: [50][   60/   74]    Overall Loss 1.188854    Objective Loss 1.188854                                        LR 0.001000    Time 0.025482    
2022-12-15 15:03:39,441 - Epoch: [50][   70/   74]    Overall Loss 1.190830    Objective Loss 1.190830                                        LR 0.001000    Time 0.025159    
2022-12-15 15:03:39,525 - Epoch: [50][   74/   74]    Overall Loss 1.192162    Objective Loss 1.192162    Top1 64.583333    Top5 90.277778    LR 0.001000    Time 0.024929    
2022-12-15 15:03:39,580 - --- validate (epoch=50)-----------
2022-12-15 15:03:39,580 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:39,849 - Epoch: [50][    9/    9]    Loss 1.419865    Top1 57.776718    Top5 88.311069    
2022-12-15 15:03:39,904 - ==> Top1: 57.777    Top5: 88.311    Loss: 1.420

2022-12-15 15:03:39,906 - ==> Confusion:
[[ 16   0   0   0   0   0   2   0   1   0   0   0   0   0   1   1   1   0   4   0   0   0   0   1   0   0   0   0   0   1   0]
 [  0   1   0   0   3   1   0   4   0   0   0   0   0   0   0   0   0   0  23   0   2   1   0   0   0   0   0   1   0   2   0]
 [  0   0 111   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   9   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  10   0  87   0   3   0   0   0   0   0   0   0   0   0   0   0  10   0   1   3   0  25   0   0   0   2   0  24   0]
 [  0   0   1   0   0  26   0   0   0   0   0   0   0   0   2   0   7   0   7   0   5   4   0   0   0   0   1   1   0   1   0]
 [  2   0   1   0   2   0 119   0   0   1   0   1   0   0   5   0   0   0   6   0   0   2   0  13   0   0   1   2   0  17   0]
 [  0   0   0   0   0   2   0   2   0   0   0   0   0   0   0   0   1   0   2   0   6   0   0   0   0   0   0   4   0   6   0]
 [  1   0   0   0   0   0   5   0   2   0   0   5   0   0   2   0   0   0  10   0   0   1   0   5   0   0   0   1   1   0   0]
 [  0   0   0   0   0   0   5   0   0   4   0   0   0   0   1   0   0   0  21   0   0   0   0   0   0   0   0   0   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   2   0   0   0   0  10   0   0   5   0   0   0   2   0   1   3   0   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   5   0   0   1   0   1   0  14   0   0   0   0   0   0   1   0  11   0]
 [  4   0   0   0   0   1   6   0   0   0   0   6   0   0 155   0   2   0   3   0   0   7   1   1   0   0   1   2   0   0   0]
 [  1   0   0   0   0   0   9   1   0   0   0   0   0   0   1   4   0   0   7   0   0   0   0   1   0   0   0   5   0   2   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   2   2  33   0   5   0   1   2   0   0   0   0   0   2   0   2   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0   0   0   2   2   0   0   0   0   0   0   0   0   0]
 [  2   0   1   0   0   0   0   0   0   0   0   0   0   1   0   2   0   0 136   0   1   5   0   1   0   0   0   1   0   8   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   2   0   1   0   0   0   0   0   0   2   0   1   0   3   0  76   8   0   0   0   0   0   1   0  14   0]
 [  0   0   0   0   1   4   0   0   0   0   0   1   0   0   9   0   8   0  10   0  14 129   0   0   0   0   0   0   0   2   0]
 [  1   0   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   7   4   0   0   0   0   0   0   0]
 [  6   0   6   0  28   0  20   0   0   0   0   6   0   0   1   1   0   0  12   0   0   1   3  49   0   0   2   0   0  14   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0]
 [  1   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0   0   2   0   4   0]
 [  1   0   1   0   0   0   0   0   0   0   0   4   0   0   1   0   0   0   0   0   0   0   2   3   0   0  56   0   0   0   0]
 [  2   1   1   0   3   3  19   0   0   0   0   0   0   0   2   0   3   0  12   0   5   0   0   2   0   0   0  43   0  12   0]
 [  0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   1   0   8   0   0   6   0   9   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   6   0   0   0   0   0   0   1   0   3   0   0  13   0   5   0   0   2   0   0   0   5   3 140   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   7   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:39,907 - ==> Best [Top1: 57.777   Top5: 88.311   Sparsity:0.00   Params: 364479 on epoch: 50]
2022-12-15 15:03:39,907 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:39,931 - 

2022-12-15 15:03:39,931 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:40,361 - Epoch: [51][   10/   74]    Overall Loss 1.158476    Objective Loss 1.158476                                        LR 0.001000    Time 0.042964    
2022-12-15 15:03:40,613 - Epoch: [51][   20/   74]    Overall Loss 1.172972    Objective Loss 1.172972                                        LR 0.001000    Time 0.034040    
2022-12-15 15:03:40,857 - Epoch: [51][   30/   74]    Overall Loss 1.155005    Objective Loss 1.155005                                        LR 0.001000    Time 0.030814    
2022-12-15 15:03:41,103 - Epoch: [51][   40/   74]    Overall Loss 1.161645    Objective Loss 1.161645                                        LR 0.001000    Time 0.029249    
2022-12-15 15:03:41,319 - Epoch: [51][   50/   74]    Overall Loss 1.146025    Objective Loss 1.146025                                        LR 0.001000    Time 0.027708    
2022-12-15 15:03:41,536 - Epoch: [51][   60/   74]    Overall Loss 1.147030    Objective Loss 1.147030                                        LR 0.001000    Time 0.026704    
2022-12-15 15:03:41,748 - Epoch: [51][   70/   74]    Overall Loss 1.145195    Objective Loss 1.145195                                        LR 0.001000    Time 0.025917    
2022-12-15 15:03:41,833 - Epoch: [51][   74/   74]    Overall Loss 1.146655    Objective Loss 1.146655    Top1 66.898148    Top5 92.592593    LR 0.001000    Time 0.025660    
2022-12-15 15:03:41,896 - --- validate (epoch=51)-----------
2022-12-15 15:03:41,896 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:42,172 - Epoch: [51][    9/    9]    Loss 1.365633    Top1 59.494275    Top5 88.454198    
2022-12-15 15:03:42,225 - ==> Top1: 59.494    Top5: 88.454    Loss: 1.366

2022-12-15 15:03:42,227 - ==> Confusion:
[[ 14   0   0   0   0   0   3   0   1   0   0   0   0   0   4   0   0   0   1   0   1   0   0   3   0   0   0   0   0   1   0]
 [  0   5   0   0   4   1   0   1   0   0   0   0   0   0   0   0   0   0  17   0   6   1   0   0   0   0   0   1   0   2   0]
 [  0   1 114   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   1   0   6   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1   9   0 112   1   2   0   0   0   0   0   0   0   0   0   0   0   3   0   2   2   0  15   0   0   0   3   0  15   0]
 [  0   0   0   0   0  32   0   0   0   0   0   0   0   0   1   0   4   0   7   0   5   4   0   0   0   0   1   1   0   0   0]
 [  3   0   2   0   5   0 114   0   0   1   0   0   0   0   4   0   0   0   6   0   0   0   0  17   0   0   1   5   0  14   0]
 [  0   4   0   0   0   2   0   4   0   0   0   0   0   0   0   0   1   0   0   0   5   0   0   0   0   0   0   2   0   5   0]
 [  2   0   0   0   0   0   7   0   2   0   0   2   0   0   1   0   0   0   7   0   0   1   0   8   0   0   0   1   2   0   0]
 [  1   0   0   0   1   0   4   0   0   2   0   0   0   0   1   0   0   0  16   0   0   0   0   2   0   0   0   0   0  14   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  36   0   1   0   0   0   0   1   0   0   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   1   0   1   0   0  13   0   0   3   0   0   0   1   0   0   1   1   0   0   0   1   0   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   6   0   0   0   0   1   0  13   0   0   0   0   0   0   1   1  11   0]
 [  5   0   0   0   0   2   9   0   0   0   0   6   0   0 150   1   2   0   2   0   0   8   1   1   0   0   1   1   0   0   0]
 [  1   0   0   0   1   0   8   0   0   2   0   0   0   0   2   0   0   0   7   0   0   0   0   2   0   0   0   5   0   3   0]
 [  0   0   0   0   0   4   0   0   0   0   0   0   0   0   4   1  34   0   4   0   0   3   0   0   0   0   0   0   0   2   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   3   0   0   0   2   2   0   0   0   0   0   0   0   0   0]
 [  4   3   0   0   2   0   1   0   0   0   0   0   0   1   0   0   0   0 127   0   2   5   0   2   0   0   0   3   1   7   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   4   0   3   0   0   0   0   0   0   0   0   1   0   1   0  72  10   0   0   0   0   0   1   0  12   0]
 [  0   1   0   0   1   8   0   0   0   0   0   0   0   0   8   0   6   0   5   0   8 140   0   0   0   0   0   0   0   1   0]
 [  1   0   6   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   9   2   0   0   1   0   0   0   0]
 [  2   1  12   0  30   0  11   0   0   0   0   5   0   0   0   0   0   0  10   0   0   0   2  58   0   0   2   1   0  15   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0]
 [  0   0   0   0   0   0   2   0   0   3   0   0   0   0   0   0   1   0   4   0   0   0   0   0   0   0   0   1   0   3   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   1   0   0   0   0   0   0   0   1   4   0   0  58   0   0   0   0]
 [  2   1   1   0   7   4  11   1   0   0   0   0   0   0   2   0   1   0   8   0   5   1   0   5   0   0   0  42   1  16   0]
 [  0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   8   0   0   6   1   8   0   0   0   0   0   0   0]
 [  0   0   0   0   9   2   6   1   0   0   0   0   0   1   0   2   0   0   7   0   4   2   0   3   0   0   0   3   1 139   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   7   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:42,229 - ==> Best [Top1: 59.494   Top5: 88.454   Sparsity:0.00   Params: 364480 on epoch: 51]
2022-12-15 15:03:42,229 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:42,252 - 

2022-12-15 15:03:42,252 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:42,632 - Epoch: [52][   10/   74]    Overall Loss 1.131496    Objective Loss 1.131496                                        LR 0.001000    Time 0.037875    
2022-12-15 15:03:42,842 - Epoch: [52][   20/   74]    Overall Loss 1.086918    Objective Loss 1.086918                                        LR 0.001000    Time 0.029358    
2022-12-15 15:03:43,058 - Epoch: [52][   30/   74]    Overall Loss 1.090658    Objective Loss 1.090658                                        LR 0.001000    Time 0.026768    
2022-12-15 15:03:43,274 - Epoch: [52][   40/   74]    Overall Loss 1.089761    Objective Loss 1.089761                                        LR 0.001000    Time 0.025470    
2022-12-15 15:03:43,491 - Epoch: [52][   50/   74]    Overall Loss 1.089320    Objective Loss 1.089320                                        LR 0.001000    Time 0.024710    
2022-12-15 15:03:43,711 - Epoch: [52][   60/   74]    Overall Loss 1.094310    Objective Loss 1.094310                                        LR 0.001000    Time 0.024241    
2022-12-15 15:03:43,923 - Epoch: [52][   70/   74]    Overall Loss 1.093721    Objective Loss 1.093721                                        LR 0.001000    Time 0.023814    
2022-12-15 15:03:44,006 - Epoch: [52][   74/   74]    Overall Loss 1.096608    Objective Loss 1.096608    Top1 68.287037    Top5 91.203704    LR 0.001000    Time 0.023645    
2022-12-15 15:03:44,069 - --- validate (epoch=52)-----------
2022-12-15 15:03:44,069 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:44,340 - Epoch: [52][    9/    9]    Loss 1.379783    Top1 59.541985    Top5 88.883588    
2022-12-15 15:03:44,390 - ==> Top1: 59.542    Top5: 88.884    Loss: 1.380

2022-12-15 15:03:44,392 - ==> Confusion:
[[ 16   0   0   0   0   0   2   0   1   0   0   0   0   0   3   1   0   0   3   0   0   0   0   0   0   0   0   0   1   1   0]
 [  0   2   0   0   3   2   1   2   0   1   0   0   0   0   0   0   0   0  22   0   3   0   0   0   0   0   0   1   0   1   0]
 [  0   0 108   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   6   0   0   0   1   9   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0   6   0  89   0   2   0   0   0   0   0   0   1   0   0   0   0  12   0   0   2   0  22   0   0   0   5   1  25   0]
 [  0   0   0   0   0  26   0   0   0   0   0   0   0   0   1   0   7   0   6   0   4   6   0   0   0   0   1   2   0   2   0]
 [  1   0   1   0   1   0 122   0   0   1   0   1   0   0   4   0   0   0   5   0   0   0   1  13   0   0   0   9   0  13   0]
 [  0   1   0   0   0   2   0   1   0   0   0   0   0   0   0   0   1   0   4   0   6   0   0   0   0   0   0   5   0   3   0]
 [  1   0   0   0   0   0   5   0   6   1   0   4   0   0   1   0   0   0   6   0   0   1   0   5   0   0   0   2   1   0   0]
 [  2   0   0   0   0   0   5   0   0   9   0   0   0   0   0   0   0   0  12   0   0   0   0   0   0   0   0   3   0  10   0]
 [  0   0   0   0   0   0   1   0   0   0   2   0   0   0  32   0   3   0   0   0   0   1   0   0   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   1   0   1   0   0  13   0   0   3   0   0   0   0   0   1   2   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   9   0   0   0   0   1   0  12   0   0   0   0   0   0   1   1   9   0]
 [  2   0   0   0   0   1   6   0   0   1   0   7   0   0 157   1   2   0   0   0   0   4   0   1   0   0   1   5   1   0   0]
 [  0   0   0   0   0   0   6   0   0   3   0   0   0   0   2   3   0   0   6   0   0   0   0   2   0   0   0   5   0   4   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   1   5   2  32   0   5   0   0   3   0   0   0   0   0   1   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   5   0   0   0   1   2   0   0   0   0   0   0   0   0   0]
 [  2   1   0   0   0   0   2   0   1   1   0   0   0   1   0   0   1   0 133   0   1   5   0   1   0   0   0   2   0   7   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   1   1   0   0   0   0   0   0   0   1   0   0   1   0   4   0  75  10   0   0   0   0   0   1   0  14   0]
 [  0   1   0   0   0   2   0   0   0   1   0   1   0   0  17   0   6   0  12   0   9 125   0   0   0   0   1   0   0   3   0]
 [  0   0   5   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   9   4   0   0   0   1   0   0   0]
 [  6   1   4   0  19   0  14   0   0   1   0   7   0   0   2   0   0   0   9   0   0   0   3  62   0   0   2   2   2  15   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0]
 [  0   0   0   0   0   0   3   0   0   3   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   3   0   1   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   2   0   0   0   0   0   0   0   2   3   0   0  56   0   1   0   0]
 [  0   0   0   0   3   2  16   0   0   2   0   0   0   0   2   2   0   0   8   0   3   0   0   3   0   0   0  54   1  12   0]
 [  0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   2   0   8   0   0   3   0   9   0   0   0   0   1   0   0]
 [  0   0   0   0   1   1   6   0   0   0   0   0   0   1   0   2   0   0   9   0   3   3   0   6   0   0   0   9   1 138   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   7   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:44,393 - ==> Best [Top1: 59.542   Top5: 88.884   Sparsity:0.00   Params: 364479 on epoch: 52]
2022-12-15 15:03:44,393 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:44,415 - 

2022-12-15 15:03:44,416 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:44,934 - Epoch: [53][   10/   74]    Overall Loss 1.045158    Objective Loss 1.045158                                        LR 0.001000    Time 0.051735    
2022-12-15 15:03:45,189 - Epoch: [53][   20/   74]    Overall Loss 1.064318    Objective Loss 1.064318                                        LR 0.001000    Time 0.038579    
2022-12-15 15:03:45,449 - Epoch: [53][   30/   74]    Overall Loss 1.080573    Objective Loss 1.080573                                        LR 0.001000    Time 0.034343    
2022-12-15 15:03:45,697 - Epoch: [53][   40/   74]    Overall Loss 1.066589    Objective Loss 1.066589                                        LR 0.001000    Time 0.031948    
2022-12-15 15:03:45,936 - Epoch: [53][   50/   74]    Overall Loss 1.064157    Objective Loss 1.064157                                        LR 0.001000    Time 0.030343    
2022-12-15 15:03:46,156 - Epoch: [53][   60/   74]    Overall Loss 1.064835    Objective Loss 1.064835                                        LR 0.001000    Time 0.028936    
2022-12-15 15:03:46,400 - Epoch: [53][   70/   74]    Overall Loss 1.071882    Objective Loss 1.071882                                        LR 0.001000    Time 0.028289    
2022-12-15 15:03:46,489 - Epoch: [53][   74/   74]    Overall Loss 1.070809    Objective Loss 1.070809    Top1 65.740741    Top5 94.675926    LR 0.001000    Time 0.027964    
2022-12-15 15:03:46,551 - --- validate (epoch=53)-----------
2022-12-15 15:03:46,551 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:46,823 - Epoch: [53][    9/    9]    Loss 1.348108    Top1 59.351145    Top5 89.408397    
2022-12-15 15:03:46,887 - ==> Top1: 59.351    Top5: 89.408    Loss: 1.348

2022-12-15 15:03:46,889 - ==> Confusion:
[[ 14   0   0   0   0   0   2   0   1   0   0   1   0   0   5   0   0   0   0   0   1   0   0   3   0   0   0   0   0   1   0]
 [  0   4   0   0   4   2   0   1   0   1   0   0   0   0   0   1   0   0  19   0   2   2   0   1   0   0   0   1   0   0   0]
 [  0   0 109   0   6   0   1   0   0   0   0   0   0   0   0   0   0   0   5   0   1   0   1  10   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1   8   0  89   1   6   0   0   0   0   0   0   0   0   0   0   0   8   0   0   1   0  32   0   0   1   3   0  15   0]
 [  0   0   0   0   1  32   0   0   0   0   0   0   0   0   2   0   7   0   4   0   0   4   0   0   0   0   1   2   1   1   0]
 [  1   0   0   0   2   0 135   0   1   0   0   1   0   0   4   1   0   0   0   0   0   2   0  17   0   0   1   3   0   4   0]
 [  0   1   0   0   0   2   0   1   0   0   0   0   0   0   0   0   1   0   4   0   5   0   0   0   0   0   0   6   0   3   0]
 [  1   0   0   0   0   0   6   0   4   2   0   5   0   0   2   0   0   0   3   0   0   1   0   5   0   0   0   2   2   0   0]
 [  1   0   0   0   0   0  10   0   0   3   0   0   0   0   1   1   0   0  11   0   0   1   0   2   0   0   0   3   0   8   0]
 [  0   0   0   0   0   0   1   0   0   0   1   0   0   0  35   0   1   0   0   0   0   1   0   0   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   2   0   1   0   0  13   0   0   3   0   0   0   0   0   0   2   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   1   0  15   1   0   0   0   0   0   2   1  11   0]
 [  1   0   0   0   0   0   5   0   0   0   1   7   0   0 164   0   0   0   0   0   0   6   0   1   0   0   1   3   0   0   0]
 [  1   0   0   0   0   0  11   0   0   0   0   0   0   0   3   1   0   0   4   0   0   0   0   3   0   0   0   5   0   3   0]
 [  1   0   0   0   0   2   0   0   1   1   0   0   0   0   7   1  28   0   1   0   0   4   0   0   0   0   1   4   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   5   0   0   0   1   2   0   0   0   0   0   0   0   0   0]
 [  5   0   0   0   0   0   2   0   2   2   0   0   0   0   3   1   0   0 119   0   1   7   0   4   0   0   0   3   3   6   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   3   0   1   0   0   0   0   0   0   1   0   0   0   4   0  78   7   0   0   0   0   0   4   0   9   0]
 [  0   1   0   0   1   3   0   0   0   0   0   0   0   0  11   0   9   0   9   0   7 132   0   0   0   0   1   1   0   3   0]
 [  2   0   6   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   3   0   0   0   0   0   0   0]
 [  3   0   8   0  18   0  22   0   1   0   0   6   0   0   2   0   0   0   4   0   0   0   3  70   0   0   3   0   1   8   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0]
 [  0   0   0   0   0   0   6   0   0   2   0   0   0   0   1   0   0   0   1   0   0   0   0   1   0   0   0   2   0   1   0]
 [  0   0   1   0   0   0   1   0   0   0   0   3   0   0   2   0   0   0   0   0   0   0   0   3   0   0  58   0   0   0   0]
 [  3   0   0   0   3   1  26   0   0   0   0   0   0   0   3   1   1   0   5   0   0   0   0   5   0   0   1  51   1   7   0]
 [  0   0   0   0   0   0   0   0   0   0   0   2   0   0   1   0   0   0   7   0   0   4   1   8   0   0   0   0   3   0   0]
 [  0   0   0   0   3   0  25   0   0   1   0   0   0   0   0   1   0   0   5   0   2   4   0   7   0   0   0   8   0 124   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   0   0   4   4   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:46,890 - ==> Best [Top1: 59.542   Top5: 88.884   Sparsity:0.00   Params: 364479 on epoch: 52]
2022-12-15 15:03:46,890 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:46,910 - 

2022-12-15 15:03:46,911 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:47,336 - Epoch: [54][   10/   74]    Overall Loss 1.096270    Objective Loss 1.096270                                        LR 0.001000    Time 0.042444    
2022-12-15 15:03:47,582 - Epoch: [54][   20/   74]    Overall Loss 1.051096    Objective Loss 1.051096                                        LR 0.001000    Time 0.033508    
2022-12-15 15:03:47,840 - Epoch: [54][   30/   74]    Overall Loss 1.031015    Objective Loss 1.031015                                        LR 0.001000    Time 0.030930    
2022-12-15 15:03:48,099 - Epoch: [54][   40/   74]    Overall Loss 1.023099    Objective Loss 1.023099                                        LR 0.001000    Time 0.029663    
2022-12-15 15:03:48,363 - Epoch: [54][   50/   74]    Overall Loss 1.029469    Objective Loss 1.029469                                        LR 0.001000    Time 0.028986    
2022-12-15 15:03:48,632 - Epoch: [54][   60/   74]    Overall Loss 1.027882    Objective Loss 1.027882                                        LR 0.001000    Time 0.028630    
2022-12-15 15:03:48,878 - Epoch: [54][   70/   74]    Overall Loss 1.025067    Objective Loss 1.025067                                        LR 0.001000    Time 0.028057    
2022-12-15 15:03:48,969 - Epoch: [54][   74/   74]    Overall Loss 1.026848    Objective Loss 1.026848    Top1 72.222222    Top5 94.444444    LR 0.001000    Time 0.027762    
2022-12-15 15:03:49,043 - --- validate (epoch=54)-----------
2022-12-15 15:03:49,044 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:49,315 - Epoch: [54][    9/    9]    Loss 1.294822    Top1 61.545802    Top5 90.171756    
2022-12-15 15:03:49,371 - ==> Top1: 61.546    Top5: 90.172    Loss: 1.295

2022-12-15 15:03:49,373 - ==> Confusion:
[[ 15   0   0   0   0   0   1   0   0   0   0   0   0   0   4   1   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0]
 [  0   8   0   0   4   2   0   2   0   2   0   0   0   0   0   0   0   0  15   0   1   1   0   0   0   0   0   2   0   1   0]
 [  0   0 101   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0  14   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   2   0 119   0   3   1   0   0   0   0   0   1   0   0   0   0   3   0   1   2   0  19   0   0   0   2   0  10   0]
 [  0   0   0   0   3  28   0   0   0   0   0   0   0   0   2   0   7   0   6   0   1   6   0   0   0   0   1   1   0   0   0]
 [  1   0   0   0   2   0 130   0   1   0   0   0   0   0   2   0   0   0   1   0   1   0   1  15   0   0   0   7   0  11   0]
 [  0   2   0   0   1   2   0   3   0   0   0   0   0   0   0   0   0   0   1   0   6   0   0   0   0   0   0   6   0   2   0]
 [  1   0   0   0   0   0   6   0   4   6   0   4   0   0   1   0   0   0   3   0   0   1   0   6   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   6   0   0   5   0   0   0   0   0   1   0   0  13   0   0   0   0   2   0   0   0   6   0   8   0]
 [  0   0   0   0   0   0   1   0   0   0   1   0   0   0  32   0   0   0   0   0   0   5   0   0   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   2   0   0   0   0  10   0   0   4   0   0   0   1   0   0   4   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   1   0   0   0   0   0   0   0  10   0   0   0   0   0   0  10   1   0   0   0   0   0   3   0   7   0]
 [  3   0   0   0   0   2   9   0   0   0   0   5   0   0 151   1   1   0   1   0   0   7   1   1   0   0   2   5   0   0   0]
 [  1   0   0   0   0   0   8   0   0   2   0   0   0   0   0   1   0   0   4   0   0   0   0   1   0   0   0  10   0   4   0]
 [  0   0   0   0   0   2   0   0   0   2   0   0   0   0   3   1  33   0   5   0   0   3   0   0   0   0   0   3   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   6   0   0   0   1   2   0   0   0   0   0   0   0   0   0]
 [  4   6   0   0   1   0   3   0   0   3   0   0   0   0   0   1   0   0 122   0   0   8   0   1   0   0   0   2   0   7   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   3   2   0   1   0   0   0   0   0   1   1   0   1   0   4   0  77   7   0   0   0   0   0   2   0   9   0]
 [  0   2   0   0   1   2   0   0   0   2   0   0   0   0  10   0   6   0   8   0   9 134   0   0   0   0   0   1   0   3   0]
 [  1   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  11   4   0   0   0   0   0   0   0]
 [  2   0   3   0  23   0  13   0   2   0   0   6   0   0   0   0   0   0   6   0   0   0   2  81   0   0   1   2   0   8   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0]
 [  1   0   0   0   0   0   3   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   4   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   2   0   0   2   0   0   0   0   0   0   1   2   4   0   0  56   0   0   0   0]
 [  0   0   0   0   4   2  16   1   0   1   0   0   0   0   2   1   1   0   8   0   2   0   0   6   0   0   0  56   0   8   0]
 [  0   0   0   0   1   0   0   0   0   0   0   2   0   0   0   0   1   0   7   0   0   4   0  10   0   0   0   0   1   0   0]
 [  0   0   0   0   6   0   9   1   0   1   0   0   0   1   0   2   0   0   6   0   3   2   0   5   0   0   0  11   0 133   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   7   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:49,374 - ==> Best [Top1: 61.546   Top5: 90.172   Sparsity:0.00   Params: 364479 on epoch: 54]
2022-12-15 15:03:49,375 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:49,395 - 

2022-12-15 15:03:49,396 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:49,793 - Epoch: [55][   10/   74]    Overall Loss 0.989435    Objective Loss 0.989435                                        LR 0.001000    Time 0.039714    
2022-12-15 15:03:50,013 - Epoch: [55][   20/   74]    Overall Loss 1.000166    Objective Loss 1.000166                                        LR 0.001000    Time 0.030820    
2022-12-15 15:03:50,264 - Epoch: [55][   30/   74]    Overall Loss 0.994155    Objective Loss 0.994155                                        LR 0.001000    Time 0.028878    
2022-12-15 15:03:50,523 - Epoch: [55][   40/   74]    Overall Loss 0.986105    Objective Loss 0.986105                                        LR 0.001000    Time 0.028140    
2022-12-15 15:03:50,789 - Epoch: [55][   50/   74]    Overall Loss 0.988515    Objective Loss 0.988515                                        LR 0.001000    Time 0.027818    
2022-12-15 15:03:51,055 - Epoch: [55][   60/   74]    Overall Loss 0.992302    Objective Loss 0.992302                                        LR 0.001000    Time 0.027602    
2022-12-15 15:03:51,299 - Epoch: [55][   70/   74]    Overall Loss 0.994353    Objective Loss 0.994353                                        LR 0.001000    Time 0.027133    
2022-12-15 15:03:51,382 - Epoch: [55][   74/   74]    Overall Loss 0.996665    Objective Loss 0.996665    Top1 68.287037    Top5 92.592593    LR 0.001000    Time 0.026794    
2022-12-15 15:03:51,444 - --- validate (epoch=55)-----------
2022-12-15 15:03:51,444 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:51,724 - Epoch: [55][    9/    9]    Loss 1.276105    Top1 61.832061    Top5 90.171756    
2022-12-15 15:03:51,777 - ==> Top1: 61.832    Top5: 90.172    Loss: 1.276

2022-12-15 15:03:51,779 - ==> Confusion:
[[ 17   0   0   0   0   0   3   0   1   0   0   0   0   0   1   0   1   0   1   0   0   0   0   2   0   0   0   0   1   1   0]
 [  0   4   0   0   4   2   0   2   0   0   0   0   0   0   0   0   0   0  19   0   2   3   0   0   0   0   0   2   0   0   0]
 [  0   0 116   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0   1   0   1   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1  15   0 104   1   3   1   0   0   0   0   0   1   0   0   0   0   8   0   0   4   0  19   0   0   0   3   0   5   0]
 [  0   0   0   0   0  35   0   0   0   0   0   0   0   0   2   0   4   0   5   0   2   3   0   0   0   0   2   2   0   0   0]
 [  1   0   0   0   2   0 117   0   2   3   0   0   0   0   7   1   0   0   6   0   0   1   0  15   0   0   0  10   0   7   0]
 [  0   3   0   0   1   2   0   3   0   0   0   0   0   0   0   0   1   0   1   0   5   0   0   0   0   0   0   5   0   2   0]
 [  1   0   0   0   0   0   1   0   9   0   0   4   0   0   1   0   0   0   5   0   0   1   0   6   0   0   1   2   2   0   0]
 [  0   0   0   0   0   0   2   0   3   8   0   0   0   0   1   0   0   0  15   0   0   0   0   1   0   0   0   4   0   7   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  35   0   2   0   1   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  15   0   0   1   0   0   0   1   0   0   2   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   7   0   0   1   0   2   0  14   1   0   0   0   0   0   1   1   6   0]
 [  4   0   0   0   0   0   4   0   1   0   0   9   0   0 163   0   0   0   0   0   0   6   0   0   0   0   0   2   0   0   0]
 [  1   0   0   0   0   0   7   0   0   3   0   0   0   0   2   0   0   0   8   0   0   0   0   2   0   0   0   5   0   3   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   0   0   6   1  34   0   4   0   0   2   0   0   0   0   0   2   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   5   0   0   0   1   2   0   0   0   0   0   0   0   0   0]
 [  4   2   1   0   1   0   0   0   3   2   0   0   0   0   0   0   0   0 133   0   1   3   0   1   0   0   0   2   2   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   5   5   0   2   0   0   0   0   0   0   0   0   1   0   4   0  71  12   0   0   0   0   0   3   0   5   0]
 [  0   1   0   0   1   2   0   0   0   0   0   1   0   0  13   0   8   0   8   0   7 134   0   0   0   0   1   1   0   1   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  14   3   0   0   1   1   0   0   0]
 [  1   0   6   0  19   0  12   0   5   2   0   4   0   0   0   0   0   0   7   0   0   0   5  72   0   0   3   1   3   9   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   1   0   4   0   1   0   0   1   0   0   0   3   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   3   0   0  58   0   0   0   0]
 [  1   0   1   0   3   2  14   0   0   1   0   0   0   0   2   1   3   0   8   0   2   1   0   8   0   0   0  55   2   4   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   9   0   0   4   1   7   0   0   0   0   2   0   0]
 [  1   0   0   0   5   0   7   0   0   3   0   0   0   0   0   2   0   0  10   0   4   4   0   5   0   0   0  12   2 125   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   7   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:51,780 - ==> Best [Top1: 61.832   Top5: 90.172   Sparsity:0.00   Params: 364480 on epoch: 55]
2022-12-15 15:03:51,780 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:51,812 - 

2022-12-15 15:03:51,812 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:52,233 - Epoch: [56][   10/   74]    Overall Loss 0.992494    Objective Loss 0.992494                                        LR 0.001000    Time 0.042047    
2022-12-15 15:03:52,487 - Epoch: [56][   20/   74]    Overall Loss 0.994440    Objective Loss 0.994440                                        LR 0.001000    Time 0.033683    
2022-12-15 15:03:52,733 - Epoch: [56][   30/   74]    Overall Loss 0.984814    Objective Loss 0.984814                                        LR 0.001000    Time 0.030639    
2022-12-15 15:03:52,995 - Epoch: [56][   40/   74]    Overall Loss 0.976972    Objective Loss 0.976972                                        LR 0.001000    Time 0.029481    
2022-12-15 15:03:53,218 - Epoch: [56][   50/   74]    Overall Loss 0.974673    Objective Loss 0.974673                                        LR 0.001000    Time 0.028036    
2022-12-15 15:03:53,471 - Epoch: [56][   60/   74]    Overall Loss 0.967822    Objective Loss 0.967822                                        LR 0.001000    Time 0.027569    
2022-12-15 15:03:53,690 - Epoch: [56][   70/   74]    Overall Loss 0.961820    Objective Loss 0.961820                                        LR 0.001000    Time 0.026768    
2022-12-15 15:03:53,775 - Epoch: [56][   74/   74]    Overall Loss 0.959878    Objective Loss 0.959878    Top1 74.305556    Top5 94.444444    LR 0.001000    Time 0.026461    
2022-12-15 15:03:53,843 - --- validate (epoch=56)-----------
2022-12-15 15:03:53,843 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:54,119 - Epoch: [56][    9/    9]    Loss 1.248647    Top1 62.881679    Top5 90.124046    
2022-12-15 15:03:54,178 - ==> Top1: 62.882    Top5: 90.124    Loss: 1.249

2022-12-15 15:03:54,180 - ==> Confusion:
[[ 18   0   0   0   0   0   3   0   0   0   0   0   0   0   2   0   1   0   1   0   0   0   0   1   0   0   0   0   1   1   0]
 [  0   4   0   0   4   2   0   2   0   0   0   0   0   0   0   0   0   0  24   0   1   0   0   0   0   0   0   1   0   0   0]
 [  0   0 119   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   6   0   0   0   0   5   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2  12   0 113   0   2   0   0   0   0   0   0   0   0   0   0   0  11   0   1   2   0  16   0   0   0   2   0   4   0]
 [  0   0   0   0   1  37   0   0   0   0   0   0   0   0   1   0   4   0   6   0   2   3   0   0   0   0   1   0   0   0   0]
 [  2   0   0   0   4   0 115   0   2   3   0   1   0   0  13   3   0   0   3   0   1   0   1  12   0   0   0   3   0   9   0]
 [  0   4   0   0   0   2   0   5   0   0   0   0   0   0   0   0   1   0   2   0   2   0   0   0   0   0   0   5   0   2   0]
 [  1   0   0   0   0   0   3   0   8   0   0   4   0   0   2   0   0   0   5   0   0   1   0   7   0   0   0   0   2   0   0]
 [  3   0   0   0   0   0   3   0   0   7   0   0   0   0   2   1   0   0  13   0   0   0   0   1   0   0   0   2   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0   2   0   0   0  33   0   2   0   0   0   0   2   0   0   0   0   0   1   0   0   0]
 [  2   0   0   0   0   0   1   0   1   1   0  12   0   0   2   0   0   0   0   0   0   4   1   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   2   0   0   0   0   0  13   0   0   1   0   1   0   9   0   0   0   0   0   0   1   0   6   0]
 [  4   0   0   0   0   0   3   0   0   0   1   6   0   0 163   0   1   0   0   0   0   7   1   1   0   0   0   0   2   0   0]
 [  3   0   0   0   0   0   5   0   0   0   0   0   0   0   3   3   0   0   7   0   0   0   0   2   0   0   0   3   1   4   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   4   1  33   0   6   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0   0   0   1   3   0   0   0   0   0   0   0   0   0]
 [  3   3   1   0   1   0   0   0   0   1   0   1   0   1   0   2   0   0 137   0   0   5   0   1   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   5   3   0   3   0   0   0   0   0   1   1   0   1   0   4   0  70   7   0   0   0   0   0   3   0  10   0]
 [  0   0   0   0   2   3   0   0   0   0   0   0   0   0   7   0   7   0  13   0   8 137   0   0   0   0   0   0   0   1   0]
 [  1   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  13   3   0   0   1   0   0   0   0]
 [  4   0   8   0  17   0  11   0   1   0   0   7   0   0   1   0   0   0   7   0   0   0   6  74   0   0   2   2   1   8   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   0   0   0   5   0   0   0   1   1   1   0   0   4   0   0   0   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   2   0   0   2   0   0   0   0   0   0   1   2   3   0   0  56   0   1   0   0]
 [  1   0   1   0   5   1  17   0   0   0   0   0   0   0   6   3   2   0  11   0   3   1   0   3   0   0   0  49   1   4   0]
 [  0   0   1   0   0   0   0   0   1   0   0   3   0   0   1   0   1   0   8   0   0   3   1   6   0   0   0   0   1   0   0]
 [  0   0   0   0   9   0   6   2   0   1   0   0   0   0   0   3   0   0  15   0   1   1   0   4   0   0   0   9   1 128   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   2   6   0   0   0   0   0   0   0   0   1]]

2022-12-15 15:03:54,182 - ==> Best [Top1: 62.882   Top5: 90.124   Sparsity:0.00   Params: 364479 on epoch: 56]
2022-12-15 15:03:54,182 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:54,206 - 

2022-12-15 15:03:54,207 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:54,621 - Epoch: [57][   10/   74]    Overall Loss 0.921828    Objective Loss 0.921828                                        LR 0.001000    Time 0.041361    
2022-12-15 15:03:54,852 - Epoch: [57][   20/   74]    Overall Loss 0.916996    Objective Loss 0.916996                                        LR 0.001000    Time 0.032213    
2022-12-15 15:03:55,097 - Epoch: [57][   30/   74]    Overall Loss 0.987029    Objective Loss 0.987029                                        LR 0.001000    Time 0.029605    
2022-12-15 15:03:55,346 - Epoch: [57][   40/   74]    Overall Loss 1.081082    Objective Loss 1.081082                                        LR 0.001000    Time 0.028424    
2022-12-15 15:03:55,576 - Epoch: [57][   50/   74]    Overall Loss 1.122803    Objective Loss 1.122803                                        LR 0.001000    Time 0.027330    
2022-12-15 15:03:55,796 - Epoch: [57][   60/   74]    Overall Loss 1.145506    Objective Loss 1.145506                                        LR 0.001000    Time 0.026439    
2022-12-15 15:03:56,012 - Epoch: [57][   70/   74]    Overall Loss 1.147049    Objective Loss 1.147049                                        LR 0.001000    Time 0.025748    
2022-12-15 15:03:56,101 - Epoch: [57][   74/   74]    Overall Loss 1.148953    Objective Loss 1.148953    Top1 70.601852    Top5 92.824074    LR 0.001000    Time 0.025552    
2022-12-15 15:03:56,157 - --- validate (epoch=57)-----------
2022-12-15 15:03:56,157 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:56,433 - Epoch: [57][    9/    9]    Loss 1.426271    Top1 61.927481    Top5 88.406489    
2022-12-15 15:03:56,483 - ==> Top1: 61.927    Top5: 88.406    Loss: 1.426

2022-12-15 15:03:56,484 - ==> Confusion:
[[ 15   0   0   0   0   0   4   0   0   0   0   0   0   0   2   0   1   0   1   0   1   0   0   3   0   0   0   0   0   1   0]
 [  0   0   0   0   4   2   0   0   0   0   0   0   0   0   0   0   0   0  27   0   2   1   0   0   0   0   0   1   0   1   0]
 [  0   0 117   0   5   0   1   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   6   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  17   0 106   0   5   0   0   0   0   0   0   0   0   0   0   0   8   0   1   1   0  16   0   0   0   2   0   9   0]
 [  0   0   0   0   1  32   0   0   0   0   0   0   0   0   2   0   3   0   7   0   4   5   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   2   0 143   0   0   0   0   0   0   0   2   0   0   0   2   0   0   1   0  10   0   0   1   2   0   9   0]
 [  0   0   0   0   1   2   0   0   0   0   0   0   0   0   0   0   1   0   4   0   6   0   0   0   0   0   0   6   0   3   0]
 [  1   0   0   0   0   0  11   0   1   0   0   2   0   0   0   0   0   0   8   0   0   2   0   6   0   0   0   2   0   0   0]
 [  0   0   0   0   0   0  10   0   0   1   0   0   0   0   1   0   0   0  16   0   0   0   0   0   0   0   0   3   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  33   0   2   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   3   0   0   0   0  10   0   0   2   0   0   0   2   0   1   3   1   0   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0  16   1   0   0   0   0   0   2   0  11   0]
 [  2   0   0   0   0   0   9   0   0   0   0   2   0   0 157   0   1   0   2   0   0  14   0   1   0   0   0   1   0   0   0]
 [  2   0   0   0   0   0  10   0   0   0   0   0   0   0   1   0   0   0   7   0   0   0   0   2   0   0   0   5   0   4   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   3   0  34   0   6   0   0   6   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   1   0   2   3   0   0   0   0   0   1   0   0   0]
 [  1   0   0   0   1   0   2   0   0   0   0   0   0   0   0   0   0   0 139   0   1   5   0   1   0   0   0   3   0   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   3   0   0   0   0   0   0   0   0   1   0   1   0   3   0  74  13   0   0   0   0   0   2   0   9   0]
 [  0   0   0   0   1   1   0   0   0   0   0   0   0   0   5   0   5   0  11   0   6 146   0   0   0   0   1   0   0   2   0]
 [  1   0   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   6   5   0   0   0   0   0   0   0]
 [  0   0   7   0  20   0  20   0   0   0   0   2   0   0   0   0   0   0  11   0   0   1   3  73   0   0   2   1   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0]
 [  0   0   0   0   0   0   5   0   0   1   0   0   0   0   1   0   0   0   3   0   0   0   0   0   0   0   0   3   0   1   0]
 [  0   0   1   0   0   1   0   0   0   0   0   2   0   0   1   0   0   0   0   0   0   1   0   4   0   0  58   0   0   0   0]
 [  0   0   1   0   4   2  24   0   0   0   0   0   0   0   3   0   3   0   9   0   1   1   0   3   0   0   0  50   0   7   0]
 [  0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   2   0   8   0   0   5   0   8   0   0   0   0   0   1   0]
 [  1   0   0   0   6   0  12   0   0   0   0   0   0   0   0   0   0   0  12   0   2   2   0   4   0   0   0   5   0 136   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   7   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:56,486 - ==> Best [Top1: 62.882   Top5: 90.124   Sparsity:0.00   Params: 364479 on epoch: 56]
2022-12-15 15:03:56,486 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:56,496 - 

2022-12-15 15:03:56,496 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:56,893 - Epoch: [58][   10/   74]    Overall Loss 1.141070    Objective Loss 1.141070                                        LR 0.001000    Time 0.039578    
2022-12-15 15:03:57,134 - Epoch: [58][   20/   74]    Overall Loss 1.165694    Objective Loss 1.165694                                        LR 0.001000    Time 0.031823    
2022-12-15 15:03:57,389 - Epoch: [58][   30/   74]    Overall Loss 1.152956    Objective Loss 1.152956                                        LR 0.001000    Time 0.029722    
2022-12-15 15:03:57,652 - Epoch: [58][   40/   74]    Overall Loss 1.154750    Objective Loss 1.154750                                        LR 0.001000    Time 0.028839    
2022-12-15 15:03:57,905 - Epoch: [58][   50/   74]    Overall Loss 1.151957    Objective Loss 1.151957                                        LR 0.001000    Time 0.028131    
2022-12-15 15:03:58,163 - Epoch: [58][   60/   74]    Overall Loss 1.146260    Objective Loss 1.146260                                        LR 0.001000    Time 0.027735    
2022-12-15 15:03:58,409 - Epoch: [58][   70/   74]    Overall Loss 1.138591    Objective Loss 1.138591                                        LR 0.001000    Time 0.027283    
2022-12-15 15:03:58,497 - Epoch: [58][   74/   74]    Overall Loss 1.135626    Objective Loss 1.135626    Top1 72.453704    Top5 92.824074    LR 0.001000    Time 0.026998    
2022-12-15 15:03:58,560 - --- validate (epoch=58)-----------
2022-12-15 15:03:58,560 - 2096 samples (256 per mini-batch)
2022-12-15 15:03:58,832 - Epoch: [58][    9/    9]    Loss 1.356598    Top1 61.641221    Top5 89.599237    
2022-12-15 15:03:58,884 - ==> Top1: 61.641    Top5: 89.599    Loss: 1.357

2022-12-15 15:03:58,886 - ==> Confusion:
[[ 16   0   0   0   0   0   6   0   0   0   0   0   0   0   1   0   1   0   1   0   0   0   0   2   0   0   0   0   0   1   0]
 [  0   0   0   0   5   2   0   0   0   0   0   0   0   0   0   0   0   0  23   0   4   1   0   0   0   0   0   1   0   2   0]
 [  0   0 112   0   9   0   1   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   7   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0  10   0 104   0   4   0   0   0   0   0   0   0   0   0   0   0   7   0   1   2   0  19   0   0   0   3   0  15   0]
 [  0   0   0   0   4  34   0   0   0   0   0   0   0   0   2   0   2   0   6   0   1   5   0   0   0   0   1   0   0   0   0]
 [  2   0   0   0   2   0 140   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0  10   0   0   1   2   0  13   0]
 [  0   0   0   0   1   2   0   0   0   0   0   0   0   0   0   0   1   0   5   0   6   0   0   0   0   0   0   5   0   3   0]
 [  2   0   0   0   0   0   7   0   3   0   0   3   0   0   1   0   0   0   7   0   0   1   0   6   0   0   0   2   0   1   0]
 [  0   0   0   0   0   0   8   0   0   1   0   0   0   0   1   0   0   0  14   0   0   0   0   1   0   0   0   2   0  14   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  35   0   1   0   1   0   0   2   0   0   0   0   0   1   0   0   0]
 [  2   0   0   0   0   0   2   0   0   0   0   9   0   0   6   0   0   0   2   0   0   1   1   0   0   0   0   0   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0  17   1   0   0   0   0   0   2   0  10   0]
 [  3   0   0   0   0   0   7   0   0   0   0   3   0   0 165   0   1   0   1   0   0   5   1   1   0   0   0   2   0   0   0]
 [  3   0   0   0   0   0  10   0   0   0   0   0   0   0   0   1   0   0   6   0   0   0   0   2   0   0   0   4   0   5   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   7   0  30   0   6   0   0   1   0   0   0   0   1   3   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   2   0   0   0   3   2   0   0   0   0   0   1   0   0   0]
 [  4   0   1   0   0   0   2   0   1   1   0   1   0   0   0   0   0   0 130   0   2   5   0   1   0   0   0   1   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   4   3   0   0   0   0   0   0   0   0   2   0   1   0   4   0  71  12   0   0   0   0   0   2   0  10   0]
 [  0   0   0   0   1   1   0   0   0   0   0   0   0   0   9   0   3   0  10   0   7 143   0   0   0   0   1   1   0   2   0]
 [  1   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   5   4   0   0   0   0   0   0   0]
 [  2   0   5   0  15   0  21   0   0   0   0   5   0   0   0   0   0   0   7   0   0   0   2  75   0   0   3   1   0  13   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0]
 [  0   0   0   0   0   0   3   0   0   0   0   0   0   0   1   0   0   0   4   0   1   0   0   0   0   0   0   2   0   3   0]
 [  0   0   1   0   0   0   0   0   0   0   0   2   0   0   2   0   0   0   0   0   0   0   2   5   0   0  56   0   0   0   0]
 [  0   0   1   0   5   2  21   0   0   0   0   0   0   0   2   0   4   0   9   0   3   0   0   2   0   0   0  51   0   8   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  10   0   0   4   0   8   0   0   0   1   0   1   0]
 [  1   0   0   0   4   0  12   0   0   0   0   0   0   0   0   0   0   0   6   0   2   2   0   4   0   0   0   3   0 146   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   7   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:03:58,887 - ==> Best [Top1: 62.882   Top5: 90.124   Sparsity:0.00   Params: 364479 on epoch: 56]
2022-12-15 15:03:58,887 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:03:58,897 - 

2022-12-15 15:03:58,898 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:03:59,303 - Epoch: [59][   10/   74]    Overall Loss 1.046148    Objective Loss 1.046148                                        LR 0.001000    Time 0.040403    
2022-12-15 15:03:59,552 - Epoch: [59][   20/   74]    Overall Loss 1.059455    Objective Loss 1.059455                                        LR 0.001000    Time 0.032662    
2022-12-15 15:03:59,802 - Epoch: [59][   30/   74]    Overall Loss 1.067069    Objective Loss 1.067069                                        LR 0.001000    Time 0.030092    
2022-12-15 15:04:00,044 - Epoch: [59][   40/   74]    Overall Loss 1.068568    Objective Loss 1.068568                                        LR 0.001000    Time 0.028610    
2022-12-15 15:04:00,283 - Epoch: [59][   50/   74]    Overall Loss 1.064420    Objective Loss 1.064420                                        LR 0.001000    Time 0.027649    
2022-12-15 15:04:00,511 - Epoch: [59][   60/   74]    Overall Loss 1.065507    Objective Loss 1.065507                                        LR 0.001000    Time 0.026836    
2022-12-15 15:04:00,727 - Epoch: [59][   70/   74]    Overall Loss 1.067794    Objective Loss 1.067794                                        LR 0.001000    Time 0.026081    
2022-12-15 15:04:00,813 - Epoch: [59][   74/   74]    Overall Loss 1.063384    Objective Loss 1.063384    Top1 74.768519    Top5 94.444444    LR 0.001000    Time 0.025839    
2022-12-15 15:04:00,877 - --- validate (epoch=59)-----------
2022-12-15 15:04:00,877 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:01,150 - Epoch: [59][    9/    9]    Loss 1.365887    Top1 61.450382    Top5 90.124046    
2022-12-15 15:04:01,201 - ==> Top1: 61.450    Top5: 90.124    Loss: 1.366

2022-12-15 15:04:01,203 - ==> Confusion:
[[ 15   0   0   0   0   0   6   0   0   0   0   0   0   0   5   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0]
 [  0   1   0   0   5   2   1   1   0   1   0   0   0   0   0   0   0   0  17   0   3   1   0   0   0   0   0   2   0   4   0]
 [  0   0 106   0  12   0   1   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0  10   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0   7   0 103   0   4   0   0   0   0   0   0   0   0   0   0   0   7   0   3   1   0  20   0   0   0   2   1  17   0]
 [  0   0   0   0   2  31   0   0   0   0   0   0   0   0   1   0   6   0   5   0   3   5   0   0   0   0   1   1   0   0   0]
 [  2   0   0   0   2   0 130   0   0   1   0   0   0   0   4   0   0   0   1   0   1   0   0  14   0   0   0   3   0  14   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   1   0   3   0   8   0   0   0   0   0   0   6   0   3   0]
 [  3   0   0   0   0   0   8   0   2   3   0   3   0   0   1   0   0   0   2   0   0   1   0   4   0   0   0   3   2   1   0]
 [  1   0   0   0   0   0   9   0   0   1   0   0   0   0   1   0   0   0  13   0   1   0   0   0   0   0   0   1   0  14   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  34   0   2   0   1   0   0   1   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   3   0   0   0   0  10   0   0   5   0   0   0   1   0   1   3   1   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0  18   1   0   0   0   0   0   2   0  10   0]
 [  2   0   0   0   0   1   7   0   0   0   0   5   0   0 163   1   1   0   0   0   0   6   0   1   0   0   0   2   0   0   0]
 [  1   0   0   0   0   0   9   0   0   1   0   0   0   0   3   1   0   0   4   0   0   0   0   2   0   0   0   4   0   6   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   4   1  33   0   6   0   0   2   0   0   0   0   0   2   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0   0   0   1   3   0   0   0   0   0   1   0   0   0]
 [  2   1   0   0   1   0   5   0   0   1   0   1   0   0   1   1   0   0 126   0   3   3   0   1   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   4   0   0   0   0   0   0   0   0   1   0   0   0   4   0  75   9   0   0   0   0   0   2   0  12   0]
 [  0   0   0   0   1   1   0   0   0   0   0   0   0   0  10   0   4   0  10   0   7 142   0   0   0   0   0   1   0   2   0]
 [  1   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   6   6   0   0   0   0   0   0   0]
 [  2   0   3   0  14   0  17   0   0   0   0   5   0   0   0   0   0   0   6   0   0   0   2  85   0   0   2   2   0  11   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0]
 [  0   0   0   0   0   0   1   0   0   1   0   0   0   0   1   0   0   0   2   0   0   0   0   1   0   0   0   3   0   5   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   0   0   0   0   0   1   1   4   0   0  56   0   0   0   0]
 [  0   0   1   0   3   1  23   0   0   0   0   0   0   0   2   0   1   0   7   0   2   0   0   3   0   0   0  54   0  11   0]
 [  0   0   0   0   1   0   1   0   0   1   0   0   0   0   0   0   0   0   7   0   0   4   0   8   0   0   0   1   2   1   0]
 [  0   0   0   0   1   0  11   0   0   0   0   0   0   0   0   1   0   0   7   0   6   1   0   4   0   0   0   4   0 145   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   3   5   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:04:01,204 - ==> Best [Top1: 62.882   Top5: 90.124   Sparsity:0.00   Params: 364479 on epoch: 56]
2022-12-15 15:04:01,204 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:01,214 - 

2022-12-15 15:04:01,215 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:01,766 - Epoch: [60][   10/   74]    Overall Loss 1.043846    Objective Loss 1.043846                                        LR 0.001000    Time 0.055082    
2022-12-15 15:04:02,018 - Epoch: [60][   20/   74]    Overall Loss 1.031900    Objective Loss 1.031900                                        LR 0.001000    Time 0.040090    
2022-12-15 15:04:02,279 - Epoch: [60][   30/   74]    Overall Loss 1.025871    Objective Loss 1.025871                                        LR 0.001000    Time 0.035442    
2022-12-15 15:04:02,562 - Epoch: [60][   40/   74]    Overall Loss 1.027115    Objective Loss 1.027115                                        LR 0.001000    Time 0.033644    
2022-12-15 15:04:02,815 - Epoch: [60][   50/   74]    Overall Loss 1.031762    Objective Loss 1.031762                                        LR 0.001000    Time 0.031966    
2022-12-15 15:04:03,078 - Epoch: [60][   60/   74]    Overall Loss 1.035901    Objective Loss 1.035901                                        LR 0.001000    Time 0.030978    
2022-12-15 15:04:03,343 - Epoch: [60][   70/   74]    Overall Loss 1.037567    Objective Loss 1.037567                                        LR 0.001000    Time 0.030333    
2022-12-15 15:04:03,438 - Epoch: [60][   74/   74]    Overall Loss 1.035064    Objective Loss 1.035064    Top1 76.388889    Top5 93.518519    LR 0.001000    Time 0.029977    
2022-12-15 15:04:03,507 - --- validate (epoch=60)-----------
2022-12-15 15:04:03,507 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:03,799 - Epoch: [60][    9/    9]    Loss 1.312761    Top1 61.593511    Top5 90.458015    
2022-12-15 15:04:03,856 - ==> Top1: 61.594    Top5: 90.458    Loss: 1.313

2022-12-15 15:04:03,858 - ==> Confusion:
[[ 15   0   0   0   0   0   6   0   0   0   0   0   0   0   1   0   1   0   0   0   1   0   0   3   0   0   0   0   0   1   0]
 [  0   2   0   0   6   2   1   0   0   1   0   0   0   0   0   0   0   0  13   0   6   2   0   0   0   0   0   2   0   3   0]
 [  0   0 103   0  13   0   1   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0  13   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0   7   0 110   0   4   0   0   0   0   0   0   0   0   0   0   0   1   0   1   2   0  23   0   0   0   2   0  15   0]
 [  0   0   0   0   4  30   0   0   0   0   0   0   0   0   1   0   5   0   4   0   3   6   0   0   0   0   1   0   1   0   0]
 [  2   0   0   0   2   0 139   0   0   0   0   0   0   0   3   0   0   0   0   0   1   0   0  11   0   0   1   3   0  10   0]
 [  0   2   0   0   0   2   0   1   0   0   0   0   0   0   0   0   0   0   1   0   9   0   0   0   0   0   0   6   0   2   0]
 [  1   0   0   0   0   0  10   0   2   3   0   5   0   0   1   0   0   0   1   0   0   1   0   6   0   0   0   2   1   0   0]
 [  2   0   0   0   0   0  11   0   0   3   0   0   0   0   2   0   0   0   6   0   1   0   0   1   0   0   0   1   0  14   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  35   0   1   0   0   0   0   2   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   0   1   0  14   0   0   3   0   0   0   1   0   0   1   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  17   0   0   0   0   0   0   2   0  11   0]
 [  2   0   0   0   0   0   7   0   0   0   0   3   0   0 158   1   1   0   0   0   0   9   0   0   0   0   3   4   0   1   0]
 [  2   0   0   0   1   0  11   0   0   1   0   0   0   0   2   0   0   0   1   0   0   0   0   2   0   0   0   5   0   6   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   1   4   3  30   0   2   0   0   2   0   0   0   0   0   4   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   3   3   0   0   0   0   0   0   0   0   0]
 [  6   2   0   0   5   0   4   0   1   5   0   0   0   0   1   1   0   0 112   0   2   6   0   2   0   0   0   1   1   9   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   1   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0  83   7   0   0   0   0   0   3   0  12   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   8   0   4   0   7   0  12 141   0   0   0   0   1   1   0   3   0]
 [  1   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  11   5   0   0   1   0   0   0   0]
 [  1   0   3   0  17   0  20   0   2   0   0   4   0   0   0   0   0   0   5   0   1   0   3  80   0   0   1   1   0  11   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0]
 [  0   0   0   0   0   0   2   0   0   3   0   0   0   0   1   0   0   0   1   0   1   0   0   1   0   0   0   3   0   2   0]
 [  0   0   1   0   0   0   0   0   0   0   0   2   0   0   1   0   0   0   0   0   0   1   0   6   0   0  57   0   0   0   0]
 [  0   0   0   0   4   1  19   0   0   0   0   0   0   0   3   0   0   0   4   0   3   0   0   5   0   0   0  59   1   9   0]
 [  0   0   0   0   0   0   1   0   0   1   0   0   0   0   1   0   1   0   5   0   0   5   1   8   0   0   0   0   2   1   0]
 [  0   0   0   0   7   0  10   0   0   1   0   0   0   0   0   0   0   0   2   0   2   2   0   9   0   0   0   9   1 137   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   7   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:04:03,860 - ==> Best [Top1: 62.882   Top5: 90.124   Sparsity:0.00   Params: 364479 on epoch: 56]
2022-12-15 15:04:03,860 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:03,880 - 

2022-12-15 15:04:03,880 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:04,297 - Epoch: [61][   10/   74]    Overall Loss 0.996455    Objective Loss 0.996455                                        LR 0.001000    Time 0.041630    
2022-12-15 15:04:04,542 - Epoch: [61][   20/   74]    Overall Loss 0.981343    Objective Loss 0.981343                                        LR 0.001000    Time 0.033054    
2022-12-15 15:04:04,787 - Epoch: [61][   30/   74]    Overall Loss 0.977671    Objective Loss 0.977671                                        LR 0.001000    Time 0.030166    
2022-12-15 15:04:05,028 - Epoch: [61][   40/   74]    Overall Loss 0.976132    Objective Loss 0.976132                                        LR 0.001000    Time 0.028595    
2022-12-15 15:04:05,267 - Epoch: [61][   50/   74]    Overall Loss 0.972490    Objective Loss 0.972490                                        LR 0.001000    Time 0.027634    
2022-12-15 15:04:05,508 - Epoch: [61][   60/   74]    Overall Loss 0.970362    Objective Loss 0.970362                                        LR 0.001000    Time 0.026998    
2022-12-15 15:04:05,752 - Epoch: [61][   70/   74]    Overall Loss 0.967675    Objective Loss 0.967675                                        LR 0.001000    Time 0.026624    
2022-12-15 15:04:05,838 - Epoch: [61][   74/   74]    Overall Loss 0.968516    Objective Loss 0.968516    Top1 77.314815    Top5 94.907407    LR 0.001000    Time 0.026353    
2022-12-15 15:04:05,903 - --- validate (epoch=61)-----------
2022-12-15 15:04:05,903 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:06,170 - Epoch: [61][    9/    9]    Loss 1.268197    Top1 63.835878    Top5 90.696565    
2022-12-15 15:04:06,235 - ==> Top1: 63.836    Top5: 90.697    Loss: 1.268

2022-12-15 15:04:06,236 - ==> Confusion:
[[ 17   0   0   0   0   0   4   0   0   1   0   0   0   0   1   0   1   0   0   0   1   0   0   1   0   0   0   0   1   1   0]
 [  0   6   0   0   5   2   0   0   0   1   0   0   0   0   0   0   0   0  16   0   2   2   0   1   0   0   0   2   0   1   0]
 [  0   0 113   0  11   0   1   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   5   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   8   0 128   0   3   0   0   0   0   0   0   0   0   0   0   0   5   0   2   1   0  11   0   0   0   1   0   4   0]
 [  0   0   0   0   2  38   0   0   0   0   0   0   0   0   0   0   3   0   5   0   2   3   0   0   0   0   2   0   0   0   0]
 [  2   0   1   0   3   0 134   0   0   0   0   0   0   0   1   0   0   0   1   0   0   0   0  16   0   0   1   6   0   7   0]
 [  0   2   0   0   1   2   0   2   0   0   0   0   0   0   0   0   0   0   2   0   7   0   0   0   0   0   0   5   0   2   0]
 [  1   0   0   0   0   0   7   0   0   3   0   3   0   0   0   0   0   0   6   0   0   1   0   9   0   0   0   2   1   0   0]
 [  0   0   0   0   0   0   6   0   0   4   0   0   0   0   1   0   0   0  15   0   0   0   0   1   0   0   0   4   0  10   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  34   0   2   0   1   0   0   1   0   0   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   3   0   0   1   0  10   0   0   2   0   1   0   0   0   1   2   2   0   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   1   0   0   0   0   0   0   0   2   0   0   1   0   0   0  19   1   0   0   0   0   0   2   0   6   0]
 [  5   0   0   0   0   0   8   0   0   0   0   2   0   0 153   0   1   0   1   0   0  11   0   1   0   0   3   4   0   0   0]
 [  3   0   0   0   0   0   7   0   0   1   0   0   0   0   2   1   0   0   3   0   0   0   0   1   0   0   0  11   0   2   0]
 [  0   0   0   0   0   3   0   1   0   0   0   0   0   0   4   0  32   0   6   0   0   3   0   0   0   0   1   2   0   0   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   1   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  2   1   1   0   4   0   1   0   0   1   0   0   0   0   0   0   0   0 128   0   4   6   0   1   0   0   0   3   1   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   4   3   0   0   0   0   0   0   0   0   0   0   1   0   3   0  76  11   0   0   0   0   0   2   0   9   0]
 [  0   2   0   0   2   1   0   0   0   0   0   0   0   0   6   0   3   0   8   0   6 147   0   0   0   0   1   0   0   2   0]
 [  0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  12   3   0   0   0   1   0   0   0]
 [  2   0   7   0  21   0  11   0   2   0   0   3   0   0   0   0   0   0   6   0   0   1   2  85   0   0   1   3   0   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   1   0   0   4   0   0   0   0   1   0   0   0   3   0   0   0   0   1   0   0   0   4   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   1   0   5   0   0  58   0   0   0   0]
 [  0   0   0   0   4   2  20   0   0   0   0   0   0   0   2   0   2   0   6   0   2   1   0   6   0   0   0  59   0   4   0]
 [  0   0   0   0   1   1   0   0   0   0   0   0   0   0   1   0   1   0   9   0   0   4   0   7   0   0   0   1   1   0   0]
 [  0   0   0   0  11   1  11   0   0   0   0   0   0   0   0   0   0   0   7   0   2   2   0   4   0   0   0  10   0 132   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   1   0   0   0   0   0   2   6   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:04:06,238 - ==> Best [Top1: 63.836   Top5: 90.697   Sparsity:0.00   Params: 364479 on epoch: 61]
2022-12-15 15:04:06,238 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:06,266 - 

2022-12-15 15:04:06,266 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:06,706 - Epoch: [62][   10/   74]    Overall Loss 0.909956    Objective Loss 0.909956                                        LR 0.001000    Time 0.043840    
2022-12-15 15:04:06,964 - Epoch: [62][   20/   74]    Overall Loss 0.939001    Objective Loss 0.939001                                        LR 0.001000    Time 0.034842    
2022-12-15 15:04:07,217 - Epoch: [62][   30/   74]    Overall Loss 0.932694    Objective Loss 0.932694                                        LR 0.001000    Time 0.031621    
2022-12-15 15:04:07,477 - Epoch: [62][   40/   74]    Overall Loss 0.935856    Objective Loss 0.935856                                        LR 0.001000    Time 0.030206    
2022-12-15 15:04:07,731 - Epoch: [62][   50/   74]    Overall Loss 0.929613    Objective Loss 0.929613                                        LR 0.001000    Time 0.029237    
2022-12-15 15:04:07,983 - Epoch: [62][   60/   74]    Overall Loss 0.933973    Objective Loss 0.933973                                        LR 0.001000    Time 0.028560    
2022-12-15 15:04:08,228 - Epoch: [62][   70/   74]    Overall Loss 0.934556    Objective Loss 0.934556                                        LR 0.001000    Time 0.027958    
2022-12-15 15:04:08,313 - Epoch: [62][   74/   74]    Overall Loss 0.935190    Objective Loss 0.935190    Top1 71.527778    Top5 94.444444    LR 0.001000    Time 0.027596    
2022-12-15 15:04:08,381 - --- validate (epoch=62)-----------
2022-12-15 15:04:08,382 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:08,652 - Epoch: [62][    9/    9]    Loss 1.257785    Top1 62.404580    Top5 90.601145    
2022-12-15 15:04:08,713 - ==> Top1: 62.405    Top5: 90.601    Loss: 1.258

2022-12-15 15:04:08,715 - ==> Confusion:
[[ 19   0   0   0   0   0   3   0   1   0   0   0   0   0   1   0   1   0   0   0   1   0   0   1   0   0   0   0   0   1   0]
 [  0   2   0   0   5   2   0   1   0   1   0   0   0   0   0   0   0   0  22   0   2   1   0   0   0   0   0   2   0   0   0]
 [  0   0 113   0   7   0   1   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0   7   0 114   0   3   0   0   0   0   0   0   0   0   0   0   0   9   0   1   3   0  13   0   0   0   6   0   9   0]
 [  0   0   0   0   2  33   0   0   0   0   0   0   0   0   1   0   4   0   7   0   1   6   0   0   0   0   1   0   0   0   0]
 [  2   0   0   0   1   0 124   0   0   3   0   0   0   0   1   1   0   0   2   0   1   0   0  19   0   0   1   3   0  14   0]
 [  0   2   0   0   0   2   0   2   0   0   0   0   0   0   0   0   1   0   2   0   7   0   0   0   0   0   0   5   0   2   0]
 [  0   0   0   0   0   0   4   0   5   3   0   2   0   0   0   1   0   0   7   0   0   1   0   9   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   4   0   0   5   0   0   0   0   0   1   0   0  17   0   1   0   0   1   0   0   0   1   0  11   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  33   0   2   0   1   0   0   2   0   0   0   0   0   1   0   0   0]
 [  2   0   0   0   0   0   1   0   0   1   0  13   0   0   2   0   0   0   2   0   1   1   2   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   1   0   0   0   0   0   0   0   1   0   1   0   0   1   0  17   1   0   0   0   0   0   1   0   9   0]
 [  3   0   0   0   0   0   9   0   1   0   0   6   0   0 147   2   2   0   2   0   0  11   0   2   0   0   0   4   0   0   0]
 [  3   0   0   0   0   0  10   0   0   4   0   0   0   0   0   3   0   0   2   0   0   0   0   2   0   0   0   5   0   2   0]
 [  1   0   0   0   0   3   0   0   0   0   0   0   0   0   0   1  32   0   7   0   0   4   0   1   0   0   0   2   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   1   3   0   0   0   0   0   0   0   0   0]
 [  2   0   0   0   2   0   0   0   1   0   0   0   0   0   0   0   0   0 137   0   2   5   0   2   0   0   0   2   0   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   3   0   0   0   0   0   0   0   0   1   0   1   0   3   0  76  11   0   0   0   0   0   1   0  10   0]
 [  0   0   0   0   2   0   0   0   0   1   0   0   0   0   7   0   5   0  14   0   4 144   0   0   0   0   0   0   0   1   0]
 [  1   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   7   5   0   0   0   0   0   0   0]
 [  2   0   6   0  17   0  11   0   4   0   0   3   0   0   0   0   0   0   6   0   0   0   1  87   0   0   1   2   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0]
 [  1   0   0   0   0   0   1   0   0   4   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   3   0   1   0]
 [  0   0   2   0   0   1   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   1   1   7   0   0  54   0   0   0   0]
 [  0   0   0   0   4   2  14   0   0   0   0   0   0   0   2   2   3   0   8   0   3   1   0   6   0   0   0  55   0   8   0]
 [  0   0   0   0   0   0   0   0   0   1   0   2   0   0   0   0   1   0   9   0   0   3   0   9   0   0   0   1   0   0   0]
 [  0   0   0   0   4   0   8   0   0   2   0   0   0   0   0   1   0   0  10   0   4   3   0   6   0   0   0   7   0 135   0]
 [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   0   0   2   6   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:04:08,717 - ==> Best [Top1: 63.836   Top5: 90.697   Sparsity:0.00   Params: 364479 on epoch: 61]
2022-12-15 15:04:08,717 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:08,737 - 

2022-12-15 15:04:08,737 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:09,133 - Epoch: [63][   10/   74]    Overall Loss 0.888842    Objective Loss 0.888842                                        LR 0.001000    Time 0.039514    
2022-12-15 15:04:09,376 - Epoch: [63][   20/   74]    Overall Loss 0.901268    Objective Loss 0.901268                                        LR 0.001000    Time 0.031816    
2022-12-15 15:04:09,627 - Epoch: [63][   30/   74]    Overall Loss 0.906969    Objective Loss 0.906969                                        LR 0.001000    Time 0.029571    
2022-12-15 15:04:09,884 - Epoch: [63][   40/   74]    Overall Loss 0.906852    Objective Loss 0.906852                                        LR 0.001000    Time 0.028588    
2022-12-15 15:04:10,136 - Epoch: [63][   50/   74]    Overall Loss 0.907365    Objective Loss 0.907365                                        LR 0.001000    Time 0.027916    
2022-12-15 15:04:10,397 - Epoch: [63][   60/   74]    Overall Loss 0.907747    Objective Loss 0.907747                                        LR 0.001000    Time 0.027600    
2022-12-15 15:04:10,642 - Epoch: [63][   70/   74]    Overall Loss 0.911343    Objective Loss 0.911343                                        LR 0.001000    Time 0.027141    
2022-12-15 15:04:10,729 - Epoch: [63][   74/   74]    Overall Loss 0.913444    Objective Loss 0.913444    Top1 76.851852    Top5 96.990741    LR 0.001000    Time 0.026857    
2022-12-15 15:04:10,795 - --- validate (epoch=63)-----------
2022-12-15 15:04:10,796 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:11,066 - Epoch: [63][    9/    9]    Loss 1.207090    Top1 63.263359    Top5 90.124046    
2022-12-15 15:04:11,120 - ==> Top1: 63.263    Top5: 90.124    Loss: 1.207

2022-12-15 15:04:11,122 - ==> Confusion:
[[ 20   0   0   0   0   0   2   0   0   0   0   1   0   0   1   1   1   0   0   0   1   0   0   0   0   0   0   0   0   1   0]
 [  0   2   0   0   3   4   0   2   0   1   0   0   0   0   0   0   0   0  22   0   1   2   0   0   0   0   0   1   0   0   0]
 [  0   0 114   0   7   0   1   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   7   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2  11   0 113   3   4   0   0   0   0   0   0   0   0   0   0   0   9   0   1   3   0  12   0   0   0   2   1   4   0]
 [  0   0   0   0   1  33   0   0   0   0   0   0   0   0   1   0   7   0   6   0   0   6   0   0   0   0   1   0   0   0   0]
 [  1   0   0   0   1   0 131   0   1   1   0   1   0   0   7   1   0   0   3   0   0   2   0  11   0   0   1   5   0   6   0]
 [  0   2   0   0   0   2   0   2   0   0   0   0   0   1   0   0   0   0   4   0   4   0   0   0   0   0   0   7   0   1   0]
 [  1   0   0   0   0   0   5   0   6   3   0   6   0   0   2   0   0   0   3   0   0   1   0   6   0   0   0   0   0   0   0]
 [  1   0   0   0   0   0   6   0   0   6   0   0   0   0   3   1   0   0  14   0   1   0   0   0   0   0   0   1   0   8   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  35   0   0   0   0   0   0   4   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  14   0   0   4   0   1   0   1   0   1   1   1   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   1   0   0   0   0   0   0   0   3   0   0   1   0   0   0  18   1   0   0   0   0   0   2   0   6   0]
 [  1   0   0   0   0   0   5   0   0   0   0   5   0   0 165   1   2   0   0   0   0   8   0   1   0   0   0   1   0   0   0]
 [  5   0   0   0   0   0   7   0   0   2   0   0   0   0   6   1   0   0   5   0   0   0   0   1   0   0   0   2   0   2   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   3   1  32   0   6   0   0   8   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   3   0   1   0   0   3   0   0   0   0   0   0   0   0   0]
 [  4   1   0   0   1   1   2   0   0   1   0   1   0   0   2   2   0   0 130   0   3   9   0   1   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   4   3   0   0   0   0   0   0   0   1   1   0   1   0   3   0  76  13   0   0   0   0   0   1   0   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   7   0   3   0   6   0   6 153   0   0   0   0   1   0   0   1   0]
 [  1   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  12   5   0   0   1   0   1   0   0]
 [  4   0   4   0  11   0  18   0   2   0   0   5   0   0   0   0   0   0   6   0   0   1   4  84   0   0   2   2   1   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   1   0   1   4   0   0   0   0   1   0   0   0   3   0   1   0   0   1   0   0   0   2   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   1   0   4   0   0  56   0   1   0   0]
 [  1   0   1   0   3   2  20   0   0   1   0   0   0   0   5   0   5   0   8   0   5   1   0   4   0   0   0  47   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   2   0   1   0   8   0   0   4   0   8   0   0   0   1   1   0   0]
 [  0   0   0   0   9   0  14   0   0   3   0   0   0   0   1   2   0   0  10   0   4   4   0   4   0   0   0   4   0 125   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:04:11,124 - ==> Best [Top1: 63.836   Top5: 90.697   Sparsity:0.00   Params: 364479 on epoch: 61]
2022-12-15 15:04:11,124 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:11,144 - 

2022-12-15 15:04:11,144 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:11,557 - Epoch: [64][   10/   74]    Overall Loss 0.892637    Objective Loss 0.892637                                        LR 0.001000    Time 0.041225    
2022-12-15 15:04:11,803 - Epoch: [64][   20/   74]    Overall Loss 0.910197    Objective Loss 0.910197                                        LR 0.001000    Time 0.032888    
2022-12-15 15:04:12,046 - Epoch: [64][   30/   74]    Overall Loss 0.905229    Objective Loss 0.905229                                        LR 0.001000    Time 0.030019    
2022-12-15 15:04:12,292 - Epoch: [64][   40/   74]    Overall Loss 0.884043    Objective Loss 0.884043                                        LR 0.001000    Time 0.028632    
2022-12-15 15:04:12,541 - Epoch: [64][   50/   74]    Overall Loss 0.879409    Objective Loss 0.879409                                        LR 0.001000    Time 0.027889    
2022-12-15 15:04:12,794 - Epoch: [64][   60/   74]    Overall Loss 0.880114    Objective Loss 0.880114                                        LR 0.001000    Time 0.027440    
2022-12-15 15:04:13,035 - Epoch: [64][   70/   74]    Overall Loss 0.880318    Objective Loss 0.880318                                        LR 0.001000    Time 0.026960    
2022-12-15 15:04:13,120 - Epoch: [64][   74/   74]    Overall Loss 0.880441    Objective Loss 0.880441    Top1 70.833333    Top5 93.518519    LR 0.001000    Time 0.026646    
2022-12-15 15:04:13,191 - --- validate (epoch=64)-----------
2022-12-15 15:04:13,191 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:13,464 - Epoch: [64][    9/    9]    Loss 1.245596    Top1 64.694656    Top5 90.696565    
2022-12-15 15:04:13,517 - ==> Top1: 64.695    Top5: 90.697    Loss: 1.246

2022-12-15 15:04:13,518 - ==> Confusion:
[[ 17   0   0   0   0   0   3   0   1   0   0   0   0   0   1   0   1   0   1   0   1   0   0   1   0   0   0   0   1   1   0]
 [  0   8   0   0   3   2   0   1   0   1   0   0   0   0   0   0   0   0  19   0   1   1   0   0   0   0   0   1   0   1   0]
 [  0   1 116   0   9   0   1   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   4   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1  10   0 121   1   3   0   0   1   0   0   0   0   0   0   0   0   8   0   0   1   0  10   0   0   0   2   1   6   0]
 [  0   0   0   0   1  40   0   0   0   0   0   1   0   0   0   0   1   0   6   0   1   4   0   0   0   0   1   0   0   0   0]
 [  1   0   1   0   4   0 123   0   1   3   0   0   0   0   4   1   0   0   3   0   0   0   0  14   0   0   1   6   0  10   0]
 [  0   4   0   0   0   2   0   4   0   0   0   0   0   1   0   0   1   0   3   0   2   0   0   0   0   0   0   5   0   1   0]
 [  1   0   0   0   0   0   5   0   3   3   0   3   0   0   0   0   0   0   6   0   0   1   0   7   0   0   1   2   1   0   0]
 [  0   0   0   0   0   0   6   0   1   7   0   0   0   0   1   0   0   0  14   0   0   0   0   1   0   0   0   2   0   9   0]
 [  0   0   0   0   0   0   1   0   0   0   1   1   0   0  32   0   1   0   0   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   2   0  16   0   0   1   0   1   0   0   0   0   1   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   0   0   1   0   0   0   0   0   6   0   0   1   0   1   0  16   0   0   0   0   0   0   1   0   5   0]
 [  3   0   0   0   0   0   6   0   0   1   1   7   0   0 161   0   1   0   0   0   0   7   0   1   0   0   0   1   0   0   0]
 [  4   0   0   0   0   0   4   0   0   5   0   0   0   0   2   2   0   0   7   0   0   0   0   2   0   0   0   2   0   3   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   1   2  33   0   6   0   0   7   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0   1   0   1   3   0   0   0   0   0   0   0   0   0]
 [  2   2   1   0   2   0   1   0   1   1   0   0   0   1   0   0   0   0 133   0   1   5   0   2   0   0   0   1   0   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   4   4   0   2   0   0   0   0   0   1   1   0   1   0   3   0  74  10   0   0   0   0   0   1   0   7   0]
 [  0   2   0   0   3   0   0   0   0   0   0   0   0   0   7   0   3   0   6   0   6 149   0   0   0   0   1   0   0   1   0]
 [  1   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   0   5   0  19   0   9   0   5   1   0   4   0   0   0   0   0   0   7   0   1   0   4  81   0   0   2   1   1   8   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   1   0   0   3   0   0   0   0   1   0   0   0   5   0   0   0   0   1   0   0   0   3   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   1   0   0   0   0   1   0   6   0   0  57   0   0   0   0]
 [  2   0   2   0   4   2  15   0   1   0   0   1   0   0   2   0   5   0  11   0   2   0   0   1   0   0   0  51   0   9   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   1   0   1   0   8   0   0   5   1   6   0   0   0   1   2   0   0]
 [  0   0   0   0   8   2   6   1   0   4   0   0   0   0   0   0   0   0   9   0   2   1   0   3   0   0   0   6   0 138   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   1   0   0   0   0   0   2   6   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:04:13,520 - ==> Best [Top1: 64.695   Top5: 90.697   Sparsity:0.00   Params: 364477 on epoch: 64]
2022-12-15 15:04:13,520 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:13,551 - 

2022-12-15 15:04:13,551 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:13,960 - Epoch: [65][   10/   74]    Overall Loss 0.881024    Objective Loss 0.881024                                        LR 0.001000    Time 0.040786    
2022-12-15 15:04:14,230 - Epoch: [65][   20/   74]    Overall Loss 0.861875    Objective Loss 0.861875                                        LR 0.001000    Time 0.033879    
2022-12-15 15:04:14,502 - Epoch: [65][   30/   74]    Overall Loss 0.849556    Objective Loss 0.849556                                        LR 0.001000    Time 0.031656    
2022-12-15 15:04:14,772 - Epoch: [65][   40/   74]    Overall Loss 0.845500    Objective Loss 0.845500                                        LR 0.001000    Time 0.030477    
2022-12-15 15:04:15,036 - Epoch: [65][   50/   74]    Overall Loss 0.857618    Objective Loss 0.857618                                        LR 0.001000    Time 0.029659    
2022-12-15 15:04:15,295 - Epoch: [65][   60/   74]    Overall Loss 0.858313    Objective Loss 0.858313                                        LR 0.001000    Time 0.029021    
2022-12-15 15:04:15,541 - Epoch: [65][   70/   74]    Overall Loss 0.863390    Objective Loss 0.863390                                        LR 0.001000    Time 0.028388    
2022-12-15 15:04:15,626 - Epoch: [65][   74/   74]    Overall Loss 0.866578    Objective Loss 0.866578    Top1 71.527778    Top5 95.138889    LR 0.001000    Time 0.028000    
2022-12-15 15:04:15,692 - --- validate (epoch=65)-----------
2022-12-15 15:04:15,693 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:15,963 - Epoch: [65][    9/    9]    Loss 1.227016    Top1 63.645038    Top5 90.362595    
2022-12-15 15:04:16,029 - ==> Top1: 63.645    Top5: 90.363    Loss: 1.227

2022-12-15 15:04:16,031 - ==> Confusion:
[[ 16   0   1   0   0   0   4   0   1   0   0   0   0   0   0   1   1   0   1   0   0   0   0   1   0   0   0   0   1   1   0]
 [  0   5   0   0   7   3   0   1   0   2   0   0   0   0   0   0   0   0  15   0   2   1   0   0   0   0   0   2   0   0   0]
 [  0   1 114   0   9   0   1   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   6   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3  11   0 120   0   3   0   0   0   0   0   0   0   0   0   0   0   6   0   1   1   0  11   0   0   0   3   0   6   0]
 [  0   1   0   0   1  41   0   0   0   0   0   0   0   0   0   0   2   0   6   0   1   1   0   0   0   0   1   0   0   1   0]
 [  1   0   0   0   2   0 131   0   1   2   0   0   0   0   2   1   0   0   1   0   0   0   1  12   0   0   0   7   0  11   0]
 [  0   2   0   0   1   2   0   4   0   0   0   0   0   1   0   0   0   0   1   0   6   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   3   4   0   1   0   0   0   1   0   0   8   0   0   1   0   7   0   0   0   3   0   0   0]
 [  0   0   0   0   0   0   5   0   0   8   0   0   0   0   1   0   0   0  14   0   0   0   0   0   0   0   0   4   0   9   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0  33   0   2   0   1   0   0   2   0   0   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   2   0   2   1   0  13   0   1   1   0   0   0   1   0   0   1   2   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   1   0   1   0   0   0   0   0   3   0   1   0   0   0   0  19   0   0   0   0   0   0   0   0   6   0]
 [  3   0   0   0   0   1   6   0   0   1   0   4   0   0 157   0   2   0   3   0   0   5   0   1   0   0   0   4   2   0   0]
 [  2   0   0   0   0   0   6   0   0   2   0   0   0   0   1   2   0   0   5   0   0   0   0   1   0   0   0   9   0   3   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   1   1  35   0   7   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   1   0   1   0   2   2   0   0   0   0   0   1   0   0   0]
 [  4   5   1   0   2   1   1   1   0   2   0   0   0   0   0   0   0   0 130   0   2   2   0   1   0   0   0   1   0   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   4   5   0   3   0   0   0   0   0   0   1   0   2   0   3   0  69   7   0   0   0   0   0   5   0   9   0]
 [  0   2   0   0   1   2   0   0   0   2   0   0   0   0  10   0   4   0   8   0   6 139   0   0   0   0   1   0   0   3   0]
 [  1   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  10   2   0   0   1   0   0   0   0]
 [  2   0   5   0  19   0  13   0   1   0   0   4   0   0   0   0   0   0   8   0   1   0   4  83   0   0   1   2   0   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   1   0   0   5   0   0   0   0   1   0   0   0   4   0   0   0   0   0   0   0   0   3   0   0   0]
 [  0   0   2   0   0   1   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   6   0   0  55   0   1   0   0]
 [  0   0   2   0   4   2  17   0   0   1   0   0   0   0   2   0   4   0   6   0   4   0   0   2   0   0   0  58   0   6   0]
 [  0   0   2   0   1   0   0   0   0   0   0   1   0   0   1   0   0   0  10   0   0   1   0   7   0   0   0   2   1   0   0]
 [  0   1   0   0   8   1   8   1   0   2   0   0   0   0   0   1   0   0   6   0   2   1   0   5   0   0   0   8   0 136   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   1   0   0   0   3   3   0   0   0   0   0   0   0   0   1]]

2022-12-15 15:04:16,032 - ==> Best [Top1: 64.695   Top5: 90.697   Sparsity:0.00   Params: 364477 on epoch: 64]
2022-12-15 15:04:16,032 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:16,042 - 

2022-12-15 15:04:16,042 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:16,465 - Epoch: [66][   10/   74]    Overall Loss 0.840471    Objective Loss 0.840471                                        LR 0.001000    Time 0.042190    
2022-12-15 15:04:16,703 - Epoch: [66][   20/   74]    Overall Loss 0.832948    Objective Loss 0.832948                                        LR 0.001000    Time 0.032993    
2022-12-15 15:04:16,946 - Epoch: [66][   30/   74]    Overall Loss 0.828993    Objective Loss 0.828993                                        LR 0.001000    Time 0.030079    
2022-12-15 15:04:17,192 - Epoch: [66][   40/   74]    Overall Loss 0.841350    Objective Loss 0.841350                                        LR 0.001000    Time 0.028698    
2022-12-15 15:04:17,440 - Epoch: [66][   50/   74]    Overall Loss 0.832495    Objective Loss 0.832495                                        LR 0.001000    Time 0.027903    
2022-12-15 15:04:17,686 - Epoch: [66][   60/   74]    Overall Loss 0.835979    Objective Loss 0.835979                                        LR 0.001000    Time 0.027345    
2022-12-15 15:04:17,928 - Epoch: [66][   70/   74]    Overall Loss 0.836550    Objective Loss 0.836550                                        LR 0.001000    Time 0.026891    
2022-12-15 15:04:18,012 - Epoch: [66][   74/   74]    Overall Loss 0.838236    Objective Loss 0.838236    Top1 73.148148    Top5 94.444444    LR 0.001000    Time 0.026570    
2022-12-15 15:04:18,085 - --- validate (epoch=66)-----------
2022-12-15 15:04:18,086 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:18,368 - Epoch: [66][    9/    9]    Loss 1.236040    Top1 63.740458    Top5 90.601145    
2022-12-15 15:04:18,434 - ==> Top1: 63.740    Top5: 90.601    Loss: 1.236

2022-12-15 15:04:18,436 - ==> Confusion:
[[ 16   1   0   0   0   0   3   0   1   0   0   1   0   0   1   1   1   0   0   0   0   0   0   2   0   0   0   0   0   1   0]
 [  0   8   0   0   5   2   0   2   0   1   0   0   0   0   0   0   0   0  15   0   1   1   0   1   0   0   0   2   0   0   0]
 [  0   0 109   0  10   0   1   0   0   0   0   0   0   0   0   0   0   0   4   0   1   0   0   9   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   4   0 118   0   3   0   0   0   0   0   0   0   0   1   0   0   4   0   0   1   0  19   0   0   0   2   0  11   0]
 [  0   0   0   0   2  37   0   0   0   0   0   0   0   0   0   0   2   0   6   0   0   5   0   0   0   0   1   0   1   1   0]
 [  1   0   1   0   2   0 127   0   1   1   0   1   0   0   1   1   0   0   2   0   0   0   0  16   0   0   1   4   0  13   0]
 [  0   4   0   0   0   2   0   5   0   0   0   0   0   2   0   0   0   0   1   0   3   0   0   0   0   0   0   5   0   1   0]
 [  1   0   0   0   0   0   5   0   6   4   0   3   0   0   0   1   0   0   3   0   0   1   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   6   0   0  10   0   0   0   0   1   1   0   0  10   0   2   0   0   1   0   0   0   0   0  10   0]
 [  0   0   0   0   0   0   1   0   0   0   2   1   0   0  30   0   1   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   3   0   0   2   0  12   0   0   1   0   0   0   1   0   1   2   2   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   1   0   0   0   0   0   5   0   0   1   0   0   0  15   1   0   0   0   0   0   2   0   7   0]
 [  4   0   0   0   0   0   9   0   2   0   0   9   0   0 146   1   2   0   0   0   0  10   0   1   0   0   1   3   1   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   0   4   0   0   3   0   0   0   0   3   0   0   0   4   0   4   0]
 [  1   0   0   0   0   2   0   0   0   0   0   0   0   0   1   2  32   0   5   0   0   6   0   0   0   0   0   2   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   3   0   0   0   0   0   1   1   0   0]
 [  3   4   0   0   2   0   3   1   4   5   0   0   0   1   0   1   0   0 121   0   1   4   0   2   0   0   0   1   0   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   3   2   0   2   0   0   0   0   0   0   0   0   1   0   2   0  74  12   0   0   0   0   0   1   0  10   0]
 [  0   2   1   0   1   0   0   0   0   0   0   0   0   0   7   0   3   0   9   0   6 146   0   0   0   0   0   0   0   3   0]
 [  0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  10   4   0   0   0   1   0   0   0]
 [  2   0   4   0  17   0   6   0   4   0   0   3   0   0   0   0   0   0   5   0   0   0   1  95   0   0   1   2   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0]
 [  0   0   0   0   0   0   1   0   0   6   0   0   0   1   1   0   0   0   2   0   0   0   0   1   0   0   0   2   0   0   0]
 [  0   0   2   0   0   1   1   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   1   4   0   0  56   0   0   0   0]
 [  0   0   0   0   5   1  19   0   0   1   0   0   0   0   2   3   3   0   6   0   1   1   0   5   0   0   0  53   0   8   0]
 [  0   0   0   0   0   0   0   0   0   1   0   1   0   0   1   0   0   0   6   0   0   4   0   9   0   0   0   1   2   1   0]
 [  0   0   0   0   6   0   7   1   0   3   0   0   0   0   0   3   0   0   5   0   2   1   0   9   0   0   0   2   0 141   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   3   5   0   0   0   0   0   0   0   0   1]]

2022-12-15 15:04:18,438 - ==> Best [Top1: 64.695   Top5: 90.697   Sparsity:0.00   Params: 364477 on epoch: 64]
2022-12-15 15:04:18,438 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:18,458 - 

2022-12-15 15:04:18,458 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:18,999 - Epoch: [67][   10/   74]    Overall Loss 0.811743    Objective Loss 0.811743                                        LR 0.001000    Time 0.054055    
2022-12-15 15:04:19,240 - Epoch: [67][   20/   74]    Overall Loss 0.810705    Objective Loss 0.810705                                        LR 0.001000    Time 0.039056    
2022-12-15 15:04:19,482 - Epoch: [67][   30/   74]    Overall Loss 0.815893    Objective Loss 0.815893                                        LR 0.001000    Time 0.034095    
2022-12-15 15:04:19,731 - Epoch: [67][   40/   74]    Overall Loss 0.810580    Objective Loss 0.810580                                        LR 0.001000    Time 0.031764    
2022-12-15 15:04:19,973 - Epoch: [67][   50/   74]    Overall Loss 0.811754    Objective Loss 0.811754                                        LR 0.001000    Time 0.030255    
2022-12-15 15:04:20,216 - Epoch: [67][   60/   74]    Overall Loss 0.811394    Objective Loss 0.811394                                        LR 0.001000    Time 0.029252    
2022-12-15 15:04:20,453 - Epoch: [67][   70/   74]    Overall Loss 0.810298    Objective Loss 0.810298                                        LR 0.001000    Time 0.028459    
2022-12-15 15:04:20,540 - Epoch: [67][   74/   74]    Overall Loss 0.812712    Objective Loss 0.812712    Top1 76.620370    Top5 94.444444    LR 0.001000    Time 0.028087    
2022-12-15 15:04:20,602 - --- validate (epoch=67)-----------
2022-12-15 15:04:20,603 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:20,882 - Epoch: [67][    9/    9]    Loss 1.219623    Top1 64.217557    Top5 91.173664    
2022-12-15 15:04:20,941 - ==> Top1: 64.218    Top5: 91.174    Loss: 1.220

2022-12-15 15:04:20,943 - ==> Confusion:
[[ 17   0   0   0   0   0   5   0   0   0   0   0   0   0   1   0   1   0   0   0   1   0   0   2   0   0   0   1   0   0   0]
 [  0   6   0   0   5   3   1   2   0   1   0   0   0   0   0   0   0   0  14   0   1   2   0   0   0   0   0   2   0   1   0]
 [  0   0 108   0  14   1   2   0   0   0   0   0   0   0   0   0   0   0   3   0   1   0   0   5   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   8   0 130   1   3   0   0   0   0   0   0   0   0   0   0   0   6   0   0   1   0   6   0   0   0   2   1   4   0]
 [  0   0   0   0   1  40   0   0   0   0   0   0   0   0   0   0   2   0   5   0   2   3   0   0   0   0   1   0   1   0   0]
 [  1   0   0   0   4   0 134   0   3   0   0   0   0   0   4   0   0   0   2   0   0   0   0   8   0   0   0  11   0   5   0]
 [  0   3   0   0   0   2   0   5   0   0   0   0   0   1   0   0   1   0   1   0   5   0   0   0   0   0   0   4   0   1   0]
 [  0   0   0   0   0   0   8   0   8   2   0   3   0   0   0   1   0   0   4   0   0   1   0   5   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   7   0   0   7   0   0   0   0   1   0   0   0  11   0   0   0   0   0   0   0   0   7   0   7   0]
 [  0   0   0   0   0   0   0   0   0   0   1   0   0   0  35   0   0   0   0   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   2   1   0  14   0   0   2   0   0   0   0   0   0   1   2   0   0   0   1   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   6   1   0   0   0   0   0   0   0   4   0   0   0   0   0   0  16   0   0   0   0   0   0   3   0   4   0]
 [  1   0   0   0   0   0   8   0   0   0   1   6   0   0 160   1   1   0   1   0   0   7   0   0   0   0   1   2   0   0   0]
 [  3   0   0   0   1   0   8   0   0   0   0   0   0   0   1   4   0   0   3   0   0   0   0   0   0   0   0   9   0   2   0]
 [  1   0   0   0   0   2   0   0   0   0   0   0   0   0   2   2  34   0   5   0   0   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   2   0   0   0   0   0   1   2   0   0]
 [  3   1   1   0   4   0   4   0   3   0   0   0   0   0   0   0   0   0 128   0   4   4   0   1   0   0   0   2   2   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   4   5   0   2   0   0   0   0   0   0   1   0   1   0   3   0  76   9   0   0   0   0   0   5   0   3   0]
 [  0   1   0   0   3   0   0   0   0   0   0   0   0   0   7   0   3   0   8   0   8 146   0   0   0   0   1   1   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  15   3   0   0   1   0   0   0   0]
 [  1   0   4   0  23   0  21   0   3   0   0   4   0   0   0   0   0   0   7   0   0   0   4  74   0   0   1   3   0   4   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   1   0   1   3   0   0   0   0   1   1   0   0   2   0   0   0   0   1   0   0   0   4   0   0   0]
 [  0   0   1   0   0   1   1   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   6   0   0  56   0   0   0   0]
 [  0   0   0   0   3   3  23   0   1   1   0   0   0   0   3   3   2   0   4   0   3   0   0   2   0   0   0  58   0   2   0]
 [  0   0   1   0   1   0   1   0   0   0   0   0   0   0   2   0   0   0   9   0   0   2   0   5   0   0   0   1   4   0   0]
 [  0   0   0   0  19   1  16   1   0   2   0   0   0   0   0   1   0   0   7   0   1   1   0   2   0   0   0  12   0 117   0]
 [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   3   0   0   0   0   0   3   3   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:04:20,944 - ==> Best [Top1: 64.695   Top5: 90.697   Sparsity:0.00   Params: 364477 on epoch: 64]
2022-12-15 15:04:20,944 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:20,960 - 

2022-12-15 15:04:20,960 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:21,380 - Epoch: [68][   10/   74]    Overall Loss 0.776964    Objective Loss 0.776964                                        LR 0.001000    Time 0.041888    
2022-12-15 15:04:21,626 - Epoch: [68][   20/   74]    Overall Loss 0.772715    Objective Loss 0.772715                                        LR 0.001000    Time 0.033228    
2022-12-15 15:04:21,881 - Epoch: [68][   30/   74]    Overall Loss 0.777554    Objective Loss 0.777554                                        LR 0.001000    Time 0.030602    
2022-12-15 15:04:22,136 - Epoch: [68][   40/   74]    Overall Loss 0.792549    Objective Loss 0.792549                                        LR 0.001000    Time 0.029287    
2022-12-15 15:04:22,389 - Epoch: [68][   50/   74]    Overall Loss 0.790377    Objective Loss 0.790377                                        LR 0.001000    Time 0.028490    
2022-12-15 15:04:22,639 - Epoch: [68][   60/   74]    Overall Loss 0.786989    Objective Loss 0.786989                                        LR 0.001000    Time 0.027903    
2022-12-15 15:04:22,883 - Epoch: [68][   70/   74]    Overall Loss 0.787748    Objective Loss 0.787748                                        LR 0.001000    Time 0.027390    
2022-12-15 15:04:22,968 - Epoch: [68][   74/   74]    Overall Loss 0.788903    Objective Loss 0.788903    Top1 74.305556    Top5 94.675926    LR 0.001000    Time 0.027054    
2022-12-15 15:04:23,034 - --- validate (epoch=68)-----------
2022-12-15 15:04:23,035 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:23,309 - Epoch: [68][    9/    9]    Loss 1.235758    Top1 64.026718    Top5 91.459924    
2022-12-15 15:04:23,358 - ==> Top1: 64.027    Top5: 91.460    Loss: 1.236

2022-12-15 15:04:23,360 - ==> Confusion:
[[ 15   0   0   0   0   0   4   0   1   0   0   0   0   0   1   1   1   0   1   0   1   0   0   2   0   0   0   0   0   1   0]
 [  0   4   0   0   3   3   0   2   0   1   0   0   0   0   0   0   0   0  20   0   1   0   0   0   0   0   0   2   0   2   0]
 [  0   0 112   0   7   0   1   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   9   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1   7   0 113   0   4   0   0   0   0   0   0   0   0   0   0   0  10   0   0   2   0  16   0   0   0   4   0   8   0]
 [  0   0   0   0   2  37   0   0   0   0   0   0   0   0   1   0   2   0   7   0   1   4   0   0   0   0   1   0   0   0   0]
 [  1   0   0   0   0   0 132   0   2   2   0   1   0   0   4   1   0   0   2   0   1   0   1  12   0   0   0   3   0  10   0]
 [  0   3   0   0   0   2   0   2   0   0   0   0   0   1   0   0   1   0   2   0   6   0   0   0   0   0   0   4   0   2   0]
 [  0   0   0   0   0   0   6   0   6   4   0   5   0   0   0   1   0   0   5   0   0   1   0   4   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   6   0   0   8   0   0   0   0   0   0   0   0  12   0   1   0   0   0   0   0   0   3   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   3   0   0   0  31   0   1   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   1   0   0   0   0  16   0   0   0   0   0   0   2   0   0   2   1   0   0   0   0   0   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   7   0   1   0   0   1   0  15   1   0   0   0   0   0   1   0   7   0]
 [  1   0   0   0   0   0   7   0   1   2   1   7   0   0 158   0   1   0   1   0   0   6   1   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   5   0   0   4   0   0   0   0   2   5   0   0   5   0   0   0   0   1   0   0   0   3   0   3   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   1   2  35   0   6   0   0   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   3   0   1   0   1   1   0   0   0   0   0   1   0   0   0]
 [  2   0   1   0   2   0   1   0   1   3   0   1   0   1   0   1   0   0 134   0   2   4   0   1   0   0   0   0   0   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   3   0   3   0   0   0   0   0   0   0   0   1   0   3   0  74  10   0   0   0   0   0   2   1  10   0]
 [  0   0   0   0   0   0   0   0   0   1   0   0   0   0  10   0   5   0  13   0   7 138   0   0   0   0   1   0   0   3   0]
 [  1   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  10   5   0   0   1   0   0   0   0]
 [  1   0   3   0  15   0  18   0   3   2   0   3   0   0   0   0   0   0   8   0   0   0   2  86   0   0   1   0   0   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   2   0]
 [  0   0   0   0   0   0   1   0   0   6   0   0   0   0   1   0   0   0   3   0   1   0   0   0   0   0   0   2   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   4   0   0   1   0   1   0   0   0   0   0   0   5   0   0  54   0   1   0   0]
 [  0   0   2   0   2   2  20   0   1   2   0   0   0   0   3   0   3   0  10   0   4   0   0   2   0   0   0  47   0  10   0]
 [  0   0   1   0   0   0   0   0   0   1   0   1   0   0   0   0   0   0  10   0   0   3   0   7   0   0   0   0   3   0   0]
 [  0   0   0   0   4   1   9   1   0   1   0   0   0   0   0   3   0   0   9   0   1   1   0   5   0   0   0   3   2 140   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1   5   0   0   0   0   0   0   0   0   2]]

2022-12-15 15:04:23,361 - ==> Best [Top1: 64.695   Top5: 90.697   Sparsity:0.00   Params: 364477 on epoch: 64]
2022-12-15 15:04:23,362 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:23,382 - 

2022-12-15 15:04:23,382 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:23,776 - Epoch: [69][   10/   74]    Overall Loss 0.733882    Objective Loss 0.733882                                        LR 0.001000    Time 0.039357    
2022-12-15 15:04:24,019 - Epoch: [69][   20/   74]    Overall Loss 0.766636    Objective Loss 0.766636                                        LR 0.001000    Time 0.031801    
2022-12-15 15:04:24,269 - Epoch: [69][   30/   74]    Overall Loss 0.764683    Objective Loss 0.764683                                        LR 0.001000    Time 0.029531    
2022-12-15 15:04:24,524 - Epoch: [69][   40/   74]    Overall Loss 0.762951    Objective Loss 0.762951                                        LR 0.001000    Time 0.028510    
2022-12-15 15:04:24,777 - Epoch: [69][   50/   74]    Overall Loss 0.764878    Objective Loss 0.764878                                        LR 0.001000    Time 0.027856    
2022-12-15 15:04:25,035 - Epoch: [69][   60/   74]    Overall Loss 0.772526    Objective Loss 0.772526                                        LR 0.001000    Time 0.027496    
2022-12-15 15:04:25,275 - Epoch: [69][   70/   74]    Overall Loss 0.774556    Objective Loss 0.774556                                        LR 0.001000    Time 0.027000    
2022-12-15 15:04:25,361 - Epoch: [69][   74/   74]    Overall Loss 0.773804    Objective Loss 0.773804    Top1 78.472222    Top5 97.222222    LR 0.001000    Time 0.026693    
2022-12-15 15:04:25,417 - --- validate (epoch=69)-----------
2022-12-15 15:04:25,418 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:25,688 - Epoch: [69][    9/    9]    Loss 1.230159    Top1 63.311069    Top5 91.173664    
2022-12-15 15:04:25,736 - ==> Top1: 63.311    Top5: 91.174    Loss: 1.230

2022-12-15 15:04:25,738 - ==> Confusion:
[[ 16   0   0   0   0   0   4   0   0   0   0   0   0   0   1   1   1   0   0   0   1   0   0   1   0   0   0   1   1   1   0]
 [  0   7   0   0   5   2   0   2   0   1   0   0   0   0   0   0   0   0  13   0   2   1   0   0   0   0   0   2   0   3   0]
 [  0   1 113   0  10   0   1   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   5   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   6   0 121   1   4   0   0   0   0   0   0   1   0   0   0   0   2   0   1   2   0   9   0   0   0   3   1  10   0]
 [  0   1   0   0   1  39   0   0   0   0   0   0   0   0   0   0   3   0   4   0   0   5   0   0   0   0   1   0   0   1   0]
 [  0   0   2   0   2   0 130   0   1   1   0   1   0   0   1   0   0   0   1   0   1   0   0  13   0   0   0   4   0  15   0]
 [  0   4   0   0   0   2   0   4   0   0   0   0   0   2   0   0   0   0   1   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   3   6   0   2   0   0   0   1   0   0   3   0   0   1   0   8   0   0   0   1   0   1   0]
 [  0   0   0   0   0   0   7   0   0   1   0   0   0   0   0   2   0   0  11   0   1   0   0   1   0   0   0   1   0  17   0]
 [  0   0   0   0   0   0   1   0   0   0   2   1   0   0  29   0   1   0   1   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   0   1   0  12   0   1   2   0   0   0   1   0   0   3   2   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   2   0   0   0   0   0   7   0   0   0   0   0   0  17   0   0   0   0   0   0   1   0   5   0]
 [  4   0   0   0   0   0   8   0   2   0   2   4   0   0 147   1   3   0   1   0   0  13   0   1   0   0   1   2   0   0   0]
 [  3   0   0   0   0   0   7   0   0   3   0   0   0   0   1   3   0   0   2   0   1   0   0   1   0   0   0   5   0   5   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   2  32   0   6   0   1   5   0   1   0   0   0   1   0   1   0]
 [  0   0   0   0   0   2   0   1   0   0   0   0   0   0   0   0   1   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  2   9   0   0   3   0   1   0   3   3   0   0   0   0   0   1   0   0 113   0   5   4   0   1   1   0   0   2   1   9   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   2   2   0   2   0   0   0   0   0   1   0   0   0   0   1   0  77  11   0   0   0   0   0   3   0   9   0]
 [  0   1   0   0   1   0   0   0   0   1   0   0   0   0   3   0   3   0   7   0   7 152   0   0   0   0   0   0   0   3   0]
 [  0   0   6   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0  10   3   0   0   0   0   0   0   0]
 [  0   0   6   0  24   0  16   0   3   1   0   3   0   0   0   0   0   0   5   0   0   0   2  76   0   0   1   1   0  11   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   1   0   0   5   0   0   0   0   1   1   0   0   0   0   0   0   0   1   0   0   0   4   0   1   0]
 [  0   0   3   0   0   1   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   1   0   5   0   0  55   0   1   0   0]
 [  0   0   1   0   3   2  16   0   0   1   0   0   0   0   2   2   2   0   3   0   5   0   0   2   0   0   0  55   0  14   0]
 [  0   1   1   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   6   0   0   4   0   7   0   0   0   1   4   1   0]
 [  0   0   0   0   8   0   5   1   0   2   0   0   0   1   0   0   0   0   1   0   2   4   0   3   0   0   0   7   0 146   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   6   0   0   0   0   0   0   0   0   2]]

2022-12-15 15:04:25,739 - ==> Best [Top1: 64.695   Top5: 90.697   Sparsity:0.00   Params: 364477 on epoch: 64]
2022-12-15 15:04:25,739 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:25,749 - 

2022-12-15 15:04:25,749 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:26,171 - Epoch: [70][   10/   74]    Overall Loss 0.746461    Objective Loss 0.746461                                        LR 0.001000    Time 0.042065    
2022-12-15 15:04:26,423 - Epoch: [70][   20/   74]    Overall Loss 0.754811    Objective Loss 0.754811                                        LR 0.001000    Time 0.033639    
2022-12-15 15:04:26,684 - Epoch: [70][   30/   74]    Overall Loss 0.766957    Objective Loss 0.766957                                        LR 0.001000    Time 0.031115    
2022-12-15 15:04:26,929 - Epoch: [70][   40/   74]    Overall Loss 0.750749    Objective Loss 0.750749                                        LR 0.001000    Time 0.029429    
2022-12-15 15:04:27,176 - Epoch: [70][   50/   74]    Overall Loss 0.746352    Objective Loss 0.746352                                        LR 0.001000    Time 0.028492    
2022-12-15 15:04:27,423 - Epoch: [70][   60/   74]    Overall Loss 0.752782    Objective Loss 0.752782                                        LR 0.001000    Time 0.027838    
2022-12-15 15:04:27,663 - Epoch: [70][   70/   74]    Overall Loss 0.756029    Objective Loss 0.756029                                        LR 0.001000    Time 0.027291    
2022-12-15 15:04:27,748 - Epoch: [70][   74/   74]    Overall Loss 0.757152    Objective Loss 0.757152    Top1 79.398148    Top5 96.296296    LR 0.001000    Time 0.026966    
2022-12-15 15:04:27,819 - --- validate (epoch=70)-----------
2022-12-15 15:04:27,820 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:28,094 - Epoch: [70][    9/    9]    Loss 1.230915    Top1 64.265267    Top5 90.553435    
2022-12-15 15:04:28,161 - ==> Top1: 64.265    Top5: 90.553    Loss: 1.231

2022-12-15 15:04:28,163 - ==> Confusion:
[[ 18   0   0   0   0   0   4   0   1   0   0   0   0   0   1   0   1   0   0   0   1   0   0   1   0   0   0   0   0   1   0]
 [  0   7   0   0   6   2   1   3   0   1   0   0   0   0   0   0   0   0  12   0   1   2   0   0   0   0   0   2   0   1   0]
 [  0   0 110   0  11   1   2   0   0   0   0   0   0   0   0   0   0   0   3   0   1   0   0   6   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1   5   0 132   0   3   0   0   0   0   0   0   0   0   0   0   0   2   0   1   1   0   8   0   0   0   3   1   8   0]
 [  0   1   0   0   1  41   0   0   0   0   0   1   0   0   0   0   2   0   3   0   1   2   0   0   0   0   1   0   1   1   0]
 [  0   0   0   0   1   0 140   0   2   0   0   1   0   0   2   0   0   0   1   0   1   0   1   9   0   0   0   8   0   6   0]
 [  0   2   0   0   1   2   0   4   0   0   0   0   0   1   0   0   0   0   1   0   6   0   0   0   0   0   0   6   0   0   0]
 [  0   0   0   0   0   0  11   0   4   3   0   4   0   0   0   1   0   0   2   0   0   0   0   5   0   0   0   2   1   0   0]
 [  3   0   0   0   0   0  11   0   1   3   0   0   0   0   1   1   0   0   6   0   0   0   0   1   0   0   0   5   0   9   0]
 [  0   0   0   0   0   0   1   0   0   0   2   0   0   0  32   0   1   0   1   0   0   2   0   0   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   4   0   1   0   0  12   0   0   2   0   0   0   0   0   1   1   2   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   4   0   0   1   0   0   0   0   0   7   0   0   0   0   0   0  14   0   0   0   0   0   0   3   0   5   0]
 [  2   0   0   0   0   0   7   0   1   0   1   7   0   0 160   1   1   0   0   0   0   5   0   0   0   0   2   1   1   0   0]
 [  2   0   0   0   0   0  10   0   0   1   0   0   0   0   1   2   0   0   2   0   0   0   0   0   0   0   0   9   0   4   0]
 [  3   0   0   0   0   2   0   0   0   0   0   0   0   0   2   2  34   0   3   0   0   3   0   0   0   0   0   2   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   2   0   0   0   1   3   0   0   0   0   0   1   1   0   0]
 [  5   8   1   0   3   0   6   0   3   5   0   0   0   0   0   2   0   0 103   0   3   3   0   2   0   0   0   4   3   7   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   4   0   0   2   0   0   0   0   0   0   1   0   0   0   1   0  81   7   0   0   0   0   0   4   0   8   0]
 [  0   1   0   0   3   1   0   0   0   1   0   0   0   0  12   0   4   0   7   0  10 137   0   0   0   0   1   1   0   0   0]
 [  1   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  14   2   0   0   1   0   0   0   0]
 [  0   0   5   0  21   0  18   0   6   0   0   4   0   0   0   0   0   0   1   0   0   0   4  81   0   0   1   3   0   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   2   0]
 [  0   0   0   0   0   0   3   0   0   5   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   4   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   6   0   0  57   0   0   0   0]
 [  0   0   0   0   4   2  26   0   0   0   0   0   0   0   4   2   1   0   3   0   4   0   0   1   0   0   0  58   1   2   0]
 [  0   0   1   0   0   0   0   0   0   0   0   1   0   0   2   0   0   0   6   0   0   2   0   7   0   0   0   1   6   0   0]
 [  0   0   0   0  12   0   9   1   0   2   0   0   0   0   0   1   0   0   2   0   1   2   0   6   0   0   0  12   0 132   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   0   3   3   0   0   0   0   0   0   0   0   1]]

2022-12-15 15:04:28,165 - ==> Best [Top1: 64.695   Top5: 90.697   Sparsity:0.00   Params: 364477 on epoch: 64]
2022-12-15 15:04:28,165 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:28,185 - 

2022-12-15 15:04:28,185 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:28,585 - Epoch: [71][   10/   74]    Overall Loss 0.770429    Objective Loss 0.770429                                        LR 0.001000    Time 0.039946    
2022-12-15 15:04:28,839 - Epoch: [71][   20/   74]    Overall Loss 0.756350    Objective Loss 0.756350                                        LR 0.001000    Time 0.032644    
2022-12-15 15:04:29,081 - Epoch: [71][   30/   74]    Overall Loss 0.763965    Objective Loss 0.763965                                        LR 0.001000    Time 0.029800    
2022-12-15 15:04:29,328 - Epoch: [71][   40/   74]    Overall Loss 0.746751    Objective Loss 0.746751                                        LR 0.001000    Time 0.028534    
2022-12-15 15:04:29,576 - Epoch: [71][   50/   74]    Overall Loss 0.741162    Objective Loss 0.741162                                        LR 0.001000    Time 0.027764    
2022-12-15 15:04:29,822 - Epoch: [71][   60/   74]    Overall Loss 0.739244    Objective Loss 0.739244                                        LR 0.001000    Time 0.027241    
2022-12-15 15:04:30,062 - Epoch: [71][   70/   74]    Overall Loss 0.741263    Objective Loss 0.741263                                        LR 0.001000    Time 0.026770    
2022-12-15 15:04:30,149 - Epoch: [71][   74/   74]    Overall Loss 0.740687    Objective Loss 0.740687    Top1 79.629630    Top5 95.138889    LR 0.001000    Time 0.026496    
2022-12-15 15:04:30,205 - --- validate (epoch=71)-----------
2022-12-15 15:04:30,205 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:30,480 - Epoch: [71][    9/    9]    Loss 1.187819    Top1 65.982824    Top5 91.078244    
2022-12-15 15:04:30,537 - ==> Top1: 65.983    Top5: 91.078    Loss: 1.188

2022-12-15 15:04:30,539 - ==> Confusion:
[[ 16   0   0   0   0   0   2   0   1   0   0   1   0   0   1   2   1   0   0   0   1   0   0   1   0   0   0   0   1   1   0]
 [  0   6   0   0   5   4   0   1   0   2   0   0   0   0   0   0   0   0  13   0   2   2   0   0   0   0   0   2   0   1   0]
 [  0   0 114   0   9   1   1   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   6   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1   6   0 122   0   4   1   0   0   0   0   0   1   0   0   0   0   6   0   0   1   0  11   0   0   0   4   1   7   0]
 [  0   1   0   0   2  42   0   0   0   0   0   0   0   0   0   0   3   0   4   0   0   1   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   2   0 131   0   2   3   0   1   0   0   4   1   0   0   1   0   1   0   0  12   0   0   1   5   0   8   0]
 [  0   3   0   0   0   2   0   5   0   0   0   0   0   1   0   0   0   0   1   0   4   0   0   0   0   0   0   6   0   1   0]
 [  0   0   0   0   0   0   7   0   7   3   0   3   0   0   0   1   0   0   3   0   0   1   0   4   0   0   0   2   2   0   0]
 [  0   0   0   0   0   0   5   0   0  13   0   0   0   0   1   0   0   0   9   0   1   0   0   0   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   1   0   0   0   5   0   0   0  28   0   1   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  14   0   1   3   0   1   0   1   0   0   2   1   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   1   0   1   0   0   0   8   0   0   1   0   0   0  14   0   0   0   0   0   0   1   0   6   0]
 [  2   0   0   0   0   0   6   0   0   1   1   6   0   0 163   0   1   0   0   0   0   7   0   0   0   0   1   1   0   0   0]
 [  2   0   0   0   0   0   5   0   0   4   0   0   0   0   4   3   0   0   4   0   0   0   0   1   0   0   0   5   0   3   0]
 [  1   0   0   0   0   2   0   0   0   1   0   0   0   0   2   2  37   0   4   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   0   0   0   0]
 [  1   7   1   0   2   0   1   0   1   3   0   0   0   1   1   1   1   0 123   0   2   5   0   3   0   0   0   0   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   4   5   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74   9   0   0   0   0   0   4   0   6   0]
 [  0   3   0   0   3   1   0   0   0   0   0   0   0   0   8   0   5   0   7   0   7 140   0   0   0   0   2   0   0   2   0]
 [  1   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   3   0   0   1   0   1   0   0]
 [  0   0   3   0  17   0  16   0   2   0   0   4   0   0   0   0   0   0   6   0   1   1   4  83   0   0   2   2   3   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   2   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   4   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   4   0   0  59   0   1   0   0]
 [  1   0   1   0   2   2  18   0   1   2   0   0   0   0   3   0   3   0   5   0   3   0   0   1   0   0   0  61   0   5   0]
 [  0   0   0   0   0   2   0   0   0   0   0   1   0   0   2   0   0   0   7   0   0   1   0   8   0   0   0   1   4   0   0]
 [  0   0   0   0   6   1  11   1   0   4   0   0   0   0   0   2   0   0   5   0   2   3   0   3   0   0   0   5   0 137   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   0   0   0   2   3   0   0   0   0   0   0   0   0   1]]

2022-12-15 15:04:30,541 - ==> Best [Top1: 65.983   Top5: 91.078   Sparsity:0.00   Params: 364479 on epoch: 71]
2022-12-15 15:04:30,541 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:30,564 - 

2022-12-15 15:04:30,564 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:31,000 - Epoch: [72][   10/   74]    Overall Loss 0.647760    Objective Loss 0.647760                                        LR 0.001000    Time 0.043442    
2022-12-15 15:04:31,247 - Epoch: [72][   20/   74]    Overall Loss 0.671315    Objective Loss 0.671315                                        LR 0.001000    Time 0.034067    
2022-12-15 15:04:31,494 - Epoch: [72][   30/   74]    Overall Loss 0.700988    Objective Loss 0.700988                                        LR 0.001000    Time 0.030921    
2022-12-15 15:04:31,742 - Epoch: [72][   40/   74]    Overall Loss 0.692469    Objective Loss 0.692469                                        LR 0.001000    Time 0.029397    
2022-12-15 15:04:31,988 - Epoch: [72][   50/   74]    Overall Loss 0.698910    Objective Loss 0.698910                                        LR 0.001000    Time 0.028417    
2022-12-15 15:04:32,234 - Epoch: [72][   60/   74]    Overall Loss 0.704788    Objective Loss 0.704788                                        LR 0.001000    Time 0.027783    
2022-12-15 15:04:32,474 - Epoch: [72][   70/   74]    Overall Loss 0.711140    Objective Loss 0.711140                                        LR 0.001000    Time 0.027230    
2022-12-15 15:04:32,562 - Epoch: [72][   74/   74]    Overall Loss 0.709179    Objective Loss 0.709179    Top1 79.166667    Top5 96.296296    LR 0.001000    Time 0.026951    
2022-12-15 15:04:32,618 - --- validate (epoch=72)-----------
2022-12-15 15:04:32,619 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:32,890 - Epoch: [72][    9/    9]    Loss 1.249530    Top1 64.217557    Top5 90.314885    
2022-12-15 15:04:32,946 - ==> Top1: 64.218    Top5: 90.315    Loss: 1.250

2022-12-15 15:04:32,948 - ==> Confusion:
[[ 19   0   0   0   0   0   3   0   2   0   0   0   0   0   0   0   1   0   0   0   1   0   0   1   0   0   0   0   0   1   0]
 [  0   7   0   0   4   1   0   1   0   2   0   0   0   0   0   0   0   0  18   0   1   1   0   0   0   0   0   2   0   1   0]
 [  0   1 113   0   4   0   1   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   1  11   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   7   0 105   0  11   0   0   0   0   0   0   1   0   0   0   0   8   0   0   3   0  19   0   0   0   3   0   6   0]
 [  0   0   0   0   2  32   0   0   0   0   0   0   0   0   0   0   5   0   7   0   0   5   0   0   0   0   1   0   2   1   0]
 [  0   0   0   0   1   0 144   0   3   2   0   1   0   0   3   1   0   0   1   0   0   0   1  10   0   0   0   1   0   4   0]
 [  0   4   0   0   0   2   0   2   0   0   0   0   0   2   0   0   1   0   3   0   3   0   0   0   0   0   0   6   0   0   0]
 [  0   0   0   0   0   0   5   0  11   2   0   4   0   0   1   1   0   0   2   0   0   1   0   3   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0  10   0   2   7   0   0   0   0   0   2   0   0   9   0   0   0   0   1   0   0   0   2   0   7   0]
 [  0   0   0   0   0   0   1   0   0   0   3   0   0   0  32   0   1   0   0   0   0   2   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   2   1   0  13   0   1   2   0   0   0   0   0   0   2   2   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   1   0   0   0   0   0  10   0   1   1   0   0   0  10   1   0   0   0   0   0   3   0   5   0]
 [  3   0   0   0   0   0   9   0   0   0   1   5   0   0 157   1   2   0   1   0   0   7   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   8   0   0   3   0   0   0   0   1   7   0   0   2   0   0   0   0   1   0   0   0   4   0   2   0]
 [  2   0   0   0   0   1   0   0   1   0   0   0   0   0   2   2  34   0   3   0   0   6   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0   1   0   0   2   0   0   0   0   0   1   0   0   0]
 [  4   4   2   0   2   0   2   0   4   8   0   1   0   2   0   2   0   0 118   0   1   3   0   2   0   0   0   0   1   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   3   2   0   2   0   0   0   0   0   1   0   0   0   0   3   0  68  11   0   0   0   0   0   7   1  10   0]
 [  0   2   0   0   1   0   0   0   0   1   0   0   0   0  11   0   2   0   8   0   5 144   0   0   0   0   0   0   0   4   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  15   4   0   0   0   0   0   0   0]
 [  0   0   2   0  13   0  16   0   7   1   0   5   0   0   0   0   0   0   2   0   0   0   3  91   0   0   1   0   1   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   0   0   1   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   3   4   0   0   0   0   1   1   0   0   0   0   0   0   0   2   0   0   0   2   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   1   1   5   0   0  56   0   1   0   0]
 [  1   0   1   0   2   2  29   0   1   0   0   0   0   0   2   2   4   0   5   0   3   0   0   3   0   0   0  46   2   5   0]
 [  0   0   0   0   0   0   0   0   1   1   0   1   0   0   0   0   0   0   3   0   0   3   0   8   0   0   0   0   9   0   0]
 [  0   0   0   0   7   0  15   1   0   6   0   0   0   0   0   5   0   0   4   0   1   1   0   6   0   0   0   1   0 133   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   0   2   3   0   0   0   0   0   0   0   0   1]]

2022-12-15 15:04:32,949 - ==> Best [Top1: 65.983   Top5: 91.078   Sparsity:0.00   Params: 364479 on epoch: 71]
2022-12-15 15:04:32,949 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:32,970 - 

2022-12-15 15:04:32,970 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:33,528 - Epoch: [73][   10/   74]    Overall Loss 0.735403    Objective Loss 0.735403                                        LR 0.001000    Time 0.055720    
2022-12-15 15:04:33,770 - Epoch: [73][   20/   74]    Overall Loss 0.716709    Objective Loss 0.716709                                        LR 0.001000    Time 0.039963    
2022-12-15 15:04:34,011 - Epoch: [73][   30/   74]    Overall Loss 0.712028    Objective Loss 0.712028                                        LR 0.001000    Time 0.034662    
2022-12-15 15:04:34,255 - Epoch: [73][   40/   74]    Overall Loss 0.712818    Objective Loss 0.712818                                        LR 0.001000    Time 0.032089    
2022-12-15 15:04:34,498 - Epoch: [73][   50/   74]    Overall Loss 0.704837    Objective Loss 0.704837                                        LR 0.001000    Time 0.030526    
2022-12-15 15:04:34,736 - Epoch: [73][   60/   74]    Overall Loss 0.702506    Objective Loss 0.702506                                        LR 0.001000    Time 0.029390    
2022-12-15 15:04:34,974 - Epoch: [73][   70/   74]    Overall Loss 0.705452    Objective Loss 0.705452                                        LR 0.001000    Time 0.028581    
2022-12-15 15:04:35,060 - Epoch: [73][   74/   74]    Overall Loss 0.704124    Objective Loss 0.704124    Top1 78.703704    Top5 97.916667    LR 0.001000    Time 0.028199    
2022-12-15 15:04:35,122 - --- validate (epoch=73)-----------
2022-12-15 15:04:35,122 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:35,395 - Epoch: [73][    9/    9]    Loss 1.206567    Top1 65.076336    Top5 91.650763    
2022-12-15 15:04:35,452 - ==> Top1: 65.076    Top5: 91.651    Loss: 1.207

2022-12-15 15:04:35,454 - ==> Confusion:
[[ 15   0   0   0   0   0   4   0   1   0   0   0   0   0   0   1   1   0   2   0   1   0   0   1   0   0   0   0   1   1   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  11   0   1   2   0   0   0   0   0   2   0   1   0]
 [  0   0 117   0   3   0   1   0   0   0   0   0   0   0   0   0   0   0   3   0   1   0   0   8   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0   6   0 109   1   4   1   0   0   0   0   0   1   0   0   0   0   6   0   0   3   0  20   0   0   0   4   0  10   0]
 [  0   1   0   0   0  38   0   0   0   0   0   0   0   0   0   0   3   0   4   0   0   5   0   0   0   0   1   1   2   0   0]
 [  0   0   0   0   1   0 135   0   4   2   0   0   0   0   4   1   0   0   1   0   1   0   0  10   0   0   1   2   0  10   0]
 [  0   1   0   0   0   2   0   5   0   0   0   0   0   2   0   0   1   0   1   0   6   0   0   0   0   0   0   4   0   1   0]
 [  0   0   0   0   0   0   8   0   5   4   0   4   0   0   0   1   0   0   3   0   0   1   0   5   0   0   0   1   1   0   0]
 [  2   0   0   0   0   0   7   0   0  11   0   0   0   0   0   1   0   0   6   0   1   1   0   1   0   0   0   2   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0   4   0   0   0  30   0   1   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   2   1   0  11   0   0   3   0   0   0   1   0   1   1   2   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0   0   8   0   0   1   0   0   0  16   1   0   0   0   0   0   2   0   4   0]
 [  1   0   0   0   0   0   6   0   0   0   0   4   0   0 162   1   3   0   1   0   0   8   0   0   0   0   1   2   0   0   0]
 [  2   0   0   0   0   0   7   0   0   2   0   0   0   0   3   5   0   0   3   0   1   0   0   2   0   0   0   4   0   2   0]
 [  1   0   0   0   0   2   0   1   0   0   0   0   0   1   2   2  33   0   4   0   0   6   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0   1   0   1   3   0   0   0   0   0   0   0   0   0]
 [  2   5   1   0   1   0   2   0   0   2   0   1   0   1   0   2   0   0 122   0   3   9   0   2   0   0   0   0   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   2   0   2   0   0   0   0   0   1   1   0   1   0   0   0  77  12   0   0   0   0   0   3   0   6   0]
 [  0   0   0   0   0   0   0   0   0   1   0   0   0   0  13   0   2   0   5   0   8 144   0   0   0   0   0   0   0   5   0]
 [  1   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  11   4   0   0   1   0   2   0   0]
 [  1   0   5   0  15   0  16   0   2   1   0   4   0   0   0   0   0   0   6   0   0   2   4  85   0   0   1   1   1   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   3   0]
 [  0   0   0   0   0   0   1   0   0   4   0   0   0   0   1   1   0   0   2   0   1   0   0   1   0   0   0   2   0   1   0]
 [  0   0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   1   0   4   0   0  59   0   1   0   0]
 [  0   0   0   0   4   2  18   0   1   2   0   0   0   0   4   0   3   0   3   0   6   0   0   2   0   0   0  54   1   8   0]
 [  0   0   0   0   0   0   0   0   0   1   0   2   0   0   2   0   1   0   6   0   0   2   1   7   0   0   0   1   3   0   0]
 [  0   0   0   0   6   0   9   1   0   3   0   0   0   0   0   3   0   0   4   0   3   3   0   5   0   0   0   4   0 139   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   1]]

2022-12-15 15:04:35,455 - ==> Best [Top1: 65.983   Top5: 91.078   Sparsity:0.00   Params: 364479 on epoch: 71]
2022-12-15 15:04:35,455 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:35,465 - 

2022-12-15 15:04:35,465 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:35,865 - Epoch: [74][   10/   74]    Overall Loss 0.671713    Objective Loss 0.671713                                        LR 0.001000    Time 0.039861    
2022-12-15 15:04:36,106 - Epoch: [74][   20/   74]    Overall Loss 0.656329    Objective Loss 0.656329                                        LR 0.001000    Time 0.032006    
2022-12-15 15:04:36,352 - Epoch: [74][   30/   74]    Overall Loss 0.664244    Objective Loss 0.664244                                        LR 0.001000    Time 0.029466    
2022-12-15 15:04:36,595 - Epoch: [74][   40/   74]    Overall Loss 0.666487    Objective Loss 0.666487                                        LR 0.001000    Time 0.028164    
2022-12-15 15:04:36,837 - Epoch: [74][   50/   74]    Overall Loss 0.679002    Objective Loss 0.679002                                        LR 0.001000    Time 0.027363    
2022-12-15 15:04:37,080 - Epoch: [74][   60/   74]    Overall Loss 0.686636    Objective Loss 0.686636                                        LR 0.001000    Time 0.026840    
2022-12-15 15:04:37,317 - Epoch: [74][   70/   74]    Overall Loss 0.690933    Objective Loss 0.690933                                        LR 0.001000    Time 0.026399    
2022-12-15 15:04:37,405 - Epoch: [74][   74/   74]    Overall Loss 0.695009    Objective Loss 0.695009    Top1 79.166667    Top5 95.833333    LR 0.001000    Time 0.026157    
2022-12-15 15:04:37,471 - --- validate (epoch=74)-----------
2022-12-15 15:04:37,472 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:37,752 - Epoch: [74][    9/    9]    Loss 1.195155    Top1 64.599237    Top5 91.269084    
2022-12-15 15:04:37,808 - ==> Top1: 64.599    Top5: 91.269    Loss: 1.195

2022-12-15 15:04:37,810 - ==> Confusion:
[[ 18   0   0   0   0   0   3   0   1   0   0   0   0   0   0   0   1   0   1   0   1   0   0   2   0   0   0   0   0   1   0]
 [  0   4   0   0   8   3   0   2   0   1   0   0   0   0   0   0   0   0  14   0   1   2   0   1   0   0   0   1   0   1   0]
 [  0   0 111   0   8   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   1   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   4   0 122   1   0   0   0   0   0   0   0   1   0   1   0   0   6   0   0   3   0  16   0   0   0   2   1   5   0]
 [  0   1   0   0   1  39   0   0   0   0   0   0   0   0   1   0   2   0   5   0   0   4   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   2   0 115   0   3   2   0   1   0   0   2   1   0   0   3   0   0   0   0  23   0   0   1  13   0   6   0]
 [  0   5   0   0   0   2   0   4   0   0   0   0   0   1   0   0   0   0   1   0   4   0   0   0   0   0   0   5   0   1   0]
 [  1   0   0   0   0   0   4   0   7   3   0   3   0   0   0   1   0   0   2   0   0   1   0   9   0   0   0   2   0   0   0]
 [  1   0   0   0   0   0   4   0   3   7   0   0   0   0   0   1   0   0   9   0   0   0   0   3   0   0   0   5   0   8   0]
 [  0   0   0   0   0   0   0   0   0   0   5   0   0   0  28   0   0   0   1   0   0   5   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   3   0   1   1   0  13   0   0   1   0   0   0   0   0   0   2   1   0   0   0   1   0   2   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0   8   0   0   1   0   1   0  14   0   0   0   0   0   0   1   0   7   0]
 [  3   0   0   0   0   0   5   0   0   0   2   7   0   0 155   1   1   0   2   0   0   8   0   0   0   0   1   3   1   0   0]
 [  3   0   0   0   0   0   4   0   0   0   0   0   0   0   1   4   0   0   6   0   0   0   0   2   0   0   0   8   1   2   0]
 [  4   0   0   0   0   2   0   0   0   0   0   0   0   0   1   1  36   0   4   0   0   4   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   3   0   0   0   0   0   0   1   0   0]
 [  3  10   1   0   4   0   0   0   4   0   0   0   0   1   0   1   0   0 124   0   0   3   0   2   0   0   0   0   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   4   3   0   5   0   0   0   0   0   0   1   0   1   0   1   0  71  11   0   0   0   0   0   2   0   7   0]
 [  0   2   0   0   2   0   0   0   0   2   0   0   0   0   8   0   2   0   7   0   5 147   0   0   0   0   2   0   0   1   0]
 [  1   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  12   4   0   0   0   0   0   0   0]
 [  0   0   3   0  16   0   6   0   3   0   0   4   0   0   0   0   0   0   5   0   0   1   3  95   0   0   1   4   3   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   2   0]
 [  0   0   0   0   0   0   0   0   0   6   0   0   0   0   0   0   0   0   3   0   0   1   0   2   0   0   0   2   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   1   0   4   0   0  58   0   1   0   0]
 [  0   0   0   0   5   4   8   0   0   2   0   0   0   1   1   2   3   0   5   0   6   0   0   4   0   0   0  58   2   7   0]
 [  0   1   0   0   0   1   0   0   0   1   0   1   0   0   0   0   0   0   3   0   0   2   0   9   0   0   0   1   7   0   0]
 [  0   0   0   0   9   0   6   1   0   5   0   0   0   0   0   2   0   0   6   0   1   3   0   7   0   0   0  10   0 130   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:04:37,812 - ==> Best [Top1: 65.983   Top5: 91.078   Sparsity:0.00   Params: 364479 on epoch: 71]
2022-12-15 15:04:37,812 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:37,832 - 

2022-12-15 15:04:37,832 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:38,239 - Epoch: [75][   10/   74]    Overall Loss 0.664966    Objective Loss 0.664966                                        LR 0.001000    Time 0.040641    
2022-12-15 15:04:38,489 - Epoch: [75][   20/   74]    Overall Loss 0.676037    Objective Loss 0.676037                                        LR 0.001000    Time 0.032786    
2022-12-15 15:04:38,759 - Epoch: [75][   30/   74]    Overall Loss 0.660810    Objective Loss 0.660810                                        LR 0.001000    Time 0.030846    
2022-12-15 15:04:39,025 - Epoch: [75][   40/   74]    Overall Loss 0.660017    Objective Loss 0.660017                                        LR 0.001000    Time 0.029778    
2022-12-15 15:04:39,294 - Epoch: [75][   50/   74]    Overall Loss 0.657472    Objective Loss 0.657472                                        LR 0.001000    Time 0.029187    
2022-12-15 15:04:39,561 - Epoch: [75][   60/   74]    Overall Loss 0.657361    Objective Loss 0.657361                                        LR 0.001000    Time 0.028755    
2022-12-15 15:04:39,812 - Epoch: [75][   70/   74]    Overall Loss 0.662231    Objective Loss 0.662231                                        LR 0.001000    Time 0.028240    
2022-12-15 15:04:39,899 - Epoch: [75][   74/   74]    Overall Loss 0.663497    Objective Loss 0.663497    Top1 80.092593    Top5 96.990741    LR 0.001000    Time 0.027881    
2022-12-15 15:04:39,958 - --- validate (epoch=75)-----------
2022-12-15 15:04:39,958 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:40,231 - Epoch: [75][    9/    9]    Loss 1.202176    Top1 65.410305    Top5 90.648855    
2022-12-15 15:04:40,278 - ==> Top1: 65.410    Top5: 90.649    Loss: 1.202

2022-12-15 15:04:40,280 - ==> Confusion:
[[ 16   1   0   0   0   0   3   0   1   0   0   1   0   0   1   0   1   0   0   0   0   0   0   1   0   0   0   2   1   0   0]
 [  0   8   0   0   5   3   0   2   0   2   0   0   0   0   0   0   0   0  15   0   1   1   0   0   0   0   0   1   0   0   0]
 [  0   1 114   0   5   0   1   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0  10   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 110   0   1   0   0   1   0   0   0   1   0   1   0   0   7   0   0   3   0  20   0   0   0   6   1   4   0]
 [  0   1   0   0   1  40   0   0   0   0   0   0   0   0   0   0   1   0   4   0   0   5   0   0   0   0   1   0   2   0   0]
 [  0   0   0   0   1   0 126   0   5   3   0   2   0   0   5   1   0   0   2   0   0   0   0  12   0   0   1   7   1   6   0]
 [  0   4   0   0   0   2   0   5   0   0   0   0   0   1   0   0   1   0   1   0   4   0   0   0   0   0   0   5   0   0   0]
 [  0   0   0   0   0   0   5   0  10   3   0   2   0   0   0   0   0   0   3   0   0   1   0   5   0   0   0   2   2   0   0]
 [  1   0   0   0   0   0   4   0   2  13   0   0   0   0   0   0   0   0  11   0   0   0   0   1   0   0   0   2   0   7   0]
 [  0   0   0   0   0   0   0   0   0   0   5   0   0   0  28   0   1   0   1   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  15   0   0   0   0   0   0   0   0   0   2   2   0   0   0   1   0   2   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   2   0   0   1   0   0   0   0   0   7   0   1   1   0   0   0  16   1   0   0   0   0   0   1   0   3   0]
 [  2   0   0   0   0   1   3   0   2   0   1   5   0   0 160   2   2   0   0   0   0   8   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   4   0   0   4   0   0   0   0   1   0   0   0   5   0   2   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   1   2  34   0   6   0   0   5   0   0   0   0   0   1   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   4   0   0   0   0   0   0   1   0   0]
 [  3   6   0   0   1   0   1   1   2   4   0   1   0   1   0   1   1   0 125   0   2   4   0   2   0   0   0   0   2   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   1   0   4   6   0   2   0   0   0   0   0   1   0   0   1   0   2   0  70  11   0   0   0   0   1   3   0   4   0]
 [  0   3   0   0   2   0   1   0   0   1   0   0   0   0  11   0   2   0   7   0   5 144   0   0   0   0   1   0   0   1   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   3   0   0   1   1   1   0   0]
 [  0   0   1   0  15   0   7   0   1   1   0   5   0   0   0   0   0   0   7   0   0   0   3 100   0   0   2   2   1   4   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   0   0   1   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   5   0   0   0   0   1   0   0   0   3   0   1   0   0   2   0   0   0   2   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   0   5   0   0  57   0   1   0   0]
 [  0   0   0   0   3   3  17   0   1   2   0   0   0   0   3   0   3   0   5   0   3   1   0   3   0   0   0  60   1   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   5   0   0   3   0   7   0   0   0   1   9   0   0]
 [  0   0   0   0   9   1   7   2   0   5   0   0   0   0   0   4   0   0  13   0   2   2   0   7   0   0   0   5   1 122   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   2]]

2022-12-15 15:04:40,281 - ==> Best [Top1: 65.983   Top5: 91.078   Sparsity:0.00   Params: 364479 on epoch: 71]
2022-12-15 15:04:40,281 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:40,301 - 

2022-12-15 15:04:40,301 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:40,707 - Epoch: [76][   10/   74]    Overall Loss 0.653134    Objective Loss 0.653134                                        LR 0.001000    Time 0.040426    
2022-12-15 15:04:40,952 - Epoch: [76][   20/   74]    Overall Loss 0.653365    Objective Loss 0.653365                                        LR 0.001000    Time 0.032445    
2022-12-15 15:04:41,216 - Epoch: [76][   30/   74]    Overall Loss 0.650514    Objective Loss 0.650514                                        LR 0.001000    Time 0.030442    
2022-12-15 15:04:41,479 - Epoch: [76][   40/   74]    Overall Loss 0.649462    Objective Loss 0.649462                                        LR 0.001000    Time 0.029394    
2022-12-15 15:04:41,743 - Epoch: [76][   50/   74]    Overall Loss 0.647603    Objective Loss 0.647603                                        LR 0.001000    Time 0.028777    
2022-12-15 15:04:42,006 - Epoch: [76][   60/   74]    Overall Loss 0.647676    Objective Loss 0.647676                                        LR 0.001000    Time 0.028372    
2022-12-15 15:04:42,250 - Epoch: [76][   70/   74]    Overall Loss 0.650461    Objective Loss 0.650461                                        LR 0.001000    Time 0.027801    
2022-12-15 15:04:42,338 - Epoch: [76][   74/   74]    Overall Loss 0.651031    Objective Loss 0.651031    Top1 81.250000    Top5 98.148148    LR 0.001000    Time 0.027480    
2022-12-15 15:04:42,396 - --- validate (epoch=76)-----------
2022-12-15 15:04:42,397 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:42,672 - Epoch: [76][    9/    9]    Loss 1.184109    Top1 64.599237    Top5 91.507634    
2022-12-15 15:04:42,728 - ==> Top1: 64.599    Top5: 91.508    Loss: 1.184

2022-12-15 15:04:42,730 - ==> Confusion:
[[ 16   1   0   0   0   0   3   0   2   0   0   1   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   1   0   0   0]
 [  0   8   0   0   4   3   0   1   0   1   0   0   0   0   0   0   0   0  14   0   2   1   0   0   0   0   0   3   0   1   0]
 [  0   0 114   0   8   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   0   1   0   7   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1   6   0 114   2   5   1   0   0   0   0   0   1   0   0   0   0   4   0   0   3   0  12   0   0   0   9   0   7   0]
 [  0   0   0   0   1  43   0   0   0   1   0   0   0   0   0   0   3   0   3   0   0   2   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   1   0 139   0   1   1   0   0   0   0   1   1   0   0   3   0   0   0   0  11   0   0   1   9   0   4   0]
 [  0   2   0   0   0   2   0   7   0   0   0   0   0   2   0   0   0   0   1   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0  11   3   0   1   0   0   0   1   0   0   2   0   0   1   0   3   0   0   0   4   0   0   0]
 [  1   0   0   0   0   0   8   0   1  10   0   0   0   0   1   1   0   0   5   0   0   0   0   0   0   0   0   5   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0   5   0   0   0  29   0   0   0   1   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   3   0   1   1   0  13   0   1   1   0   0   0   1   0   0   2   2   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   1   0   1   0  14   0   0   0   0   0   0   2   0   3   0]
 [  1   0   0   0   0   0  12   0   2   0   2   3   0   0 155   1   2   0   1   0   0   5   0   1   0   0   1   2   1   0   0]
 [  1   0   0   0   0   0   6   0   0   2   0   0   0   0   3   3   0   0   3   0   0   0   0   1   0   0   0   9   0   3   0]
 [  1   0   0   0   0   3   0   0   0   1   0   0   0   0   0   3  35   0   4   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   2   0   0   0   0   0   0   1   0   0]
 [  5   4   1   0   2   1   2   1   3   7   0   0   0   0   0   1   1   0 113   0   2   2   0   1   1   0   0   3   3   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   3   2   0   1   0   0   0   0   0   0   0   0   1   0   2   0  74  11   0   0   0   0   0   6   0   8   0]
 [  0   2   0   0   0   0   0   1   0   1   0   1   0   0  11   0   6   0   9   0   4 138   0   0   0   0   1   0   0   4   0]
 [  1   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  13   3   0   0   1   0   1   0   0]
 [  0   0   2   0  15   0  25   0   4   0   0   3   0   0   0   0   0   0   5   0   0   1   2  76   0   0   2   5   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   2   0]
 [  0   0   0   0   0   0   1   0   0   6   0   0   0   0   1   0   0   0   1   0   0   0   0   1   0   0   0   4   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   1   6   0   0  56   0   0   0   0]
 [  0   0   1   0   2   2  18   0   1   1   0   0   0   0   3   2   4   0   6   0   4   0   0   1   0   0   0  58   0   5   0]
 [  0   0   0   0   0   0   0   0   2   1   0   1   0   0   1   0   1   0   6   0   0   2   0   6   0   0   0   1   5   0   0]
 [  0   0   0   0   8   0   8   1   0   6   0   0   0   2   0   3   0   0   2   0   2   1   0   2   0   0   0  11   0 134   0]
 [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   2   0   0   0   0   0   2   3   0   0   0   0   0   0   0   0   2]]

2022-12-15 15:04:42,732 - ==> Best [Top1: 65.983   Top5: 91.078   Sparsity:0.00   Params: 364479 on epoch: 71]
2022-12-15 15:04:42,732 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:42,752 - 

2022-12-15 15:04:42,752 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:43,198 - Epoch: [77][   10/   74]    Overall Loss 0.591010    Objective Loss 0.591010                                        LR 0.001000    Time 0.044445    
2022-12-15 15:04:43,452 - Epoch: [77][   20/   74]    Overall Loss 0.613997    Objective Loss 0.613997                                        LR 0.001000    Time 0.034940    
2022-12-15 15:04:43,704 - Epoch: [77][   30/   74]    Overall Loss 0.618571    Objective Loss 0.618571                                        LR 0.001000    Time 0.031658    
2022-12-15 15:04:43,954 - Epoch: [77][   40/   74]    Overall Loss 0.618561    Objective Loss 0.618561                                        LR 0.001000    Time 0.029981    
2022-12-15 15:04:44,198 - Epoch: [77][   50/   74]    Overall Loss 0.627073    Objective Loss 0.627073                                        LR 0.001000    Time 0.028866    
2022-12-15 15:04:44,441 - Epoch: [77][   60/   74]    Overall Loss 0.630307    Objective Loss 0.630307                                        LR 0.001000    Time 0.028094    
2022-12-15 15:04:44,680 - Epoch: [77][   70/   74]    Overall Loss 0.630714    Objective Loss 0.630714                                        LR 0.001000    Time 0.027491    
2022-12-15 15:04:44,766 - Epoch: [77][   74/   74]    Overall Loss 0.634641    Objective Loss 0.634641    Top1 79.398148    Top5 95.833333    LR 0.001000    Time 0.027160    
2022-12-15 15:04:44,827 - --- validate (epoch=77)-----------
2022-12-15 15:04:44,827 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:45,098 - Epoch: [77][    9/    9]    Loss 1.207305    Top1 65.601145    Top5 91.364504    
2022-12-15 15:04:45,154 - ==> Top1: 65.601    Top5: 91.365    Loss: 1.207

2022-12-15 15:04:45,156 - ==> Confusion:
[[ 17   0   0   0   0   0   4   0   1   0   0   0   0   0   1   1   1   0   0   0   1   0   0   1   0   0   0   0   0   1   0]
 [  0   9   0   0   8   2   0   1   0   1   0   0   0   0   0   0   0   0  10   0   1   2   0   0   0   0   0   1   0   3   0]
 [  0   0 113   0   8   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   7   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   4   0 133   0   4   0   0   0   0   0   0   1   0   0   0   0   3   0   0   3   0   4   0   0   0   4   0   7   0]
 [  0   1   0   0   1  40   0   1   0   0   0   0   0   0   0   0   2   0   5   0   0   3   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   4   0 130   0   2   2   0   1   0   0   3   0   0   0   0   0   0   0   1   9   0   0   0   6   0  14   0]
 [  0   4   0   0   1   1   0   7   0   0   0   0   0   2   0   0   0   0   1   0   2   0   0   0   0   0   0   5   0   0   0]
 [  0   0   0   0   0   0  11   0   6   4   0   1   0   0   0   1   0   0   3   0   0   1   0   5   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   6   0   0  12   0   0   0   0   0   2   0   0   5   0   1   1   0   1   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0   7   0   0   0  26   0   0   0   1   0   0   5   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   3   0   0   1   0  14   0   1   1   0   0   0   1   0   0   3   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0   0  11   0   0   0   0   0   0  16   0   0   0   0   0   0   2   0   3   0]
 [  1   0   0   0   0   0  10   0   2   0   1   2   0   0 158   2   4   0   1   0   0   7   0   0   0   0   0   1   0   0   0]
 [  3   0   0   0   0   0   7   0   0   3   0   0   0   0   3   4   0   0   2   0   1   0   0   1   0   0   0   5   0   2   0]
 [  0   0   0   0   0   3   0   0   0   0   1   0   0   1   1   2  33   0   5   0   0   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   3   0   0   0   1   2   0   0   0   0   0   0   1   0   0]
 [  2   9   1   0   6   0   2   0   2   3   0   0   0   2   1   2   1   0 115   0   2   4   0   0   0   0   0   1   0   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   4   2   0   5   0   0   0   0   0   1   0   0   1   0   1   0  75  11   0   0   0   0   0   2   0   6   0]
 [  0   2   0   0   3   0   0   0   0   0   0   0   0   0  12   0   3   0   7   0   7 142   0   0   0   0   0   0   0   2   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0  12   4   0   0   0   0   0   0   0]
 [  0   0   5   0  21   0  18   0   2   0   0   4   0   0   0   0   0   0   6   0   0   2   1  80   0   0   1   2   1   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   2   0]
 [  0   0   0   0   0   0   1   0   0   6   0   0   0   0   1   0   0   0   0   0   1   0   0   1   0   0   0   2   0   2   0]
 [  0   0   1   0   0   0   1   0   0   0   0   3   0   0   0   0   0   0   0   0   0   1   1   5   0   0  56   0   0   0   0]
 [  0   0   0   0   6   4  16   0   1   0   0   0   0   0   3   3   2   0   4   0   5   0   0   1   0   0   0  55   0   8   0]
 [  0   0   1   0   1   1   0   0   0   1   0   1   0   0   1   0   0   0   7   0   0   2   0   6   0   0   0   1   4   0   0]
 [  0   0   0   0  13   1   7   2   0   3   0   0   0   0   0   2   0   0   3   0   4   0   0   2   0   0   0   6   0 137   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   3   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:04:45,158 - ==> Best [Top1: 65.983   Top5: 91.078   Sparsity:0.00   Params: 364479 on epoch: 71]
2022-12-15 15:04:45,158 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:45,178 - 

2022-12-15 15:04:45,178 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:45,565 - Epoch: [78][   10/   74]    Overall Loss 0.613088    Objective Loss 0.613088                                        LR 0.001000    Time 0.038615    
2022-12-15 15:04:45,799 - Epoch: [78][   20/   74]    Overall Loss 0.615582    Objective Loss 0.615582                                        LR 0.001000    Time 0.030960    
2022-12-15 15:04:46,055 - Epoch: [78][   30/   74]    Overall Loss 0.616976    Objective Loss 0.616976                                        LR 0.001000    Time 0.029179    
2022-12-15 15:04:46,301 - Epoch: [78][   40/   74]    Overall Loss 0.619675    Objective Loss 0.619675                                        LR 0.001000    Time 0.028026    
2022-12-15 15:04:46,546 - Epoch: [78][   50/   74]    Overall Loss 0.618553    Objective Loss 0.618553                                        LR 0.001000    Time 0.027307    
2022-12-15 15:04:46,789 - Epoch: [78][   60/   74]    Overall Loss 0.621717    Objective Loss 0.621717                                        LR 0.001000    Time 0.026795    
2022-12-15 15:04:47,028 - Epoch: [78][   70/   74]    Overall Loss 0.622674    Objective Loss 0.622674                                        LR 0.001000    Time 0.026377    
2022-12-15 15:04:47,109 - Epoch: [78][   74/   74]    Overall Loss 0.620161    Objective Loss 0.620161    Top1 82.870370    Top5 97.916667    LR 0.001000    Time 0.026043    
2022-12-15 15:04:47,168 - --- validate (epoch=78)-----------
2022-12-15 15:04:47,168 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:47,441 - Epoch: [78][    9/    9]    Loss 1.195590    Top1 66.650763    Top5 91.459924    
2022-12-15 15:04:47,509 - ==> Top1: 66.651    Top5: 91.460    Loss: 1.196

2022-12-15 15:04:47,511 - ==> Confusion:
[[ 17   1   0   0   0   0   2   0   1   0   0   2   0   0   0   2   1   0   0   0   0   0   0   0   0   0   0   2   0   0   0]
 [  0  11   0   0   4   2   0   2   0   2   0   0   0   0   0   0   0   0  14   0   1   1   0   0   0   0   0   1   0   0   0]
 [  0   0 114   0   7   1   1   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   6   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   6   0 124   0   5   0   0   0   0   0   0   1   0   1   0   0   4   0   0   4   0   4   0   0   0   5   1   6   0]
 [  0   1   0   0   1  42   0   0   0   0   0   0   0   0   0   0   3   0   4   0   0   1   0   0   0   0   1   0   1   1   0]
 [  0   0   0   0   2   0 134   0   1   4   0   1   0   0   3   1   0   0   3   0   0   0   0  10   0   0   1   6   0   6   0]
 [  0   3   0   0   0   2   0   7   0   0   0   0   0   1   0   0   1   0   1   0   3   0   0   0   0   0   0   4   0   1   0]
 [  0   0   0   0   0   0   5   0  15   3   0   1   0   0   0   1   0   0   2   0   0   1   0   2   0   0   0   3   0   0   0]
 [  0   0   0   0   0   0   5   0   1  14   0   0   0   0   0   2   0   0   8   0   2   0   0   0   0   0   0   2   0   7   0]
 [  0   0   0   0   0   0   0   0   0   0   7   0   0   0  25   0   0   0   1   0   0   6   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   2   0  11   0   0   1   0   0   0   1   0   0   4   2   1   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   2   0   0   0   0   0  13   0   0   1   0   1   0  11   1   0   0   0   0   0   1   0   3   0]
 [  1   0   0   0   0   1   4   0   2   0   2   4   0   0 156   1   3   0   2   0   0  11   0   0   0   0   1   1   0   0   0]
 [  2   0   0   0   0   0   5   0   0   5   0   0   0   0   3   3   0   0   3   0   0   0   0   1   0   0   0   8   0   1   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   1   2  37   0   6   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   3   0   0   0   0   0   0   1   0   0]
 [  3   5   1   0   1   1   1   2   3   2   0   0   0   1   0   0   2   0 125   0   0   4   0   0   0   0   0   1   1   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   2   3   0   3   0   0   0   0   0   1   1   0   1   0   2   0  68  14   0   0   0   0   0   5   0   8   0]
 [  0   3   0   0   1   0   0   0   0   1   0   0   0   0   4   0   5   0   7   0   4 149   0   0   0   0   1   0   0   3   0]
 [  1   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  13   2   0   0   0   0   0   0   0]
 [  2   0   2   0  23   0  18   0   6   0   0   3   0   0   0   0   0   0   5   0   0   1   4  74   0   0   1   4   1   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   6   0   0   0   0   1   0   0   0   3   0   0   0   0   0   0   0   0   3   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   2   0   4   0   0  55   0   1   0   0]
 [  0   0   1   0   3   2  13   0   1   2   0   0   0   1   3   2   2   0   4   0   5   2   0   1   0   0   0  59   0   7   0]
 [  0   1   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0   7   0   0   3   0   7   0   0   0   0   6   0   0]
 [  0   0   0   0   7   0   8   1   0   5   0   0   0   1   0   4   0   0   8   0   1   1   0   3   1   0   0   3   0 137   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:04:47,512 - ==> Best [Top1: 66.651   Top5: 91.460   Sparsity:0.00   Params: 364478 on epoch: 78]
2022-12-15 15:04:47,512 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:47,544 - 

2022-12-15 15:04:47,544 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:47,965 - Epoch: [79][   10/   74]    Overall Loss 0.590935    Objective Loss 0.590935                                        LR 0.001000    Time 0.041988    
2022-12-15 15:04:48,203 - Epoch: [79][   20/   74]    Overall Loss 0.586042    Objective Loss 0.586042                                        LR 0.001000    Time 0.032886    
2022-12-15 15:04:48,446 - Epoch: [79][   30/   74]    Overall Loss 0.587023    Objective Loss 0.587023                                        LR 0.001000    Time 0.030018    
2022-12-15 15:04:48,689 - Epoch: [79][   40/   74]    Overall Loss 0.587793    Objective Loss 0.587793                                        LR 0.001000    Time 0.028583    
2022-12-15 15:04:48,932 - Epoch: [79][   50/   74]    Overall Loss 0.587693    Objective Loss 0.587693                                        LR 0.001000    Time 0.027711    
2022-12-15 15:04:49,174 - Epoch: [79][   60/   74]    Overall Loss 0.596545    Objective Loss 0.596545                                        LR 0.001000    Time 0.027124    
2022-12-15 15:04:49,408 - Epoch: [79][   70/   74]    Overall Loss 0.603573    Objective Loss 0.603573                                        LR 0.001000    Time 0.026579    
2022-12-15 15:04:49,493 - Epoch: [79][   74/   74]    Overall Loss 0.603544    Objective Loss 0.603544    Top1 82.407407    Top5 96.990741    LR 0.001000    Time 0.026296    
2022-12-15 15:04:49,556 - --- validate (epoch=79)-----------
2022-12-15 15:04:49,556 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:49,829 - Epoch: [79][    9/    9]    Loss 1.233223    Top1 66.030534    Top5 91.078244    
2022-12-15 15:04:49,877 - ==> Top1: 66.031    Top5: 91.078    Loss: 1.233

2022-12-15 15:04:49,879 - ==> Confusion:
[[ 19   0   0   0   0   0   3   0   0   0   0   1   0   0   1   1   1   0   0   0   1   0   0   0   0   0   0   1   0   0   0]
 [  0   7   1   0   5   1   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   3   0   1   0   0   0   1   0   1   0]
 [  0   0 120   0   2   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   0   1   0   7   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  1   5   9   0 109   0   3   0   0   0   0   0   0   1   0   1   0   0   5   0   0   4   1  16   0   0   0   4   1   5   0]
 [  0   1   0   0   3  37   0   0   0   0   0   0   0   0   0   0   1   0   5   0   0   5   0   0   0   0   1   0   2   0   0]
 [  0   0   0   0   1   0 123   0   2   3   0   3   0   0   4   4   0   0   3   0   0   0   1  18   0   0   0   4   0   6   0]
 [  0   3   0   0   1   2   0   5   0   0   0   0   0   2   0   0   1   0   1   0   4   0   0   0   0   0   0   4   0   0   0]
 [  0   0   0   0   0   0   5   0   9   2   0   7   0   0   1   0   0   0   2   0   0   1   0   4   0   0   0   2   0   0   0]
 [  0   0   0   0   0   0   3   0   1  14   0   0   0   0   2   2   0   0   8   0   2   1   0   0   0   0   0   0   0   8   0]
 [  0   0   0   0   0   0   0   0   0   0   7   0   0   0  29   0   0   0   1   0   0   2   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  13   0   0   3   0   0   0   1   0   0   1   2   0   0   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   2   0   0   0   0   0  13   0   0   1   0   0   0  12   1   0   0   0   0   0   1   0   2   0]
 [  1   0   0   0   0   1   6   0   2   0   1   6   0   0 161   1   3   0   0   0   0   6   0   0   0   0   0   1   0   0   0]
 [  3   0   0   0   1   0   4   0   0   4   0   0   0   0   4   5   0   0   3   0   0   0   0   2   0   0   0   3   0   2   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   1   2  36   0   5   0   1   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   4   0   0   0   0   0   0   1   0   0]
 [  2   6   1   0   1   0   1   0   4   4   0   1   0   1   1   1   1   0 120   0   2   4   0   1   0   0   0   1   4   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   5   0   2   0   0   0   0   0   1   0   0   0   0   1   0  71  16   0   0   0   0   0   3   0   6   0]
 [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   8   0   3   0   8   0   4 148   0   0   0   0   1   0   1   3   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0  15   3   0   0   0   0   0   0   0]
 [  0   0   2   0  13   0  11   0   6   1   0   5   0   0   0   0   0   0   4   0   0   1   2  95   0   0   1   1   0   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   1   0   0   3   0   0   1   0   2   0   0   0   2   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   4   0   0  57   0   0   0   0]
 [  0   0   1   0   2   3  13   0   1   2   0   0   0   1   2   4   1   0   5   0   2   1   0   1   0   0   0  60   1   8   0]
 [  0   0   0   0   0   1   0   0   0   0   0   1   0   0   1   0   0   0   5   0   0   3   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   6   0   6   2   0   5   0   0   0   0   0   5   0   0  11   0   3   2   0   7   1   0   0   2   1 129   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   1]]

2022-12-15 15:04:49,881 - ==> Best [Top1: 66.651   Top5: 91.460   Sparsity:0.00   Params: 364478 on epoch: 78]
2022-12-15 15:04:49,881 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:49,901 - 

2022-12-15 15:04:49,901 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:50,443 - Epoch: [80][   10/   74]    Overall Loss 0.583597    Objective Loss 0.583597                                        LR 0.001000    Time 0.054148    
2022-12-15 15:04:50,697 - Epoch: [80][   20/   74]    Overall Loss 0.612730    Objective Loss 0.612730                                        LR 0.001000    Time 0.039735    
2022-12-15 15:04:50,956 - Epoch: [80][   30/   74]    Overall Loss 0.605456    Objective Loss 0.605456                                        LR 0.001000    Time 0.035054    
2022-12-15 15:04:51,227 - Epoch: [80][   40/   74]    Overall Loss 0.604539    Objective Loss 0.604539                                        LR 0.001000    Time 0.033009    
2022-12-15 15:04:51,483 - Epoch: [80][   50/   74]    Overall Loss 0.603402    Objective Loss 0.603402                                        LR 0.001000    Time 0.031520    
2022-12-15 15:04:51,749 - Epoch: [80][   60/   74]    Overall Loss 0.602579    Objective Loss 0.602579                                        LR 0.001000    Time 0.030705    
2022-12-15 15:04:52,001 - Epoch: [80][   70/   74]    Overall Loss 0.600703    Objective Loss 0.600703                                        LR 0.001000    Time 0.029906    
2022-12-15 15:04:52,088 - Epoch: [80][   74/   74]    Overall Loss 0.598744    Objective Loss 0.598744    Top1 82.870370    Top5 97.453704    LR 0.001000    Time 0.029462    
2022-12-15 15:04:52,148 - --- validate (epoch=80)-----------
2022-12-15 15:04:52,148 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:52,418 - Epoch: [80][    9/    9]    Loss 1.216202    Top1 65.458015    Top5 91.078244    
2022-12-15 15:04:52,468 - ==> Top1: 65.458    Top5: 91.078    Loss: 1.216

2022-12-15 15:04:52,470 - ==> Confusion:
[[ 19   0   0   0   0   0   1   0   1   1   0   0   0   1   1   0   1   0   1   0   0   0   0   1   0   0   0   0   0   1   0]
 [  0  11   0   0   3   3   0   2   0   2   0   0   0   0   0   0   0   0  14   0   1   1   0   0   0   0   0   1   0   0   0]
 [  0   1 112   0  11   0   1   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   6   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   6   7   0 116   1   6   0   0   0   0   0   0   1   0   0   0   0   8   0   0   2   0   9   0   0   0   2   1   6   0]
 [  0   1   0   0   1  42   0   0   0   0   0   0   0   0   0   0   2   0   5   0   0   2   0   0   0   0   1   0   1   0   0]
 [  0   0   2   0   3   0 127   0   3   3   0   0   0   0   3   1   0   0   2   0   0   0   0  14   0   0   0   4   0  10   0]
 [  0   4   0   0   0   2   0   6   0   0   0   0   0   2   0   0   0   0   1   0   2   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   8   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   1   0   1   0]
 [  2   0   0   0   0   0   5   0   1   8   0   0   0   0   1   0   0   0  11   0   0   1   0   1   0   0   0   3   0   8   0]
 [  0   0   0   0   0   0   0   0   0   0   4   0   0   0  30   0   2   0   1   0   0   2   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   3   0   1   1   0  11   0   0   2   0   0   0   1   0   1   3   2   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   2   0   0   0   0   0  11   0   0   0   0   1   0  13   1   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   0   1   5   0   2   0   3   2   0   0 163   1   0   0   0   0   0   6   0   0   0   0   1   2   1   0   0]
 [  3   0   0   0   0   0   5   0   0   4   0   0   0   0   2   3   0   0   3   0   0   0   0   2   0   0   0   6   0   3   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   1   1  33   0   6   0   0   4   0   0   0   0   0   1   0   1   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   3   0   0   0   0   0   1   1   0   0]
 [  4   9   1   0   1   0   1   0   0   1   0   1   0   2   1   1   1   0 130   0   1   2   0   1   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   3   4   0   2   0   0   0   0   0   1   1   0   1   0   1   0  73   8   0   0   0   0   0   4   0   9   0]
 [  0   3   0   0   0   0   0   0   0   0   0   1   0   0  13   0   2   0  11   0   6 137   0   0   0   0   1   0   0   4   0]
 [  0   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   9   3   0   0   0   1   0   0   0]
 [  0   0   2   0  19   0  12   0   5   0   0   4   0   0   0   1   0   0   4   0   0   0   2  87   0   0   1   3   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   5   0   0   0   0   1   0   0   0   3   0   0   0   0   0   0   0   0   4   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   5   0   0  56   0   1   0   0]
 [  0   1   1   0   2   3  13   0   1   3   0   0   0   0   3   1   3   0   5   0   5   0   0   4   0   0   0  56   0   7   0]
 [  0   0   0   0   0   1   0   0   0   0   0   1   0   0   1   0   0   0   6   0   0   3   0   8   0   0   0   1   5   0   0]
 [  0   1   0   0   4   0   5   2   0   5   0   0   0   1   0   3   0   0   9   0   1   1   0   5   1   0   0   3   0 139   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:04:52,471 - ==> Best [Top1: 66.651   Top5: 91.460   Sparsity:0.00   Params: 364478 on epoch: 78]
2022-12-15 15:04:52,471 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:52,491 - 

2022-12-15 15:04:52,492 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:52,905 - Epoch: [81][   10/   74]    Overall Loss 0.539416    Objective Loss 0.539416                                        LR 0.001000    Time 0.041246    
2022-12-15 15:04:53,159 - Epoch: [81][   20/   74]    Overall Loss 0.567417    Objective Loss 0.567417                                        LR 0.001000    Time 0.033291    
2022-12-15 15:04:53,394 - Epoch: [81][   30/   74]    Overall Loss 0.570327    Objective Loss 0.570327                                        LR 0.001000    Time 0.030010    
2022-12-15 15:04:53,648 - Epoch: [81][   40/   74]    Overall Loss 0.576970    Objective Loss 0.576970                                        LR 0.001000    Time 0.028868    
2022-12-15 15:04:53,904 - Epoch: [81][   50/   74]    Overall Loss 0.574602    Objective Loss 0.574602                                        LR 0.001000    Time 0.028208    
2022-12-15 15:04:54,172 - Epoch: [81][   60/   74]    Overall Loss 0.576590    Objective Loss 0.576590                                        LR 0.001000    Time 0.027950    
2022-12-15 15:04:54,419 - Epoch: [81][   70/   74]    Overall Loss 0.573539    Objective Loss 0.573539                                        LR 0.001000    Time 0.027490    
2022-12-15 15:04:54,509 - Epoch: [81][   74/   74]    Overall Loss 0.573435    Objective Loss 0.573435    Top1 84.953704    Top5 98.148148    LR 0.001000    Time 0.027209    
2022-12-15 15:04:54,566 - --- validate (epoch=81)-----------
2022-12-15 15:04:54,566 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:54,846 - Epoch: [81][    9/    9]    Loss 1.195865    Top1 66.269084    Top5 90.648855    
2022-12-15 15:04:54,902 - ==> Top1: 66.269    Top5: 90.649    Loss: 1.196

2022-12-15 15:04:54,904 - ==> Confusion:
[[ 17   1   0   0   0   0   3   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   1   0   0   0   1   1   0   0]
 [  0   7   0   0   7   1   0   2   0   2   0   0   0   0   0   0   0   0  15   0   1   2   0   0   0   0   0   1   0   0   0]
 [  0   0 118   0   4   0   1   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   7   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   5   0 121   0   6   0   0   0   0   0   0   0   0   0   0   0   4   0   0   3   0  13   0   0   0   3   3   4   0]
 [  0   2   0   0   1  41   0   0   0   0   0   0   0   0   0   0   1   0   5   0   0   3   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   1   0 131   0   5   2   0   1   0   0   2   1   0   0   1   0   0   1   1  14   0   0   0   4   1   7   0]
 [  0   5   0   0   1   2   0   4   0   0   0   0   0   2   0   0   0   0   2   0   3   0   0   0   0   0   0   4   0   0   0]
 [  0   0   0   0   0   0   3   0  10   4   0   3   0   0   0   0   0   0   2   0   0   1   0   6   0   0   0   2   1   1   0]
 [  2   0   0   0   0   0   4   0   3  13   0   0   0   0   0   0   0   0   7   0   1   1   0   2   0   0   0   2   0   6   0]
 [  0   0   0   0   0   0   0   0   0   0   7   0   0   0  27   0   1   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   2   1   0  13   0   0   1   0   0   0   1   0   0   3   2   1   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   1   2   0   2   0   0   0   0   0   7   0   0   0   0   1   0  15   1   0   0   0   0   0   1   0   3   0]
 [  1   0   0   0   0   2   7   0   0   0   1   7   0   0 156   1   2   0   2   0   0   8   0   0   0   0   1   1   0   0   0]
 [  4   0   0   0   1   0   5   0   0   5   0   0   0   0   1   5   0   0   3   0   0   0   0   2   0   0   0   3   0   2   0]
 [  3   0   0   0   0   3   0   0   0   0   0   0   0   0   1   1  33   0   5   0   1   3   0   0   0   0   0   1   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   4   0   0   0   0   0   1   1   0   0]
 [  2   4   2   0   2   0   1   0   1   3   0   1   0   1   0   1   1   0 132   0   1   2   0   2   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   4   1   0   3   0   0   0   0   0   1   1   0   0   0   2   0  68  15   0   0   0   0   0   5   0   6   0]
 [  0   2   0   0   1   0   0   0   0   1   0   0   0   0   9   0   3   0   7   0   4 147   0   0   0   0   1   0   0   3   0]
 [  1   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16   2   0   0   0   0   1   0   0]
 [  0   0   2   0  15   0  13   0   4   0   0   5   0   0   0   0   0   0   7   0   0   1   3  89   0   0   1   2   2   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   1   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   2   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   1   1   3   0   0  55   0   1   0   0]
 [  0   0   1   0   3   3  19   0   1   3   0   0   0   0   2   3   1   0   6   0   4   1   0   2   0   0   0  53   1   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   6   0   0   2   0   7   0   0   0   0  10   0   0]
 [  0   0   0   0  10   0   8   1   0   7   0   0   0   0   0   4   0   0   9   0   2   0   0   6   1   0   0   2   0 130   0]
 [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   2   3   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:04:54,906 - ==> Best [Top1: 66.651   Top5: 91.460   Sparsity:0.00   Params: 364478 on epoch: 78]
2022-12-15 15:04:54,906 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:54,926 - 

2022-12-15 15:04:54,926 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:55,335 - Epoch: [82][   10/   74]    Overall Loss 0.560383    Objective Loss 0.560383                                        LR 0.001000    Time 0.040785    
2022-12-15 15:04:55,582 - Epoch: [82][   20/   74]    Overall Loss 0.548698    Objective Loss 0.548698                                        LR 0.001000    Time 0.032694    
2022-12-15 15:04:55,805 - Epoch: [82][   30/   74]    Overall Loss 0.553902    Objective Loss 0.553902                                        LR 0.001000    Time 0.029220    
2022-12-15 15:04:56,019 - Epoch: [82][   40/   74]    Overall Loss 0.549748    Objective Loss 0.549748                                        LR 0.001000    Time 0.027264    
2022-12-15 15:04:56,235 - Epoch: [82][   50/   74]    Overall Loss 0.554732    Objective Loss 0.554732                                        LR 0.001000    Time 0.026122    
2022-12-15 15:04:56,481 - Epoch: [82][   60/   74]    Overall Loss 0.554536    Objective Loss 0.554536                                        LR 0.001000    Time 0.025856    
2022-12-15 15:04:56,724 - Epoch: [82][   70/   74]    Overall Loss 0.560368    Objective Loss 0.560368                                        LR 0.001000    Time 0.025637    
2022-12-15 15:04:56,811 - Epoch: [82][   74/   74]    Overall Loss 0.565493    Objective Loss 0.565493    Top1 82.175926    Top5 96.527778    LR 0.001000    Time 0.025429    
2022-12-15 15:04:56,876 - --- validate (epoch=82)-----------
2022-12-15 15:04:56,876 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:57,154 - Epoch: [82][    9/    9]    Loss 1.239962    Top1 64.694656    Top5 90.696565    
2022-12-15 15:04:57,208 - ==> Top1: 64.695    Top5: 90.697    Loss: 1.240

2022-12-15 15:04:57,210 - ==> Confusion:
[[ 15   1   0   0   0   0   4   0   1   0   0   3   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   1   1   0   0]
 [  0  10   0   0   6   2   0   1   0   2   0   0   0   0   0   0   0   0  11   0   1   2   0   0   0   0   0   2   0   1   0]
 [  0   0 119   0   3   1   2   0   0   0   0   0   0   0   0   0   0   0   3   0   1   0   0   5   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   8   0 101   2   7   0   0   0   0   0   0   1   0   0   0   0   2   0   1   3   0  26   0   0   0   3   1   6   0]
 [  0   1   0   0   0  41   0   0   0   0   0   0   0   0   0   0   1   0   4   0   0   4   0   0   0   0   2   1   1   0   0]
 [  0   0   1   0   1   0 142   0   4   1   0   1   0   0   2   0   0   0   2   0   0   0   1  10   0   0   0   3   0   4   0]
 [  0   3   0   0   0   2   0   3   0   0   0   0   0   2   0   0   0   0   2   0   5   0   0   0   0   0   0   6   0   0   0]
 [  0   0   0   0   0   0   7   0  11   4   0   2   0   0   0   1   0   0   2   0   0   1   0   3   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   7   0   3  13   0   0   0   0   1   1   0   0   6   0   0   1   0   0   0   0   0   2   0   6   0]
 [  0   0   0   0   0   0   0   0   0   0  11   0   0   0  23   0   0   0   0   0   0   5   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   1   1   0  15   0   0   1   0   0   0   1   0   0   2   1   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   1   0   0   0   0   0  13   0   1   1   0   0   0  13   0   0   0   0   0   0   1   0   2   0]
 [  1   0   0   0   0   0   7   0   0   0   8   7   0   0 150   2   3   0   1   0   0   7   0   0   0   0   2   1   0   0   0]
 [  3   0   0   0   0   0   8   0   0   5   0   0   0   0   2   4   0   0   2   0   0   0   0   1   0   0   0   4   0   2   0]
 [  0   0   0   0   0   3   0   0   0   1   0   0   0   0   4   2  32   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   3   0   0   0   0   0   1   1   0   0]
 [  5   9   1   0   2   0   4   0   4   5   0   1   0   1   1   1   1   0 108   0   1   6   0   0   0   0   0   2   3   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   3   1   0   1   0   0   0   0   0   1   0   0   0   0   2   0  68  12   0   0   0   0   0  11   0   9   0]
 [  0   4   0   0   0   0   1   0   0   0   0   1   0   0   6   0   2   0   7   0   5 147   0   0   0   0   1   0   0   4   0]
 [  0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0  15   2   0   0   0   0   1   0   0]
 [  0   0   1   0  12   0  23   0   6   1   0   4   0   0   0   0   0   0   5   0   0   1   6  82   0   0   1   2   1   4   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   1   6   1   0   0   0   0   2   0   0   1   0   0   0   0   0   0   0   0   2   0   0   0]
 [  0   0   1   0   0   0   1   0   0   0   0   5   0   0   1   0   0   0   0   0   0   0   2   2   0   0  55   0   1   0   0]
 [  0   0   2   0   2   2  18   0   2   3   0   0   0   0   3   2   4   0   2   0   2   0   0   1   0   0   0  60   1   4   0]
 [  0   0   0   0   0   0   0   0   0   1   0   1   0   0   1   0   0   0   3   0   0   3   0   7   0   0   0   1   9   0   0]
 [  0   0   0   0   7   0  20   1   0   7   0   0   0   0   0   2   0   0   4   0   1   1   0   6   0   0   0   4   0 127   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:04:57,211 - ==> Best [Top1: 66.651   Top5: 91.460   Sparsity:0.00   Params: 364478 on epoch: 78]
2022-12-15 15:04:57,211 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:57,232 - 

2022-12-15 15:04:57,232 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:57,643 - Epoch: [83][   10/   74]    Overall Loss 0.555322    Objective Loss 0.555322                                        LR 0.001000    Time 0.040994    
2022-12-15 15:04:57,886 - Epoch: [83][   20/   74]    Overall Loss 0.549715    Objective Loss 0.549715                                        LR 0.001000    Time 0.032649    
2022-12-15 15:04:58,117 - Epoch: [83][   30/   74]    Overall Loss 0.538013    Objective Loss 0.538013                                        LR 0.001000    Time 0.029442    
2022-12-15 15:04:58,335 - Epoch: [83][   40/   74]    Overall Loss 0.543225    Objective Loss 0.543225                                        LR 0.001000    Time 0.027512    
2022-12-15 15:04:58,551 - Epoch: [83][   50/   74]    Overall Loss 0.547140    Objective Loss 0.547140                                        LR 0.001000    Time 0.026330    
2022-12-15 15:04:58,793 - Epoch: [83][   60/   74]    Overall Loss 0.552164    Objective Loss 0.552164                                        LR 0.001000    Time 0.025966    
2022-12-15 15:04:59,035 - Epoch: [83][   70/   74]    Overall Loss 0.553978    Objective Loss 0.553978                                        LR 0.001000    Time 0.025703    
2022-12-15 15:04:59,120 - Epoch: [83][   74/   74]    Overall Loss 0.555603    Objective Loss 0.555603    Top1 83.101852    Top5 97.916667    LR 0.001000    Time 0.025464    
2022-12-15 15:04:59,195 - --- validate (epoch=83)-----------
2022-12-15 15:04:59,195 - 2096 samples (256 per mini-batch)
2022-12-15 15:04:59,462 - Epoch: [83][    9/    9]    Loss 1.256058    Top1 64.837786    Top5 90.505725    
2022-12-15 15:04:59,513 - ==> Top1: 64.838    Top5: 90.506    Loss: 1.256

2022-12-15 15:04:59,515 - ==> Confusion:
[[ 18   0   0   0   0   0   4   0   0   0   0   1   0   0   0   1   1   0   1   0   1   0   0   0   0   0   0   0   0   1   0]
 [  0   8   1   0   6   2   0   2   0   3   0   0   0   0   0   0   0   0  11   0   1   1   0   0   0   0   0   2   0   1   0]
 [  0   0 119   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0   3   0   1   0   0   6   0   0   0   0   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   8   0 112   1   7   2   0   0   0   0   0   2   0   0   0   0   3   0   1   3   0  14   0   0   0   2   0   7   0]
 [  0   2   0   0   1  39   0   1   0   0   0   0   0   0   0   0   3   0   4   0   0   3   0   0   0   0   1   0   1   0   0]
 [  0   0   2   0   1   0 134   0   3   1   0   1   0   0   2   1   0   0   1   0   1   0   0  10   0   0   0   5   0  10   0]
 [  0   5   0   0   1   1   0   7   0   0   0   0   0   2   0   0   0   0   0   0   3   0   0   0   0   0   0   4   0   0   0]
 [  0   0   0   0   0   0  11   0  10   3   0   1   0   0   0   1   0   0   2   0   0   1   0   2   0   0   0   1   0   1   0]
 [  1   0   0   0   0   0   7   0   0  12   0   0   0   0   0   4   0   0   5   0   1   1   0   0   0   0   0   0   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   7   0   0   0  27   0   1   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   1   0   0  16   0   0   0   0   0   0   1   0   0   2   1   0   0   1   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   2   0   0   0   0   0  10   0   0   0   0   1   0  15   0   0   0   0   0   0   2   0   3   0]
 [  1   0   0   0   0   0   5   0   0   0   1   5   0   0 159   2   3   0   1   0   0   8   0   0   0   0   1   1   2   0   0]
 [  4   0   0   0   0   0   7   0   0   3   0   0   0   0   1   5   0   0   2   0   0   0   0   1   0   0   0   4   0   4   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   3   2  33   0   4   0   1   3   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   4   0   0   0   0   0   1   1   0   0]
 [  5  11   2   0   2   0   3   2   2   5   0   0   0   2   0   3   2   0 109   0   1   3   0   0   0   0   0   0   0   6   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   4   2   0   3   0   0   0   0   0   1   1   0   0   0   1   0  71   9   0   0   0   0   0   5   0   9   0]
 [  0   4   0   0   1   0   0   0   0   1   0   1   0   0  13   0   4   0   7   0   5 137   0   0   0   0   1   0   0   4   0]
 [  0   0   6   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0  10   2   0   0   1   1   0   0   0]
 [  0   0   3   0  17   0  20   0   6   1   0   3   0   0   0   0   0   0   3   0   1   0   4  81   0   0   1   1   0   8   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   5   0   0   0   0   1   2   0   0   1   0   1   0   0   1   0   0   0   2   0   0   0]
 [  0   0   3   0   0   0   1   0   0   0   0   2   0   0   0   0   0   0   0   0   0   1   1   3   0   0  56   0   1   0   0]
 [  0   0   3   0   5   2  22   0   1   0   0   1   0   0   2   3   1   0   4   0   3   1   0   0   0   0   0  52   0   8   0]
 [  0   0   2   0   0   0   0   0   1   1   0   2   0   0   0   0   0   0   5   0   0   2   0   7   0   0   0   1   5   0   0]
 [  0   0   0   0   7   0   7   1   0   3   0   0   0   2   0   4   0   0   2   0   3   1   0   3   1   0   0   3   0 143   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   3   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:04:59,516 - ==> Best [Top1: 66.651   Top5: 91.460   Sparsity:0.00   Params: 364478 on epoch: 78]
2022-12-15 15:04:59,516 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:04:59,526 - 

2022-12-15 15:04:59,526 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:04:59,932 - Epoch: [84][   10/   74]    Overall Loss 0.548485    Objective Loss 0.548485                                        LR 0.001000    Time 0.040542    
2022-12-15 15:05:00,178 - Epoch: [84][   20/   74]    Overall Loss 0.535937    Objective Loss 0.535937                                        LR 0.001000    Time 0.032543    
2022-12-15 15:05:00,427 - Epoch: [84][   30/   74]    Overall Loss 0.544253    Objective Loss 0.544253                                        LR 0.001000    Time 0.029969    
2022-12-15 15:05:00,673 - Epoch: [84][   40/   74]    Overall Loss 0.536972    Objective Loss 0.536972                                        LR 0.001000    Time 0.028610    
2022-12-15 15:05:00,917 - Epoch: [84][   50/   74]    Overall Loss 0.536260    Objective Loss 0.536260                                        LR 0.001000    Time 0.027770    
2022-12-15 15:05:01,163 - Epoch: [84][   60/   74]    Overall Loss 0.542499    Objective Loss 0.542499                                        LR 0.001000    Time 0.027233    
2022-12-15 15:05:01,403 - Epoch: [84][   70/   74]    Overall Loss 0.545152    Objective Loss 0.545152                                        LR 0.001000    Time 0.026758    
2022-12-15 15:05:01,488 - Epoch: [84][   74/   74]    Overall Loss 0.547176    Objective Loss 0.547176    Top1 81.712963    Top5 97.453704    LR 0.001000    Time 0.026457    
2022-12-15 15:05:01,552 - --- validate (epoch=84)-----------
2022-12-15 15:05:01,553 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:01,839 - Epoch: [84][    9/    9]    Loss 1.230139    Top1 65.505725    Top5 90.267176    
2022-12-15 15:05:01,896 - ==> Top1: 65.506    Top5: 90.267    Loss: 1.230

2022-12-15 15:05:01,898 - ==> Confusion:
[[ 20   0   0   0   0   0   1   0   1   1   0   3   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   5   1   0   1   0   2   0   0   0   0   0   0   0   0  18   0   1   0   0   0   0   0   0   1   0   0   0]
 [  0   0 117   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0   1   1   0   6   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   8   0 103   0   4   1   0   2   0   0   0   1   0   1   0   0  10   0   0   3   0  19   0   0   0   5   2   3   0]
 [  0   1   0   0   1  35   0   0   0   1   0   0   0   0   0   0   4   0   4   0   1   4   0   0   0   0   2   0   2   0   0]
 [  1   0   1   0   1   0 124   0   6   6   0   1   0   0   2   2   0   0   3   0   0   0   1  12   0   0   0   5   0   7   0]
 [  0   4   0   0   0   2   0   4   0   0   0   0   0   2   0   0   1   0   3   0   2   0   0   0   0   0   0   4   0   1   0]
 [  0   0   0   0   0   0   6   0  12   4   0   2   0   0   0   0   0   0   3   0   0   1   0   4   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   4   0   2  15   0   0   0   0   0   0   0   0  10   0   1   1   0   2   0   0   0   0   0   5   0]
 [  0   0   0   0   0   0   0   0   0   0   9   0   0   0  23   1   1   0   0   0   0   5   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   2   0   0   0   1   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   4   0   0   0   0   0  11   0   0   0   0   2   0  11   0   0   0   0   0   0   1   0   3   0]
 [  3   0   1   0   0   0   6   0   1   1   2   4   0   0 154   0   3   0   2   0   0   8   0   0   0   0   1   1   2   0   0]
 [  4   0   0   0   0   0   4   1   0   5   0   0   0   0   3   6   0   0   3   0   0   0   0   2   0   0   0   2   0   1   0]
 [  3   0   0   0   0   1   0   0   0   0   0   0   0   0   1   1  33   0   5   0   0   6   0   0   0   0   0   1   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   3   0   0   0   0   0   0   1   0   0]
 [  3   1   0   0   1   0   1   0   1   7   0   0   0   1   0   1   0   0 135   0   1   2   0   1   0   0   0   0   2   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   3   2   0   2   0   0   0   0   0   1   0   0   2   0   3   0  72  11   0   0   0   0   0   4   0   7   0]
 [  0   2   0   0   0   1   0   0   0   1   0   0   0   0  11   0   4   0  10   0   4 141   0   0   0   0   0   0   1   3   0]
 [  1   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  15   2   0   0   0   0   0   0   0]
 [  1   0   3   0  16   0   9   0   9   2   0   4   0   0   0   0   0   0   5   0   0   2   3  88   0   0   1   0   2   4   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   0   0   2   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0   0   6   0   0   0   0   0   2   0   0   2   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   1   0   0   0   0   3   0   0   1   0   1   0   0   0   0   1   0   4   0   0  54   0   0   0   0]
 [  0   1   1   0   2   2  13   0   3   3   0   0   0   0   3   2   5   0   7   0   1   1   1   2   0   0   0  55   1   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   6   0   0   2   0   7   0   0   0   0   9   0   0]
 [  0   0   0   0   7   0   5   1   0  10   0   0   0   0   0   5   0   0  10   0   1   2   0   4   0   0   0   3   1 131   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   5   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:05:01,900 - ==> Best [Top1: 66.651   Top5: 91.460   Sparsity:0.00   Params: 364478 on epoch: 78]
2022-12-15 15:05:01,900 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:01,910 - 

2022-12-15 15:05:01,910 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:02,327 - Epoch: [85][   10/   74]    Overall Loss 0.570504    Objective Loss 0.570504                                        LR 0.001000    Time 0.041662    
2022-12-15 15:05:02,572 - Epoch: [85][   20/   74]    Overall Loss 0.562863    Objective Loss 0.562863                                        LR 0.001000    Time 0.033062    
2022-12-15 15:05:02,817 - Epoch: [85][   30/   74]    Overall Loss 0.558525    Objective Loss 0.558525                                        LR 0.001000    Time 0.030176    
2022-12-15 15:05:03,063 - Epoch: [85][   40/   74]    Overall Loss 0.542762    Objective Loss 0.542762                                        LR 0.001000    Time 0.028784    
2022-12-15 15:05:03,311 - Epoch: [85][   50/   74]    Overall Loss 0.537742    Objective Loss 0.537742                                        LR 0.001000    Time 0.027976    
2022-12-15 15:05:03,562 - Epoch: [85][   60/   74]    Overall Loss 0.539511    Objective Loss 0.539511                                        LR 0.001000    Time 0.027486    
2022-12-15 15:05:03,803 - Epoch: [85][   70/   74]    Overall Loss 0.542660    Objective Loss 0.542660                                        LR 0.001000    Time 0.026992    
2022-12-15 15:05:03,891 - Epoch: [85][   74/   74]    Overall Loss 0.543781    Objective Loss 0.543781    Top1 83.796296    Top5 96.990741    LR 0.001000    Time 0.026717    
2022-12-15 15:05:03,961 - --- validate (epoch=85)-----------
2022-12-15 15:05:03,962 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:04,230 - Epoch: [85][    9/    9]    Loss 1.237507    Top1 65.267176    Top5 91.173664    
2022-12-15 15:05:04,283 - ==> Top1: 65.267    Top5: 91.174    Loss: 1.238

2022-12-15 15:05:04,285 - ==> Confusion:
[[ 16   1   0   0   0   0   1   0   3   1   0   0   0   0   0   1   1   0   2   0   0   0   0   1   0   0   0   1   0   0   0]
 [  0  10   0   0   4   3   0   2   0   2   0   0   0   0   0   0   0   0  11   0   1   2   0   0   0   0   0   0   1   2   0]
 [  0   1 113   0   9   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   6   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   5   0 120   1   3   0   0   0   0   0   0   1   0   1   0   0   4   0   1   3   0   8   0   0   0   2   0  12   0]
 [  0   1   0   0   1  41   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   5   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   1   0 119   0   3   6   0   0   0   0   2   1   0   0   2   0   1   0   1  19   0   0   0   4   0  13   0]
 [  0   4   0   0   0   2   0   7   0   0   0   0   0   2   0   0   0   0   0   0   2   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0  11   4   0   1   0   0   0   0   0   0   2   0   0   1   0   6   0   0   0   2   0   0   0]
 [  0   0   0   0   0   0   3   0   1  11   0   0   0   0   0   1   0   0   7   0   1   0   0   1   0   0   0   2   0  14   0]
 [  0   0   0   0   0   0   1   0   0   0   8   0   0   0  22   0   0   0   0   0   0   8   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   2   0   0  13   0   0   0   0   0   0   1   0   0   2   2   0   0   0   1   0   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   0   0   3   0   0   0   0   0  14   0   0   0   0   0   0  10   0   0   0   0   0   0   1   0   3   0]
 [  2   0   0   0   0   0   9   0   2   1   2   2   0   0 147   1   1   0   3   0   0  14   0   0   0   0   1   1   3   0   0]
 [  2   0   0   0   0   0   4   0   0   7   0   0   0   0   2   3   0   0   2   0   0   0   0   4   0   0   0   5   0   2   0]
 [  0   0   0   0   0   4   0   1   0   1   0   0   0   0   2   0  32   0   4   0   1   6   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   1   0   1   0   1   4   0   0   0   0   0   0   0   0   0]
 [  0  13   0   0   1   0   1   1   2   6   0   0   0   1   0   1   1   0 121   0   0   3   0   1   0   0   0   0   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   1   0   5   0   0   0   0   0   1   0   0   1   0   0   0  76   9   0   0   0   0   0   2   0  10   0]
 [  0   1   0   0   0   0   0   1   0   2   0   0   0   0   8   0   4   0   8   0   8 140   0   0   0   0   1   0   0   5   0]
 [  0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   9   5   0   0   0   0   0   0   0]
 [  1   0   2   0  17   0   7   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  93   0   0   2   0   1  10   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   1   0   0   0   0   1   0   1   0   0   1   0   0   0   1   0   1   0]
 [  0   0   1   0   0   0   1   0   0   0   0   2   0   0   1   0   0   0   0   0   0   1   1   7   0   0  53   0   1   0   0]
 [  0   0   2   0   3   1  12   0   1   1   0   0   0   1   2   3   4   0   5   0   7   0   0   2   0   0   0  52   0  12   0]
 [  0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   9   0   0   2   0   8   0   0   0   0   6   0   0]
 [  0   1   0   0   6   1   3   1   0   4   0   0   0   0   0   3   0   0   2   0   2   1   0   3   1   0   0   5   0 147   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:05:04,287 - ==> Best [Top1: 66.651   Top5: 91.460   Sparsity:0.00   Params: 364478 on epoch: 78]
2022-12-15 15:05:04,287 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:04,307 - 

2022-12-15 15:05:04,308 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:04,859 - Epoch: [86][   10/   74]    Overall Loss 0.514386    Objective Loss 0.514386                                        LR 0.001000    Time 0.055032    
2022-12-15 15:05:05,113 - Epoch: [86][   20/   74]    Overall Loss 0.513916    Objective Loss 0.513916                                        LR 0.001000    Time 0.040202    
2022-12-15 15:05:05,362 - Epoch: [86][   30/   74]    Overall Loss 0.516912    Objective Loss 0.516912                                        LR 0.001000    Time 0.035106    
2022-12-15 15:05:05,616 - Epoch: [86][   40/   74]    Overall Loss 0.518145    Objective Loss 0.518145                                        LR 0.001000    Time 0.032624    
2022-12-15 15:05:05,862 - Epoch: [86][   50/   74]    Overall Loss 0.530358    Objective Loss 0.530358                                        LR 0.001000    Time 0.031005    
2022-12-15 15:05:06,114 - Epoch: [86][   60/   74]    Overall Loss 0.533827    Objective Loss 0.533827                                        LR 0.001000    Time 0.029994    
2022-12-15 15:05:06,346 - Epoch: [86][   70/   74]    Overall Loss 0.532123    Objective Loss 0.532123                                        LR 0.001000    Time 0.029023    
2022-12-15 15:05:06,433 - Epoch: [86][   74/   74]    Overall Loss 0.531188    Objective Loss 0.531188    Top1 84.027778    Top5 98.611111    LR 0.001000    Time 0.028622    
2022-12-15 15:05:06,502 - --- validate (epoch=86)-----------
2022-12-15 15:05:06,502 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:06,778 - Epoch: [86][    9/    9]    Loss 1.226656    Top1 66.221374    Top5 91.125954    
2022-12-15 15:05:06,833 - ==> Top1: 66.221    Top5: 91.126    Loss: 1.227

2022-12-15 15:05:06,835 - ==> Confusion:
[[ 18   0   0   0   0   0   4   0   1   0   0   2   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   4   3   0   2   0   2   0   0   0   0   0   0   0   0  11   0   1   2   0   0   0   0   0   0   1   1   0]
 [  0   0 115   0   7   0   1   0   0   0   0   0   0   0   0   0   0   0   3   0   0   1   0   6   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 122   3   4   1   0   0   0   0   0   1   0   0   0   0   3   0   0   4   0   6   0   0   0   4   3   4   0]
 [  0   2   0   0   1  43   0   0   0   0   0   0   0   0   0   0   1   0   3   0   0   1   0   0   0   0   2   0   2   0   0]
 [  0   0   1   0   1   0 128   0   3   2   0   0   0   0   2   1   0   0   1   0   0   0   1  14   0   0   1   5   1  11   0]
 [  0   4   0   0   1   1   0   7   0   0   0   0   0   2   0   0   0   0   1   0   2   0   0   0   0   0   0   5   0   0   0]
 [  0   0   0   0   0   0   7   0  10   4   0   3   0   0   0   0   0   0   3   0   0   1   0   2   0   0   0   2   1   0   0]
 [  2   0   0   0   0   0   5   0   1  10   0   0   0   0   0   0   0   0   6   0   1   1   0   2   0   0   0   2   0  11   0]
 [  0   0   0   0   0   0   0   0   0   0   9   0   0   0  25   0   0   0   1   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  15   0   0   2   0   0   0   1   0   0   1   2   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   2   0   0   0   0   0  14   0   0   0   0   0   0  11   0   0   0   0   0   0   2   0   3   0]
 [  1   0   0   0   0   0   5   0   0   0   2   5   0   0 163   1   0   0   1   0   0   6   0   0   0   0   1   2   2   0   0]
 [  2   0   0   0   0   0   6   1   0   2   0   0   0   0   4   3   0   0   2   0   0   0   0   3   0   0   0   6   0   2   0]
 [  2   0   0   0   0   3   0   1   0   0   0   0   0   0   4   0  32   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   3   0   0   0   0   0   1   1   0   0]
 [  2   8   1   0   3   1   0   0   3   3   0   0   0   1   1   1   1   0 117   0   1   7   0   1   0   0   0   0   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   2   2   0   3   0   0   0   0   0   1   1   0   1   0   1   0  73  13   0   0   0   0   0   4   0   7   0]
 [  0   3   0   0   1   0   0   0   0   1   0   0   0   0  15   0   4   0   7   0   5 136   0   0   0   0   1   0   1   4   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0  16   2   0   0   0   0   1   0   0]
 [  0   0   1   0  20   0  12   0   4   1   0   5   0   0   0   0   0   0   5   0   1   0   3  84   0   0   2   5   1   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   9   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   0   0   2   0   0   0]
 [  0   0   0   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   0   3   6   0   0  54   0   0   0   0]
 [  1   0   1   0   2   2  13   0   2   2   0   0   0   0   2   3   2   0   4   0   3   0   0   2   0   0   0  60   0   9   0]
 [  0   0   0   0   0   0   0   0   1   0   0   2   0   0   0   0   0   0   7   0   0   1   0   8   0   0   0   0   7   0   0]
 [  0   0   0   0  10   1   9   1   0   7   0   0   0   0   0   2   0   0   4   0   1   1   0   4   1   0   0   4   0 135   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:05:06,836 - ==> Best [Top1: 66.651   Top5: 91.460   Sparsity:0.00   Params: 364478 on epoch: 78]
2022-12-15 15:05:06,836 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:06,846 - 

2022-12-15 15:05:06,846 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:07,250 - Epoch: [87][   10/   74]    Overall Loss 0.500138    Objective Loss 0.500138                                        LR 0.001000    Time 0.040346    
2022-12-15 15:05:07,489 - Epoch: [87][   20/   74]    Overall Loss 0.502991    Objective Loss 0.502991                                        LR 0.001000    Time 0.032088    
2022-12-15 15:05:07,740 - Epoch: [87][   30/   74]    Overall Loss 0.491053    Objective Loss 0.491053                                        LR 0.001000    Time 0.029733    
2022-12-15 15:05:07,958 - Epoch: [87][   40/   74]    Overall Loss 0.490971    Objective Loss 0.490971                                        LR 0.001000    Time 0.027741    
2022-12-15 15:05:08,169 - Epoch: [87][   50/   74]    Overall Loss 0.498870    Objective Loss 0.498870                                        LR 0.001000    Time 0.026404    
2022-12-15 15:05:08,382 - Epoch: [87][   60/   74]    Overall Loss 0.505338    Objective Loss 0.505338                                        LR 0.001000    Time 0.025550    
2022-12-15 15:05:08,610 - Epoch: [87][   70/   74]    Overall Loss 0.513571    Objective Loss 0.513571                                        LR 0.001000    Time 0.025161    
2022-12-15 15:05:08,698 - Epoch: [87][   74/   74]    Overall Loss 0.513774    Objective Loss 0.513774    Top1 84.259259    Top5 96.759259    LR 0.001000    Time 0.024979    
2022-12-15 15:05:08,774 - --- validate (epoch=87)-----------
2022-12-15 15:05:08,774 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:09,058 - Epoch: [87][    9/    9]    Loss 1.216378    Top1 66.173664    Top5 90.791985    
2022-12-15 15:05:09,120 - ==> Top1: 66.174    Top5: 90.792    Loss: 1.216

2022-12-15 15:05:09,122 - ==> Confusion:
[[ 19   0   0   0   0   0   3   0   2   1   0   0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   1   0]
 [  0  12   0   0   4   1   0   2   0   3   0   0   0   0   0   0   0   0  12   0   1   0   0   0   0   0   0   1   1   1   0]
 [  0   0 116   0   4   1   0   0   0   1   0   0   0   0   0   0   0   0   2   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   8   0 107   0   3   0   0   0   0   0   0   1   0   1   0   0   9   0   0   3   0  16   0   0   0   3   1  10   0]
 [  0   1   1   0   1  37   0   2   0   0   0   0   0   0   0   0   1   0   3   0   1   4   0   0   0   0   1   0   3   0   0]
 [  0   0   0   0   2   0 123   0   3   4   0   1   0   0   2   1   0   0   4   0   0   0   0  14   0   0   0   3   0  15   0]
 [  0   4   0   0   0   1   0   7   0   0   0   0   0   2   0   0   0   0   1   0   2   0   0   0   0   0   0   5   0   1   0]
 [  1   0   0   0   0   0   5   0   8   4   0   3   0   0   0   0   0   0   3   0   0   1   0   4   0   0   0   3   1   0   0]
 [  1   0   0   0   0   0   2   0   1  10   0   0   0   0   1   1   0   0   6   0   1   1   0   2   0   0   0   1   0  14   0]
 [  0   0   0   0   0   0   0   0   0   0   7   0   0   0  27   0   1   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   2   1   0  15   0   0   0   0   0   0   1   0   0   2   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   2   0   0   0   0   0  14   0   0   0   0   0   0  11   0   0   0   0   0   0   1   0   4   0]
 [  3   0   0   0   0   1   8   0   0   1   1   5   0   0 152   1   1   0   4   0   0   8   0   0   0   0   1   2   1   0   0]
 [  2   0   0   0   0   0   7   0   0   6   0   0   0   0   1   3   0   0   2   0   0   0   0   2   0   0   0   6   0   2   0]
 [  1   0   0   0   0   4   0   0   0   0   0   0   0   0   0   2  34   0   5   0   1   3   0   0   0   0   0   0   0   2   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   3   0   0   0   0   0   1   1   0   0]
 [  1   4   0   0   2   1   1   1   2  10   0   0   0   1   0   2   0   0 127   0   1   1   0   0   0   0   0   0   2   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   5   0   0   0   0   0   1   0   0   1   0   2   0  78   8   0   0   0   0   0   2   0  11   0]
 [  0   1   0   0   0   0   1   0   0   1   0   0   0   0   6   0   3   0   9   0   6 147   0   0   0   0   0   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   4   0   0   0   0   0   0   0]
 [  0   0   2   0  16   0  10   0   1   1   0   4   0   0   0   0   0   0   8   0   0   1   1  88   0   0   2   2   2  11   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   2   0]
 [  0   0   0   0   0   0   1   0   0   7   1   0   0   1   0   0   0   0   1   0   0   0   0   1   0   0   0   2   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   2   0   0   0   0   2   0   0   0   0   1   1   4   0   0  54   0   1   0   0]
 [  0   0   1   0   2   2  14   0   1   1   0   0   0   1   2   4   1   0   5   0   3   0   0   2   0   0   0  56   2  11   0]
 [  0   0   0   0   0   0   0   0   0   1   0   1   0   0   0   0   0   0   5   0   0   2   0   8   0   0   0   0   9   0   0]
 [  0   0   0   0   7   0   4   2   0   3   0   0   0   0   1   2   0   0   4   0   3   0   0   3   0   0   0   4   0 147   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:05:09,123 - ==> Best [Top1: 66.651   Top5: 91.460   Sparsity:0.00   Params: 364478 on epoch: 78]
2022-12-15 15:05:09,124 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:09,133 - 

2022-12-15 15:05:09,133 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:09,534 - Epoch: [88][   10/   74]    Overall Loss 0.548890    Objective Loss 0.548890                                        LR 0.001000    Time 0.039957    
2022-12-15 15:05:09,784 - Epoch: [88][   20/   74]    Overall Loss 0.538492    Objective Loss 0.538492                                        LR 0.001000    Time 0.032483    
2022-12-15 15:05:10,048 - Epoch: [88][   30/   74]    Overall Loss 0.534750    Objective Loss 0.534750                                        LR 0.001000    Time 0.030427    
2022-12-15 15:05:10,313 - Epoch: [88][   40/   74]    Overall Loss 0.536332    Objective Loss 0.536332                                        LR 0.001000    Time 0.029414    
2022-12-15 15:05:10,571 - Epoch: [88][   50/   74]    Overall Loss 0.530242    Objective Loss 0.530242                                        LR 0.001000    Time 0.028689    
2022-12-15 15:05:10,834 - Epoch: [88][   60/   74]    Overall Loss 0.525978    Objective Loss 0.525978                                        LR 0.001000    Time 0.028277    
2022-12-15 15:05:11,085 - Epoch: [88][   70/   74]    Overall Loss 0.527402    Objective Loss 0.527402                                        LR 0.001000    Time 0.027810    
2022-12-15 15:05:11,172 - Epoch: [88][   74/   74]    Overall Loss 0.528067    Objective Loss 0.528067    Top1 84.490741    Top5 98.148148    LR 0.001000    Time 0.027482    
2022-12-15 15:05:11,229 - --- validate (epoch=88)-----------
2022-12-15 15:05:11,229 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:11,493 - Epoch: [88][    9/    9]    Loss 1.212999    Top1 66.746183    Top5 91.793893    
2022-12-15 15:05:11,542 - ==> Top1: 66.746    Top5: 91.794    Loss: 1.213

2022-12-15 15:05:11,544 - ==> Confusion:
[[ 18   1   0   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   1   1   0   0]
 [  0   4   0   0   8   2   0   2   0   3   0   0   0   0   0   0   0   0  16   0   1   0   0   0   0   0   0   1   1   0   0]
 [  0   0 115   0   6   0   1   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   6   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1   6   0 119   3   4   0   0   0   0   0   0   1   0   0   0   0   3   0   0   3   0  10   0   0   0   6   3   6   0]
 [  0   1   0   0   1  39   0   1   0   0   0   0   0   0   0   0   2   0   4   0   1   3   0   0   0   0   1   0   2   0   0]
 [  0   0   0   0   1   0 135   0   4   0   0   1   0   0   2   3   0   0   2   0   0   0   1   9   0   0   0   6   1   7   0]
 [  0   3   0   0   0   1   0   9   0   0   0   0   0   2   0   0   0   0   1   0   2   0   0   0   0   0   0   4   0   1   0]
 [  0   0   0   0   0   0   7   0   9   5   0   1   0   0   0   1   0   0   4   0   0   1   0   2   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   2  10   0   0   0   0   0   2   0   0   7   0   1   1   0   0   0   0   0   2   0  11   0]
 [  0   0   0   0   0   0   0   0   0   0   8   0   0   0  24   0   0   0   0   0   0   6   0   0   0   0   0   1   1   0   0]
 [  0   0   0   0   0   0   3   0   1   1   0  15   0   0   2   0   0   0   1   0   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   3   0   0   0   0   0  14   0   0   0   0   1   0  11   0   0   0   0   0   0   1   0   3   0]
 [  1   0   0   0   1   1   4   0   2   0   3   3   0   0 163   1   0   0   0   0   0   7   0   0   0   0   1   1   1   0   0]
 [  2   0   0   0   0   0   6   0   0   3   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   6   0   2   0]
 [  0   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  34   0   7   0   0   3   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   3   0   0   0   0   0   1   1   0   0]
 [  2   5   2   0   3   0   2   0   1   5   0   1   0   2   1   1   0   0 121   0   0   4   0   0   0   0   0   0   3   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   2   1   0   3   0   0   0   0   0   1   1   0   0   0   2   0  75   9   0   0   0   0   0   7   0   7   0]
 [  0   2   0   0   0   0   0   0   0   2   0   0   0   0  12   0   4   0   6   0   7 142   0   0   0   0   1   0   0   2   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  15   3   0   0   1   0   0   0   0]
 [  0   0   4   0  18   0  12   0   3   0   0   5   0   0   0   0   0   0   5   0   0   1   1  87   0   0   2   2   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   6   1   0   0   0   0   2   0   0   1   0   0   0   0   1   0   0   0   2   0   0   0]
 [  0   0   1   0   0   0   1   0   0   0   0   2   0   0   1   0   1   0   0   0   0   1   0   3   0   0  55   0   3   0   0]
 [  0   1   2   0   2   1  15   0   2   1   0   0   0   0   2   4   3   0   6   0   4   0   0   1   0   0   0  56   0   8   0]
 [  0   0   0   0   0   0   0   0   0   1   0   1   0   0   0   0   0   0   5   0   0   2   0   7   0   0   0   1   9   0   0]
 [  0   0   0   0   8   0   7   2   0   5   0   0   0   0   0   3   0   0   5   0   2   3   0   2   1   0   0   5   1 136   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:05:11,546 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:11,546 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:11,577 - 

2022-12-15 15:05:11,577 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:12,002 - Epoch: [89][   10/   74]    Overall Loss 0.502871    Objective Loss 0.502871                                        LR 0.001000    Time 0.042442    
2022-12-15 15:05:12,255 - Epoch: [89][   20/   74]    Overall Loss 0.493062    Objective Loss 0.493062                                        LR 0.001000    Time 0.033810    
2022-12-15 15:05:12,510 - Epoch: [89][   30/   74]    Overall Loss 0.490643    Objective Loss 0.490643                                        LR 0.001000    Time 0.031040    
2022-12-15 15:05:12,762 - Epoch: [89][   40/   74]    Overall Loss 0.482286    Objective Loss 0.482286                                        LR 0.001000    Time 0.029574    
2022-12-15 15:05:13,015 - Epoch: [89][   50/   74]    Overall Loss 0.482856    Objective Loss 0.482856                                        LR 0.001000    Time 0.028684    
2022-12-15 15:05:13,277 - Epoch: [89][   60/   74]    Overall Loss 0.485587    Objective Loss 0.485587                                        LR 0.001000    Time 0.028249    
2022-12-15 15:05:13,516 - Epoch: [89][   70/   74]    Overall Loss 0.484571    Objective Loss 0.484571                                        LR 0.001000    Time 0.027632    
2022-12-15 15:05:13,597 - Epoch: [89][   74/   74]    Overall Loss 0.487902    Objective Loss 0.487902    Top1 84.953704    Top5 97.222222    LR 0.001000    Time 0.027225    
2022-12-15 15:05:13,665 - --- validate (epoch=89)-----------
2022-12-15 15:05:13,665 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:13,941 - Epoch: [89][    9/    9]    Loss 1.231461    Top1 64.980916    Top5 91.030534    
2022-12-15 15:05:13,995 - ==> Top1: 64.981    Top5: 91.031    Loss: 1.231

2022-12-15 15:05:13,997 - ==> Confusion:
[[ 16   1   0   0   0   0   3   0   1   0   0   1   0   1   0   2   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   8   0   0   6   3   0   3   0   3   0   0   0   0   0   0   0   0  11   0   0   1   0   0   0   0   0   2   0   1   0]
 [  0   0 109   0  14   0   1   0   0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   5   0   0   0   0   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   3   0 131   1   3   0   0   0   0   0   0   1   0   0   0   0   3   0   0   2   0   7   0   0   0   3   0   9   0]
 [  0   1   0   0   1  42   0   2   0   0   0   0   0   0   0   0   1   0   3   0   0   2   0   0   0   0   1   0   2   0   0]
 [  0   0   1   0   3   0 130   0   2   1   0   0   0   0   2   1   0   0   1   0   0   0   0  13   0   0   1   8   0   9   0]
 [  0   3   0   0   0   1   0   9   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   4   0   2   0]
 [  0   0   0   0   0   0   5   0  10   2   0   3   0   0   0   0   0   0   3   0   0   0   0   5   0   0   0   3   0   2   0]
 [  0   0   0   0   0   0   3   0   1   7   0   0   0   0   1   3   0   0   6   0   0   0   0   3   0   0   0   2   0  15   0]
 [  0   0   0   0   0   0   1   0   0   0   8   0   0   0  26   0   1   0   1   0   0   2   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   2   0   0  12   0   0   1   0   0   0   1   0   0   2   2   0   0   0   1   0   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   2   0   0   0   0   0  13   0   1   0   0   0   0  12   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   2  12   0   2   0   0   3   0   0 155   1   1   0   0   0   0   5   0   0   0   0   2   2   2   0   0]
 [  0   0   0   0   0   0   5   0   0   4   0   0   0   0   2   5   0   0   3   0   0   0   0   4   0   0   0   6   0   2   0]
 [  3   0   0   0   0   4   0   0   0   1   0   0   0   0   0   2  32   0   3   0   1   3   0   0   0   0   0   2   0   1   0]
 [  0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   3   0   0   0   0   0   1   1   0   0]
 [  2   9   1   0   4   1   1   2   3  12   0   0   0   0   0   4   0   0 103   0   2   2   0   1   0   0   0   2   1   8   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   1   1   0   3   0   0   0   0   0   1   1   0   0   0   1   0  75   8   0   0   0   0   0   7   0  10   0]
 [  0   1   1   0   0   0   0   2   0   1   0   0   0   0  13   0   4   0   9   0   6 133   0   0   0   0   2   0   1   5   0]
 [  0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   7   3   0   0   0   1   0   0   0]
 [  0   0   2   0  22   0  13   0   6   1   0   3   0   0   0   0   0   0   3   0   1   0   1  88   0   0   0   0   1   8   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   2   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   2   0   1   0]
 [  0   0   2   0   1   0   4   0   0   0   0   2   0   0   0   0   1   0   0   0   0   0   0   3   0   0  54   0   1   0   0]
 [  0   0   1   0   3   3  15   0   0   1   0   1   0   1   1   3   2   0   3   0   2   0   0   1   1   0   0  59   0  11   0]
 [  0   2   1   0   0   1   0   0   1   1   0   2   0   0   0   0   0   0   4   0   0   1   0   7   0   0   0   1   5   0   0]
 [  0   0   0   0   8   1   6   1   0   3   0   0   0   0   0   3   0   0   3   0   2   0   0   4   1   0   0   3   0 145   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:05:13,998 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:13,999 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:14,016 - 

2022-12-15 15:05:14,016 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:14,430 - Epoch: [90][   10/   74]    Overall Loss 0.480774    Objective Loss 0.480774                                        LR 0.001000    Time 0.041350    
2022-12-15 15:05:14,673 - Epoch: [90][   20/   74]    Overall Loss 0.466099    Objective Loss 0.466099                                        LR 0.001000    Time 0.032798    
2022-12-15 15:05:14,912 - Epoch: [90][   30/   74]    Overall Loss 0.473809    Objective Loss 0.473809                                        LR 0.001000    Time 0.029802    
2022-12-15 15:05:15,150 - Epoch: [90][   40/   74]    Overall Loss 0.477767    Objective Loss 0.477767                                        LR 0.001000    Time 0.028307    
2022-12-15 15:05:15,400 - Epoch: [90][   50/   74]    Overall Loss 0.474916    Objective Loss 0.474916                                        LR 0.001000    Time 0.027641    
2022-12-15 15:05:15,653 - Epoch: [90][   60/   74]    Overall Loss 0.473225    Objective Loss 0.473225                                        LR 0.001000    Time 0.027243    
2022-12-15 15:05:15,897 - Epoch: [90][   70/   74]    Overall Loss 0.471424    Objective Loss 0.471424                                        LR 0.001000    Time 0.026833    
2022-12-15 15:05:16,063 - Epoch: [90][   74/   74]    Overall Loss 0.475333    Objective Loss 0.475333    Top1 85.416667    Top5 97.685185    LR 0.001000    Time 0.027616    
2022-12-15 15:05:16,118 - --- validate (epoch=90)-----------
2022-12-15 15:05:16,118 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:16,393 - Epoch: [90][    9/    9]    Loss 1.212159    Top1 65.553435    Top5 90.553435    
2022-12-15 15:05:16,448 - ==> Top1: 65.553    Top5: 90.553    Loss: 1.212

2022-12-15 15:05:16,450 - ==> Confusion:
[[ 19   0   0   0   0   0   2   0   2   0   0   2   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   7   2   0   1   0   3   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   0   0]
 [  0   0 117   0   3   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   0   1   0   9   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   7   0 107   2   4   0   0   0   0   0   0   1   0   0   0   0   6   0   0   3   0  23   0   0   0   1   1   6   0]
 [  0   1   0   0   1  37   0   0   0   0   0   0   0   0   0   0   3   0   5   0   0   4   0   0   0   0   2   0   2   0   0]
 [  0   0   1   0   1   0 134   0   5   3   0   0   0   0   2   1   0   0   3   0   0   0   1  12   0   0   1   5   0   3   0]
 [  0   3   0   0   1   2   0   4   0   0   0   0   0   2   0   0   0   0   3   0   3   0   0   0   0   0   0   5   0   0   0]
 [  0   0   0   0   0   0   8   0  10   3   0   4   0   0   0   0   0   0   2   0   0   0   0   5   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   6   0   2  12   0   0   0   0   0   0   0   0   6   0   1   1   0   1   0   0   0   3   0   8   0]
 [  0   0   0   0   0   0   0   0   0   0   9   0   0   0  25   0   1   0   0   0   0   3   0   0   0   0   1   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   2   0  18   0   0   1   0   0   0   0   0   0   1   1   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0  13   0   0   1   0   1   0  13   0   0   0   0   0   0   2   0   3   0]
 [  1   0   0   0   1   0   6   0   1   0   5   7   0   0 157   1   0   0   0   0   0   5   0   0   0   0   2   1   2   0   0]
 [  2   0   0   0   0   0   7   0   0   2   0   0   0   0   2   5   0   0   3   0   0   0   0   3   0   0   0   5   0   2   0]
 [  1   0   0   0   0   3   0   0   0   0   1   0   0   0   3   2  32   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   1   0   2   0   0   0   0   3   0   0   0   0   0   0   1   0   0]
 [  4   6   1   0   1   0   1   0   6   7   0   1   0   0   0   2   0   0 115   0   0   4   0   1   0   0   0   1   5   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  73  12   0   0   0   0   0   4   0   8   0]
 [  0   1   0   0   1   0   1   0   0   2   0   1   0   0  16   0   3   0   5   0   4 142   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0  16   2   0   0   1   0   0   0   0]
 [  0   0   1   0  14   0  13   0  11   3   0   5   0   0   0   0   0   0   2   0   0   1   3  87   0   0   1   4   1   3   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   1   0   0   0   0   1   0   0   0   0   1   0   0   1   0   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   4   0   0   1   0   0   0   0   0   0   0   1   5   0   0  56   0   1   0   0]
 [  0   1   1   0   2   3  19   0   2   2   0   0   0   0   2   5   2   0   2   0   0   1   0   2   0   0   0  58   2   4   0]
 [  0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   0   0   0   5   0   0   2   0   7   0   0   0   0  10   0   0]
 [  0   0   0   0   6   1  10   1   1   7   0   0   0   0   0   5   0   0   6   0   2   1   0   6   0   0   0   5   0 129   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:05:16,451 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:16,451 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:16,461 - 

2022-12-15 15:05:16,461 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:16,888 - Epoch: [91][   10/   74]    Overall Loss 0.467552    Objective Loss 0.467552                                        LR 0.001000    Time 0.042637    
2022-12-15 15:05:17,107 - Epoch: [91][   20/   74]    Overall Loss 0.461738    Objective Loss 0.461738                                        LR 0.001000    Time 0.032215    
2022-12-15 15:05:17,349 - Epoch: [91][   30/   74]    Overall Loss 0.460004    Objective Loss 0.460004                                        LR 0.001000    Time 0.029528    
2022-12-15 15:05:17,597 - Epoch: [91][   40/   74]    Overall Loss 0.460062    Objective Loss 0.460062                                        LR 0.001000    Time 0.028341    
2022-12-15 15:05:17,850 - Epoch: [91][   50/   74]    Overall Loss 0.550008    Objective Loss 0.550008                                        LR 0.001000    Time 0.027728    
2022-12-15 15:05:18,105 - Epoch: [91][   60/   74]    Overall Loss 0.600803    Objective Loss 0.600803                                        LR 0.001000    Time 0.027355    
2022-12-15 15:05:18,337 - Epoch: [91][   70/   74]    Overall Loss 0.628997    Objective Loss 0.628997                                        LR 0.001000    Time 0.026749    
2022-12-15 15:05:18,424 - Epoch: [91][   74/   74]    Overall Loss 0.638342    Objective Loss 0.638342    Top1 84.722222    Top5 97.222222    LR 0.001000    Time 0.026481    
2022-12-15 15:05:18,487 - --- validate (epoch=91)-----------
2022-12-15 15:05:18,488 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:18,752 - Epoch: [91][    9/    9]    Loss 1.241670    Top1 65.839695    Top5 91.698473    
2022-12-15 15:05:18,812 - ==> Top1: 65.840    Top5: 91.698    Loss: 1.242

2022-12-15 15:05:18,814 - ==> Confusion:
[[ 18   0   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   1   1   0]
 [  0   4   0   0   6   2   0   2   0   2   0   0   0   0   0   0   0   0  17   0   1   2   0   0   0   0   0   1   0   1   0]
 [  0   0 114   0   8   1   1   0   0   0   0   0   0   0   0   0   0   0   3   0   0   1   0   6   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1   6   0 128   1   5   0   0   0   0   0   0   0   0   0   0   0   5   0   0   2   0   6   0   0   0   3   1   7   0]
 [  0   0   1   0   1  38   0   0   0   0   0   0   0   0   1   0   1   0   6   0   1   5   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   1   0 136   0   3   0   0   1   0   0   3   0   0   0   3   0   0   0   1  11   0   0   1   2   0  10   0]
 [  0   1   0   0   1   1   0   4   0   0   0   0   0   1   0   0   0   0   4   0   5   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   9   0   4   3   0   4   0   0   0   0   0   0   5   0   0   1   0   5   0   0   0   1   0   1   0]
 [  2   0   0   0   0   0   7   0   0   8   0   0   0   0   0   0   0   0   8   0   1   1   0   1   0   0   0   0   0  13   0]
 [  0   0   0   0   0   0   0   0   0   0   2   0   0   0  33   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   0   1   0  14   0   0   3   0   0   0   2   0   0   1   1   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   4   1   0   1   0   1   0  18   0   0   0   0   0   0   1   0   7   0]
 [  1   0   0   0   1   0   5   0   0   0   0   5   0   0 164   1   0   0   1   0   0   8   0   0   0   0   1   1   1   0   0]
 [  2   0   0   0   0   0   8   0   0   4   0   0   0   0   3   2   0   0   2   0   0   0   0   1   0   0   0   7   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   5   1  29   0   5   0   1   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   1   0   2   0   0   3   0   0   0   0   0   1   0   0   0]
 [  1   4   0   0   1   0   2   0   0   1   0   1   0   0   2   0   0   0 131   0   1   6   0   1   0   0   0   0   2   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   1   0   1   0   0   0   0   0   1   0   0   1   0   3   0  74  13   0   0   0   0   0   3   0   9   0]
 [  0   1   0   0   2   0   0   0   0   0   0   0   0   0  12   0   2   0   7   0   6 146   0   0   0   0   0   0   0   2   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0  15   2   0   0   1   0   0   0   0]
 [  1   0   3   0  18   0  11   0   2   0   0   5   0   0   0   0   0   0   5   0   0   2   1  90   0   0   2   1   1   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   2   0]
 [  0   0   0   0   0   0   1   0   1   8   0   0   0   0   0   0   0   0   2   0   0   1   0   0   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   1   0   0   0   0   2   0   0   0   0   1   0   0   0   0   1   0   3   0   0  57   0   0   0   0]
 [  0   0   1   0   3   2  18   0   1   1   0   0   0   0   3   1   3   0   6   0   7   0   0   1   0   0   0  52   0   9   0]
 [  0   1   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   7   0   0   5   0   7   0   0   0   0   4   0   0]
 [  0   0   0   0  10   0   8   1   0   4   0   0   0   0   1   3   0   0   5   0   2   1   0   3   0   0   0   2   0 140   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   6   0   0   0   0   0   0   0   0   1]]

2022-12-15 15:05:18,815 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:18,815 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:18,825 - 

2022-12-15 15:05:18,825 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:19,234 - Epoch: [92][   10/   74]    Overall Loss 0.763634    Objective Loss 0.763634                                        LR 0.001000    Time 0.040757    
2022-12-15 15:05:19,468 - Epoch: [92][   20/   74]    Overall Loss 0.745983    Objective Loss 0.745983                                        LR 0.001000    Time 0.032093    
2022-12-15 15:05:19,717 - Epoch: [92][   30/   74]    Overall Loss 0.744089    Objective Loss 0.744089                                        LR 0.001000    Time 0.029670    
2022-12-15 15:05:19,940 - Epoch: [92][   40/   74]    Overall Loss 0.734301    Objective Loss 0.734301                                        LR 0.001000    Time 0.027810    
2022-12-15 15:05:20,184 - Epoch: [92][   50/   74]    Overall Loss 0.728065    Objective Loss 0.728065                                        LR 0.001000    Time 0.027130    
2022-12-15 15:05:20,429 - Epoch: [92][   60/   74]    Overall Loss 0.724028    Objective Loss 0.724028                                        LR 0.001000    Time 0.026675    
2022-12-15 15:05:20,667 - Epoch: [92][   70/   74]    Overall Loss 0.722302    Objective Loss 0.722302                                        LR 0.001000    Time 0.026271    
2022-12-15 15:05:20,754 - Epoch: [92][   74/   74]    Overall Loss 0.720512    Objective Loss 0.720512    Top1 84.027778    Top5 98.379630    LR 0.001000    Time 0.026012    
2022-12-15 15:05:20,816 - --- validate (epoch=92)-----------
2022-12-15 15:05:20,816 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:21,087 - Epoch: [92][    9/    9]    Loss 1.249602    Top1 66.030534    Top5 91.841603    
2022-12-15 15:05:21,140 - ==> Top1: 66.031    Top5: 91.842    Loss: 1.250

2022-12-15 15:05:21,142 - ==> Confusion:
[[ 16   0   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   2   0   0   0   0   1   0   0   0   0   1   1   0]
 [  0   7   0   0   4   2   0   1   0   2   0   0   0   0   0   0   0   0  17   0   1   2   0   0   0   0   0   0   1   1   0]
 [  0   0 117   0   4   1   0   0   0   0   0   0   0   0   0   0   0   0   4   0   0   1   0   7   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   8   0 122   2   2   0   0   0   0   0   0   0   0   1   0   0   5   0   0   3   0   8   0   0   0   3   0   8   0]
 [  0   1   1   0   1  39   0   0   0   0   0   0   0   0   1   0   1   0   5   0   2   3   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   1   0 127   0   3   1   0   0   0   0   3   1   0   0   3   0   0   0   1  15   0   0   1   5   0  11   0]
 [  0   3   0   0   0   2   0   4   0   0   0   0   0   1   0   0   0   0   4   0   2   0   0   0   0   0   0   5   0   2   0]
 [  0   0   0   0   0   0   7   0   6   4   0   2   0   0   0   0   0   0   5   0   0   1   0   5   0   0   0   2   0   1   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   0   0   0   7   0   1   1   0   1   0   0   0   1   0  13   0]
 [  0   0   0   0   0   0   0   0   0   0   4   0   0   0  30   0   0   0   0   0   0   4   0   0   0   0   1   1   0   0   0]
 [  0   0   0   0   0   0   2   0   0   1   0  13   0   0   1   0   0   0   1   0   0   3   2   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0  21   0   0   0   0   0   0   2   0   5   0]
 [  1   0   0   0   0   0   5   0   0   1   0   4   0   0 162   1   1   0   1   0   0  10   0   0   0   0   1   1   1   0   0]
 [  2   0   0   0   0   0   5   0   0   5   0   0   0   0   2   2   0   0   4   0   0   0   0   3   0   0   0   6   0   2   0]
 [  1   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   0   0   0   2   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  2   1   0   0   2   0   2   0   0   3   0   1   0   0   1   0   2   0 130   0   4   4   0   0   0   0   0   0   0   6   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   1   0   1   0   0   0   0   0   1   0   0   1   0   2   0  75  14   0   0   0   0   0   5   0   7   0]
 [  0   1   0   0   1   0   0   0   0   0   0   0   0   0   6   0   3   0   9   0   6 148   0   0   0   0   0   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   0   2   0  17   0   9   0   1   0   0   4   0   0   0   0   0   0   6   0   0   2   2  93   0   0   2   2   1   8   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   1   0   0   6   0   0   0   0   0   0   0   0   2   0   0   1   0   1   0   0   0   2   0   1   0]
 [  0   0   2   0   0   0   1   0   0   0   0   2   0   0   1   0   1   0   0   0   0   1   0   4   0   0  55   0   1   0   0]
 [  0   0   1   0   2   2  13   0   1   2   0   0   0   0   2   1   3   0   5   0   5   0   0   3   0   0   0  56   0  12   0]
 [  0   0   1   0   0   1   0   0   0   0   0   1   0   0   1   0   0   0   9   0   0   2   0   8   0   0   0   0   3   0   0]
 [  0   0   0   0   8   0   4   1   0   3   0   0   0   0   0   4   0   0   7   0   3   0   0   4   0   0   0   3   0 143   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   6   0   0   0   0   0   0   0   0   1]]

2022-12-15 15:05:21,144 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:21,144 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:21,161 - 

2022-12-15 15:05:21,161 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:21,880 - Epoch: [93][   10/   74]    Overall Loss 0.645265    Objective Loss 0.645265                                        LR 0.001000    Time 0.071857    
2022-12-15 15:05:22,128 - Epoch: [93][   20/   74]    Overall Loss 0.648700    Objective Loss 0.648700                                        LR 0.001000    Time 0.048278    
2022-12-15 15:05:22,378 - Epoch: [93][   30/   74]    Overall Loss 0.650563    Objective Loss 0.650563                                        LR 0.001000    Time 0.040514    
2022-12-15 15:05:22,643 - Epoch: [93][   40/   74]    Overall Loss 0.647296    Objective Loss 0.647296                                        LR 0.001000    Time 0.036998    
2022-12-15 15:05:22,910 - Epoch: [93][   50/   74]    Overall Loss 0.651278    Objective Loss 0.651278                                        LR 0.001000    Time 0.034927    
2022-12-15 15:05:23,174 - Epoch: [93][   60/   74]    Overall Loss 0.646802    Objective Loss 0.646802                                        LR 0.001000    Time 0.033496    
2022-12-15 15:05:23,422 - Epoch: [93][   70/   74]    Overall Loss 0.647432    Objective Loss 0.647432                                        LR 0.001000    Time 0.032253    
2022-12-15 15:05:23,507 - Epoch: [93][   74/   74]    Overall Loss 0.648798    Objective Loss 0.648798    Top1 84.953704    Top5 97.916667    LR 0.001000    Time 0.031658    
2022-12-15 15:05:23,573 - --- validate (epoch=93)-----------
2022-12-15 15:05:23,573 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:23,852 - Epoch: [93][    9/    9]    Loss 1.213452    Top1 65.171756    Top5 91.173664    
2022-12-15 15:05:23,909 - ==> Top1: 65.172    Top5: 91.174    Loss: 1.213

2022-12-15 15:05:23,911 - ==> Confusion:
[[ 16   0   0   0   0   0   5   0   0   0   0   2   0   0   0   0   1   0   2   0   0   0   1   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   3   0   1   0   2   0   0   0   0   0   0   0   0  12   0   1   2   0   0   0   0   0   0   1   0   0]
 [  0   0 112   0   9   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   1   6   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   8   0 120   2   6   0   0   0   0   0   0   0   0   0   0   0   4   0   0   4   0  10   0   0   0   3   1   4   0]
 [  0   0   0   0   1  41   0   0   0   0   0   0   0   0   1   0   1   0   5   0   1   3   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   1   0 137   0   4   0   0   1   0   0   5   0   0   0   2   0   0   0   1  11   0   0   1   5   0   3   0]
 [  0   2   0   0   1   2   0   2   0   0   0   0   0   0   0   0   0   0   5   0   4   0   0   0   0   0   0   6   0   1   0]
 [  0   0   0   0   0   0   9   0   6   4   0   2   0   0   0   1   0   0   4   0   0   1   0   5   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   6   0   1   8   0   0   0   0   0   2   0   0   9   0   1   1   0   4   0   0   0   0   0   8   0]
 [  0   0   0   0   0   0   0   0   0   0   5   0   0   0  30   0   0   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  15   0   0   1   0   0   0   2   0   0   1   2   0   0   0   1   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   1   0   0   0   0   0   0   0   5   0   1   0   0   1   0  19   0   0   0   0   0   0   1   0   5   0]
 [  1   0   0   0   1   0   5   0   0   0   0   6   0   0 161   1   0   0   1   0   0   9   0   0   0   0   2   1   1   0   0]
 [  4   0   0   0   0   0   8   0   0   2   0   0   0   0   2   4   0   0   2   0   0   0   0   2   0   0   0   5   0   2   0]
 [  1   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   6   0   0   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   4   1   0   2   0   2   1   1   2   0   1   0   0   1   1   0   0 122   0   1   9   0   0   0   0   0   2   3   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   2   0   1   0   0   0   0   0   1   2   0   1   0   2   0  69  15   0   0   0   0   0   6   0   6   0]
 [  0   2   0   0   1   0   0   0   0   1   0   0   0   0  12   0   4   0   5   0   4 145   0   0   0   0   1   0   0   3   0]
 [  1   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  14   2   0   0   1   0   0   0   0]
 [  0   0   2   0  15   0  16   0   1   0   0   4   0   0   0   0   0   0   6   0   0   1   3  92   0   0   1   2   1   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   2   0   0   1   0   0   0   0   0   0   1   0   4   0   0  56   0   2   0   0]
 [  0   0   2   0   2   3  21   0   1   1   0   1   0   0   3   1   3   0   4   0   4   0   0   2   0   0   0  56   0   4   0]
 [  1   0   0   0   0   0   0   0   0   0   0   2   0   0   1   0   0   0   8   0   0   3   0   7   0   0   0   1   3   0   0]
 [  0   0   0   0   9   0  11   1   0   4   0   0   0   0   0   5   0   0   7   0   2   1   0   4   0   0   0   3   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   0]]

2022-12-15 15:05:23,912 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:23,912 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:23,922 - 

2022-12-15 15:05:23,922 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:24,348 - Epoch: [94][   10/   74]    Overall Loss 0.611275    Objective Loss 0.611275                                        LR 0.001000    Time 0.042487    
2022-12-15 15:05:24,597 - Epoch: [94][   20/   74]    Overall Loss 0.605182    Objective Loss 0.605182                                        LR 0.001000    Time 0.033677    
2022-12-15 15:05:24,846 - Epoch: [94][   30/   74]    Overall Loss 0.612075    Objective Loss 0.612075                                        LR 0.001000    Time 0.030744    
2022-12-15 15:05:25,106 - Epoch: [94][   40/   74]    Overall Loss 0.614987    Objective Loss 0.614987                                        LR 0.001000    Time 0.029544    
2022-12-15 15:05:25,366 - Epoch: [94][   50/   74]    Overall Loss 0.617388    Objective Loss 0.617388                                        LR 0.001000    Time 0.028820    
2022-12-15 15:05:25,632 - Epoch: [94][   60/   74]    Overall Loss 0.617596    Objective Loss 0.617596                                        LR 0.001000    Time 0.028415    
2022-12-15 15:05:25,858 - Epoch: [94][   70/   74]    Overall Loss 0.613830    Objective Loss 0.613830                                        LR 0.001000    Time 0.027585    
2022-12-15 15:05:25,943 - Epoch: [94][   74/   74]    Overall Loss 0.612202    Objective Loss 0.612202    Top1 87.268519    Top5 98.611111    LR 0.001000    Time 0.027237    
2022-12-15 15:05:26,014 - --- validate (epoch=94)-----------
2022-12-15 15:05:26,014 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:26,325 - Epoch: [94][    9/    9]    Loss 1.246002    Top1 65.267176    Top5 91.507634    
2022-12-15 15:05:26,382 - ==> Top1: 65.267    Top5: 91.508    Loss: 1.246

2022-12-15 15:05:26,384 - ==> Confusion:
[[ 18   0   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   2   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   4   3   0   2   0   2   0   0   0   0   0   0   0   0  15   0   1   0   0   0   0   0   0   2   0   0   0]
 [  0   0 110   0  10   1   1   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   7   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1   7   0 113   2   6   0   0   0   0   0   0   1   1   0   0   0   7   0   0   4   0   9   0   0   0   6   0   8   0]
 [  0   0   1   0   0  39   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   5   0   0   0   0   1   1   1   0   0]
 [  0   0   1   0   1   0 130   0   1   3   0   0   0   0   3   1   0   0   2   0   0   0   1  12   0   0   1   3   0  13   0]
 [  0   3   0   0   0   1   0   4   0   0   0   0   0   2   0   0   0   0   3   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   9   0   5   7   0   1   0   0   0   0   0   0   5   0   0   1   0   3   0   0   0   2   0   0   0]
 [  0   0   0   0   0   0   2   0   0  10   0   0   0   0   2   4   0   0   7   0   1   1   0   0   0   0   0   0   0  14   0]
 [  0   0   0   0   0   0   0   0   0   0   8   0   0   0  26   0   1   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   0   2   0  14   0   0   0   0   0   0   2   0   0   3   2   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   9   0   0   1   0   1   0  15   1   0   0   0   0   0   2   0   4   0]
 [  1   0   0   0   0   0   5   0   0   1   0   5   0   0 158   1   2   0   2   0   0  11   0   0   0   0   1   1   1   0   0]
 [  1   0   0   0   0   0   6   0   0   3   0   0   0   0   2   7   0   0   4   0   0   0   0   0   0   0   0   6   0   2   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  34   0   6   0   0   4   0   0   0   0   0   0   0   2   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0   1   0   1   2   0   0   0   0   0   0   1   0   0]
 [  2   5   1   0   1   0   1   0   1   5   0   0   0   0   0   1   2   0 127   0   2   4   0   0   0   0   0   1   0   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   1   0   2   0   0   0   0   0   1   0   0   1   0   2   0  75  13   0   0   0   0   0   7   0   5   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   9   0   4   0   6   0   6 148   0   0   0   0   0   0   0   4   0]
 [  0   0   6   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   9   3   0   0   1   0   0   0   0]
 [  1   0   2   0  15   0  16   0   3   2   0   3   0   0   0   0   0   0   6   0   0   2   2  81   0   0   2   2   0  12   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   1   0   0   1   0   0   0   1   0   0   0]
 [  0   0   0   0   0   1   1   0   0   0   0   2   0   0   1   0   0   0   0   0   0   1   1   5   0   0  55   0   1   0   0]
 [  0   0   1   0   2   1  13   0   1   1   0   0   0   0   3   2   5   0   5   0   6   0   0   2   0   0   0  55   0  11   0]
 [  0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0   8   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   1   0   0   6   0   5   1   0   3   0   0   0   0   1   5   0   0   5   0   4   1   0   3   0   0   0   3   0 142   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   2   5   0   0   0   0   0   0   0   0   1]]

2022-12-15 15:05:26,386 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:26,386 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:26,405 - 

2022-12-15 15:05:26,406 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:26,862 - Epoch: [95][   10/   74]    Overall Loss 0.583319    Objective Loss 0.583319                                        LR 0.001000    Time 0.045534    
2022-12-15 15:05:27,146 - Epoch: [95][   20/   74]    Overall Loss 0.585967    Objective Loss 0.585967                                        LR 0.001000    Time 0.036927    
2022-12-15 15:05:27,428 - Epoch: [95][   30/   74]    Overall Loss 0.586485    Objective Loss 0.586485                                        LR 0.001000    Time 0.034017    
2022-12-15 15:05:27,698 - Epoch: [95][   40/   74]    Overall Loss 0.581775    Objective Loss 0.581775                                        LR 0.001000    Time 0.032250    
2022-12-15 15:05:27,949 - Epoch: [95][   50/   74]    Overall Loss 0.582940    Objective Loss 0.582940                                        LR 0.001000    Time 0.030808    
2022-12-15 15:05:28,199 - Epoch: [95][   60/   74]    Overall Loss 0.584183    Objective Loss 0.584183                                        LR 0.001000    Time 0.029828    
2022-12-15 15:05:28,442 - Epoch: [95][   70/   74]    Overall Loss 0.583034    Objective Loss 0.583034                                        LR 0.001000    Time 0.029043    
2022-12-15 15:05:28,531 - Epoch: [95][   74/   74]    Overall Loss 0.584403    Objective Loss 0.584403    Top1 83.101852    Top5 98.379630    LR 0.001000    Time 0.028667    
2022-12-15 15:05:28,586 - --- validate (epoch=95)-----------
2022-12-15 15:05:28,586 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:28,865 - Epoch: [95][    9/    9]    Loss 1.233159    Top1 65.601145    Top5 91.507634    
2022-12-15 15:05:28,912 - ==> Top1: 65.601    Top5: 91.508    Loss: 1.233

2022-12-15 15:05:28,914 - ==> Confusion:
[[ 18   1   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   1   0   0]
 [  0  10   0   0   7   1   0   1   0   3   0   0   0   0   0   0   0   0  10   0   2   2   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   1   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   6   0 125   2   4   0   0   0   0   0   0   1   0   1   0   0   3   0   0   3   0   7   0   0   0   3   1   5   0]
 [  0   0   0   0   1  40   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   1   0   1   0 126   0   4   2   0   2   0   0   4   1   0   0   2   0   0   0   1  11   0   0   1   7   0   9   0]
 [  0   5   0   0   0   1   0   5   0   0   0   0   0   0   0   0   0   0   2   0   4   0   0   0   0   0   0   5   0   1   0]
 [  1   0   0   0   0   0   7   0   6   4   0   3   0   0   0   0   0   0   3   0   0   1   0   6   0   0   0   2   0   0   0]
 [  2   0   0   0   0   0   4   0   1  11   0   0   0   0   0   1   0   0   6   0   1   1   0   1   0   0   0   2   0  11   0]
 [  0   0   0   0   0   0   0   0   0   0   8   0   0   0  27   0   1   0   1   0   0   2   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   2   0  16   0   0   2   0   0   0   0   0   0   2   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0   0   6   0   0   0   0   0   0  21   0   0   0   0   0   0   2   0   3   0]
 [  1   0   0   0   0   1   5   0   0   1   1   3   0   0 161   0   3   0   1   0   0   8   0   0   0   0   1   2   1   0   0]
 [  3   0   0   0   0   0   5   0   0   5   0   0   0   0   2   2   0   0   3   0   0   0   0   2   0   0   0   7   0   2   0]
 [  3   0   0   0   0   2   0   0   0   0   0   0   0   0   2   1  33   0   4   0   0   6   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   3   0   1   0   0   3   0   0   0   0   0   0   0   0   0]
 [  3   6   1   0   2   0   1   2   1   2   0   0   0   0   0   0   2   0 123   0   3   4   0   1   0   0   0   0   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   2   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  78  10   0   0   0   0   0   7   0   4   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0  10   0   5   0   6   0   9 143   0   0   0   0   1   0   0   3   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   4   0  18   0  13   0   1   0   0   5   0   0   0   0   0   0   6   0   1   1   1  80   0   0   2   7   3   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   2   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   0   0   0   2   0   1   1   0   1   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   2   0   0   0   0   2   0   0   0   0   2   0   3   0   0  56   0   0   0   0]
 [  0   0   2   0   3   1  14   0   1   2   0   0   0   0   3   2   4   0   6   0   4   0   0   0   0   0   0  58   0   8   0]
 [  0   1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   6   0   0   3   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   0   8   2   0   5   0   0   0   0   1   3   0   0   4   0   4   3   0   1   0   0   0   5   0 135   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   6   0   0   0   0   0   0   0   0   1]]

2022-12-15 15:05:28,915 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:28,915 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:28,925 - 

2022-12-15 15:05:28,926 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:29,342 - Epoch: [96][   10/   74]    Overall Loss 0.546852    Objective Loss 0.546852                                        LR 0.001000    Time 0.041553    
2022-12-15 15:05:29,580 - Epoch: [96][   20/   74]    Overall Loss 0.548445    Objective Loss 0.548445                                        LR 0.001000    Time 0.032666    
2022-12-15 15:05:29,834 - Epoch: [96][   30/   74]    Overall Loss 0.554458    Objective Loss 0.554458                                        LR 0.001000    Time 0.030224    
2022-12-15 15:05:30,095 - Epoch: [96][   40/   74]    Overall Loss 0.553676    Objective Loss 0.553676                                        LR 0.001000    Time 0.029178    
2022-12-15 15:05:30,350 - Epoch: [96][   50/   74]    Overall Loss 0.556845    Objective Loss 0.556845                                        LR 0.001000    Time 0.028437    
2022-12-15 15:05:30,606 - Epoch: [96][   60/   74]    Overall Loss 0.562349    Objective Loss 0.562349                                        LR 0.001000    Time 0.027959    
2022-12-15 15:05:30,855 - Epoch: [96][   70/   74]    Overall Loss 0.564705    Objective Loss 0.564705                                        LR 0.001000    Time 0.027519    
2022-12-15 15:05:30,944 - Epoch: [96][   74/   74]    Overall Loss 0.563819    Objective Loss 0.563819    Top1 90.046296    Top5 98.148148    LR 0.001000    Time 0.027224    
2022-12-15 15:05:31,012 - --- validate (epoch=96)-----------
2022-12-15 15:05:31,012 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:31,280 - Epoch: [96][    9/    9]    Loss 1.222229    Top1 65.553435    Top5 91.364504    
2022-12-15 15:05:31,330 - ==> Top1: 65.553    Top5: 91.365    Loss: 1.222

2022-12-15 15:05:31,332 - ==> Confusion:
[[ 17   1   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   1   1   0]
 [  0  11   0   0   7   1   0   1   0   2   0   0   0   0   0   0   0   0  10   0   1   1   0   1   0   0   0   1   1   1   0]
 [  0   0 111   0  11   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   0   1   0   7   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   5   0 132   1   6   0   0   0   0   0   0   0   0   0   0   0   2   0   0   2   0   7   0   0   0   0   0   6   0]
 [  0   2   0   0   1  40   0   0   0   1   0   0   0   0   0   0   2   0   3   0   0   4   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   1   0 129   0   1   3   0   1   0   0   2   1   0   0   1   0   0   0   1  14   0   0   1   6   0  11   0]
 [  0   3   0   0   1   1   0   4   0   0   0   0   0   2   0   0   0   0   1   0   6   0   0   0   0   0   0   5   0   0   0]
 [  0   0   0   0   0   0   6   0   8   4   0   1   0   0   0   0   0   0   3   0   0   1   0   7   0   0   0   1   1   1   0]
 [  1   0   0   0   0   0   5   0   1  10   0   0   0   0   0   0   0   0   6   0   1   1   0   3   0   0   0   1   0  12   0]
 [  0   0   0   0   0   0   1   0   0   0   7   0   0   0  26   0   0   0   1   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   0   1   0  15   0   0   1   0   0   0   2   0   0   1   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   7   0   0   0   0   1   0  17   0   0   0   0   0   0   2   0   6   0]
 [  2   0   0   0   1   0   5   0   0   1   1   5   0   0 156   1   1   0   1   0   0  10   0   0   0   0   1   2   2   0   0]
 [  1   0   0   0   0   0   5   0   1   3   0   0   0   0   3   2   0   0   4   0   0   0   0   4   0   0   0   6   0   2   0]
 [  1   0   0   0   0   3   0   0   0   0   0   0   0   0   2   0  32   0   6   0   1   5   0   0   0   0   0   0   0   2   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  2  14   1   0   6   0   1   0   1   3   0   0   0   0   0   0   1   0 112   0   1   4   0   3   0   0   0   0   3   6   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   1   0   2   0   0   0   0   0   1   0   0   0   0   1   0  76   9   0   0   0   0   0   6   0  10   0]
 [  0   3   0   0   2   0   0   0   0   0   0   0   0   0  10   0   4   0   7   0   7 141   0   0   0   0   1   0   0   3   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   0   1   0  20   0  10   0   2   0   0   4   0   0   0   0   0   0   5   0   0   2   2  92   0   0   2   1   0   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   1   0   0   1   0   1   0   0   1   0   0   0   1   0   1   0]
 [  0   0   1   0   0   0   1   0   0   0   0   1   0   0   1   0   1   0   0   0   0   1   0   4   0   0  56   0   2   0   0]
 [  0   0   2   0   2   3  17   0   2   1   0   0   0   0   2   1   2   0   5   0   3   0   0   1   0   0   0  57   0  10   0]
 [  0   1   0   0   1   0   0   0   0   0   0   1   0   0   1   0   0   0   5   0   0   3   0   8   0   0   0   1   5   0   0]
 [  0   0   0   0  11   0   9   1   0   5   0   0   0   0   0   3   0   0   2   0   2   1   0   5   0   0   0   2   0 139   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   6   0   0   0   0   0   0   0   0   2]]

2022-12-15 15:05:31,333 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:31,333 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:31,343 - 

2022-12-15 15:05:31,343 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:31,752 - Epoch: [97][   10/   74]    Overall Loss 0.547567    Objective Loss 0.547567                                        LR 0.001000    Time 0.040807    
2022-12-15 15:05:31,999 - Epoch: [97][   20/   74]    Overall Loss 0.538423    Objective Loss 0.538423                                        LR 0.001000    Time 0.032707    
2022-12-15 15:05:32,253 - Epoch: [97][   30/   74]    Overall Loss 0.541120    Objective Loss 0.541120                                        LR 0.001000    Time 0.030225    
2022-12-15 15:05:32,507 - Epoch: [97][   40/   74]    Overall Loss 0.542988    Objective Loss 0.542988                                        LR 0.001000    Time 0.029025    
2022-12-15 15:05:32,763 - Epoch: [97][   50/   74]    Overall Loss 0.540680    Objective Loss 0.540680                                        LR 0.001000    Time 0.028302    
2022-12-15 15:05:33,019 - Epoch: [97][   60/   74]    Overall Loss 0.545203    Objective Loss 0.545203                                        LR 0.001000    Time 0.027847    
2022-12-15 15:05:33,261 - Epoch: [97][   70/   74]    Overall Loss 0.546022    Objective Loss 0.546022                                        LR 0.001000    Time 0.027324    
2022-12-15 15:05:33,348 - Epoch: [97][   74/   74]    Overall Loss 0.547085    Objective Loss 0.547085    Top1 85.185185    Top5 97.916667    LR 0.001000    Time 0.027019    
2022-12-15 15:05:33,408 - --- validate (epoch=97)-----------
2022-12-15 15:05:33,409 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:33,683 - Epoch: [97][    9/    9]    Loss 1.227046    Top1 66.173664    Top5 91.125954    
2022-12-15 15:05:33,737 - ==> Top1: 66.174    Top5: 91.126    Loss: 1.227

2022-12-15 15:05:33,739 - ==> Confusion:
[[ 18   0   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   1   0   0]
 [  0  10   0   0   4   3   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   0   0   0   0   0   0   1   1   1   0]
 [  0   0 112   0  10   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   6   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   5   7   0 120   1   3   0   0   0   0   0   0   0   0   1   0   0   5   0   0   4   0   8   0   0   0   4   2   5   0]
 [  0   0   0   0   0  39   0   0   0   0   0   0   0   0   0   0   1   0   6   0   0   6   0   0   0   0   1   1   1   0   0]
 [  0   0   0   0   1   0 126   0   3   2   0   2   0   0   4   1   0   0   5   0   0   0   1  13   0   0   0   5   0   9   0]
 [  0   4   0   0   1   2   0   4   0   0   0   0   0   2   0   0   0   0   2   0   3   0   0   0   0   0   0   5   0   0   0]
 [  0   0   0   0   0   0   8   0   8   5   0   2   0   0   0   0   0   0   4   0   0   1   0   3   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   2   0   2  12   0   0   0   0   1   0   0   0   7   0   1   1   0   1   0   0   0   1   0  12   0]
 [  0   0   0   0   0   0   0   0   0   0  10   0   0   0  21   0   0   0   1   0   0   7   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   2   0  15   0   0   0   0   0   0   1   0   0   3   2   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   2   0   0   0   0   0   7   0   0   0   0   1   0  17   1   0   0   0   0   0   2   0   3   0]
 [  1   0   0   0   0   1   4   0   0   1   2   6   0   0 158   0   1   0   1   0   0  11   0   0   0   0   1   1   1   0   0]
 [  1   0   0   0   0   0   7   0   0   2   0   0   0   0   2   7   0   0   3   0   0   0   0   2   0   0   0   5   0   2   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   2   1  33   0   7   0   0   6   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  2   6   0   0   0   0   1   0   0   4   0   1   0   1   0   1   1   0 127   0   1   7   0   1   0   0   0   1   1   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  76  11   0   0   0   0   0   4   0   8   0]
 [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   6   0   5   0   6   0   6 147   0   0   0   0   1   0   1   4   0]
 [  0   0   1   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  14   3   0   0   1   0   0   0   0]
 [  0   0   6   0  18   0   9   0   3   0   0   5   0   0   0   1   0   0   5   0   0   1   1  87   0   0   2   1   2   8   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   2   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   1   0   0   2   0   1   1   0   1   0   0   0   0   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   2   0   4   0   0  55   0   2   0   0]
 [  0   0   1   0   3   3  12   0   1   3   0   0   0   0   3   2   4   0   5   0   4   0   0   2   0   0   0  57   0   8   0]
 [  0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   7   0   0   3   0   8   0   0   0   0   5   0   0]
 [  0   1   0   0   6   0   6   2   0   5   0   0   0   0   0   3   0   0   5   0   4   3   0   3   0   0   0   4   0 138   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   6   0   0   0   0   0   0   0   0   1]]

2022-12-15 15:05:33,740 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:33,740 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:33,750 - 

2022-12-15 15:05:33,750 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:34,154 - Epoch: [98][   10/   74]    Overall Loss 0.535775    Objective Loss 0.535775                                        LR 0.001000    Time 0.040324    
2022-12-15 15:05:34,394 - Epoch: [98][   20/   74]    Overall Loss 0.531072    Objective Loss 0.531072                                        LR 0.001000    Time 0.032124    
2022-12-15 15:05:34,640 - Epoch: [98][   30/   74]    Overall Loss 0.536521    Objective Loss 0.536521                                        LR 0.001000    Time 0.029593    
2022-12-15 15:05:34,891 - Epoch: [98][   40/   74]    Overall Loss 0.541047    Objective Loss 0.541047                                        LR 0.001000    Time 0.028422    
2022-12-15 15:05:35,139 - Epoch: [98][   50/   74]    Overall Loss 0.538826    Objective Loss 0.538826                                        LR 0.001000    Time 0.027705    
2022-12-15 15:05:35,359 - Epoch: [98][   60/   74]    Overall Loss 0.542734    Objective Loss 0.542734                                        LR 0.001000    Time 0.026733    
2022-12-15 15:05:35,584 - Epoch: [98][   70/   74]    Overall Loss 0.542331    Objective Loss 0.542331                                        LR 0.001000    Time 0.026123    
2022-12-15 15:05:35,666 - Epoch: [98][   74/   74]    Overall Loss 0.543280    Objective Loss 0.543280    Top1 87.037037    Top5 97.685185    LR 0.001000    Time 0.025827    
2022-12-15 15:05:35,731 - --- validate (epoch=98)-----------
2022-12-15 15:05:35,731 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:36,001 - Epoch: [98][    9/    9]    Loss 1.231051    Top1 65.458015    Top5 91.316794    
2022-12-15 15:05:36,050 - ==> Top1: 65.458    Top5: 91.317    Loss: 1.231

2022-12-15 15:05:36,052 - ==> Confusion:
[[ 16   1   1   0   0   0   4   0   1   0   0   1   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   1   1   0   0]
 [  0  11   1   0   7   2   0   1   0   2   0   0   0   0   0   0   0   0  10   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 113   0  10   0   1   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   4   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   4   0 137   1   0   0   0   0   0   0   0   0   0   1   0   0   3   0   0   2   0   7   0   0   0   2   0   5   0]
 [  0   1   0   0   1  43   0   0   0   0   0   0   0   0   0   0   1   0   3   0   0   3   0   0   0   0   1   0   2   0   0]
 [  0   0   1   0   3   0 123   0   4   3   0   0   0   0   2   1   0   0   1   0   0   1   1  15   0   0   0   9   0   8   0]
 [  0   4   0   0   1   2   0   4   0   0   0   0   0   1   0   0   0   0   2   0   4   0   0   0   0   0   0   5   0   0   0]
 [  0   0   0   0   0   0   6   0  10   4   0   2   0   0   0   0   0   0   3   0   0   1   0   4   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   3   0   1  13   0   0   0   0   0   0   0   0   6   0   1   1   0   2   0   0   0   3   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  11   0   0   0  24   0   0   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   3   0   0   2   0  13   0   0   2   0   0   0   1   0   0   1   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   1   0   0   0   0   0   6   0   0   0   0   0   0  19   0   0   0   0   0   0   2   0   4   0]
 [  1   0   0   0   1   0   5   0   0   1   2   4   0   0 159   0   1   0   1   0   0  10   0   0   0   0   1   2   1   0   0]
 [  1   0   0   0   0   0   6   0   0   4   0   0   0   0   2   5   0   0   2   0   0   0   0   4   0   0   0   5   0   2   0]
 [  1   0   0   0   0   4   0   1   0   0   0   0   0   0   2   2  33   0   5   0   0   4   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   1   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  2  10   2   0   4   1   1   0   2   4   0   0   0   0   0   1   1   0 117   0   1   4   0   0   0   0   0   1   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   4   2   0   2   0   0   0   0   0   1   1   0   1   0   1   0  76   9   0   0   0   0   0   4   0   7   0]
 [  0   4   0   0   3   0   0   0   0   0   0   0   0   0  16   0   4   0   5   0   7 134   0   0   0   0   2   0   1   2   0]
 [  0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0  13   2   0   0   1   0   1   0   0]
 [  1   0   5   0  23   0  13   0   1   0   0   4   0   0   0   0   0   0   5   0   0   2   2  79   0   0   2   4   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   2   0]
 [  0   0   0   0   0   0   1   0   0   6   0   0   0   0   0   1   0   0   1   0   2   0   0   1   0   0   0   1   0   1   0]
 [  0   0   2   0   0   0   1   0   0   0   0   1   0   0   1   0   0   0   0   0   0   0   0   4   0   0  58   0   1   0   0]
 [  0   0   1   0   2   4  15   1   1   2   0   1   0   0   2   1   3   0   3   0   2   0   1   0   0   0   1  60   0   8   0]
 [  0   1   0   0   1   1   0   0   0   0   0   2   0   0   1   0   1   0   6   0   0   2   1   5   0   0   0   0   5   0   0]
 [  0   0   0   0  18   0   9   1   0   4   0   0   0   0   0   2   0   0   5   0   3   1   0   2   0   0   0   6   0 129   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   5   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:05:36,054 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:36,054 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:36,071 - 

2022-12-15 15:05:36,072 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:36,816 - Epoch: [99][   10/   74]    Overall Loss 0.514638    Objective Loss 0.514638                                        LR 0.001000    Time 0.074392    
2022-12-15 15:05:37,096 - Epoch: [99][   20/   74]    Overall Loss 0.517255    Objective Loss 0.517255                                        LR 0.001000    Time 0.051179    
2022-12-15 15:05:37,379 - Epoch: [99][   30/   74]    Overall Loss 0.520816    Objective Loss 0.520816                                        LR 0.001000    Time 0.043525    
2022-12-15 15:05:37,657 - Epoch: [99][   40/   74]    Overall Loss 0.519738    Objective Loss 0.519738                                        LR 0.001000    Time 0.039592    
2022-12-15 15:05:37,935 - Epoch: [99][   50/   74]    Overall Loss 0.522505    Objective Loss 0.522505                                        LR 0.001000    Time 0.037226    
2022-12-15 15:05:38,209 - Epoch: [99][   60/   74]    Overall Loss 0.523927    Objective Loss 0.523927                                        LR 0.001000    Time 0.035574    
2022-12-15 15:05:38,447 - Epoch: [99][   70/   74]    Overall Loss 0.527668    Objective Loss 0.527668                                        LR 0.001000    Time 0.033883    
2022-12-15 15:05:38,535 - Epoch: [99][   74/   74]    Overall Loss 0.524768    Objective Loss 0.524768    Top1 86.805556    Top5 97.685185    LR 0.001000    Time 0.033246    
2022-12-15 15:05:38,609 - --- validate (epoch=99)-----------
2022-12-15 15:05:38,609 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:38,894 - Epoch: [99][    9/    9]    Loss 1.238216    Top1 66.125954    Top5 90.839695    
2022-12-15 15:05:38,953 - ==> Top1: 66.126    Top5: 90.840    Loss: 1.238

2022-12-15 15:05:38,955 - ==> Confusion:
[[ 21   0   0   0   0   0   3   0   1   0   0   1   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   4   2   0   1   0   3   0   0   0   0   0   0   0   0  14   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 110   0   9   0   1   0   0   0   0   0   0   0   0   0   0   0   4   0   1   2   0   6   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   5   0 118   1   8   0   0   0   0   0   0   0   0   0   0   0   6   0   0   3   0  11   0   0   0   1   0   8   0]
 [  0   1   0   0   1  38   0   0   0   0   0   0   0   0   0   0   4   0   5   0   0   3   0   0   0   0   1   0   2   0   0]
 [  0   0   0   0   0   0 139   0   4   0   0   1   0   0   2   1   0   0   2   0   0   0   0  14   0   0   0   2   0   7   0]
 [  0   4   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   2   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0  11   4   0   4   0   0   0   1   0   0   3   0   0   0   0   4   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   6   0   1  13   0   0   0   0   0   3   0   0   5   0   1   1   0   3   0   0   0   0   0   7   0]
 [  0   0   0   0   0   0   0   0   0   0   8   0   0   0  26   0   0   0   0   0   0   5   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  17   0   0   1   0   0   0   0   0   0   1   2   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   1   0   1   0   0   0   0   0   8   0   1   0   0   1   0  13   0   0   0   0   0   0   1   0   7   0]
 [  1   0   0   0   0   0   5   0   0   2   1   6   0   0 158   0   3   0   0   0   0   9   0   0   0   0   1   2   1   0   0]
 [  3   0   0   0   0   0   6   0   0   3   0   0   0   0   2   6   0   0   2   0   0   0   0   4   0   0   0   3   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  32   0   5   0   1   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   4   1   0   1   0   1   0   1   8   0   1   0   0   1   0   0   0 120   0   2   5   0   2   0   0   0   1   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  69   8   0   0   0   0   0   8   0  13   0]
 [  0   2   0   0   0   0   1   0   0   1   0   1   0   0  13   0   5   0   9   0   6 133   0   0   0   0   1   0   0   6   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0  15   2   0   0   1   0   0   0   0]
 [  0   1   1   0  14   0  12   0   5   0   0   5   0   0   0   0   0   0   3   0   0   1   1  94   0   0   2   2   1   7   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   1   0   0   0   0   1   0   0   1   0   0   0   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   0   0   0]
 [  0   0   2   0   2   2  15   0   1   3   0   0   0   0   3   3   3   0   5   0   2   0   0   1   0   0   0  57   1   8   0]
 [  0   0   0   0   0   0   0   0   0   0   0   2   0   0   2   0   2   0   4   0   0   1   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   7   0   8   1   0   6   0   0   0   1   0   4   0   0   5   0   1   0   0   6   0   0   0   4   0 137   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:05:38,956 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:38,956 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:38,966 - 

2022-12-15 15:05:38,966 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:39,397 - Epoch: [100][   10/   74]    Overall Loss 0.476377    Objective Loss 0.476377                                        LR 0.000100    Time 0.042984    
2022-12-15 15:05:39,646 - Epoch: [100][   20/   74]    Overall Loss 0.461696    Objective Loss 0.461696                                        LR 0.000100    Time 0.033921    
2022-12-15 15:05:39,901 - Epoch: [100][   30/   74]    Overall Loss 0.465825    Objective Loss 0.465825                                        LR 0.000100    Time 0.031120    
2022-12-15 15:05:40,152 - Epoch: [100][   40/   74]    Overall Loss 0.465880    Objective Loss 0.465880                                        LR 0.000100    Time 0.029603    
2022-12-15 15:05:40,405 - Epoch: [100][   50/   74]    Overall Loss 0.463011    Objective Loss 0.463011                                        LR 0.000100    Time 0.028723    
2022-12-15 15:05:40,656 - Epoch: [100][   60/   74]    Overall Loss 0.459240    Objective Loss 0.459240                                        LR 0.000100    Time 0.028127    
2022-12-15 15:05:40,893 - Epoch: [100][   70/   74]    Overall Loss 0.453266    Objective Loss 0.453266                                        LR 0.000100    Time 0.027460    
2022-12-15 15:05:40,983 - Epoch: [100][   74/   74]    Overall Loss 0.452759    Objective Loss 0.452759    Top1 88.657407    Top5 98.148148    LR 0.000100    Time 0.027190    
2022-12-15 15:05:41,042 - --- validate (epoch=100)-----------
2022-12-15 15:05:41,042 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:41,320 - Epoch: [100][    9/    9]    Loss 1.207453    Top1 66.269084    Top5 91.793893    
2022-12-15 15:05:41,373 - ==> Top1: 66.269    Top5: 91.794    Loss: 1.207

2022-12-15 15:05:41,375 - ==> Confusion:
[[ 19   0   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   6   3   0   1   0   2   0   0   0   0   0   0   0   0  10   0   1   1   0   1   0   0   0   0   1   1   0]
 [  0   0 115   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   6   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 126   1   5   0   0   0   0   0   0   0   0   0   0   0   2   0   0   3   0   7   0   0   0   5   0   6   0]
 [  0   2   0   0   1  40   0   0   0   0   0   0   0   0   0   0   1   0   3   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   2   0   2   0 132   0   3   0   0   0   0   0   3   1   0   0   2   0   0   0   1  11   0   0   1   5   0   9   0]
 [  0   6   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   1   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   9   4   0   2   0   0   0   0   0   0   3   0   0   1   0   4   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   6   0   1  10   0   0   0   0   0   2   0   0   6   0   1   1   0   2   0   0   0   1   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  11   0   0   0  23   0   0   0   0   0   0   5   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  15   0   0   0   0   0   0   1   0   0   2   2   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0   9   0   1   0   0   0   0  17   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   0   0   5   0   0   1   2   4   0   0 154   0   2   0   2   0   0  13   0   0   0   0   1   3   1   0   0]
 [  3   0   0   0   0   0   7   0   0   2   0   0   0   0   2   5   0   0   2   0   0   0   0   3   0   0   0   5   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   9   1   0   3   0   1   0   2   5   0   0   0   0   0   1   0   0 117   0   2   5   0   1   0   0   0   0   4   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   1   0   3   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   5   0   7   0]
 [  0   3   0   0   0   0   1   0   0   0   0   0   0   0   8   0   4   0   8   0   5 143   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   4   0  20   0  10   0   1   0   0   4   0   0   0   0   0   0   5   0   0   2   2  86   0   0   2   3   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   1   0   6   0   0  55   0   0   0   0]
 [  0   1   2   0   2   3  13   0   1   2   0   0   0   0   3   3   2   0   4   0   3   0   0   1   0   0   0  60   0   8   0]
 [  0   1   0   0   0   1   0   0   0   0   0   1   0   0   1   0   1   0   6   0   0   3   0   7   0   0   0   0   5   0   0]
 [  0   0   0   0  10   1   7   1   0   4   0   0   0   0   0   4   0   0   5   0   3   0   0   4   0   0   0   4   0 137   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:05:41,376 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:41,377 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:41,386 - 

2022-12-15 15:05:41,387 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:41,791 - Epoch: [101][   10/   74]    Overall Loss 0.436901    Objective Loss 0.436901                                        LR 0.000100    Time 0.040345    
2022-12-15 15:05:42,027 - Epoch: [101][   20/   74]    Overall Loss 0.432773    Objective Loss 0.432773                                        LR 0.000100    Time 0.031973    
2022-12-15 15:05:42,280 - Epoch: [101][   30/   74]    Overall Loss 0.433766    Objective Loss 0.433766                                        LR 0.000100    Time 0.029732    
2022-12-15 15:05:42,534 - Epoch: [101][   40/   74]    Overall Loss 0.435780    Objective Loss 0.435780                                        LR 0.000100    Time 0.028638    
2022-12-15 15:05:42,785 - Epoch: [101][   50/   74]    Overall Loss 0.434761    Objective Loss 0.434761                                        LR 0.000100    Time 0.027915    
2022-12-15 15:05:43,038 - Epoch: [101][   60/   74]    Overall Loss 0.436220    Objective Loss 0.436220                                        LR 0.000100    Time 0.027474    
2022-12-15 15:05:43,292 - Epoch: [101][   70/   74]    Overall Loss 0.434413    Objective Loss 0.434413                                        LR 0.000100    Time 0.027161    
2022-12-15 15:05:43,378 - Epoch: [101][   74/   74]    Overall Loss 0.435280    Objective Loss 0.435280    Top1 89.583333    Top5 98.842593    LR 0.000100    Time 0.026854    
2022-12-15 15:05:43,444 - --- validate (epoch=101)-----------
2022-12-15 15:05:43,444 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:43,720 - Epoch: [101][    9/    9]    Loss 1.205662    Top1 66.507634    Top5 91.173664    
2022-12-15 15:05:43,775 - ==> Top1: 66.508    Top5: 91.174    Loss: 1.206

2022-12-15 15:05:43,776 - ==> Confusion:
[[ 19   0   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  12   0   0   5   2   0   1   0   3   0   0   0   0   0   0   0   0  10   0   1   2   0   0   0   0   0   0   1   1   0]
 [  0   0 114   0   6   0   1   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   7   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1   7   0 124   1   4   0   0   0   0   0   0   0   0   0   0   0   5   0   0   3   0  10   0   0   0   4   0   6   0]
 [  0   0   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   5   0   0   0   0   1   0   2   0   0]
 [  0   0   1   0   1   0 131   0   4   1   0   0   0   0   4   1   0   0   2   0   0   0   1  11   0   0   1   5   0   9   0]
 [  0   5   0   0   0   2   0   4   0   0   0   0   0   1   0   0   0   0   2   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   8   0   9   4   0   2   0   0   0   1   0   0   4   0   0   1   0   2   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  11   0   0   0   0   0   1   0   0   6   0   1   1   0   2   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  10   0   0   0  25   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  14   0   0   1   0   0   0   0   0   0   3   2   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0   8   0   1   0   0   0   0  17   0   0   0   0   0   0   1   0   5   0]
 [  1   0   0   0   0   0   4   0   0   1   4   4   0   0 159   0   1   0   2   0   0  10   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   7   0   0   3   0   0   0   0   3   5   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   2   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   6   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  4   5   1   0   2   0   1   0   2   6   0   0   0   1   0   0   1   0 121   0   2   5   0   0   0   0   0   0   4   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74  12   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   0   0   0   0   0   0   0   0   0   0  11   0   5   0   6   0   5 141   0   0   0   0   2   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   0   4   0  16   0   9   0   1   0   0   4   0   0   0   0   0   0   5   0   0   2   2  91   0   0   2   4   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   2   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   4   0   0  55   0   1   0   0]
 [  0   1   2   0   2   3  14   0   1   2   0   0   0   0   3   3   2   0   4   0   3   0   0   2   0   0   0  57   0   9   0]
 [  0   1   0   0   0   0   0   0   0   0   0   1   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   6   0   0]
 [  0   0   0   0   8   1   5   1   0   4   0   0   0   0   1   5   0   0   5   0   2   1   0   4   0   0   0   3   0 140   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:05:43,778 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:43,778 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:43,788 - 

2022-12-15 15:05:43,788 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:44,195 - Epoch: [102][   10/   74]    Overall Loss 0.434374    Objective Loss 0.434374                                        LR 0.000100    Time 0.040585    
2022-12-15 15:05:44,437 - Epoch: [102][   20/   74]    Overall Loss 0.430811    Objective Loss 0.430811                                        LR 0.000100    Time 0.032372    
2022-12-15 15:05:44,686 - Epoch: [102][   30/   74]    Overall Loss 0.424677    Objective Loss 0.424677                                        LR 0.000100    Time 0.029865    
2022-12-15 15:05:44,936 - Epoch: [102][   40/   74]    Overall Loss 0.427341    Objective Loss 0.427341                                        LR 0.000100    Time 0.028649    
2022-12-15 15:05:45,183 - Epoch: [102][   50/   74]    Overall Loss 0.432305    Objective Loss 0.432305                                        LR 0.000100    Time 0.027854    
2022-12-15 15:05:45,432 - Epoch: [102][   60/   74]    Overall Loss 0.429638    Objective Loss 0.429638                                        LR 0.000100    Time 0.027343    
2022-12-15 15:05:45,671 - Epoch: [102][   70/   74]    Overall Loss 0.429474    Objective Loss 0.429474                                        LR 0.000100    Time 0.026851    
2022-12-15 15:05:45,758 - Epoch: [102][   74/   74]    Overall Loss 0.430102    Objective Loss 0.430102    Top1 90.740741    Top5 97.685185    LR 0.000100    Time 0.026577    
2022-12-15 15:05:45,820 - --- validate (epoch=102)-----------
2022-12-15 15:05:45,820 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:46,098 - Epoch: [102][    9/    9]    Loss 1.207284    Top1 65.982824    Top5 91.603053    
2022-12-15 15:05:46,147 - ==> Top1: 65.983    Top5: 91.603    Loss: 1.207

2022-12-15 15:05:46,149 - ==> Confusion:
[[ 19   0   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   3   0   1   0   3   0   0   0   0   0   0   0   0  10   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 113   0   7   1   1   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   7   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 126   1   3   0   0   0   0   0   0   0   0   1   0   0   4   0   0   3   0   7   0   0   0   4   0   7   0]
 [  0   1   0   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   6   0   1   5   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   1   0 125   0   3   3   0   1   0   0   3   1   0   0   2   0   0   0   1  12   0   0   1   5   0  13   0]
 [  0   6   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   1   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   7   4   0   2   0   0   0   0   0   0   5   0   0   1   0   4   0   0   0   1   1   1   0]
 [  1   0   0   0   0   0   6   0   1  12   0   0   0   0   0   2   0   0   6   0   1   1   0   1   0   0   0   0   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  10   0   0   0  24   0   0   0   1   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   0   1   0  16   0   0   0   0   0   0   2   0   0   2   1   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0   9   0   1   0   0   0   0  17   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   0   0   5   0   0   1   2   4   0   0 155   1   2   0   2   0   0  12   0   0   0   0   1   2   1   0   0]
 [  2   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  2   9   1   0   3   0   1   0   2   5   0   0   0   0   0   1   2   0 119   0   2   5   0   0   0   0   0   0   1   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   2   0   0   3   0   0   0   0   0   1   1   0   1   0   1   0  76  10   0   0   0   0   0   6   0   7   0]
 [  0   3   0   0   0   0   0   0   0   1   0   0   0   0  10   0   5   0   7   0   5 141   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   2   0  18   0   9   0   1   0   0   4   0   0   0   0   0   0   5   0   0   2   2  88   0   0   2   4   2   8   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   2   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   1   0   6   0   0  55   0   0   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   4   3   0   4   0   4   0   0   1   0   0   0  55   0  11   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   8   0   4   2   0   3   0   0   0   0   1   5   0   0   6   0   4   0   0   4   0   0   0   3   0 140   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:05:46,150 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:46,150 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:46,160 - 

2022-12-15 15:05:46,160 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:46,595 - Epoch: [103][   10/   74]    Overall Loss 0.425194    Objective Loss 0.425194                                        LR 0.000100    Time 0.043443    
2022-12-15 15:05:46,875 - Epoch: [103][   20/   74]    Overall Loss 0.426137    Objective Loss 0.426137                                        LR 0.000100    Time 0.035683    
2022-12-15 15:05:47,133 - Epoch: [103][   30/   74]    Overall Loss 0.423865    Objective Loss 0.423865                                        LR 0.000100    Time 0.032386    
2022-12-15 15:05:47,372 - Epoch: [103][   40/   74]    Overall Loss 0.425339    Objective Loss 0.425339                                        LR 0.000100    Time 0.030254    
2022-12-15 15:05:47,611 - Epoch: [103][   50/   74]    Overall Loss 0.426808    Objective Loss 0.426808                                        LR 0.000100    Time 0.028965    
2022-12-15 15:05:47,861 - Epoch: [103][   60/   74]    Overall Loss 0.426317    Objective Loss 0.426317                                        LR 0.000100    Time 0.028298    
2022-12-15 15:05:48,093 - Epoch: [103][   70/   74]    Overall Loss 0.425332    Objective Loss 0.425332                                        LR 0.000100    Time 0.027576    
2022-12-15 15:05:48,183 - Epoch: [103][   74/   74]    Overall Loss 0.426086    Objective Loss 0.426086    Top1 90.277778    Top5 99.074074    LR 0.000100    Time 0.027296    
2022-12-15 15:05:48,249 - --- validate (epoch=103)-----------
2022-12-15 15:05:48,249 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:48,525 - Epoch: [103][    9/    9]    Loss 1.218707    Top1 66.078244    Top5 91.459924    
2022-12-15 15:05:48,575 - ==> Top1: 66.078    Top5: 91.460    Loss: 1.219

2022-12-15 15:05:48,577 - ==> Confusion:
[[ 19   0   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   3   0   1   0   2   0   0   0   0   0   0   0   0  10   0   1   1   0   1   0   0   0   1   1   1   0]
 [  0   0 115   0   6   1   1   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   6   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 127   1   5   0   0   0   0   0   0   0   0   0   0   0   4   0   0   3   0   7   0   0   0   4   0   5   0]
 [  0   2   0   0   1  40   0   0   0   0   0   0   0   0   0   0   1   0   3   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   0   0   1   0 130   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  14   0   0   1   5   0   8   0]
 [  0   6   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   1   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   8   0   9   4   0   2   0   0   0   0   0   0   4   0   0   1   0   2   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   5   0   1  11   0   0   0   0   0   1   0   0   6   0   1   1   0   2   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   9   0   0   0  25   0   0   0   0   0   0   5   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0   9   0   1   0   0   0   0  17   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   5   0   0   1   1   5   0   0 158   0   2   0   1   0   0  11   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   7   0   0   3   0   0   0   0   2   4   0   0   2   0   0   0   0   3   0   0   0   5   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   3   0   1   0   1   4   0   0   0   0   0   1   1   0 116   0   2   5   0   1   0   0   0   1   4   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   2   1   0   1   0   0   0   0   0   1   1   0   1   0   1   0  76  11   0   0   0   0   0   7   0   6   0]
 [  0   3   0   0   1   0   0   0   0   0   0   0   0   0  10   0   5   0   7   0   5 142   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   0   3   0  21   0  10   0   2   1   0   4   0   0   0   0   0   0   5   0   0   2   2  83   0   0   2   5   3   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   2   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   3   0   0  55   0   1   0   0]
 [  0   1   2   0   2   3  14   0   1   2   0   0   0   0   3   2   2   0   4   0   3   0   0   2   0   0   0  59   0   8   0]
 [  0   1   0   0   0   0   0   0   0   0   0   1   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0  11   1   8   2   0   3   0   0   0   0   1   5   0   0   4   0   3   1   0   3   0   0   0   5   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   3   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:05:48,578 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:48,578 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:48,588 - 

2022-12-15 15:05:48,588 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:49,148 - Epoch: [104][   10/   74]    Overall Loss 0.414950    Objective Loss 0.414950                                        LR 0.000100    Time 0.055924    
2022-12-15 15:05:49,405 - Epoch: [104][   20/   74]    Overall Loss 0.407996    Objective Loss 0.407996                                        LR 0.000100    Time 0.040748    
2022-12-15 15:05:49,665 - Epoch: [104][   30/   74]    Overall Loss 0.410937    Objective Loss 0.410937                                        LR 0.000100    Time 0.035820    
2022-12-15 15:05:49,922 - Epoch: [104][   40/   74]    Overall Loss 0.418487    Objective Loss 0.418487                                        LR 0.000100    Time 0.033281    
2022-12-15 15:05:50,182 - Epoch: [104][   50/   74]    Overall Loss 0.416674    Objective Loss 0.416674                                        LR 0.000100    Time 0.031824    
2022-12-15 15:05:50,439 - Epoch: [104][   60/   74]    Overall Loss 0.419738    Objective Loss 0.419738                                        LR 0.000100    Time 0.030797    
2022-12-15 15:05:50,683 - Epoch: [104][   70/   74]    Overall Loss 0.424383    Objective Loss 0.424383                                        LR 0.000100    Time 0.029874    
2022-12-15 15:05:50,770 - Epoch: [104][   74/   74]    Overall Loss 0.422810    Objective Loss 0.422810    Top1 90.740741    Top5 98.611111    LR 0.000100    Time 0.029433    
2022-12-15 15:05:50,828 - --- validate (epoch=104)-----------
2022-12-15 15:05:50,829 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:51,103 - Epoch: [104][    9/    9]    Loss 1.214994    Top1 66.746183    Top5 91.125954    
2022-12-15 15:05:51,156 - ==> Top1: 66.746    Top5: 91.126    Loss: 1.215

2022-12-15 15:05:51,158 - ==> Confusion:
[[ 19   0   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  12   0   0   5   3   0   1   0   3   0   0   0   0   0   0   0   0  10   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 116   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   6   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 124   1   5   0   0   0   0   0   0   0   0   0   0   0   4   0   0   3   0  10   0   0   0   3   0   5   0]
 [  0   2   0   0   1  39   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   1   0   1   0 131   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0   8   0]
 [  0   5   0   0   0   2   0   4   0   0   0   0   0   1   0   0   0   0   2   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   9   4   0   2   0   0   0   0   0   0   4   0   0   1   0   3   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   1   0   0   6   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  12   0   0   0  22   0   0   0   1   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   1   0   0   2   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0   7   0   1   0   0   0   0  17   0   0   0   0   0   0   1   0   6   0]
 [  1   0   0   0   0   0   5   0   0   1   1   5   0   0 159   0   2   0   1   0   0  11   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   7   0   0   3   0   0   0   0   2   5   0   0   2   0   0   0   0   2   0   0   0   5   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   2   0   1   0   2   6   0   0   0   0   0   1   2   0 118   0   2   5   0   0   0   0   0   0   2   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   0   0   0   0   0   0   0   0   0   0  10   0   5   0   6   0   5 143   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   0   3   0  19   0  10   0   1   1   0   4   0   0   0   0   0   0   5   0   0   1   2  88   0   0   2   4   3   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   2   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   1   0   0   0   0   2   0   0   0   0   1   0   0   0   0   1   1   4   0   0  56   0   1   0   0]
 [  0   1   2   0   2   3  15   0   1   2   0   0   0   0   3   4   2   0   4   0   3   0   0   1   0   0   0  58   0   7   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   8   0   6   2   0   3   0   0   0   0   1   5   0   0   5   0   4   0   0   5   0   0   0   3   0 138   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   3   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:05:51,160 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:51,160 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:51,170 - 

2022-12-15 15:05:51,170 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:51,600 - Epoch: [105][   10/   74]    Overall Loss 0.402392    Objective Loss 0.402392                                        LR 0.000100    Time 0.042976    
2022-12-15 15:05:51,850 - Epoch: [105][   20/   74]    Overall Loss 0.422290    Objective Loss 0.422290                                        LR 0.000100    Time 0.033949    
2022-12-15 15:05:52,111 - Epoch: [105][   30/   74]    Overall Loss 0.428179    Objective Loss 0.428179                                        LR 0.000100    Time 0.031334    
2022-12-15 15:05:52,361 - Epoch: [105][   40/   74]    Overall Loss 0.422283    Objective Loss 0.422283                                        LR 0.000100    Time 0.029731    
2022-12-15 15:05:52,610 - Epoch: [105][   50/   74]    Overall Loss 0.421885    Objective Loss 0.421885                                        LR 0.000100    Time 0.028764    
2022-12-15 15:05:52,866 - Epoch: [105][   60/   74]    Overall Loss 0.419944    Objective Loss 0.419944                                        LR 0.000100    Time 0.028218    
2022-12-15 15:05:53,107 - Epoch: [105][   70/   74]    Overall Loss 0.420055    Objective Loss 0.420055                                        LR 0.000100    Time 0.027634    
2022-12-15 15:05:53,196 - Epoch: [105][   74/   74]    Overall Loss 0.419823    Objective Loss 0.419823    Top1 89.120370    Top5 98.148148    LR 0.000100    Time 0.027340    
2022-12-15 15:05:53,257 - --- validate (epoch=105)-----------
2022-12-15 15:05:53,257 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:53,533 - Epoch: [105][    9/    9]    Loss 1.242221    Top1 66.030534    Top5 91.459924    
2022-12-15 15:05:53,587 - ==> Top1: 66.031    Top5: 91.460    Loss: 1.242

2022-12-15 15:05:53,588 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   3   0   1   0   2   0   0   0   0   0   0   0   0  11   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 115   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   7   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   7   0 125   2   4   0   0   0   0   0   0   0   0   0   0   0   5   0   0   3   0   8   0   0   0   4   0   5   0]
 [  0   0   1   0   1  40   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   0   0   1   0 126   0   4   2   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0  12   0]
 [  0   4   0   0   0   2   0   4   0   0   0   0   0   2   0   0   0   0   2   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   8   4   0   2   0   0   0   0   0   0   4   0   0   1   0   4   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   5   0   1  10   0   0   0   0   0   1   0   0   6   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  10   0   0   0  24   0   0   0   0   0   0   5   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   0   2   0  15   0   0   0   0   0   0   0   0   0   3   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0   8   0   0   0   0   0   0  17   0   0   0   0   0   0   2   0   5   0]
 [  1   0   0   0   1   1   7   0   0   1   3   4   0   0 153   0   2   0   2   0   0  11   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   7   0   0   2   0   0   0   0   2   4   0   0   2   0   0   0   0   3   0   0   0   6   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   6   1   0   2   0   1   0   1   4   0   0   0   0   0   1   3   0 121   0   2   5   0   1   0   0   0   0   2   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   2   0   0   1   0   0   0   0   0   1   1   0   1   0   1   0  77  10   0   0   0   0   0   7   0   7   0]
 [  0   2   0   0   0   0   0   0   0   1   0   0   0   0  11   0   6   0   6   0   6 139   0   0   0   0   2   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   0   2   0  18   0  10   0   1   0   0   4   0   0   0   0   0   0   5   0   0   2   2  88   0   0   2   5   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   2   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   1   0   0   0   0   0   0   0   1   5   0   0  55   0   0   0   0]
 [  0   0   2   0   2   3  12   0   1   2   0   0   0   0   3   3   3   0   4   0   3   0   0   1   0   0   0  60   0   9   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0  11   1   5   1   0   3   0   0   0   0   1   5   0   0   4   0   2   2   0   3   0   0   0   5   0 137   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   3   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:05:53,590 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:53,590 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:53,600 - 

2022-12-15 15:05:53,600 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:54,024 - Epoch: [106][   10/   74]    Overall Loss 0.412526    Objective Loss 0.412526                                        LR 0.000100    Time 0.042316    
2022-12-15 15:05:54,280 - Epoch: [106][   20/   74]    Overall Loss 0.410501    Objective Loss 0.410501                                        LR 0.000100    Time 0.033954    
2022-12-15 15:05:54,534 - Epoch: [106][   30/   74]    Overall Loss 0.416670    Objective Loss 0.416670                                        LR 0.000100    Time 0.031063    
2022-12-15 15:05:54,779 - Epoch: [106][   40/   74]    Overall Loss 0.424320    Objective Loss 0.424320                                        LR 0.000100    Time 0.029422    
2022-12-15 15:05:55,025 - Epoch: [106][   50/   74]    Overall Loss 0.425371    Objective Loss 0.425371                                        LR 0.000100    Time 0.028451    
2022-12-15 15:05:55,273 - Epoch: [106][   60/   74]    Overall Loss 0.422011    Objective Loss 0.422011                                        LR 0.000100    Time 0.027827    
2022-12-15 15:05:55,513 - Epoch: [106][   70/   74]    Overall Loss 0.420226    Objective Loss 0.420226                                        LR 0.000100    Time 0.027279    
2022-12-15 15:05:55,601 - Epoch: [106][   74/   74]    Overall Loss 0.416707    Objective Loss 0.416707    Top1 93.055556    Top5 99.074074    LR 0.000100    Time 0.026986    
2022-12-15 15:05:55,677 - --- validate (epoch=106)-----------
2022-12-15 15:05:55,677 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:55,955 - Epoch: [106][    9/    9]    Loss 1.193028    Top1 65.839695    Top5 91.221374    
2022-12-15 15:05:56,012 - ==> Top1: 65.840    Top5: 91.221    Loss: 1.193

2022-12-15 15:05:56,014 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   3   0   2   0   3   0   0   0   0   0   0   0   0  10   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 114   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1   7   0 124   2   3   0   0   0   0   0   0   0   0   1   0   0   5   0   0   3   0   9   0   0   0   4   0   6   0]
 [  0   1   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   5   0   0   0   0   1   0   2   0   0]
 [  0   0   1   0   1   0 125   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  15   0   0   1   5   0  11   0]
 [  0   5   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   2   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   8   4   0   1   0   0   0   0   0   0   5   0   0   1   0   4   0   0   0   1   1   1   0]
 [  1   0   0   0   0   0   4   0   1  12   0   0   0   0   0   2   0   0   5   0   1   1   0   2   0   0   0   1   0  11   0]
 [  0   0   0   0   0   0   0   0   0   0  10   0   0   0  25   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0   8   0   1   0   0   1   0  17   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   0   0   7   0   0   1   1   5   0   0 156   1   2   0   1   0   0  10   0   0   0   0   1   2   1   0   0]
 [  3   0   0   0   0   0   7   0   0   3   0   0   0   0   2   4   0   0   2   0   0   0   0   3   0   0   0   5   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   3   0   1   1   1   6   0   0   0   1   0   1   2   0 116   0   2   5   0   0   0   0   0   1   3   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   2   0   0   1   0   0   0   0   0   1   1   0   1   0   1   0  77  10   0   0   0   0   0   7   0   7   0]
 [  0   1   0   0   0   0   0   0   0   0   0   1   0   0  11   0   5   0   6   0   6 142   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   0   3   0  17   0  10   0   1   0   0   4   0   0   0   0   0   0   6   0   0   2   2  90   0   0   2   4   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   2   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   6   0   0  54   0   1   0   0]
 [  0   1   2   0   2   2  14   1   1   2   0   0   0   0   3   3   2   0   4   0   3   0   0   2   0   0   0  57   0   9   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   9   0   5   2   0   3   0   0   0   0   1   5   0   0   6   0   4   0   0   4   0   0   0   3   0 138   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:05:56,016 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:56,016 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:56,033 - 

2022-12-15 15:05:56,033 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:56,459 - Epoch: [107][   10/   74]    Overall Loss 0.415282    Objective Loss 0.415282                                        LR 0.000100    Time 0.042486    
2022-12-15 15:05:56,719 - Epoch: [107][   20/   74]    Overall Loss 0.423530    Objective Loss 0.423530                                        LR 0.000100    Time 0.034213    
2022-12-15 15:05:56,976 - Epoch: [107][   30/   74]    Overall Loss 0.422312    Objective Loss 0.422312                                        LR 0.000100    Time 0.031365    
2022-12-15 15:05:57,229 - Epoch: [107][   40/   74]    Overall Loss 0.418096    Objective Loss 0.418096                                        LR 0.000100    Time 0.029843    
2022-12-15 15:05:57,486 - Epoch: [107][   50/   74]    Overall Loss 0.417922    Objective Loss 0.417922                                        LR 0.000100    Time 0.029004    
2022-12-15 15:05:57,739 - Epoch: [107][   60/   74]    Overall Loss 0.416764    Objective Loss 0.416764                                        LR 0.000100    Time 0.028389    
2022-12-15 15:05:57,985 - Epoch: [107][   70/   74]    Overall Loss 0.413778    Objective Loss 0.413778                                        LR 0.000100    Time 0.027843    
2022-12-15 15:05:58,073 - Epoch: [107][   74/   74]    Overall Loss 0.414375    Objective Loss 0.414375    Top1 91.203704    Top5 99.305556    LR 0.000100    Time 0.027524    
2022-12-15 15:05:58,136 - --- validate (epoch=107)-----------
2022-12-15 15:05:58,136 - 2096 samples (256 per mini-batch)
2022-12-15 15:05:58,405 - Epoch: [107][    9/    9]    Loss 1.226535    Top1 66.459924    Top5 91.173664    
2022-12-15 15:05:58,458 - ==> Top1: 66.460    Top5: 91.174    Loss: 1.227

2022-12-15 15:05:58,460 - ==> Confusion:
[[ 19   0   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  12   0   0   5   3   0   1   0   2   0   0   0   0   0   0   0   0  11   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 114   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   7   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 125   0   3   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   9   0   0   0   2   0   6   0]
 [  0   1   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   5   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   1   0 123   0   4   2   0   1   0   0   4   1   0   0   2   0   0   0   1  14   0   0   1   6   0  11   0]
 [  0   5   0   0   0   2   0   4   0   0   0   0   0   2   0   0   0   0   1   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   7   5   0   2   0   0   0   0   0   0   5   0   0   1   0   4   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  13   0   0   0   0   0   0   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  12   0   0   0  23   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   1   0   0   2   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   5   0   0   1   1   4   0   0 157   0   2   0   2   0   0  12   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   5   0   0   3   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   7   1   0   3   0   1   0   1   6   0   0   0   0   0   1   1   0 121   0   2   5   0   0   0   0   0   0   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  76  10   0   0   0   0   0   7   0   6   0]
 [  0   3   0   0   1   0   0   0   0   0   0   0   0   0   8   0   5   0   7   0   5 144   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   1   0  16   0   9   0   1   1   0   4   0   0   0   0   0   0   5   0   0   2   2  90   0   0   2   5   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   6   0   0  54   0   1   0   0]
 [  0   1   2   0   2   3  14   0   1   2   0   0   0   0   3   4   3   0   4   0   3   0   0   1   0   0   0  56   0   9   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   8   1   5   2   0   3   0   0   0   0   1   5   0   0   6   0   3   0   0   5   0   0   0   3   0 138   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:05:58,461 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:05:58,461 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:05:58,471 - 

2022-12-15 15:05:58,472 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:05:58,889 - Epoch: [108][   10/   74]    Overall Loss 0.406865    Objective Loss 0.406865                                        LR 0.000100    Time 0.041617    
2022-12-15 15:05:59,144 - Epoch: [108][   20/   74]    Overall Loss 0.402480    Objective Loss 0.402480                                        LR 0.000100    Time 0.033568    
2022-12-15 15:05:59,397 - Epoch: [108][   30/   74]    Overall Loss 0.406579    Objective Loss 0.406579                                        LR 0.000100    Time 0.030789    
2022-12-15 15:05:59,646 - Epoch: [108][   40/   74]    Overall Loss 0.412109    Objective Loss 0.412109                                        LR 0.000100    Time 0.029324    
2022-12-15 15:05:59,899 - Epoch: [108][   50/   74]    Overall Loss 0.410986    Objective Loss 0.410986                                        LR 0.000100    Time 0.028508    
2022-12-15 15:06:00,146 - Epoch: [108][   60/   74]    Overall Loss 0.407971    Objective Loss 0.407971                                        LR 0.000100    Time 0.027859    
2022-12-15 15:06:00,389 - Epoch: [108][   70/   74]    Overall Loss 0.412317    Objective Loss 0.412317                                        LR 0.000100    Time 0.027342    
2022-12-15 15:06:00,475 - Epoch: [108][   74/   74]    Overall Loss 0.412513    Objective Loss 0.412513    Top1 88.888889    Top5 98.379630    LR 0.000100    Time 0.027034    
2022-12-15 15:06:00,539 - --- validate (epoch=108)-----------
2022-12-15 15:06:00,539 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:00,817 - Epoch: [108][    9/    9]    Loss 1.233937    Top1 65.982824    Top5 90.839695    
2022-12-15 15:06:00,874 - ==> Top1: 65.983    Top5: 90.840    Loss: 1.234

2022-12-15 15:06:00,876 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   2   0   2   0   1   0   0   0   0   0   0   0   0  11   0   1   2   0   1   0   0   0   0   1   1   0]
 [  0   0 114   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   7   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   7   0 124   1   3   0   0   0   0   0   0   0   0   1   0   0   5   0   0   3   0   7   0   0   0   5   0   7   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   5   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   1   0 125   0   3   3   0   0   0   0   4   1   0   0   2   0   0   0   1  14   0   0   1   6   0  11   0]
 [  0   6   0   0   0   2   0   4   0   0   0   0   0   1   0   0   0   0   1   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   8   5   0   2   0   0   0   0   0   0   5   0   0   1   0   3   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  13   0   0   0   0   0   1   0   0   5   0   1   1   0   2   0   0   0   1   0  11   0]
 [  0   0   0   0   0   0   0   0   0   0  10   0   0   0  25   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   2   0   0   2   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   1   0  15   0   0   0   0   0   0   2   0   3   0]
 [  1   0   0   0   1   0   5   0   0   1   2   4   0   0 157   0   3   0   2   0   0  10   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   3   0   0   3   0   0   0   0   3   0   0   0   5   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  32   0   5   0   1   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   7   1   0   2   0   1   0   1   5   0   0   0   1   0   1   4   0 121   0   2   5   0   0   0   0   0   0   1   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75  10   0   0   0   0   0   7   0   6   0]
 [  0   3   0   0   0   0   0   0   0   0   0   0   0   0   9   0   6   0   7   0   6 141   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   6   0  17   0   9   0   2   1   0   4   0   0   0   0   0   0   5   0   0   1   2  83   0   0   2   6   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   1   0   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   4   0   0  54   0   1   0   0]
 [  0   1   2   0   2   3  11   0   1   2   0   0   0   0   3   3   2   0   4   0   3   0   0   1   0   0   0  61   0   9   0]
 [  0   1   0   0   0   1   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   6   0   0]
 [  0   0   0   0   7   2   5   1   0   3   0   0   0   0   1   5   0   0   6   0   2   1   0   4   0   0   0   3   0 140   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   5   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:06:00,879 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:00,879 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:00,888 - 

2022-12-15 15:06:00,889 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:01,316 - Epoch: [109][   10/   74]    Overall Loss 0.375731    Objective Loss 0.375731                                        LR 0.000100    Time 0.042617    
2022-12-15 15:06:01,561 - Epoch: [109][   20/   74]    Overall Loss 0.393241    Objective Loss 0.393241                                        LR 0.000100    Time 0.033567    
2022-12-15 15:06:01,807 - Epoch: [109][   30/   74]    Overall Loss 0.397821    Objective Loss 0.397821                                        LR 0.000100    Time 0.030566    
2022-12-15 15:06:02,044 - Epoch: [109][   40/   74]    Overall Loss 0.407517    Objective Loss 0.407517                                        LR 0.000100    Time 0.028823    
2022-12-15 15:06:02,296 - Epoch: [109][   50/   74]    Overall Loss 0.409227    Objective Loss 0.409227                                        LR 0.000100    Time 0.028107    
2022-12-15 15:06:02,553 - Epoch: [109][   60/   74]    Overall Loss 0.406709    Objective Loss 0.406709                                        LR 0.000100    Time 0.027691    
2022-12-15 15:06:02,758 - Epoch: [109][   70/   74]    Overall Loss 0.408869    Objective Loss 0.408869                                        LR 0.000100    Time 0.026656    
2022-12-15 15:06:02,836 - Epoch: [109][   74/   74]    Overall Loss 0.410029    Objective Loss 0.410029    Top1 91.435185    Top5 98.611111    LR 0.000100    Time 0.026270    
2022-12-15 15:06:02,901 - --- validate (epoch=109)-----------
2022-12-15 15:06:02,902 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:03,177 - Epoch: [109][    9/    9]    Loss 1.230579    Top1 65.982824    Top5 91.364504    
2022-12-15 15:06:03,226 - ==> Top1: 65.983    Top5: 91.365    Loss: 1.231

2022-12-15 15:06:03,228 - ==> Confusion:
[[ 19   0   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  12   0   0   5   3   0   1   0   2   0   0   0   0   0   0   0   0  11   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 115   0   5   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 125   1   2   0   0   0   0   0   0   0   0   1   0   0   5   0   0   3   0   9   0   0   0   3   0   6   0]
 [  0   1   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   2   0   1   0 126   0   4   1   0   1   0   0   4   1   0   0   2   0   0   0   1  14   0   0   1   5   0   9   0]
 [  0   5   0   0   0   2   0   4   0   0   0   0   0   1   0   0   0   0   2   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   8   0   6   4   0   2   0   0   0   0   0   0   5   0   0   1   0   4   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   3   0   1  11   0   0   0   0   0   2   0   0   6   0   1   1   0   3   0   0   0   1   0  11   0]
 [  0   0   0   0   0   0   0   0   0   0  10   0   0   0  25   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   2   0   0   2   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0   8   0   0   0   0   1   0  17   0   0   0   0   0   0   2   0   4   0]
 [  2   0   0   0   1   0   4   0   0   1   1   4   0   0 156   1   2   0   2   0   0  12   0   0   0   0   1   1   1   0   0]
 [  4   0   0   0   0   0   7   0   0   3   0   0   0   0   2   4   0   0   2   0   0   0   0   2   0   0   0   5   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   5   1   0   2   0   1   0   1   5   0   0   0   1   0   2   2   0 122   0   2   5   0   0   0   0   0   0   3   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   0   0   1   0   0   0   0   0   1   1   0   1   0   1   0  76  10   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   0   0   0   0   0   0   0   0   0   0   9   0   5   0   7   0   5 144   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   4   0  18   0   9   0   2   1   0   4   0   0   0   0   0   0   5   0   0   2   2  84   0   0   2   6   3   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   2   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   6   0   0  54   0   1   0   0]
 [  0   1   2   0   2   3  12   0   1   2   0   0   0   0   3   3   2   0   4   0   3   0   0   2   0   0   0  59   0   9   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   9   1   6   1   0   4   0   0   0   0   1   5   0   0   6   0   2   1   0   5   0   0   0   4   0 135   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:03,230 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:03,230 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:03,240 - 

2022-12-15 15:06:03,240 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:03,665 - Epoch: [110][   10/   74]    Overall Loss 0.389087    Objective Loss 0.389087                                        LR 0.000100    Time 0.042368    
2022-12-15 15:06:03,910 - Epoch: [110][   20/   74]    Overall Loss 0.390984    Objective Loss 0.390984                                        LR 0.000100    Time 0.033430    
2022-12-15 15:06:04,159 - Epoch: [110][   30/   74]    Overall Loss 0.394607    Objective Loss 0.394607                                        LR 0.000100    Time 0.030581    
2022-12-15 15:06:04,411 - Epoch: [110][   40/   74]    Overall Loss 0.399469    Objective Loss 0.399469                                        LR 0.000100    Time 0.029222    
2022-12-15 15:06:04,669 - Epoch: [110][   50/   74]    Overall Loss 0.399822    Objective Loss 0.399822                                        LR 0.000100    Time 0.028528    
2022-12-15 15:06:04,948 - Epoch: [110][   60/   74]    Overall Loss 0.401911    Objective Loss 0.401911                                        LR 0.000100    Time 0.028413    
2022-12-15 15:06:05,199 - Epoch: [110][   70/   74]    Overall Loss 0.406058    Objective Loss 0.406058                                        LR 0.000100    Time 0.027932    
2022-12-15 15:06:05,290 - Epoch: [110][   74/   74]    Overall Loss 0.406838    Objective Loss 0.406838    Top1 93.055556    Top5 98.842593    LR 0.000100    Time 0.027654    
2022-12-15 15:06:05,366 - --- validate (epoch=110)-----------
2022-12-15 15:06:05,366 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:05,643 - Epoch: [110][    9/    9]    Loss 1.245502    Top1 66.459924    Top5 91.269084    
2022-12-15 15:06:05,697 - ==> Top1: 66.460    Top5: 91.269    Loss: 1.246

2022-12-15 15:06:05,699 - ==> Confusion:
[[ 19   0   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  12   0   0   5   2   0   1   0   2   0   0   0   0   0   0   0   0  11   0   1   2   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   1   1   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 125   0   3   0   0   0   0   0   0   0   0   1   0   0   5   0   0   3   0   9   0   0   0   3   1   5   0]
 [  0   1   1   0   1  37   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   5   0   0   0   0   1   0   2   0   0]
 [  0   0   0   0   1   0 128   0   4   4   0   1   0   0   3   1   0   0   2   0   0   0   1  14   0   0   1   4   0   8   0]
 [  0   5   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   2   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   8   0   7   5   0   2   0   0   0   0   0   0   5   0   0   1   0   3   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  12   0   0   0   0   0   1   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   6   0   0   1   2   4   0   0 156   0   1   0   2   0   0  12   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   7   0   0   3   0   0   0   0   2   4   0   0   2   0   0   0   0   3   0   0   0   5   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   6   1   0   2   0   1   0   2   5   0   0   0   0   0   2   2   0 121   0   2   5   0   0   0   0   0   0   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75  10   0   0   0   0   0   7   0   7   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   9   0   6   0   7   0   6 143   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   2   0  17   0   9   0   2   0   0   4   0   0   0   0   0   0   5   0   0   2   2  88   0   0   2   5   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   2   6   0   0  54   0   1   0   0]
 [  0   1   2   0   2   3  12   0   1   2   0   0   0   0   3   4   2   0   4   0   3   0   0   1   0   0   0  58   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   1   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   6   0   0]
 [  0   0   0   0   7   1   5   1   0   4   0   0   0   0   1   5   0   0   3   0   2   2   0   5   0   0   0   4   0 140   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:05,700 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:05,700 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:05,711 - 

2022-12-15 15:06:05,711 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:06,255 - Epoch: [111][   10/   74]    Overall Loss 0.413733    Objective Loss 0.413733                                        LR 0.000100    Time 0.054357    
2022-12-15 15:06:06,515 - Epoch: [111][   20/   74]    Overall Loss 0.404831    Objective Loss 0.404831                                        LR 0.000100    Time 0.040132    
2022-12-15 15:06:06,770 - Epoch: [111][   30/   74]    Overall Loss 0.406418    Objective Loss 0.406418                                        LR 0.000100    Time 0.035265    
2022-12-15 15:06:07,027 - Epoch: [111][   40/   74]    Overall Loss 0.408188    Objective Loss 0.408188                                        LR 0.000100    Time 0.032847    
2022-12-15 15:06:07,278 - Epoch: [111][   50/   74]    Overall Loss 0.412334    Objective Loss 0.412334                                        LR 0.000100    Time 0.031290    
2022-12-15 15:06:07,559 - Epoch: [111][   60/   74]    Overall Loss 0.406504    Objective Loss 0.406504                                        LR 0.000100    Time 0.030755    
2022-12-15 15:06:07,803 - Epoch: [111][   70/   74]    Overall Loss 0.405186    Objective Loss 0.405186                                        LR 0.000100    Time 0.029848    
2022-12-15 15:06:07,893 - Epoch: [111][   74/   74]    Overall Loss 0.404657    Objective Loss 0.404657    Top1 91.666667    Top5 98.842593    LR 0.000100    Time 0.029444    
2022-12-15 15:06:07,954 - --- validate (epoch=111)-----------
2022-12-15 15:06:07,954 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:08,229 - Epoch: [111][    9/    9]    Loss 1.234989    Top1 65.791985    Top5 90.935115    
2022-12-15 15:06:08,289 - ==> Top1: 65.792    Top5: 90.935    Loss: 1.235

2022-12-15 15:06:08,291 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   3   0   2   0   3   0   0   0   0   0   0   0   0  11   0   1   1   0   0   0   0   0   0   1   0   0]
 [  0   0 115   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   7   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 125   2   4   0   0   0   0   0   0   0   0   1   0   0   4   0   0   3   0   7   0   0   0   3   0   6   0]
 [  0   1   0   0   1  41   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   2   0   1   0 126   0   4   3   0   1   0   0   3   1   0   0   2   0   0   0   1  14   0   0   1   5   0   8   0]
 [  0   6   0   0   0   2   0   4   0   0   0   0   0   1   0   0   0   0   1   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   6   4   0   2   0   0   0   0   0   0   5   0   0   1   0   6   0   0   0   3   1   0   0]
 [  1   0   0   0   0   0   5   0   1  11   0   0   0   0   0   1   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  15   0   0   0  20   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   1   0   0   2   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0   8   0   1   0   0   0   0  17   0   0   0   0   0   0   1   0   5   0]
 [  1   0   0   0   1   0   7   0   0   1   3   4   0   0 152   0   2   0   2   0   0  12   0   0   0   0   1   2   1   0   0]
 [  3   0   0   0   0   0   7   0   0   3   0   0   0   0   2   5   0   0   2   0   0   0   0   3   0   0   0   4   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   9   1   0   2   0   1   0   1   6   0   0   0   0   0   1   3   0 117   0   2   5   0   0   0   0   0   2   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   6   0]
 [  0   3   0   0   1   0   0   0   0   0   0   0   0   0  11   0   6   0   6   0   5 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   0   5   0  20   0   9   0   1   0   0   4   0   0   0   0   0   0   5   0   0   1   2  85   0   0   2   5   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   2   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   1   0   6   0   0  56   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   3   2   0   4   0   4   0   0   2   0   0   0  57   0  10   0]
 [  0   1   0   0   0   1   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   6   0   0]
 [  0   0   0   0   8   1   6   2   0   4   0   0   0   0   1   5   0   0   3   0   4   1   0   4   0   0   0   3   0 138   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   5   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:06:08,292 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:08,292 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:08,313 - 

2022-12-15 15:06:08,313 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:08,732 - Epoch: [112][   10/   74]    Overall Loss 0.400172    Objective Loss 0.400172                                        LR 0.000100    Time 0.041851    
2022-12-15 15:06:08,982 - Epoch: [112][   20/   74]    Overall Loss 0.404943    Objective Loss 0.404943                                        LR 0.000100    Time 0.033404    
2022-12-15 15:06:09,232 - Epoch: [112][   30/   74]    Overall Loss 0.411267    Objective Loss 0.411267                                        LR 0.000100    Time 0.030575    
2022-12-15 15:06:09,485 - Epoch: [112][   40/   74]    Overall Loss 0.407905    Objective Loss 0.407905                                        LR 0.000100    Time 0.029266    
2022-12-15 15:06:09,741 - Epoch: [112][   50/   74]    Overall Loss 0.404714    Objective Loss 0.404714                                        LR 0.000100    Time 0.028491    
2022-12-15 15:06:09,998 - Epoch: [112][   60/   74]    Overall Loss 0.401349    Objective Loss 0.401349                                        LR 0.000100    Time 0.027989    
2022-12-15 15:06:10,252 - Epoch: [112][   70/   74]    Overall Loss 0.403614    Objective Loss 0.403614                                        LR 0.000100    Time 0.027617    
2022-12-15 15:06:10,345 - Epoch: [112][   74/   74]    Overall Loss 0.402057    Objective Loss 0.402057    Top1 92.361111    Top5 99.768519    LR 0.000100    Time 0.027370    
2022-12-15 15:06:10,422 - --- validate (epoch=112)-----------
2022-12-15 15:06:10,423 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:10,710 - Epoch: [112][    9/    9]    Loss 1.208483    Top1 65.839695    Top5 91.173664    
2022-12-15 15:06:10,761 - ==> Top1: 65.840    Top5: 91.174    Loss: 1.208

2022-12-15 15:06:10,763 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   2   0   0   0   0   0   1   1   0   0]
 [  0   0 113   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   7   0 124   2   3   0   0   0   0   0   0   0   0   1   0   0   5   0   0   3   0   8   0   0   0   4   1   5   0]
 [  0   2   0   0   1  39   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   1   0 126   0   4   3   0   1   0   0   3   1   0   0   2   0   0   0   1  13   0   0   1   7   0   9   0]
 [  0   5   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   2   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   8   4   0   2   0   0   0   1   0   0   5   0   0   1   0   4   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  10   0   0   0   0   0   2   0   0   6   0   1   1   0   3   0   0   0   1   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  10   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   3   0]
 [  2   0   0   0   1   0   5   0   0   1   4   4   0   0 154   0   1   0   2   0   0  12   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   3   0   0   2   0   0   0   0   3   0   0   0   5   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   5   1   0   2   0   1   0   2   6   0   0   0   0   0   1   2   0 123   0   2   4   0   0   0   0   0   0   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74  10   0   0   0   0   0   7   0   6   0]
 [  0   3   0   0   0   0   0   0   0   0   0   1   0   0   9   0   6   0   6   0   5 143   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   4   0  17   0  11   0   1   1   0   4   0   0   0   0   0   0   5   0   0   2   2  83   0   0   2   6   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   1   1   6   0   0  55   0   1   0   0]
 [  0   1   2   0   2   3  14   0   1   2   0   0   0   0   3   3   3   0   4   0   4   0   0   0   0   0   0  56   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   8   2   5   2   0   3   0   0   0   0   1   5   0   0   6   0   2   1   0   4   0   0   0   3   0 138   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:10,765 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:10,765 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:10,774 - 

2022-12-15 15:06:10,775 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:11,220 - Epoch: [113][   10/   74]    Overall Loss 0.386567    Objective Loss 0.386567                                        LR 0.000100    Time 0.044414    
2022-12-15 15:06:11,499 - Epoch: [113][   20/   74]    Overall Loss 0.389397    Objective Loss 0.389397                                        LR 0.000100    Time 0.036177    
2022-12-15 15:06:11,777 - Epoch: [113][   30/   74]    Overall Loss 0.385417    Objective Loss 0.385417                                        LR 0.000100    Time 0.033364    
2022-12-15 15:06:12,061 - Epoch: [113][   40/   74]    Overall Loss 0.391646    Objective Loss 0.391646                                        LR 0.000100    Time 0.032105    
2022-12-15 15:06:12,345 - Epoch: [113][   50/   74]    Overall Loss 0.390100    Objective Loss 0.390100                                        LR 0.000100    Time 0.031356    
2022-12-15 15:06:12,600 - Epoch: [113][   60/   74]    Overall Loss 0.392304    Objective Loss 0.392304                                        LR 0.000100    Time 0.030371    
2022-12-15 15:06:12,868 - Epoch: [113][   70/   74]    Overall Loss 0.396904    Objective Loss 0.396904                                        LR 0.000100    Time 0.029847    
2022-12-15 15:06:12,960 - Epoch: [113][   74/   74]    Overall Loss 0.398205    Objective Loss 0.398205    Top1 91.203704    Top5 99.305556    LR 0.000100    Time 0.029475    
2022-12-15 15:06:13,025 - --- validate (epoch=113)-----------
2022-12-15 15:06:13,025 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:13,314 - Epoch: [113][    9/    9]    Loss 1.249135    Top1 65.839695    Top5 91.364504    
2022-12-15 15:06:13,364 - ==> Top1: 65.840    Top5: 91.365    Loss: 1.249

2022-12-15 15:06:13,366 - ==> Confusion:
[[ 18   0   0   0   0   0   4   0   1   0   0   1   0   0   1   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  11   0   1   2   0   0   0   0   0   1   1   1   0]
 [  0   0 114   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   6   0 126   1   4   0   0   0   0   0   0   0   0   2   0   0   4   0   0   3   0   7   0   0   0   3   0   5   0]
 [  0   2   0   0   1  39   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   2   0   1   0 125   0   3   3   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0  11   0]
 [  0   6   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   8   5   0   2   0   0   0   0   0   0   4   0   0   1   0   4   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  11   0   0   0   0   0   1   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   2   0   0   2   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  10   0   0   0   0   0   0  16   0   0   0   0   0   0   2   0   4   0]
 [  1   0   0   0   1   1   6   0   0   1   3   4   0   0 156   0   1   0   2   0   0  10   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   4   0   0   2   0   0   0   0   3   0   0   0   4   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   2   0   1   0   2   5   0   0   0   0   0   1   3   0 118   0   2   6   0   0   0   0   0   0   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   3   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   6   0]
 [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   8   0   6   0   7   0   5 145   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   3   0  18   0  11   0   3   1   0   4   0   0   0   0   0   0   5   0   0   1   2  84   0   0   2   5   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   0   0   0   0   0   1   0   5   0   0  55   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   3   4   0   4   0   4   0   0   2   0   0   0  54   0  10   0]
 [  0   1   0   0   0   1   0   0   0   0   0   1   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   6   0   0]
 [  0   0   0   0   8   3   5   2   0   4   0   0   0   0   1   5   0   0   5   0   2   2   0   4   0   0   0   3   0 136   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   5   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:06:13,368 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:13,368 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:13,389 - 

2022-12-15 15:06:13,389 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:13,804 - Epoch: [114][   10/   74]    Overall Loss 0.388852    Objective Loss 0.388852                                        LR 0.000100    Time 0.041417    
2022-12-15 15:06:14,047 - Epoch: [114][   20/   74]    Overall Loss 0.401289    Objective Loss 0.401289                                        LR 0.000100    Time 0.032848    
2022-12-15 15:06:14,295 - Epoch: [114][   30/   74]    Overall Loss 0.390553    Objective Loss 0.390553                                        LR 0.000100    Time 0.030135    
2022-12-15 15:06:14,537 - Epoch: [114][   40/   74]    Overall Loss 0.397310    Objective Loss 0.397310                                        LR 0.000100    Time 0.028650    
2022-12-15 15:06:14,786 - Epoch: [114][   50/   74]    Overall Loss 0.395109    Objective Loss 0.395109                                        LR 0.000100    Time 0.027878    
2022-12-15 15:06:15,038 - Epoch: [114][   60/   74]    Overall Loss 0.396781    Objective Loss 0.396781                                        LR 0.000100    Time 0.027429    
2022-12-15 15:06:15,283 - Epoch: [114][   70/   74]    Overall Loss 0.399445    Objective Loss 0.399445                                        LR 0.000100    Time 0.027006    
2022-12-15 15:06:15,373 - Epoch: [114][   74/   74]    Overall Loss 0.397659    Objective Loss 0.397659    Top1 92.824074    Top5 98.148148    LR 0.000100    Time 0.026767    
2022-12-15 15:06:15,445 - --- validate (epoch=114)-----------
2022-12-15 15:06:15,445 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:15,714 - Epoch: [114][    9/    9]    Loss 1.243129    Top1 65.887405    Top5 91.125954    
2022-12-15 15:06:15,769 - ==> Top1: 65.887    Top5: 91.126    Loss: 1.243

2022-12-15 15:06:15,771 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   2   0   1   0   2   0   0   0   0   0   0   0   0  11   0   1   2   0   0   0   0   0   1   1   1   0]
 [  0   0 113   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   6   0 128   0   4   0   0   0   0   0   0   0   0   2   0   0   4   0   0   3   0   6   0   0   0   3   0   5   0]
 [  0   1   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   6   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   1   2   0   1   0 124   0   3   4   0   1   0   0   3   1   0   0   2   0   0   0   1  13   0   0   1   5   0  10   0]
 [  0   7   0   0   0   2   0   4   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   7   4   0   2   0   0   0   1   0   0   4   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   5   0   0  10   0   0   0   0   0   2   0   0   6   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  15   0   0   0  20   0   0   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   3   0   0   1   0  14   0   0   0   0   0   0   2   0   0   2   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  10   0   1   0   0   0   0  16   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   4   4   0   0 152   0   1   0   1   0   0  12   0   0   0   0   1   1   2   0   0]
 [  2   0   0   0   0   0   6   0   0   3   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   6   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   0   1   0   2   6   0   0   0   0   0   1   1   0 115   0   2   5   0   0   0   0   0   1   4   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  76   9   0   0   0   0   0   7   0   6   0]
 [  0   2   0   0   1   0   0   0   0   0   0   0   0   0   8   0   7   0   7   0   5 144   0   0   0   0   1   0   0   3   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   2   0  19   0   9   0   1   0   0   4   0   0   0   0   0   0   6   0   0   2   2  85   0   0   2   6   3   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   5   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  11   0   1   2   0   0   0   0   3   2   2   0   4   0   4   0   0   2   0   0   0  60   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   8   1   6   2   0   3   0   0   0   0   1   5   0   0   5   0   2   1   0   6   0   0   0   3   0 137   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:15,773 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:15,773 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:15,783 - 

2022-12-15 15:06:15,783 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:16,178 - Epoch: [115][   10/   74]    Overall Loss 0.394390    Objective Loss 0.394390                                        LR 0.000100    Time 0.039461    
2022-12-15 15:06:16,418 - Epoch: [115][   20/   74]    Overall Loss 0.410522    Objective Loss 0.410522                                        LR 0.000100    Time 0.031722    
2022-12-15 15:06:16,679 - Epoch: [115][   30/   74]    Overall Loss 0.398993    Objective Loss 0.398993                                        LR 0.000100    Time 0.029819    
2022-12-15 15:06:16,932 - Epoch: [115][   40/   74]    Overall Loss 0.398870    Objective Loss 0.398870                                        LR 0.000100    Time 0.028685    
2022-12-15 15:06:17,164 - Epoch: [115][   50/   74]    Overall Loss 0.395007    Objective Loss 0.395007                                        LR 0.000100    Time 0.027571    
2022-12-15 15:06:17,403 - Epoch: [115][   60/   74]    Overall Loss 0.393442    Objective Loss 0.393442                                        LR 0.000100    Time 0.026950    
2022-12-15 15:06:17,634 - Epoch: [115][   70/   74]    Overall Loss 0.396812    Objective Loss 0.396812                                        LR 0.000100    Time 0.026399    
2022-12-15 15:06:17,723 - Epoch: [115][   74/   74]    Overall Loss 0.395559    Objective Loss 0.395559    Top1 92.824074    Top5 99.074074    LR 0.000100    Time 0.026172    
2022-12-15 15:06:17,790 - --- validate (epoch=115)-----------
2022-12-15 15:06:17,791 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:18,073 - Epoch: [115][    9/    9]    Loss 1.237877    Top1 65.744275    Top5 91.078244    
2022-12-15 15:06:18,129 - ==> Top1: 65.744    Top5: 91.078    Loss: 1.238

2022-12-15 15:06:18,131 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   2   0   1   0   2   0   0   0   0   0   0   0   0  11   0   1   2   0   0   0   0   0   1   1   1   0]
 [  0   0 112   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   7   0 125   1   5   0   0   0   0   0   0   0   0   1   0   0   5   0   0   3   0   8   0   0   0   3   0   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   1   0   1   0 131   0   3   3   0   1   0   0   3   1   0   0   2   0   0   0   1  12   0   0   0   4   0   9   0]
 [  0   6   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   1   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   8   4   0   1   0   0   0   1   0   0   4   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   6   0   1   9   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  11   0   0   0  24   0   0   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   0   2   0  15   0   0   0   0   0   0   0   0   0   3   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   1   0  15   0   0   0   0   0   0   1   0   3   0]
 [  1   0   0   0   1   0   6   0   0   1   1   4   0   0 156   1   2   0   2   0   0  11   0   0   0   0   1   1   1   0   0]
 [  2   0   0   0   0   0   7   0   0   2   0   0   0   0   3   5   0   0   2   0   0   0   0   2   0   0   0   6   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   9   1   0   3   0   1   0   2   7   0   0   0   0   0   2   2   0 114   0   2   5   0   0   0   0   0   1   3   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  76  10   0   0   0   0   0   7   0   6   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0   9   0   6   0   7   0   5 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   2   0  18   0  12   0   2   0   0   4   0   0   0   0   0   0   5   0   0   2   2  86   0   0   2   5   1   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   2   3   0   4   0   4   0   0   2   0   0   0  58   0   8   0]
 [  0   1   0   0   0   0   0   0   0   0   0   1   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0  10   0   7   2   0   4   0   0   0   0   1   5   0   0   4   0   3   1   0   5   0   0   0   2   0 136   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:18,133 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:18,134 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:18,154 - 

2022-12-15 15:06:18,154 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:18,591 - Epoch: [116][   10/   74]    Overall Loss 0.408001    Objective Loss 0.408001                                        LR 0.000100    Time 0.043582    
2022-12-15 15:06:18,843 - Epoch: [116][   20/   74]    Overall Loss 0.403349    Objective Loss 0.403349                                        LR 0.000100    Time 0.034398    
2022-12-15 15:06:19,094 - Epoch: [116][   30/   74]    Overall Loss 0.404141    Objective Loss 0.404141                                        LR 0.000100    Time 0.031280    
2022-12-15 15:06:19,340 - Epoch: [116][   40/   74]    Overall Loss 0.402661    Objective Loss 0.402661                                        LR 0.000100    Time 0.029597    
2022-12-15 15:06:19,588 - Epoch: [116][   50/   74]    Overall Loss 0.397786    Objective Loss 0.397786                                        LR 0.000100    Time 0.028635    
2022-12-15 15:06:19,840 - Epoch: [116][   60/   74]    Overall Loss 0.393223    Objective Loss 0.393223                                        LR 0.000100    Time 0.028057    
2022-12-15 15:06:20,078 - Epoch: [116][   70/   74]    Overall Loss 0.393280    Objective Loss 0.393280                                        LR 0.000100    Time 0.027435    
2022-12-15 15:06:20,165 - Epoch: [116][   74/   74]    Overall Loss 0.393930    Objective Loss 0.393930    Top1 92.592593    Top5 99.074074    LR 0.000100    Time 0.027132    
2022-12-15 15:06:20,225 - --- validate (epoch=116)-----------
2022-12-15 15:06:20,225 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:20,497 - Epoch: [116][    9/    9]    Loss 1.216328    Top1 66.030534    Top5 91.412214    
2022-12-15 15:06:20,546 - ==> Top1: 66.031    Top5: 91.412    Loss: 1.216

2022-12-15 15:06:20,548 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   2   0   0   0   0   0   0   1   0   0]
 [  0   0 114   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   5   0 126   2   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   8   0   0   0   3   0   5   0]
 [  0   2   0   0   1  40   0   0   0   0   0   0   0   0   1   0   1   0   3   0   1   3   0   0   0   0   1   0   2   0   0]
 [  0   0   1   0   1   0 128   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  13   0   0   1   5   0  10   0]
 [  0   6   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   1   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   8   0   9   5   0   1   0   0   0   0   0   0   4   0   0   1   0   3   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  12   0   0   0   0   0   1   0   0   5   0   1   1   0   3   0   0   0   2   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0   9   0   1   0   0   0   0  17   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   6   0   0   1   2   5   0   0 157   0   1   0   1   0   0  11   0   0   0   0   1   1   1   0   0]
 [  2   0   0   0   0   0   7   0   0   3   0   0   0   0   3   5   0   0   2   0   0   0   0   2   0   0   0   5   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   9   1   0   2   0   1   0   2   7   0   0   0   0   0   1   2   0 115   0   2   5   0   0   0   0   0   2   3   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   1   0   0   3   0   0   0   0   0   1   1   0   1   0   1   0  74  11   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0  10   0   5   0   7   0   5 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   2   0  17   0   9   0   2   1   0   4   0   0   0   0   0   0   5   0   0   2   2  87   0   0   2   6   3   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   2   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   2   0   0   1   0   1   0   0   0   0   0   1   6   0   0  55   0   1   0   0]
 [  0   0   2   0   2   3  15   0   1   2   0   0   0   0   3   2   4   0   4   0   4   0   0   2   0   0   0  55   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0   0   2   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   8   1   6   2   0   4   0   0   0   0   1   5   0   0   3   0   2   2   0   7   0   0   0   4   0 135   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:20,550 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:20,550 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:20,560 - 

2022-12-15 15:06:20,561 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:21,102 - Epoch: [117][   10/   74]    Overall Loss 0.393844    Objective Loss 0.393844                                        LR 0.000100    Time 0.054068    
2022-12-15 15:06:21,348 - Epoch: [117][   20/   74]    Overall Loss 0.390979    Objective Loss 0.390979                                        LR 0.000100    Time 0.039285    
2022-12-15 15:06:21,598 - Epoch: [117][   30/   74]    Overall Loss 0.391501    Objective Loss 0.391501                                        LR 0.000100    Time 0.034518    
2022-12-15 15:06:21,865 - Epoch: [117][   40/   74]    Overall Loss 0.391784    Objective Loss 0.391784                                        LR 0.000100    Time 0.032566    
2022-12-15 15:06:22,125 - Epoch: [117][   50/   74]    Overall Loss 0.389071    Objective Loss 0.389071                                        LR 0.000100    Time 0.031247    
2022-12-15 15:06:22,389 - Epoch: [117][   60/   74]    Overall Loss 0.391348    Objective Loss 0.391348                                        LR 0.000100    Time 0.030433    
2022-12-15 15:06:22,637 - Epoch: [117][   70/   74]    Overall Loss 0.392709    Objective Loss 0.392709                                        LR 0.000100    Time 0.029617    
2022-12-15 15:06:22,724 - Epoch: [117][   74/   74]    Overall Loss 0.390696    Objective Loss 0.390696    Top1 92.361111    Top5 98.842593    LR 0.000100    Time 0.029185    
2022-12-15 15:06:22,794 - --- validate (epoch=117)-----------
2022-12-15 15:06:22,794 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:23,067 - Epoch: [117][    9/    9]    Loss 1.257745    Top1 66.364504    Top5 90.935115    
2022-12-15 15:06:23,113 - ==> Top1: 66.365    Top5: 90.935    Loss: 1.258

2022-12-15 15:06:23,115 - ==> Confusion:
[[ 19   0   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  13   0   0   4   2   0   1   0   2   0   0   0   0   0   0   0   0  12   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 113   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 127   1   4   0   0   0   0   0   0   0   0   2   0   0   4   0   0   3   0   8   0   0   0   1   0   6   0]
 [  0   2   0   0   1  39   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  1   0   1   0   1   0 127   0   3   2   0   1   0   0   4   1   0   0   3   0   0   0   1  12   0   0   1   5   0   9   0]
 [  0   5   0   0   0   2   0   4   0   0   0   0   0   1   0   0   0   0   2   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   9   5   0   1   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  10   0   0   0   0   0   1   0   0   6   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  12   0   0   0  23   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   2   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   5   0   0   1   2   4   0   0 157   0   1   0   2   0   0  12   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   4   0   0   2   0   0   0   0   2   0   0   0   5   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   2   0   1   0   1   6   0   0   0   0   0   1   2   0 120   0   1   5   0   0   0   0   0   0   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74  10   0   0   0   0   0   7   0   6   0]
 [  0   2   0   0   0   0   0   0   0   0   0   1   0   0  10   0   6   0   6   0   5 143   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   4   0  17   0   9   0   2   1   0   4   0   0   0   0   0   0   5   0   0   2   2  86   0   0   2   5   3   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   1   0   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   1   2   0   2   3  12   0   1   2   0   0   0   0   3   3   4   0   4   0   3   0   0   2   0   0   0  56   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   0   7   2   0   3   0   0   0   0   1   5   0   0   5   0   3   2   0   4   0   0   0   2   0 137   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:23,116 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:23,116 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:23,136 - 

2022-12-15 15:06:23,137 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:23,540 - Epoch: [118][   10/   74]    Overall Loss 0.380864    Objective Loss 0.380864                                        LR 0.000100    Time 0.040270    
2022-12-15 15:06:23,779 - Epoch: [118][   20/   74]    Overall Loss 0.381435    Objective Loss 0.381435                                        LR 0.000100    Time 0.032046    
2022-12-15 15:06:23,995 - Epoch: [118][   30/   74]    Overall Loss 0.386279    Objective Loss 0.386279                                        LR 0.000100    Time 0.028559    
2022-12-15 15:06:24,213 - Epoch: [118][   40/   74]    Overall Loss 0.385591    Objective Loss 0.385591                                        LR 0.000100    Time 0.026854    
2022-12-15 15:06:24,432 - Epoch: [118][   50/   74]    Overall Loss 0.387201    Objective Loss 0.387201                                        LR 0.000100    Time 0.025862    
2022-12-15 15:06:24,649 - Epoch: [118][   60/   74]    Overall Loss 0.387560    Objective Loss 0.387560                                        LR 0.000100    Time 0.025162    
2022-12-15 15:06:24,861 - Epoch: [118][   70/   74]    Overall Loss 0.386699    Objective Loss 0.386699                                        LR 0.000100    Time 0.024588    
2022-12-15 15:06:24,939 - Epoch: [118][   74/   74]    Overall Loss 0.388086    Objective Loss 0.388086    Top1 91.666667    Top5 98.842593    LR 0.000100    Time 0.024314    
2022-12-15 15:06:25,008 - --- validate (epoch=118)-----------
2022-12-15 15:06:25,008 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:25,282 - Epoch: [118][    9/    9]    Loss 1.232925    Top1 65.839695    Top5 90.791985    
2022-12-15 15:06:25,329 - ==> Top1: 65.840    Top5: 90.792    Loss: 1.233

2022-12-15 15:06:25,331 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   1   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 114   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   7   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   7   0 125   0   5   0   0   0   0   0   0   0   0   1   0   0   5   0   0   2   0   7   0   0   0   3   0   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   1   0   1   0 130   0   3   1   0   0   0   0   4   1   0   0   2   0   0   0   1  11   0   0   1   5   0  11   0]
 [  0   5   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   2   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   9   0   7   4   0   2   0   0   0   1   0   0   4   0   0   1   0   3   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  13   0   0   0   0   0   0   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  11   0   0   0  23   0   0   0   0   0   0   5   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   1   1   0  15   0   0   0   0   0   0   0   0   0   3   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  15   0   0   0   0   0   0   2   0   4   0]
 [  2   0   0   0   1   0   8   0   0   1   1   4   0   0 153   0   3   0   2   0   0  11   0   0   0   0   1   1   1   0   0]
 [  1   0   0   0   0   0   7   0   0   2   0   0   0   0   3   7   0   0   2   0   0   0   0   2   0   0   0   5   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   2   0   1   0   1   5   0   0   0   0   0   2   1   0 118   0   2   5   0   0   0   0   0   1   4   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  76  10   0   0   0   0   0   7   0   7   0]
 [  0   2   0   0   1   0   0   0   0   0   0   1   0   0  10   0   6   0   8   0   6 139   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   3   0  16   0  11   0   1   1   0   4   0   0   0   0   0   0   5   0   0   2   2  86   0   0   2   5   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   5   0   0  54   0   1   0   0]
 [  0   1   2   0   2   3  15   0   1   3   0   0   0   0   3   3   4   0   4   0   4   0   0   1   0   0   0  56   0   6   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   2   8   2   0   3   0   0   0   0   1   4   0   0   5   0   2   1   0   7   0   0   0   1   0 135   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:25,333 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:25,333 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:25,343 - 

2022-12-15 15:06:25,343 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:25,758 - Epoch: [119][   10/   74]    Overall Loss 0.387090    Objective Loss 0.387090                                        LR 0.000100    Time 0.041489    
2022-12-15 15:06:26,005 - Epoch: [119][   20/   74]    Overall Loss 0.387164    Objective Loss 0.387164                                        LR 0.000100    Time 0.033075    
2022-12-15 15:06:26,253 - Epoch: [119][   30/   74]    Overall Loss 0.381360    Objective Loss 0.381360                                        LR 0.000100    Time 0.030270    
2022-12-15 15:06:26,469 - Epoch: [119][   40/   74]    Overall Loss 0.385299    Objective Loss 0.385299                                        LR 0.000100    Time 0.028097    
2022-12-15 15:06:26,687 - Epoch: [119][   50/   74]    Overall Loss 0.393312    Objective Loss 0.393312                                        LR 0.000100    Time 0.026844    
2022-12-15 15:06:26,906 - Epoch: [119][   60/   74]    Overall Loss 0.388403    Objective Loss 0.388403                                        LR 0.000100    Time 0.026001    
2022-12-15 15:06:27,122 - Epoch: [119][   70/   74]    Overall Loss 0.387291    Objective Loss 0.387291                                        LR 0.000100    Time 0.025367    
2022-12-15 15:06:27,202 - Epoch: [119][   74/   74]    Overall Loss 0.386941    Objective Loss 0.386941    Top1 90.972222    Top5 99.074074    LR 0.000100    Time 0.025078    
2022-12-15 15:06:27,277 - --- validate (epoch=119)-----------
2022-12-15 15:06:27,277 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:27,550 - Epoch: [119][    9/    9]    Loss 1.228536    Top1 65.839695    Top5 91.078244    
2022-12-15 15:06:27,602 - ==> Top1: 65.840    Top5: 91.078    Loss: 1.229

2022-12-15 15:06:27,604 - ==> Confusion:
[[ 19   0   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 112   0   8   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   6   0 125   1   4   0   0   0   0   0   0   0   0   1   0   0   4   0   0   3   0   7   0   0   0   3   0   7   0]
 [  0   2   0   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   5   0   0   0   0   1   0   1   0   0]
 [  1   0   1   0   1   0 128   0   3   0   0   0   0   0   4   1   0   0   2   0   0   0   1  13   0   0   1   5   0  11   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   7   4   0   2   0   0   0   0   0   0   5   0   0   1   0   4   0   0   0   1   1   1   0]
 [  1   0   0   0   0   0   5   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   1   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   2   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  10   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   5   0]
 [  1   0   0   0   1   1   5   0   0   1   1   5   0   0 156   1   2   0   1   0   0  11   0   0   0   0   1   1   1   0   0]
 [  2   0   0   0   0   0   7   0   0   3   0   0   0   0   3   7   0   0   2   0   0   0   0   1   0   0   0   4   0   2   0]
 [  1   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  32   0   6   0   1   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   2   0   1   3   2   5   0   0   0   1   0   1   3   0 115   0   2   5   0   0   0   0   0   1   2   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  76  11   0   0   0   0   0   7   0   7   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0  10   0   6   0   6   0   6 143   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  11   0   3   1   0   4   0   0   0   0   0   0   6   0   0   1   2  84   0   0   2   5   1   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   2   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   2   0   0   0   0   2   0   5   0   0  52   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   4   3   0   4   0   4   0   0   0   0   0   0  55   0  11   0]
 [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   8   2   7   1   0   3   0   0   0   0   1   5   0   0   4   0   2   2   0   3   0   0   0   3   0 139   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:27,605 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:27,606 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:27,626 - 

2022-12-15 15:06:27,626 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:28,045 - Epoch: [120][   10/   74]    Overall Loss 0.376710    Objective Loss 0.376710                                        LR 0.000100    Time 0.041804    
2022-12-15 15:06:28,304 - Epoch: [120][   20/   74]    Overall Loss 0.376727    Objective Loss 0.376727                                        LR 0.000100    Time 0.033825    
2022-12-15 15:06:28,553 - Epoch: [120][   30/   74]    Overall Loss 0.380924    Objective Loss 0.380924                                        LR 0.000100    Time 0.030842    
2022-12-15 15:06:28,802 - Epoch: [120][   40/   74]    Overall Loss 0.379739    Objective Loss 0.379739                                        LR 0.000100    Time 0.029354    
2022-12-15 15:06:29,049 - Epoch: [120][   50/   74]    Overall Loss 0.384400    Objective Loss 0.384400                                        LR 0.000100    Time 0.028405    
2022-12-15 15:06:29,297 - Epoch: [120][   60/   74]    Overall Loss 0.384808    Objective Loss 0.384808                                        LR 0.000100    Time 0.027810    
2022-12-15 15:06:29,542 - Epoch: [120][   70/   74]    Overall Loss 0.383599    Objective Loss 0.383599                                        LR 0.000100    Time 0.027324    
2022-12-15 15:06:29,624 - Epoch: [120][   74/   74]    Overall Loss 0.386078    Objective Loss 0.386078    Top1 90.046296    Top5 98.148148    LR 0.000100    Time 0.026946    
2022-12-15 15:06:29,689 - --- validate (epoch=120)-----------
2022-12-15 15:06:29,689 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:29,965 - Epoch: [120][    9/    9]    Loss 1.255065    Top1 65.839695    Top5 91.269084    
2022-12-15 15:06:30,021 - ==> Top1: 65.840    Top5: 91.269    Loss: 1.255

2022-12-15 15:06:30,023 - ==> Confusion:
[[ 19   0   0   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   1   0   5   2   0   2   0   3   0   0   0   0   0   0   0   0  10   0   1   2   0   0   0   0   0   1   1   1   0]
 [  0   0 115   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   7   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1   6   0 126   2   6   0   0   0   0   0   0   1   0   1   0   0   5   0   0   2   0   7   0   0   0   3   0   5   0]
 [  0   1   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   1   0   1   0 129   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0  10   0]
 [  0   6   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   1   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   8   5   0   2   0   0   0   0   0   0   4   0   0   1   0   4   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  10   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  12   0   0   0  22   0   0   0   1   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   2   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   1   8   0   0   1   3   5   0   0 153   0   1   0   1   0   0  10   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   3   4   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   7   1   0   2   0   1   1   2   6   0   0   0   0   0   1   2   0 117   0   2   5   0   0   0   0   0   1   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   2   0   0   1   0   0   0   0   0   1   1   0   1   0   1   0  75  11   0   0   0   0   0   7   0   8   0]
 [  0   1   0   0   1   0   0   0   0   0   0   0   0   0  10   0   6   0   6   0   6 143   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   5   0  17   0  11   0   2   1   0   4   0   0   0   0   0   0   5   0   0   1   2  84   0   0   2   5   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   4   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  15   0   1   2   0   0   0   0   3   4   3   0   4   0   4   0   0   1   0   0   0  56   0   8   0]
 [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   2   7   1   0   4   0   0   0   0   1   5   0   0   4   0   2   1   0   5   0   0   0   2   0 137   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:30,025 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:30,026 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:30,036 - 

2022-12-15 15:06:30,036 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:30,437 - Epoch: [121][   10/   74]    Overall Loss 0.364865    Objective Loss 0.364865                                        LR 0.000100    Time 0.040062    
2022-12-15 15:06:30,668 - Epoch: [121][   20/   74]    Overall Loss 0.380821    Objective Loss 0.380821                                        LR 0.000100    Time 0.031556    
2022-12-15 15:06:30,889 - Epoch: [121][   30/   74]    Overall Loss 0.376974    Objective Loss 0.376974                                        LR 0.000100    Time 0.028375    
2022-12-15 15:06:31,110 - Epoch: [121][   40/   74]    Overall Loss 0.374142    Objective Loss 0.374142                                        LR 0.000100    Time 0.026814    
2022-12-15 15:06:31,332 - Epoch: [121][   50/   74]    Overall Loss 0.377803    Objective Loss 0.377803                                        LR 0.000100    Time 0.025880    
2022-12-15 15:06:31,553 - Epoch: [121][   60/   74]    Overall Loss 0.379811    Objective Loss 0.379811                                        LR 0.000100    Time 0.025246    
2022-12-15 15:06:31,762 - Epoch: [121][   70/   74]    Overall Loss 0.380341    Objective Loss 0.380341                                        LR 0.000100    Time 0.024615    
2022-12-15 15:06:31,847 - Epoch: [121][   74/   74]    Overall Loss 0.382244    Objective Loss 0.382244    Top1 90.972222    Top5 97.453704    LR 0.000100    Time 0.024439    
2022-12-15 15:06:31,917 - --- validate (epoch=121)-----------
2022-12-15 15:06:31,917 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:32,193 - Epoch: [121][    9/    9]    Loss 1.227429    Top1 65.982824    Top5 91.364504    
2022-12-15 15:06:32,240 - ==> Top1: 65.983    Top5: 91.365    Loss: 1.227

2022-12-15 15:06:32,242 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   4   1   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   2   0   0   0   0   0   1   1   1   0]
 [  0   0 113   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 123   1   3   0   0   0   0   0   0   0   0   0   0   0   5   0   0   3   0  11   0   0   0   4   1   5   0]
 [  0   1   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   2   0   0]
 [  0   0   0   0   1   0 134   0   3   1   0   1   0   0   3   1   0   0   2   0   0   0   1  10   0   0   1   5   0   9   0]
 [  0   5   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   2   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   8   0   8   4   0   2   0   0   0   1   0   0   3   0   0   1   0   4   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   1   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  12   0   0   0  23   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   2   0  16   0   0   0   0   0   0   1   0   0   2   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   8   0   0   1   2   4   0   0 156   2   0   0   2   0   0   9   0   0   0   0   1   1   1   0   0]
 [  2   0   0   0   0   0   7   0   0   3   0   0   0   0   3   5   0   0   2   0   0   0   0   2   0   0   0   5   0   2   0]
 [  2   0   0   0   0   2   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   6   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   7   1   0   2   0   1   1   3   6   0   0   0   1   0   3   2   0 115   0   2   5   0   0   0   0   0   1   3   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   1   0   0   0   0   0   1   1   0   1   0   1   0  75  10   0   0   0   0   0   7   0   9   0]
 [  0   3   0   0   0   0   0   0   0   0   0   1   0   0  11   0   6   0   6   0   5 140   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   4   0  15   0  12   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  89   0   0   2   4   2   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   7   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   3   3   0   4   0   4   0   0   2   0   0   0  56   0   9   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   8   0   6   2   0   5   0   0   0   0   1   5   0   0   4   0   3   1   0   6   0   0   0   4   0 135   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:06:32,243 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:32,243 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:32,254 - 

2022-12-15 15:06:32,254 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:32,692 - Epoch: [122][   10/   74]    Overall Loss 0.389735    Objective Loss 0.389735                                        LR 0.000100    Time 0.043779    
2022-12-15 15:06:32,951 - Epoch: [122][   20/   74]    Overall Loss 0.384362    Objective Loss 0.384362                                        LR 0.000100    Time 0.034797    
2022-12-15 15:06:33,201 - Epoch: [122][   30/   74]    Overall Loss 0.378220    Objective Loss 0.378220                                        LR 0.000100    Time 0.031500    
2022-12-15 15:06:33,449 - Epoch: [122][   40/   74]    Overall Loss 0.379976    Objective Loss 0.379976                                        LR 0.000100    Time 0.029834    
2022-12-15 15:06:33,699 - Epoch: [122][   50/   74]    Overall Loss 0.383811    Objective Loss 0.383811                                        LR 0.000100    Time 0.028856    
2022-12-15 15:06:33,955 - Epoch: [122][   60/   74]    Overall Loss 0.382988    Objective Loss 0.382988                                        LR 0.000100    Time 0.028295    
2022-12-15 15:06:34,174 - Epoch: [122][   70/   74]    Overall Loss 0.380950    Objective Loss 0.380950                                        LR 0.000100    Time 0.027381    
2022-12-15 15:06:34,253 - Epoch: [122][   74/   74]    Overall Loss 0.379569    Objective Loss 0.379569    Top1 92.129630    Top5 99.074074    LR 0.000100    Time 0.026958    
2022-12-15 15:06:34,317 - --- validate (epoch=122)-----------
2022-12-15 15:06:34,317 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:34,593 - Epoch: [122][    9/    9]    Loss 1.267458    Top1 65.839695    Top5 91.125954    
2022-12-15 15:06:34,653 - ==> Top1: 65.840    Top5: 91.126    Loss: 1.267

2022-12-15 15:06:34,654 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   1   0   1   0   0   0   1   1   1   0]
 [  0   0 115   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   1   0   7   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   5   0 126   2   5   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   7   0   0   0   3   0   5   0]
 [  0   2   1   0   1  39   0   0   0   0   0   0   0   0   0   0   1   0   3   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   0   0   1   0 132   0   3   1   0   0   0   0   4   1   0   0   3   0   0   0   1  12   0   0   1   5   0   8   0]
 [  0   7   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   0   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   6   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  17   0   0   0   0   0   0   0   0   0   2   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0   9   0   0   0   0   1   0  17   0   0   0   0   0   0   2   0   3   0]
 [  1   0   0   0   0   0   7   0   0   1   1   5   0   0 157   0   4   0   1   0   0   8   0   0   0   0   1   2   1   0   0]
 [  2   0   0   0   0   0   7   0   0   3   0   0   0   0   3   4   0   0   2   0   0   0   0   2   0   0   0   6   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   9   1   0   2   0   1   2   3   6   0   0   0   0   0   1   3   0 115   0   1   5   0   0   0   0   0   0   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   1   0   0   1   0   0   0   0   0   1   1   0   1   0   1   0  76  11   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   0   0   0   0   0   0   0   0   0   0  11   0   6   0   6   0   5 141   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   4   0  17   0  11   0   1   1   0   4   0   0   0   0   0   0   5   0   0   1   2  84   0   0   2   6   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   5   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   3   3   0   4   0   4   0   0   2   0   0   0  56   0   9   0]
 [  0   1   0   0   0   0   0   0   0   0   0   1   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   8   0   7   2   0   6   0   0   0   0   1   5   0   0   5   0   3   1   0   5   0   0   0   2   0 135   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:34,656 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:34,656 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:34,667 - 

2022-12-15 15:06:34,667 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:35,225 - Epoch: [123][   10/   74]    Overall Loss 0.365470    Objective Loss 0.365470                                        LR 0.000100    Time 0.055753    
2022-12-15 15:06:35,469 - Epoch: [123][   20/   74]    Overall Loss 0.374024    Objective Loss 0.374024                                        LR 0.000100    Time 0.040041    
2022-12-15 15:06:35,727 - Epoch: [123][   30/   74]    Overall Loss 0.382727    Objective Loss 0.382727                                        LR 0.000100    Time 0.035293    
2022-12-15 15:06:35,989 - Epoch: [123][   40/   74]    Overall Loss 0.385456    Objective Loss 0.385456                                        LR 0.000100    Time 0.032998    
2022-12-15 15:06:36,246 - Epoch: [123][   50/   74]    Overall Loss 0.380769    Objective Loss 0.380769                                        LR 0.000100    Time 0.031528    
2022-12-15 15:06:36,506 - Epoch: [123][   60/   74]    Overall Loss 0.377896    Objective Loss 0.377896                                        LR 0.000100    Time 0.030606    
2022-12-15 15:06:36,750 - Epoch: [123][   70/   74]    Overall Loss 0.378001    Objective Loss 0.378001                                        LR 0.000100    Time 0.029703    
2022-12-15 15:06:36,839 - Epoch: [123][   74/   74]    Overall Loss 0.377475    Objective Loss 0.377475    Top1 90.046296    Top5 99.074074    LR 0.000100    Time 0.029307    
2022-12-15 15:06:36,917 - --- validate (epoch=123)-----------
2022-12-15 15:06:36,918 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:37,197 - Epoch: [123][    9/    9]    Loss 1.257865    Top1 65.028626    Top5 91.173664    
2022-12-15 15:06:37,245 - ==> Top1: 65.029    Top5: 91.174    Loss: 1.258

2022-12-15 15:06:37,246 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   8   1   0   5   2   0   2   0   1   0   0   0   0   0   0   0   0  12   0   1   2   0   1   0   0   0   1   1   1   0]
 [  0   0 113   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   8   0 122   2   4   0   0   0   0   0   0   0   0   1   0   0   5   0   0   3   0  10   0   0   0   2   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   1   0   1   0 131   0   4   0   0   1   0   0   4   1   0   0   3   0   0   0   1  12   0   0   1   5   0   7   0]
 [  0   7   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   0   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   6   4   0   2   0   0   0   1   0   0   5   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   6   0   1   9   0   0   0   0   0   3   0   0   5   0   1   1   0   3   0   0   0   1   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  11   0   0   0  24   0   0   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   1   1   0  15   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0   9   0   0   0   0   1   0  17   0   0   0   0   0   0   2   0   3   0]
 [  1   0   0   0   1   0   6   0   0   0   2   4   0   0 156   1   1   0   1   0   0  12   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   7   0   0   2   0   0   0   0   3   4   0   0   2   0   0   0   0   2   0   0   0   6   0   2   0]
 [  2   0   0   0   0   1   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   6   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  4   7   1   0   2   0   1   1   1   4   0   0   0   0   0   3   1   0 119   0   1   5   0   0   0   0   0   1   4   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   1   0   1   0   0   0   0   0   1   1   0   1   0   1   0  75  11   0   0   0   0   0   7   0   6   0]
 [  0   3   0   0   0   0   0   0   0   0   0   1   0   0  11   0   6   0   6   0   5 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   4   0  18   0  12   0   1   1   0   4   0   0   0   0   0   0   5   0   0   1   2  84   0   0   2   4   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   2   0   4   0   0  53   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   3   3   0   4   0   3   1   0   2   0   0   0  57   0   8   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   9   0   0]
 [  0   0   0   0   9   2   8   2   0   7   0   0   0   0   1   5   0   0   3   0   2   2   0   6   0   0   0   4   0 129   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:37,248 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:37,248 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:37,259 - 

2022-12-15 15:06:37,259 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:37,692 - Epoch: [124][   10/   74]    Overall Loss 0.372507    Objective Loss 0.372507                                        LR 0.000100    Time 0.043200    
2022-12-15 15:06:37,941 - Epoch: [124][   20/   74]    Overall Loss 0.374672    Objective Loss 0.374672                                        LR 0.000100    Time 0.034054    
2022-12-15 15:06:38,194 - Epoch: [124][   30/   74]    Overall Loss 0.376070    Objective Loss 0.376070                                        LR 0.000100    Time 0.031111    
2022-12-15 15:06:38,433 - Epoch: [124][   40/   74]    Overall Loss 0.369765    Objective Loss 0.369765                                        LR 0.000100    Time 0.029278    
2022-12-15 15:06:38,648 - Epoch: [124][   50/   74]    Overall Loss 0.371699    Objective Loss 0.371699                                        LR 0.000100    Time 0.027711    
2022-12-15 15:06:38,866 - Epoch: [124][   60/   74]    Overall Loss 0.372537    Objective Loss 0.372537                                        LR 0.000100    Time 0.026730    
2022-12-15 15:06:39,074 - Epoch: [124][   70/   74]    Overall Loss 0.376602    Objective Loss 0.376602                                        LR 0.000100    Time 0.025873    
2022-12-15 15:06:39,154 - Epoch: [124][   74/   74]    Overall Loss 0.376717    Objective Loss 0.376717    Top1 90.046296    Top5 99.074074    LR 0.000100    Time 0.025549    
2022-12-15 15:06:39,211 - --- validate (epoch=124)-----------
2022-12-15 15:06:39,211 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:39,490 - Epoch: [124][    9/    9]    Loss 1.263166    Top1 65.744275    Top5 90.935115    
2022-12-15 15:06:39,550 - ==> Top1: 65.744    Top5: 90.935    Loss: 1.263

2022-12-15 15:06:39,552 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   8   1   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  14   0   1   1   0   0   0   0   0   1   1   0   0]
 [  0   0 113   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 124   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   8   0   0   0   3   1   5   0]
 [  0   1   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   2   0   0]
 [  1   0   0   0   0   0 130   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   8   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   4   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   2   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   4   0   0   1   1   4   0   0 159   0   1   0   1   0   0  12   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   5   0   0   5   0   0   0   0   3   5   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   2   0   1   1   2   8   0   0   0   0   0   1   1   0 116   0   2   5   0   0   0   0   0   0   4   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   0   0   2   0   0   0   0   0   1   0   0   1   0   1   0  75  10   0   0   0   0   0   8   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   0   0   0  10   0   6   0   7   0   5 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   4   0  17   0  11   0   3   1   0   4   0   0   0   0   0   0   5   0   0   1   2  83   0   0   2   5   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   2   0   0   1   0   0   1   0   1   0   0   0   0   0   1   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   2   0   5   0   0  53   0   1   0   0]
 [  0   0   2   0   3   3  15   0   1   2   0   0   0   0   3   2   4   0   4   0   5   0   0   1   0   0   0  54   0   9   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   7   2   8   2   0   3   0   0   0   0   1   5   0   0   5   0   2   2   0   4   0   0   0   2   0 137   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:39,554 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:39,554 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:39,564 - 

2022-12-15 15:06:39,564 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:39,974 - Epoch: [125][   10/   74]    Overall Loss 0.354943    Objective Loss 0.354943                                        LR 0.000100    Time 0.040909    
2022-12-15 15:06:40,200 - Epoch: [125][   20/   74]    Overall Loss 0.355558    Objective Loss 0.355558                                        LR 0.000100    Time 0.031734    
2022-12-15 15:06:40,437 - Epoch: [125][   30/   74]    Overall Loss 0.367740    Objective Loss 0.367740                                        LR 0.000100    Time 0.029020    
2022-12-15 15:06:40,681 - Epoch: [125][   40/   74]    Overall Loss 0.370314    Objective Loss 0.370314                                        LR 0.000100    Time 0.027861    
2022-12-15 15:06:40,931 - Epoch: [125][   50/   74]    Overall Loss 0.369672    Objective Loss 0.369672                                        LR 0.000100    Time 0.027288    
2022-12-15 15:06:41,181 - Epoch: [125][   60/   74]    Overall Loss 0.370606    Objective Loss 0.370606                                        LR 0.000100    Time 0.026896    
2022-12-15 15:06:41,405 - Epoch: [125][   70/   74]    Overall Loss 0.371706    Objective Loss 0.371706                                        LR 0.000100    Time 0.026249    
2022-12-15 15:06:41,484 - Epoch: [125][   74/   74]    Overall Loss 0.373651    Objective Loss 0.373651    Top1 90.972222    Top5 97.685185    LR 0.000100    Time 0.025895    
2022-12-15 15:06:41,549 - --- validate (epoch=125)-----------
2022-12-15 15:06:41,550 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:41,828 - Epoch: [125][    9/    9]    Loss 1.241507    Top1 65.601145    Top5 90.839695    
2022-12-15 15:06:41,886 - ==> Top1: 65.601    Top5: 90.840    Loss: 1.242

2022-12-15 15:06:41,888 - ==> Confusion:
[[ 17   0   1   0   0   0   4   0   1   0   0   2   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   5   2   0   2   0   3   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   1   1   0   0]
 [  0   0 114   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   7   0 125   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   9   0   0   0   1   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   1   0   1   0 133   0   5   1   0   0   0   0   4   1   0   0   3   0   0   0   1  10   0   0   1   5   0   6   0]
 [  0   7   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   0   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   9   0   6   4   0   2   0   0   0   1   0   0   4   0   0   1   0   4   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  12   0   0   0   0   0   1   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  11   0   0   0  24   0   0   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  10   0   1   0   0   0   0  16   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   8   0   0   1   3   4   0   0 154   1   0   0   1   0   0  11   0   0   0   0   1   1   2   0   0]
 [  4   0   0   0   0   0   7   0   0   4   0   0   0   0   2   4   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   2   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   7   1   0   2   0   1   0   3   6   0   0   0   0   0   1   2   0 119   0   2   5   0   0   0   0   0   0   3   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   0   0   1   0   0   0   0   0   1   1   0   1   0   1   0  74  11   0   0   0   0   0   7   0   8   0]
 [  0   2   0   0   0   0   0   0   0   0   0   1   0   0  11   0   6   0   6   0   5 142   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   3   0  16   0  12   0   2   1   0   4   0   0   0   0   0   0   5   0   0   2   2  85   0   0   2   4   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   2   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   5   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  15   0   1   2   0   0   0   0   3   3   4   0   4   0   3   1   0   1   0   0   0  55   0   9   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   5   0   0   2   0   7   0   0   0   0   9   0   0]
 [  1   0   0   0   8   1   9   2   0   5   0   0   0   0   1   4   0   0   3   0   2   2   0   7   0   0   0   3   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:41,889 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:41,889 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:41,907 - 

2022-12-15 15:06:41,907 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:42,323 - Epoch: [126][   10/   74]    Overall Loss 0.361725    Objective Loss 0.361725                                        LR 0.000100    Time 0.041494    
2022-12-15 15:06:42,575 - Epoch: [126][   20/   74]    Overall Loss 0.359511    Objective Loss 0.359511                                        LR 0.000100    Time 0.033324    
2022-12-15 15:06:42,829 - Epoch: [126][   30/   74]    Overall Loss 0.366460    Objective Loss 0.366460                                        LR 0.000100    Time 0.030663    
2022-12-15 15:06:43,088 - Epoch: [126][   40/   74]    Overall Loss 0.371112    Objective Loss 0.371112                                        LR 0.000100    Time 0.029452    
2022-12-15 15:06:43,343 - Epoch: [126][   50/   74]    Overall Loss 0.371839    Objective Loss 0.371839                                        LR 0.000100    Time 0.028660    
2022-12-15 15:06:43,606 - Epoch: [126][   60/   74]    Overall Loss 0.371556    Objective Loss 0.371556                                        LR 0.000100    Time 0.028231    
2022-12-15 15:06:43,857 - Epoch: [126][   70/   74]    Overall Loss 0.371234    Objective Loss 0.371234                                        LR 0.000100    Time 0.027780    
2022-12-15 15:06:43,939 - Epoch: [126][   74/   74]    Overall Loss 0.370770    Objective Loss 0.370770    Top1 92.361111    Top5 98.611111    LR 0.000100    Time 0.027388    
2022-12-15 15:06:44,006 - --- validate (epoch=126)-----------
2022-12-15 15:06:44,006 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:44,284 - Epoch: [126][    9/    9]    Loss 1.256598    Top1 65.505725    Top5 90.887405    
2022-12-15 15:06:44,343 - ==> Top1: 65.506    Top5: 90.887    Loss: 1.257

2022-12-15 15:06:44,345 - ==> Confusion:
[[ 19   0   1   0   0   0   3   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  13   0   0   4   2   0   1   0   2   0   0   0   0   0   0   0   0  11   0   1   2   0   0   0   0   0   0   1   1   0]
 [  0   0 111   0   8   1   1   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   6   0 124   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0  10   0   0   0   1   1   6   0]
 [  0   2   1   0   1  39   0   0   0   0   0   0   0   0   0   0   1   0   3   0   1   4   0   0   0   0   1   0   2   0   0]
 [  1   0   0   0   0   0 126   0   5   0   0   1   0   0   4   1   0   0   3   0   0   0   1  15   0   0   1   5   0   9   0]
 [  0   7   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   0   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   8   5   0   1   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  12   0   0   0   0   0   1   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   1   0  15   0   0   0   0   0   0   2   0   3   0]
 [  2   0   0   0   1   0   7   0   0   1   3   5   0   0 152   1   1   0   2   0   0  11   0   0   0   0   1   1   1   0   0]
 [  4   0   0   0   0   0   7   0   0   4   0   0   0   0   2   5   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  11   1   0   2   1   1   0   3   6   0   0   0   0   0   1   2   0 114   0   2   4   0   0   0   0   0   0   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   1   0   1   0   0   0   0   0   1   1   0   1   0   1   0  74  10   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0   9   0   6   0   7   0   5 140   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   5   0  17   0   8   0   2   1   0   4   0   0   0   0   0   0   5   0   0   1   2  87   0   0   2   5   3   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  12   0   1   3   0   0   0   0   3   2   4   0   4   0   4   0   0   2   0   0   0  56   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   9   0   0]
 [  0   0   0   0   9   2   8   2   1   4   0   0   0   0   1   4   0   0   4   0   2   1   0   6   0   0   0   2   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:44,346 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:44,347 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:44,356 - 

2022-12-15 15:06:44,356 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:44,746 - Epoch: [127][   10/   74]    Overall Loss 0.364605    Objective Loss 0.364605                                        LR 0.000100    Time 0.038949    
2022-12-15 15:06:44,982 - Epoch: [127][   20/   74]    Overall Loss 0.363680    Objective Loss 0.363680                                        LR 0.000100    Time 0.031215    
2022-12-15 15:06:45,221 - Epoch: [127][   30/   74]    Overall Loss 0.362020    Objective Loss 0.362020                                        LR 0.000100    Time 0.028778    
2022-12-15 15:06:45,464 - Epoch: [127][   40/   74]    Overall Loss 0.358296    Objective Loss 0.358296                                        LR 0.000100    Time 0.027642    
2022-12-15 15:06:45,705 - Epoch: [127][   50/   74]    Overall Loss 0.360177    Objective Loss 0.360177                                        LR 0.000100    Time 0.026928    
2022-12-15 15:06:45,950 - Epoch: [127][   60/   74]    Overall Loss 0.365178    Objective Loss 0.365178                                        LR 0.000100    Time 0.026509    
2022-12-15 15:06:46,187 - Epoch: [127][   70/   74]    Overall Loss 0.366828    Objective Loss 0.366828                                        LR 0.000100    Time 0.026109    
2022-12-15 15:06:46,269 - Epoch: [127][   74/   74]    Overall Loss 0.368482    Objective Loss 0.368482    Top1 92.592593    Top5 98.842593    LR 0.000100    Time 0.025805    
2022-12-15 15:06:46,338 - --- validate (epoch=127)-----------
2022-12-15 15:06:46,338 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:46,607 - Epoch: [127][    9/    9]    Loss 1.263720    Top1 65.553435    Top5 90.744275    
2022-12-15 15:06:46,674 - ==> Top1: 65.553    Top5: 90.744    Loss: 1.264

2022-12-15 15:06:46,676 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   1   0   2   0   0   0   0   0   0   0   0  13   0   1   2   0   0   0   0   0   1   1   0   0]
 [  0   0 115   0   5   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   8   0 123   0   3   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   8   0   0   0   3   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  1   0   1   0   1   0 125   0   4   2   0   1   0   0   4   1   0   0   3   0   0   0   1  12   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   0   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   9   0   7   4   0   1   0   0   0   1   0   0   4   0   0   1   0   4   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   3   0   1  12   0   0   0   0   1   2   0   0   6   0   1   1   0   3   0   0   0   1   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  16   0   0   0  19   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   2   0   0   2   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   3   0]
 [  2   0   0   0   1   0   7   0   0   1   4   4   0   0 151   1   1   0   1   0   0  12   0   0   0   0   1   1   2   0   0]
 [  2   0   0   0   0   0   7   0   0   3   0   0   0   0   3   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   7   1   0   2   0   1   0   3   6   0   0   0   0   0   1   2   0 117   0   2   5   0   0   0   0   0   1   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  76   9   0   0   0   0   0   7   0   5   0]
 [  0   3   0   0   0   0   0   0   0   0   0   1   0   0   9   0   6   0   7   0   5 142   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   4   0  17   0   9   0   3   1   0   3   0   0   0   0   0   0   6   0   0   2   2  87   0   0   2   5   1   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   2   0   0   1   0   1   0   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   5   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   3   0   0   0   0   3   3   4   0   4   0   5   0   0   2   0   0   0  56   0   7   0]
 [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   1   0   7   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   9   0   8   2   0   6   0   0   0   0   0   5   0   0   6   0   3   1   0   5   0   0   0   3   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   5   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:06:46,677 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:46,678 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:46,698 - 

2022-12-15 15:06:46,698 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:47,085 - Epoch: [128][   10/   74]    Overall Loss 0.350827    Objective Loss 0.350827                                        LR 0.000100    Time 0.038647    
2022-12-15 15:06:47,312 - Epoch: [128][   20/   74]    Overall Loss 0.352298    Objective Loss 0.352298                                        LR 0.000100    Time 0.030642    
2022-12-15 15:06:47,561 - Epoch: [128][   30/   74]    Overall Loss 0.357938    Objective Loss 0.357938                                        LR 0.000100    Time 0.028716    
2022-12-15 15:06:47,812 - Epoch: [128][   40/   74]    Overall Loss 0.360448    Objective Loss 0.360448                                        LR 0.000100    Time 0.027790    
2022-12-15 15:06:48,064 - Epoch: [128][   50/   74]    Overall Loss 0.361253    Objective Loss 0.361253                                        LR 0.000100    Time 0.027270    
2022-12-15 15:06:48,312 - Epoch: [128][   60/   74]    Overall Loss 0.363004    Objective Loss 0.363004                                        LR 0.000100    Time 0.026854    
2022-12-15 15:06:48,547 - Epoch: [128][   70/   74]    Overall Loss 0.364233    Objective Loss 0.364233                                        LR 0.000100    Time 0.026361    
2022-12-15 15:06:48,625 - Epoch: [128][   74/   74]    Overall Loss 0.366350    Objective Loss 0.366350    Top1 90.277778    Top5 99.305556    LR 0.000100    Time 0.025991    
2022-12-15 15:06:48,683 - --- validate (epoch=128)-----------
2022-12-15 15:06:48,684 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:48,958 - Epoch: [128][    9/    9]    Loss 1.268010    Top1 64.933206    Top5 90.839695    
2022-12-15 15:06:49,006 - ==> Top1: 64.933    Top5: 90.840    Loss: 1.268

2022-12-15 15:06:49,008 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   6   1   0   2   0   2   0   0   0   0   0   0   0   0  11   0   1   2   0   0   0   0   0   0   1   1   0]
 [  0   0 114   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   5   8   0 120   0   4   0   0   0   0   0   0   0   0   2   0   0   4   0   0   3   0   9   0   0   0   3   2   5   0]
 [  0   3   1   0   1  37   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  1   0   2   0   1   0 125   0   4   2   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   0   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   8   5   0   1   0   0   0   0   0   0   5   0   0   1   0   4   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   4   0   0   5   0   1   1   0   4   0   0   0   0   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   1   0  15   0   0   0   0   0   0   1   0   3   0]
 [  1   0   0   0   1   0   6   0   0   1   5   4   0   0 151   1   2   0   2   0   0  12   0   0   0   0   1   1   1   0   0]
 [  2   0   0   0   0   0   6   0   0   5   0   0   0   0   3   5   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   2   0   1   1   2   6   0   0   0   0   0   2   1   0 118   0   1   5   0   0   0   0   0   1   3   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   4   0   0   1   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74   9   0   0   0   0   0   7   0   7   0]
 [  0   2   0   0   1   0   0   0   0   0   0   2   0   0   9   0   6   0   6   0   6 142   0   0   0   0   1   0   0   3   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  10   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  87   0   0   2   3   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   1   0   0   2   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   2   0   0   0   0   1   0   0   0   0   1   1   3   0   0  55   0   2   0   0]
 [  0   1   2   0   2   3  13   0   1   3   0   0   0   0   3   3   4   0   4   0   4   0   0   2   0   0   0  53   0  10   0]
 [  1   1   0   0   0   1   0   0   0   0   0   0   0   0   1   0   1   0   7   0   0   2   0   7   0   0   0   0   5   0   0]
 [  0   1   0   0   7   2   7   2   0   6   0   0   0   0   1   5   0   0   6   0   2   1   0   6   0   0   0   3   0 131   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:06:49,009 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:49,009 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:49,019 - 

2022-12-15 15:06:49,019 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:49,548 - Epoch: [129][   10/   74]    Overall Loss 0.359144    Objective Loss 0.359144                                        LR 0.000100    Time 0.052837    
2022-12-15 15:06:49,779 - Epoch: [129][   20/   74]    Overall Loss 0.360073    Objective Loss 0.360073                                        LR 0.000100    Time 0.037916    
2022-12-15 15:06:50,013 - Epoch: [129][   30/   74]    Overall Loss 0.362623    Objective Loss 0.362623                                        LR 0.000100    Time 0.033085    
2022-12-15 15:06:50,244 - Epoch: [129][   40/   74]    Overall Loss 0.369222    Objective Loss 0.369222                                        LR 0.000100    Time 0.030562    
2022-12-15 15:06:50,480 - Epoch: [129][   50/   74]    Overall Loss 0.364434    Objective Loss 0.364434                                        LR 0.000100    Time 0.029164    
2022-12-15 15:06:50,715 - Epoch: [129][   60/   74]    Overall Loss 0.366443    Objective Loss 0.366443                                        LR 0.000100    Time 0.028215    
2022-12-15 15:06:50,931 - Epoch: [129][   70/   74]    Overall Loss 0.366170    Objective Loss 0.366170                                        LR 0.000100    Time 0.027261    
2022-12-15 15:06:51,015 - Epoch: [129][   74/   74]    Overall Loss 0.365000    Objective Loss 0.365000    Top1 93.287037    Top5 99.074074    LR 0.000100    Time 0.026926    
2022-12-15 15:06:51,081 - --- validate (epoch=129)-----------
2022-12-15 15:06:51,081 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:51,348 - Epoch: [129][    9/    9]    Loss 1.258042    Top1 65.410305    Top5 90.648855    
2022-12-15 15:06:51,404 - ==> Top1: 65.410    Top5: 90.649    Loss: 1.258

2022-12-15 15:06:51,406 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   6   3   0   1   0   3   0   0   0   0   0   0   0   0  10   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 115   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   7   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   6   0 128   0   6   0   0   0   0   0   0   0   0   1   0   0   3   0   0   3   0   7   0   0   0   1   1   5   0]
 [  0   2   1   0   1  39   0   0   0   0   0   0   0   0   0   0   1   0   3   0   1   4   0   0   0   0   1   0   2   0   0]
 [  1   0   1   0   2   0 126   0   4   2   0   0   0   0   4   1   0   0   1   0   0   0   1  14   0   0   1   4   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   5   4   0   2   0   0   0   0   0   0   5   0   0   1   0   6   0   0   0   2   1   1   0]
 [  1   0   0   0   0   0   3   0   1  12   0   0   0   0   1   1   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  14   0   0   0   0   0   0   2   0   3   0]
 [  1   0   0   0   1   0   5   0   0   1   5   4   0   0 153   1   3   0   1   0   0  10   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   4   0   0   2   0   0   0   0   2   0   0   0   5   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  4  11   1   0   4   0   1   3   2   4   0   0   0   0   0   2   3   0 110   0   1   5   0   0   0   0   0   0   2   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   0   0   4   0   0   0   0   0   1   1   0   1   0   1   0  74   9   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   0   0   0   9   0   6   0   8   0   6 140   0   0   0   0   1   0   0   4   0]
 [  0   0   4   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   2   0   0   1   0   0   0   0]
 [  0   1   4   0  18   0  11   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  84   0   0   2   4   3   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   4   0   0  55   0   1   0   0]
 [  0   0   2   0   2   3  10   0   1   2   0   0   0   0   3   4   3   0   4   0   4   0   0   1   0   0   0  59   0  10   0]
 [  1   1   0   0   0   1   0   0   0   0   0   0   0   0   1   0   1   0   7   0   0   2   0   7   0   0   0   0   5   0   0]
 [  0   0   0   0   9   1   7   2   0   4   0   0   0   0   1   5   0   0   2   0   3   2   0   5   0   0   0   2   0 137   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:51,407 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:51,407 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:51,428 - 

2022-12-15 15:06:51,428 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:51,832 - Epoch: [130][   10/   74]    Overall Loss 0.383711    Objective Loss 0.383711                                        LR 0.000100    Time 0.040318    
2022-12-15 15:06:52,073 - Epoch: [130][   20/   74]    Overall Loss 0.359659    Objective Loss 0.359659                                        LR 0.000100    Time 0.032182    
2022-12-15 15:06:52,323 - Epoch: [130][   30/   74]    Overall Loss 0.355580    Objective Loss 0.355580                                        LR 0.000100    Time 0.029778    
2022-12-15 15:06:52,559 - Epoch: [130][   40/   74]    Overall Loss 0.357151    Objective Loss 0.357151                                        LR 0.000100    Time 0.028227    
2022-12-15 15:06:52,806 - Epoch: [130][   50/   74]    Overall Loss 0.356184    Objective Loss 0.356184                                        LR 0.000100    Time 0.027486    
2022-12-15 15:06:53,051 - Epoch: [130][   60/   74]    Overall Loss 0.359675    Objective Loss 0.359675                                        LR 0.000100    Time 0.026974    
2022-12-15 15:06:53,303 - Epoch: [130][   70/   74]    Overall Loss 0.362477    Objective Loss 0.362477                                        LR 0.000100    Time 0.026717    
2022-12-15 15:06:53,389 - Epoch: [130][   74/   74]    Overall Loss 0.362850    Objective Loss 0.362850    Top1 93.750000    Top5 98.611111    LR 0.000100    Time 0.026438    
2022-12-15 15:06:53,454 - --- validate (epoch=130)-----------
2022-12-15 15:06:53,454 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:53,719 - Epoch: [130][    9/    9]    Loss 1.263407    Top1 65.601145    Top5 90.648855    
2022-12-15 15:06:53,776 - ==> Top1: 65.601    Top5: 90.649    Loss: 1.263

2022-12-15 15:06:53,778 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   2   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  12   1   0   4   1   0   1   0   2   0   0   0   0   0   0   0   0  12   0   1   2   0   0   0   0   0   0   1   1   0]
 [  0   0 115   0   5   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   8   0 121   0   5   0   0   1   0   0   0   0   0   0   0   0   5   0   0   3   0   8   0   0   0   3   1   6   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  0   0   1   0   1   0 131   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  10   0   0   1   4   0  11   0]
 [  0   6   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   1   0   4   0   0   0   0   0   0   4   0   2   0]
 [  0   0   0   0   0   0   8   0   7   4   0   2   0   0   0   1   0   0   4   0   0   1   0   4   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  11   0   0   0   0   0   2   0   0   6   0   1   1   0   2   0   0   0   1   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  15   0   0   0  20   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   8   0   0   1   3   4   0   0 153   1   1   0   3   0   0  10   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   7   0   1   4   0   0   0   0   2   4   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   2   0   0   0   0   0   0   0   0   2   1  32   0   5   0   0   6   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   2   0   1   0   1   6   0   0   0   0   0   2   1   0 120   0   2   5   0   0   0   0   0   0   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  76  10   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   0   0   0   0   0   0   0   1   0   0   9   0   6   0   7   0   5 142   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  1   1   4   0  17   0  13   0   4   0   0   4   0   0   0   0   0   0   5   0   0   1   2  83   0   0   2   3   1   8   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   1   8   0   0   0   0   0   1   0   0   1   0   0   1   0   0   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   5   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  15   0   1   2   0   0   0   0   3   3   4   0   4   0   4   0   0   2   0   0   0  54   0   9   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   7   0   0   2   0   7   0   0   0   0   6   0   0]
 [  0   0   0   0   9   1   8   2   0   5   0   0   0   0   1   5   0   0   4   0   4   2   0   3   0   0   0   1   0 135   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   5   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:06:53,780 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:53,780 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:53,790 - 

2022-12-15 15:06:53,790 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:54,201 - Epoch: [131][   10/   74]    Overall Loss 0.333555    Objective Loss 0.333555                                        LR 0.000100    Time 0.041020    
2022-12-15 15:06:54,446 - Epoch: [131][   20/   74]    Overall Loss 0.343584    Objective Loss 0.343584                                        LR 0.000100    Time 0.032734    
2022-12-15 15:06:54,689 - Epoch: [131][   30/   74]    Overall Loss 0.350519    Objective Loss 0.350519                                        LR 0.000100    Time 0.029927    
2022-12-15 15:06:54,944 - Epoch: [131][   40/   74]    Overall Loss 0.358646    Objective Loss 0.358646                                        LR 0.000100    Time 0.028808    
2022-12-15 15:06:55,185 - Epoch: [131][   50/   74]    Overall Loss 0.360382    Objective Loss 0.360382                                        LR 0.000100    Time 0.027848    
2022-12-15 15:06:55,427 - Epoch: [131][   60/   74]    Overall Loss 0.361225    Objective Loss 0.361225                                        LR 0.000100    Time 0.027236    
2022-12-15 15:06:55,660 - Epoch: [131][   70/   74]    Overall Loss 0.362483    Objective Loss 0.362483                                        LR 0.000100    Time 0.026672    
2022-12-15 15:06:55,747 - Epoch: [131][   74/   74]    Overall Loss 0.360316    Objective Loss 0.360316    Top1 93.750000    Top5 99.537037    LR 0.000100    Time 0.026405    
2022-12-15 15:06:55,814 - --- validate (epoch=131)-----------
2022-12-15 15:06:55,815 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:56,087 - Epoch: [131][    9/    9]    Loss 1.275130    Top1 65.458015    Top5 90.648855    
2022-12-15 15:06:56,133 - ==> Top1: 65.458    Top5: 90.649    Loss: 1.275

2022-12-15 15:06:56,135 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  12   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  11   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 110   0   8   1   1   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   7   0 125   0   5   0   0   0   0   0   0   0   0   1   0   0   5   0   0   2   0   8   0   0   0   2   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   2   0   2   0 129   0   3   1   0   0   0   0   3   1   0   0   2   0   0   0   0  15   0   0   1   5   0   8   0]
 [  0   6   0   0   0   1   0   4   0   0   0   0   0   1   0   0   0   0   1   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   6   5   0   2   0   0   0   0   0   0   5   0   0   1   0   4   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   2   0  16   0   0   0   0   0   0   1   0   0   2   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   1   0  15   0   0   0   0   0   0   1   0   3   0]
 [  1   0   0   0   1   0   6   0   0   1   8   3   0   0 153   0   2   0   1   0   0   9   0   0   0   0   1   1   2   0   0]
 [  2   0   0   0   0   0   7   0   0   3   0   0   0   0   3   5   0   0   2   0   0   0   0   2   0   0   0   5   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  11   1   0   2   0   1   1   2   5   0   0   0   0   0   2   3   0 114   0   2   4   0   0   0   0   0   1   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   2   0   1   0   1   0  77   9   0   0   0   0   0   6   0   5   0]
 [  0   3   0   0   0   0   0   0   0   0   0   1   0   0  10   0   6   0   6   0   6 140   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   4   0  18   0  10   0   2   1   0   4   0   0   0   0   0   0   5   0   0   1   2  86   0   0   2   3   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   2   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  16   0   1   2   0   0   0   0   3   3   3   0   4   0   5   0   0   1   0   0   0  55   0   8   0]
 [  0   1   0   0   0   1   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   6   0   0]
 [  0   0   0   0   8   2   8   2   0   4   0   0   0   0   1   5   0   0   5   0   3   1   0   4   0   0   0   1   0 136   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:56,136 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:56,137 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:56,146 - 

2022-12-15 15:06:56,146 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:56,561 - Epoch: [132][   10/   74]    Overall Loss 0.345733    Objective Loss 0.345733                                        LR 0.000100    Time 0.041415    
2022-12-15 15:06:56,811 - Epoch: [132][   20/   74]    Overall Loss 0.354013    Objective Loss 0.354013                                        LR 0.000100    Time 0.033152    
2022-12-15 15:06:57,057 - Epoch: [132][   30/   74]    Overall Loss 0.357211    Objective Loss 0.357211                                        LR 0.000100    Time 0.030299    
2022-12-15 15:06:57,304 - Epoch: [132][   40/   74]    Overall Loss 0.355818    Objective Loss 0.355818                                        LR 0.000100    Time 0.028878    
2022-12-15 15:06:57,548 - Epoch: [132][   50/   74]    Overall Loss 0.354336    Objective Loss 0.354336                                        LR 0.000100    Time 0.027987    
2022-12-15 15:06:57,778 - Epoch: [132][   60/   74]    Overall Loss 0.355238    Objective Loss 0.355238                                        LR 0.000100    Time 0.027144    
2022-12-15 15:06:58,004 - Epoch: [132][   70/   74]    Overall Loss 0.354032    Objective Loss 0.354032                                        LR 0.000100    Time 0.026487    
2022-12-15 15:06:58,087 - Epoch: [132][   74/   74]    Overall Loss 0.358117    Objective Loss 0.358117    Top1 92.361111    Top5 98.842593    LR 0.000100    Time 0.026177    
2022-12-15 15:06:58,144 - --- validate (epoch=132)-----------
2022-12-15 15:06:58,144 - 2096 samples (256 per mini-batch)
2022-12-15 15:06:58,412 - Epoch: [132][    9/    9]    Loss 1.247157    Top1 65.171756    Top5 90.696565    
2022-12-15 15:06:58,459 - ==> Top1: 65.172    Top5: 90.697    Loss: 1.247

2022-12-15 15:06:58,461 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   1   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   1   1   0   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   7   0 126   0   4   0   0   0   0   0   0   0   0   2   0   0   4   0   0   3   0   8   0   0   0   1   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  1   0   1   0   1   0 129   0   3   3   0   0   0   0   3   1   0   0   3   0   0   0   1  11   0   0   1   5   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   8   0   6   4   0   2   0   0   0   1   0   0   5   0   0   1   0   4   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  12   0   0   0   0   0   2   0   0   5   0   1   1   0   2   0   0   0   2   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  11   0   0   0  24   0   0   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   1   0   0   0   0   0  11   0   1   0   0   1   0  14   0   0   0   0   0   0   1   0   3   0]
 [  2   0   0   0   1   0   7   0   0   1   4   4   0   0 153   0   2   0   2   0   0  10   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   5   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   9   1   0   2   0   1   2   2   5   0   0   0   0   0   2   2   0 116   0   2   4   0   0   0   0   0   0   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   3   0   0   0   0   0   1   0   0   1   0   1   0  75   9   0   0   0   0   0   8   0   6   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0   9   0   7   0   7   0   6 140   0   0   0   0   1   0   0   3   0]
 [  0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  11   3   0   0   1   0   0   0   0]
 [  0   1   4   0  19   0  11   0   3   1   0   4   0   0   0   0   0   0   6   0   0   1   2  82   0   0   2   6   1   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   4   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  10   1   1   2   0   0   0   0   3   3   3   0   4   0   4   0   0   2   0   0   0  58   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   7   0   0   2   0   7   0   0   0   0   6   0   0]
 [  0   0   0   0   9   1   9   2   0   4   0   0   0   0   1   5   0   0   4   0   3   2   0   3   0   0   0   3   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   3   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:06:58,463 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:06:58,463 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:06:58,472 - 

2022-12-15 15:06:58,473 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:06:58,867 - Epoch: [133][   10/   74]    Overall Loss 0.360904    Objective Loss 0.360904                                        LR 0.000100    Time 0.039391    
2022-12-15 15:06:59,088 - Epoch: [133][   20/   74]    Overall Loss 0.366250    Objective Loss 0.366250                                        LR 0.000100    Time 0.030714    
2022-12-15 15:06:59,309 - Epoch: [133][   30/   74]    Overall Loss 0.351205    Objective Loss 0.351205                                        LR 0.000100    Time 0.027820    
2022-12-15 15:06:59,535 - Epoch: [133][   40/   74]    Overall Loss 0.355392    Objective Loss 0.355392                                        LR 0.000100    Time 0.026508    
2022-12-15 15:06:59,753 - Epoch: [133][   50/   74]    Overall Loss 0.356095    Objective Loss 0.356095                                        LR 0.000100    Time 0.025550    
2022-12-15 15:06:59,974 - Epoch: [133][   60/   74]    Overall Loss 0.353333    Objective Loss 0.353333                                        LR 0.000100    Time 0.024969    
2022-12-15 15:07:00,188 - Epoch: [133][   70/   74]    Overall Loss 0.356305    Objective Loss 0.356305                                        LR 0.000100    Time 0.024463    
2022-12-15 15:07:00,268 - Epoch: [133][   74/   74]    Overall Loss 0.357096    Objective Loss 0.357096    Top1 92.361111    Top5 99.074074    LR 0.000100    Time 0.024222    
2022-12-15 15:07:00,336 - --- validate (epoch=133)-----------
2022-12-15 15:07:00,336 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:00,605 - Epoch: [133][    9/    9]    Loss 1.254476    Top1 64.933206    Top5 91.078244    
2022-12-15 15:07:00,672 - ==> Top1: 64.933    Top5: 91.078    Loss: 1.254

2022-12-15 15:07:00,674 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   1   0   5   2   0   1   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 113   0   6   0   0   0   0   0   0   0   0   0   1   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 118   1   5   0   0   0   0   0   0   0   0   1   0   0   5   0   0   3   0   9   0   0   0   4   2   7   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  1   0   1   0   0   0 134   0   3   1   0   1   0   0   4   1   0   0   3   0   0   0   1  10   0   0   1   4   0   7   0]
 [  0   6   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   1   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   8   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   4   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  10   0   0   0   0   1   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   6   0   0   1   8   4   0   0 149   1   1   0   1   0   0  11   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   4   0   0   2   0   0   0   0   2   0   0   0   5   0   2   0]
 [  2   0   0   0   0   2   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   6   1   0   2   0   1   1   2   6   0   0   0   0   0   2   2   0 117   0   2   5   0   0   0   0   0   1   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75  11   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0  10   0   6   0   9   0   6 137   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  1   1   5   0  16   0  11   0   3   1   0   4   0   0   0   0   0   0   5   0   0   1   2  86   0   0   2   4   1   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   1   6   0   0  54   0   1   0   0]
 [  0   1   2   0   2   3  14   0   1   2   0   0   0   0   3   3   4   0   4   0   3   0   0   1   0   0   0  55   0  10   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   8   2   8   2   0   5   0   0   0   0   1   5   0   0   4   0   2   1   0   6   0   0   0   5   0 131   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:00,676 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:00,676 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:00,686 - 

2022-12-15 15:07:00,686 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:01,090 - Epoch: [134][   10/   74]    Overall Loss 0.350155    Objective Loss 0.350155                                        LR 0.000100    Time 0.040297    
2022-12-15 15:07:01,316 - Epoch: [134][   20/   74]    Overall Loss 0.356673    Objective Loss 0.356673                                        LR 0.000100    Time 0.031466    
2022-12-15 15:07:01,544 - Epoch: [134][   30/   74]    Overall Loss 0.356270    Objective Loss 0.356270                                        LR 0.000100    Time 0.028549    
2022-12-15 15:07:01,780 - Epoch: [134][   40/   74]    Overall Loss 0.350473    Objective Loss 0.350473                                        LR 0.000100    Time 0.027315    
2022-12-15 15:07:01,998 - Epoch: [134][   50/   74]    Overall Loss 0.354076    Objective Loss 0.354076                                        LR 0.000100    Time 0.026194    
2022-12-15 15:07:02,238 - Epoch: [134][   60/   74]    Overall Loss 0.352665    Objective Loss 0.352665                                        LR 0.000100    Time 0.025820    
2022-12-15 15:07:02,460 - Epoch: [134][   70/   74]    Overall Loss 0.353194    Objective Loss 0.353194                                        LR 0.000100    Time 0.025297    
2022-12-15 15:07:02,545 - Epoch: [134][   74/   74]    Overall Loss 0.355304    Objective Loss 0.355304    Top1 91.898148    Top5 98.842593    LR 0.000100    Time 0.025074    
2022-12-15 15:07:02,611 - --- validate (epoch=134)-----------
2022-12-15 15:07:02,611 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:02,883 - Epoch: [134][    9/    9]    Loss 1.307462    Top1 65.171756    Top5 90.696565    
2022-12-15 15:07:02,939 - ==> Top1: 65.172    Top5: 90.697    Loss: 1.307

2022-12-15 15:07:02,941 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   3   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   1   0   0   0   0   0   0   1   0   0]
 [  0   0 115   0   5   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   1   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   7   0 124   2   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0  10   0   0   0   1   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  1   0   1   0   1   0 127   0   5   1   0   1   0   0   3   1   0   0   3   0   0   0   1  14   0   0   1   5   0   7   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   9   4   0   2   0   0   0   1   0   0   4   0   0   1   0   4   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   2  10   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   2   0  17   0   0   0   0   0   0   0   0   0   2   1   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  10   0   1   0   0   0   0  16   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   1   7   0   0   1   4   4   0   0 155   0   0   0   1   0   0  10   0   0   0   0   1   1   2   0   0]
 [  4   0   0   0   0   0   7   0   0   4   0   0   0   0   2   4   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   2   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  4  12   1   0   2   1   1   1   3   4   0   0   0   0   0   2   1   0 110   0   2   5   0   0   0   0   0   3   3   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  73  10   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   0   0   0   0   0   0   0   2   0   0   9   0   6   0   7   0   5 140   0   0   0   0   1   0   1   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   5   0  18   0   8   0   1   1   0   4   0   0   0   0   0   0   5   0   0   1   2  85   0   0   2   6   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   2   0   0   1   0   1   0   0   0   0   0   1   4   0   0  56   0   1   0   0]
 [  0   1   2   0   2   3  15   0   1   2   0   0   0   0   3   4   4   0   4   0   2   0   0   2   0   0   0  55   0   8   0]
 [  0   1   0   0   0   0   0   0   0   0   0   1   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0  10   2   8   2   0   5   0   0   0   0   1   5   0   0   4   0   2   1   0   6   0   0   0   3   0 131   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:02,944 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:02,944 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:02,964 - 

2022-12-15 15:07:02,965 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:03,365 - Epoch: [135][   10/   74]    Overall Loss 0.378777    Objective Loss 0.378777                                        LR 0.000100    Time 0.039992    
2022-12-15 15:07:03,617 - Epoch: [135][   20/   74]    Overall Loss 0.361467    Objective Loss 0.361467                                        LR 0.000100    Time 0.032463    
2022-12-15 15:07:03,847 - Epoch: [135][   30/   74]    Overall Loss 0.358000    Objective Loss 0.358000                                        LR 0.000100    Time 0.029300    
2022-12-15 15:07:04,099 - Epoch: [135][   40/   74]    Overall Loss 0.353994    Objective Loss 0.353994                                        LR 0.000100    Time 0.028260    
2022-12-15 15:07:04,355 - Epoch: [135][   50/   74]    Overall Loss 0.352052    Objective Loss 0.352052                                        LR 0.000100    Time 0.027720    
2022-12-15 15:07:04,604 - Epoch: [135][   60/   74]    Overall Loss 0.352643    Objective Loss 0.352643                                        LR 0.000100    Time 0.027250    
2022-12-15 15:07:04,855 - Epoch: [135][   70/   74]    Overall Loss 0.352489    Objective Loss 0.352489                                        LR 0.000100    Time 0.026925    
2022-12-15 15:07:04,944 - Epoch: [135][   74/   74]    Overall Loss 0.353471    Objective Loss 0.353471    Top1 92.361111    Top5 98.842593    LR 0.000100    Time 0.026675    
2022-12-15 15:07:05,004 - --- validate (epoch=135)-----------
2022-12-15 15:07:05,005 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:05,275 - Epoch: [135][    9/    9]    Loss 1.300978    Top1 64.933206    Top5 91.030534    
2022-12-15 15:07:05,329 - ==> Top1: 64.933    Top5: 91.031    Loss: 1.301

2022-12-15 15:07:05,331 - ==> Confusion:
[[ 18   0   0   0   0   0   4   0   1   0   0   2   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   4   2   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   2   0   0   0   0   0   0   1   1   0]
 [  0   0 113   0   5   0   0   0   0   0   0   0   0   0   1   0   0   0   3   0   1   1   0   9   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 119   1   5   0   0   1   0   0   0   0   0   1   0   0   5   0   0   3   0  10   0   0   0   2   2   7   0]
 [  0   2   1   0   1  39   0   0   0   0   0   0   0   0   0   0   1   0   3   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   1   0   0   0 126   0   5   4   0   1   0   0   3   1   0   0   1   0   0   0   1  14   0   0   1   5   0   9   0]
 [  0   6   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   1   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   9   5   0   1   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   5   0   1  11   0   0   0   0   0   1   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  17   0   0   0  18   0   0   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   2   0  16   0   0   0   0   0   0   1   0   0   2   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   2   0   0   0   0   0  11   0   1   0   0   0   0  14   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   0   0   8   0   0   1   7   5   0   0 145   2   3   0   2   0   0  11   0   0   0   0   1   2   1   0   0]
 [  2   0   0   0   0   0   7   0   0   5   0   0   0   0   2   5   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   2   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   1   1   1   1   3   8   0   0   0   0   0   1   2   0 116   0   1   4   0   0   0   0   0   1   3   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   4   0   0   1   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  76   9   0   0   0   0   0   7   0   5   0]
 [  0   2   0   0   1   0   0   0   0   0   0   2   0   0   9   0   6   0   8   0   5 140   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  1   2   3   0  16   0  12   0   3   1   0   3   0   0   0   0   0   0   5   0   0   1   2  86   0   0   2   3   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   1   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   3   0   0   0   0   3   4   4   0   4   0   5   0   0   1   0   0   0  53   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   7   1   8   2   1   7   0   0   0   0   0   5   0   0   5   0   3   1   0   5   0   0   0   2   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   5   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:07:05,333 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:05,333 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:05,343 - 

2022-12-15 15:07:05,343 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:05,761 - Epoch: [136][   10/   74]    Overall Loss 0.357920    Objective Loss 0.357920                                        LR 0.000100    Time 0.041655    
2022-12-15 15:07:06,024 - Epoch: [136][   20/   74]    Overall Loss 0.354508    Objective Loss 0.354508                                        LR 0.000100    Time 0.033945    
2022-12-15 15:07:06,296 - Epoch: [136][   30/   74]    Overall Loss 0.347418    Objective Loss 0.347418                                        LR 0.000100    Time 0.031690    
2022-12-15 15:07:06,561 - Epoch: [136][   40/   74]    Overall Loss 0.353300    Objective Loss 0.353300                                        LR 0.000100    Time 0.030393    
2022-12-15 15:07:06,800 - Epoch: [136][   50/   74]    Overall Loss 0.350375    Objective Loss 0.350375                                        LR 0.000100    Time 0.029089    
2022-12-15 15:07:07,044 - Epoch: [136][   60/   74]    Overall Loss 0.353007    Objective Loss 0.353007                                        LR 0.000100    Time 0.028295    
2022-12-15 15:07:07,289 - Epoch: [136][   70/   74]    Overall Loss 0.351288    Objective Loss 0.351288                                        LR 0.000100    Time 0.027747    
2022-12-15 15:07:07,377 - Epoch: [136][   74/   74]    Overall Loss 0.350236    Objective Loss 0.350236    Top1 93.518519    Top5 99.305556    LR 0.000100    Time 0.027430    
2022-12-15 15:07:07,436 - --- validate (epoch=136)-----------
2022-12-15 15:07:07,436 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:07,711 - Epoch: [136][    9/    9]    Loss 1.295088    Top1 65.171756    Top5 90.982824    
2022-12-15 15:07:07,772 - ==> Top1: 65.172    Top5: 90.983    Loss: 1.295

2022-12-15 15:07:07,774 - ==> Confusion:
[[ 17   0   1   0   0   0   3   0   1   0   0   2   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   2   0   0   0   0   0   0   1   1   0]
 [  0   0 114   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   8   0 124   0   3   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   7   0   0   0   4   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   1   0   1   0 130   0   3   1   0   0   0   0   4   1   0   0   2   0   0   0   1  11   0   0   1   5   0  11   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   8   4   0   2   0   0   0   1   0   0   4   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  15   0   0   0  20   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  15   0   0   0   0   0   0   2   0   4   0]
 [  1   0   0   0   1   0   7   0   0   1   7   4   0   0 150   0   1   0   2   0   0  11   0   0   0   0   1   2   1   0   0]
 [  2   0   0   0   0   0   7   0   0   4   0   0   0   0   3   7   0   0   2   0   0   0   0   1   0   0   0   3   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  4  12   1   0   2   1   1   0   1   4   0   0   0   0   0   2   4   0 113   0   1   6   0   0   0   0   0   1   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   1   0   2   0   0   0   0   0   1   0   0   1   0   1   0  76   9   0   0   0   0   0   8   0   5   0]
 [  0   3   0   0   0   0   0   0   0   0   0   1   0   0   9   0   6   0   7   0   6 140   0   0   0   0   1   0   1   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   5   0  18   0  13   0   3   1   0   4   0   0   0   0   0   0   5   0   0   1   2  80   0   0   2   4   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   1   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   3   0   0  55   0   1   0   0]
 [  0   0   2   0   3   3  11   1   1   2   0   0   0   0   3   3   4   0   4   0   4   0   0   2   0   0   0  55   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   1   0   0   2   0   1   0   7   0   0   2   0   7   0   0   0   0   5   0   0]
 [  0   0   0   0   8   2   9   2   0   5   0   0   0   0   1   5   0   0   4   0   3   1   0   4   0   0   0   2   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:07,776 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:07,776 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:07,793 - 

2022-12-15 15:07:07,794 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:08,327 - Epoch: [137][   10/   74]    Overall Loss 0.362968    Objective Loss 0.362968                                        LR 0.000100    Time 0.053267    
2022-12-15 15:07:08,558 - Epoch: [137][   20/   74]    Overall Loss 0.341192    Objective Loss 0.341192                                        LR 0.000100    Time 0.038170    
2022-12-15 15:07:08,821 - Epoch: [137][   30/   74]    Overall Loss 0.341052    Objective Loss 0.341052                                        LR 0.000100    Time 0.034189    
2022-12-15 15:07:09,073 - Epoch: [137][   40/   74]    Overall Loss 0.343097    Objective Loss 0.343097                                        LR 0.000100    Time 0.031925    
2022-12-15 15:07:09,315 - Epoch: [137][   50/   74]    Overall Loss 0.344424    Objective Loss 0.344424                                        LR 0.000100    Time 0.030366    
2022-12-15 15:07:09,547 - Epoch: [137][   60/   74]    Overall Loss 0.346796    Objective Loss 0.346796                                        LR 0.000100    Time 0.029169    
2022-12-15 15:07:09,773 - Epoch: [137][   70/   74]    Overall Loss 0.348768    Objective Loss 0.348768                                        LR 0.000100    Time 0.028230    
2022-12-15 15:07:09,862 - Epoch: [137][   74/   74]    Overall Loss 0.349369    Objective Loss 0.349369    Top1 93.055556    Top5 99.074074    LR 0.000100    Time 0.027908    
2022-12-15 15:07:09,930 - --- validate (epoch=137)-----------
2022-12-15 15:07:09,930 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:10,204 - Epoch: [137][    9/    9]    Loss 1.263873    Top1 65.458015    Top5 90.648855    
2022-12-15 15:07:10,259 - ==> Top1: 65.458    Top5: 90.649    Loss: 1.264

2022-12-15 15:07:10,261 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   2   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   2   0   0   0   0   0   0   1   0   0]
 [  0   0 115   0   4   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   9   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   9   0 121   0   3   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   7   0   0   0   5   1   6   0]
 [  0   2   1   0   0  37   0   0   0   0   0   0   0   0   0   0   2   0   4   0   1   4   0   0   0   0   1   1   2   0   0]
 [  1   0   0   0   1   0 131   0   4   0   0   1   0   0   4   1   0   0   2   0   0   0   1   9   0   0   1   6   0  10   0]
 [  0   6   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   1   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   7   4   0   2   0   0   0   1   0   0   5   0   0   1   0   4   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   2   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  15   0   0   0  20   0   0   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   6   0   0   1   7   4   0   0 151   1   1   0   2   0   0  11   0   0   0   0   1   1   1   0   0]
 [  2   0   0   0   0   0   6   0   0   4   0   0   0   0   3   6   0   0   2   0   0   0   0   1   0   0   0   5   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   3   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   7   1   0   2   1   1   1   2   6   0   0   0   0   0   2   2   0 117   0   2   5   0   0   0   0   0   0   3   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75  10   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   0   0   0   0   0   0   0   2   0   0  10   0   6   0   6   0   5 140   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   4   0  18   0  11   0   3   1   0   4   0   0   0   0   0   0   5   0   0   1   2  81   0   0   2   5   2   8   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   0   0   0   1   0   0   1   0   1   0   0   0   2   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   4   0   0  55   0   1   0   0]
 [  0   1   2   0   2   3  12   0   1   2   0   0   0   0   3   3   4   0   4   0   3   1   0   2   0   0   0  55   0  10   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   7   1   9   2   0   5   0   0   0   0   1   4   0   0   5   0   3   1   0   5   0   0   0   2   0 135   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:10,262 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:10,262 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:10,272 - 

2022-12-15 15:07:10,273 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:10,674 - Epoch: [138][   10/   74]    Overall Loss 0.351595    Objective Loss 0.351595                                        LR 0.000100    Time 0.040078    
2022-12-15 15:07:10,909 - Epoch: [138][   20/   74]    Overall Loss 0.344129    Objective Loss 0.344129                                        LR 0.000100    Time 0.031756    
2022-12-15 15:07:11,162 - Epoch: [138][   30/   74]    Overall Loss 0.340991    Objective Loss 0.340991                                        LR 0.000100    Time 0.029594    
2022-12-15 15:07:11,449 - Epoch: [138][   40/   74]    Overall Loss 0.344226    Objective Loss 0.344226                                        LR 0.000100    Time 0.029367    
2022-12-15 15:07:11,739 - Epoch: [138][   50/   74]    Overall Loss 0.346351    Objective Loss 0.346351                                        LR 0.000100    Time 0.029279    
2022-12-15 15:07:12,032 - Epoch: [138][   60/   74]    Overall Loss 0.344657    Objective Loss 0.344657                                        LR 0.000100    Time 0.029265    
2022-12-15 15:07:12,299 - Epoch: [138][   70/   74]    Overall Loss 0.345975    Objective Loss 0.345975                                        LR 0.000100    Time 0.028880    
2022-12-15 15:07:12,388 - Epoch: [138][   74/   74]    Overall Loss 0.346524    Objective Loss 0.346524    Top1 90.740741    Top5 99.074074    LR 0.000100    Time 0.028515    
2022-12-15 15:07:12,453 - --- validate (epoch=138)-----------
2022-12-15 15:07:12,454 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:12,730 - Epoch: [138][    9/    9]    Loss 1.245201    Top1 65.028626    Top5 90.458015    
2022-12-15 15:07:12,783 - ==> Top1: 65.029    Top5: 90.458    Loss: 1.245

2022-12-15 15:07:12,785 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   1   0   6   3   0   1   0   3   0   0   0   0   0   0   0   0   9   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 112   0   8   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   1   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 128   3   2   0   0   0   0   0   0   0   0   1   0   0   3   0   0   2   0   7   0   0   0   4   1   5   0]
 [  0   1   0   0   1  40   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   5   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   2   0 129   0   4   0   0   0   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   6   0  10   0]
 [  0   6   0   0   0   1   0   6   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   7   4   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   1   1   1   0]
 [  1   0   0   0   0   0   5   0   1  11   0   0   0   0   0   1   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  10   0   1   0   0   0   0  16   0   0   0   0   0   0   1   0   4   0]
 [  1   0   1   0   1   1   7   0   0   1   5   4   0   0 152   1   0   0   1   0   0  10   0   0   0   0   1   1   2   0   0]
 [  2   0   0   0   0   0   7   0   0   4   0   0   0   0   3   5   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  1   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  32   0   6   0   1   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   3   0   0   0   0   0   1   1   0   0]
 [  3  15   1   0   3   0   1   3   3   5   0   0   0   0   0   1   2   0 103   0   2   5   0   0   0   0   0   4   2   5   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   1   0   2   0   0   0   0   0   1   1   0   0   0   1   0  76  10   0   0   0   0   0   7   0   6   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0   9   0   6   0   6   0   6 140   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  12   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  86   0   0   2   3   1   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   7   0   0   0   0   0   0   0   0   1   0   0   1   0   1   0   0   0   2   0   1   0]
 [  0   0   3   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   5   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   3   3   0   3   0   6   0   0   2   0   0   0  56   0   9   0]
 [  1   2   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   4   0   0   2   0   7   0   0   0   1   7   0   0]
 [  1   0   0   0  10   3   9   1   0   3   0   0   0   0   1   4   0   0   3   0   2   2   0   4   0   0   0   3   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:07:12,787 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:12,787 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:12,807 - 

2022-12-15 15:07:12,807 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:13,198 - Epoch: [139][   10/   74]    Overall Loss 0.320126    Objective Loss 0.320126                                        LR 0.000100    Time 0.038969    
2022-12-15 15:07:13,427 - Epoch: [139][   20/   74]    Overall Loss 0.323867    Objective Loss 0.323867                                        LR 0.000100    Time 0.030934    
2022-12-15 15:07:13,647 - Epoch: [139][   30/   74]    Overall Loss 0.333564    Objective Loss 0.333564                                        LR 0.000100    Time 0.027934    
2022-12-15 15:07:13,895 - Epoch: [139][   40/   74]    Overall Loss 0.335653    Objective Loss 0.335653                                        LR 0.000100    Time 0.027141    
2022-12-15 15:07:14,143 - Epoch: [139][   50/   74]    Overall Loss 0.338027    Objective Loss 0.338027                                        LR 0.000100    Time 0.026662    
2022-12-15 15:07:14,387 - Epoch: [139][   60/   74]    Overall Loss 0.339533    Objective Loss 0.339533                                        LR 0.000100    Time 0.026270    
2022-12-15 15:07:14,626 - Epoch: [139][   70/   74]    Overall Loss 0.343386    Objective Loss 0.343386                                        LR 0.000100    Time 0.025936    
2022-12-15 15:07:14,714 - Epoch: [139][   74/   74]    Overall Loss 0.344184    Objective Loss 0.344184    Top1 93.055556    Top5 98.611111    LR 0.000100    Time 0.025713    
2022-12-15 15:07:14,774 - --- validate (epoch=139)-----------
2022-12-15 15:07:14,774 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:15,042 - Epoch: [139][    9/    9]    Loss 1.306539    Top1 64.742366    Top5 90.410305    
2022-12-15 15:07:15,108 - ==> Top1: 64.742    Top5: 90.410    Loss: 1.307

2022-12-15 15:07:15,110 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   1   0   5   3   0   1   0   3   0   0   0   0   0   0   0   0  11   0   1   1   0   0   0   0   0   1   1   0   0]
 [  0   0 113   0   7   1   1   0   0   0   0   0   0   0   0   0   0   0   2   0   1   1   0   7   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 121   2   4   0   0   0   0   0   0   0   0   2   0   0   4   0   0   3   0   8   0   0   0   7   0   5   0]
 [  0   1   1   0   1  40   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   1   0 133   0   3   1   0   1   0   0   3   1   0   0   2   0   0   0   1  10   0   0   1   7   0   8   0]
 [  0   6   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   4   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   5   6   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   6   0   1  10   0   0   0   0   0   2   0   0   5   0   1   1   0   2   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  16   0   0   0  19   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  12   0   1   0   0   0   0  14   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   9   0   0   1   7   4   0   0 148   0   3   0   1   0   0  10   0   0   0   0   1   1   2   0   0]
 [  1   0   0   0   0   0   6   0   0   3   0   0   0   0   3   6   0   0   2   0   0   0   0   2   0   0   0   6   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  32   0   5   0   1   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   3   0   0   0   0   0   1   1   0   0]
 [  3  11   1   0   2   0   1   2   3   6   0   0   0   0   0   2   3   0 108   0   1   5   0   0   0   0   0   4   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   1   0   0   2   0   0   0   0   0   1   0   0   1   0   1   0  76  10   0   0   0   0   0   8   0   8   0]
 [  0   1   0   0   0   0   0   0   0   0   0   2   0   0  11   0   8   0   5   0   6 138   0   0   0   0   1   0   2   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  1   1   5   0  16   0  15   0   2   1   0   4   0   0   0   0   0   0   5   0   0   1   2  81   0   0   2   4   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   0   0   0   1   0   0   1   0   1   0   0   0   2   0   0   0]
 [  0   0   1   0   0   0   1   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   1   5   0   0  54   0   1   0   0]
 [  0   1   2   0   2   3  14   0   1   2   0   0   0   0   3   3   3   0   3   0   5   0   0   0   0   0   0  57   0   9   0]
 [  0   0   0   0   0   1   0   0   0   0   0   1   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   1   6   0   0]
 [  0   0   0   0   7   2  10   2   0   5   0   0   0   0   1   5   0   0   2   0   3   2   0   5   0   0   0   3   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:15,112 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:15,112 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:15,122 - 

2022-12-15 15:07:15,123 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:15,567 - Epoch: [140][   10/   74]    Overall Loss 0.339994    Objective Loss 0.339994                                        LR 0.000010    Time 0.044378    
2022-12-15 15:07:15,826 - Epoch: [140][   20/   74]    Overall Loss 0.347461    Objective Loss 0.347461                                        LR 0.000010    Time 0.035091    
2022-12-15 15:07:16,072 - Epoch: [140][   30/   74]    Overall Loss 0.341301    Objective Loss 0.341301                                        LR 0.000010    Time 0.031597    
2022-12-15 15:07:16,339 - Epoch: [140][   40/   74]    Overall Loss 0.336062    Objective Loss 0.336062                                        LR 0.000010    Time 0.030351    
2022-12-15 15:07:16,587 - Epoch: [140][   50/   74]    Overall Loss 0.337149    Objective Loss 0.337149                                        LR 0.000010    Time 0.029239    
2022-12-15 15:07:16,853 - Epoch: [140][   60/   74]    Overall Loss 0.336403    Objective Loss 0.336403                                        LR 0.000010    Time 0.028796    
2022-12-15 15:07:17,100 - Epoch: [140][   70/   74]    Overall Loss 0.336582    Objective Loss 0.336582                                        LR 0.000010    Time 0.028210    
2022-12-15 15:07:17,190 - Epoch: [140][   74/   74]    Overall Loss 0.335338    Objective Loss 0.335338    Top1 94.212963    Top5 98.379630    LR 0.000010    Time 0.027898    
2022-12-15 15:07:17,260 - --- validate (epoch=140)-----------
2022-12-15 15:07:17,260 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:17,549 - Epoch: [140][    9/    9]    Loss 1.292330    Top1 65.028626    Top5 90.887405    
2022-12-15 15:07:17,605 - ==> Top1: 65.029    Top5: 90.887    Loss: 1.292

2022-12-15 15:07:17,607 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   1   0   4   2   0   2   0   2   0   0   0   0   0   0   0   0  14   0   1   1   0   0   0   0   0   0   1   0   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   7   0 123   1   4   0   0   0   0   0   0   0   0   2   0   0   4   0   0   3   0   7   0   0   0   4   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  1   0   1   0   1   0 130   0   3   1   0   1   0   0   4   1   0   0   3   0   0   0   1   9   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   6   5   0   2   0   0   0   0   0   0   5   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  10   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   7   0   0   1   4   4   0   0 153   0   2   0   2   0   0  10   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   2   1   1   1   2   5   0   0   0   0   0   2   2   0 115   0   1   5   0   0   0   0   0   2   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   0   0   1   0   1   0  75   9   0   0   0   0   0   8   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0   9   0   6   0   7   0   5 140   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  1   1   4   0  18   0  13   0   2   1   0   4   0   0   0   0   0   0   5   0   0   1   2  81   0   0   2   4   3   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  12   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  54   0  10   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   8   2   9   2   0   4   0   0   0   0   1   5   0   0   5   0   3   1   0   5   0   0   0   1   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:07:17,608 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:17,609 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:17,629 - 

2022-12-15 15:07:17,629 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:18,049 - Epoch: [141][   10/   74]    Overall Loss 0.347892    Objective Loss 0.347892                                        LR 0.000010    Time 0.041928    
2022-12-15 15:07:18,298 - Epoch: [141][   20/   74]    Overall Loss 0.336975    Objective Loss 0.336975                                        LR 0.000010    Time 0.033396    
2022-12-15 15:07:18,551 - Epoch: [141][   30/   74]    Overall Loss 0.335130    Objective Loss 0.335130                                        LR 0.000010    Time 0.030676    
2022-12-15 15:07:18,800 - Epoch: [141][   40/   74]    Overall Loss 0.336856    Objective Loss 0.336856                                        LR 0.000010    Time 0.029214    
2022-12-15 15:07:19,045 - Epoch: [141][   50/   74]    Overall Loss 0.332306    Objective Loss 0.332306                                        LR 0.000010    Time 0.028278    
2022-12-15 15:07:19,301 - Epoch: [141][   60/   74]    Overall Loss 0.334332    Objective Loss 0.334332                                        LR 0.000010    Time 0.027824    
2022-12-15 15:07:19,544 - Epoch: [141][   70/   74]    Overall Loss 0.332084    Objective Loss 0.332084                                        LR 0.000010    Time 0.027306    
2022-12-15 15:07:19,632 - Epoch: [141][   74/   74]    Overall Loss 0.333099    Objective Loss 0.333099    Top1 92.129630    Top5 99.537037    LR 0.000010    Time 0.027024    
2022-12-15 15:07:19,690 - --- validate (epoch=141)-----------
2022-12-15 15:07:19,691 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:19,973 - Epoch: [141][    9/    9]    Loss 1.276490    Top1 65.171756    Top5 90.696565    
2022-12-15 15:07:20,026 - ==> Top1: 65.172    Top5: 90.697    Loss: 1.276

2022-12-15 15:07:20,028 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 114   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   1   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   7   0 124   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   8   0   0   0   3   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   0   0 129   0   4   0   0   1   0   0   4   1   0   0   3   0   0   0   1  14   0   0   1   5   0   8   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   7   4   0   2   0   0   0   1   0   0   4   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  10   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  12   0   0   0  23   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   3   4   0   0 152   0   3   0   2   0   0  11   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   0   1   2   2   5   0   0   0   0   0   2   2   0 115   0   1   5   0   0   0   0   0   1   3   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   6   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0   9   0   7   0   6   0   6 139   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   4   0  18   0  11   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  85   0   0   2   4   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   8   0   9   2   0   4   0   0   0   0   1   5   0   0   6   0   3   1   0   6   0   0   0   1   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:20,029 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:20,029 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:20,039 - 

2022-12-15 15:07:20,039 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:20,433 - Epoch: [142][   10/   74]    Overall Loss 0.339945    Objective Loss 0.339945                                        LR 0.000010    Time 0.039309    
2022-12-15 15:07:20,659 - Epoch: [142][   20/   74]    Overall Loss 0.325960    Objective Loss 0.325960                                        LR 0.000010    Time 0.030899    
2022-12-15 15:07:20,902 - Epoch: [142][   30/   74]    Overall Loss 0.336429    Objective Loss 0.336429                                        LR 0.000010    Time 0.028692    
2022-12-15 15:07:21,148 - Epoch: [142][   40/   74]    Overall Loss 0.335216    Objective Loss 0.335216                                        LR 0.000010    Time 0.027626    
2022-12-15 15:07:21,400 - Epoch: [142][   50/   74]    Overall Loss 0.332133    Objective Loss 0.332133                                        LR 0.000010    Time 0.027116    
2022-12-15 15:07:21,651 - Epoch: [142][   60/   74]    Overall Loss 0.331833    Objective Loss 0.331833                                        LR 0.000010    Time 0.026779    
2022-12-15 15:07:21,873 - Epoch: [142][   70/   74]    Overall Loss 0.331238    Objective Loss 0.331238                                        LR 0.000010    Time 0.026127    
2022-12-15 15:07:21,955 - Epoch: [142][   74/   74]    Overall Loss 0.331809    Objective Loss 0.331809    Top1 91.666667    Top5 99.537037    LR 0.000010    Time 0.025819    
2022-12-15 15:07:22,025 - --- validate (epoch=142)-----------
2022-12-15 15:07:22,026 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:22,295 - Epoch: [142][    9/    9]    Loss 1.245990    Top1 64.790076    Top5 90.601145    
2022-12-15 15:07:22,344 - ==> Top1: 64.790    Top5: 90.601    Loss: 1.246

2022-12-15 15:07:22,346 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 111   0   8   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   6   0 126   1   3   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   7   0   0   0   4   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  0   0   2   0   1   0 128   0   4   0   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   1   0   0   0   4   0   1  10   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   2   4   0   0 152   1   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  2   0   0   0   0   0   6   0   0   4   0   0   0   0   3   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  12   1   0   2   0   1   1   2   5   0   0   0   0   0   2   2   0 112   0   1   5   0   0   0   0   0   2   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0  10   0   6   0   6   0   6 140   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  11   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  84   0   0   2   5   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   5   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   8   3  10   2   0   4   0   0   0   0   1   5   0   0   5   0   2   1   0   5   0   0   0   3   0 131   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:22,347 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:22,347 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:22,357 - 

2022-12-15 15:07:22,358 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:22,746 - Epoch: [143][   10/   74]    Overall Loss 0.328332    Objective Loss 0.328332                                        LR 0.000010    Time 0.038743    
2022-12-15 15:07:22,958 - Epoch: [143][   20/   74]    Overall Loss 0.330245    Objective Loss 0.330245                                        LR 0.000010    Time 0.029953    
2022-12-15 15:07:23,172 - Epoch: [143][   30/   74]    Overall Loss 0.331629    Objective Loss 0.331629                                        LR 0.000010    Time 0.027105    
2022-12-15 15:07:23,410 - Epoch: [143][   40/   74]    Overall Loss 0.326704    Objective Loss 0.326704                                        LR 0.000010    Time 0.026264    
2022-12-15 15:07:23,673 - Epoch: [143][   50/   74]    Overall Loss 0.328150    Objective Loss 0.328150                                        LR 0.000010    Time 0.026249    
2022-12-15 15:07:23,926 - Epoch: [143][   60/   74]    Overall Loss 0.331563    Objective Loss 0.331563                                        LR 0.000010    Time 0.026089    
2022-12-15 15:07:24,162 - Epoch: [143][   70/   74]    Overall Loss 0.332259    Objective Loss 0.332259                                        LR 0.000010    Time 0.025728    
2022-12-15 15:07:24,251 - Epoch: [143][   74/   74]    Overall Loss 0.332089    Objective Loss 0.332089    Top1 93.750000    Top5 99.537037    LR 0.000010    Time 0.025537    
2022-12-15 15:07:24,314 - --- validate (epoch=143)-----------
2022-12-15 15:07:24,314 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:24,588 - Epoch: [143][    9/    9]    Loss 1.262965    Top1 64.933206    Top5 90.601145    
2022-12-15 15:07:24,656 - ==> Top1: 64.933    Top5: 90.601    Loss: 1.263

2022-12-15 15:07:24,657 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  14   0   1   1   0   0   0   0   0   0   1   0   0]
 [  0   0 112   0   8   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   7   0 122   2   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   8   0   0   0   4   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  1   0   1   0   1   0 131   0   3   1   0   1   0   0   4   1   0   0   3   0   0   0   1  11   0   0   1   4   0   8   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   6   4   0   2   0   0   0   1   0   0   5   0   0   1   0   6   0   0   0   1   1   0   0]
 [  1   0   1   0   0   0   4   0   2   9   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   4   4   0   0 153   0   1   0   1   0   0  11   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  5   9   1   0   2   0   1   2   2   7   0   0   0   0   0   2   1   0 111   0   2   5   0   0   0   0   0   1   4   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0   9   0   6   0   6   0   5 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  12   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  85   0   0   2   3   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   4   0   0  55   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   4   4   0   4   0   4   0   0   2   0   0   0  54   0   9   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   8   3   9   2   0   5   0   0   0   0   1   5   0   0   5   0   2   1   0   7   0   0   0   2   0 130   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:07:24,659 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:24,659 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:24,669 - 

2022-12-15 15:07:24,669 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:25,215 - Epoch: [144][   10/   74]    Overall Loss 0.318985    Objective Loss 0.318985                                        LR 0.000010    Time 0.054484    
2022-12-15 15:07:25,470 - Epoch: [144][   20/   74]    Overall Loss 0.322866    Objective Loss 0.322866                                        LR 0.000010    Time 0.039971    
2022-12-15 15:07:25,723 - Epoch: [144][   30/   74]    Overall Loss 0.332620    Objective Loss 0.332620                                        LR 0.000010    Time 0.035089    
2022-12-15 15:07:25,973 - Epoch: [144][   40/   74]    Overall Loss 0.330968    Objective Loss 0.330968                                        LR 0.000010    Time 0.032552    
2022-12-15 15:07:26,223 - Epoch: [144][   50/   74]    Overall Loss 0.338263    Objective Loss 0.338263                                        LR 0.000010    Time 0.031021    
2022-12-15 15:07:26,473 - Epoch: [144][   60/   74]    Overall Loss 0.334844    Objective Loss 0.334844                                        LR 0.000010    Time 0.029992    
2022-12-15 15:07:26,713 - Epoch: [144][   70/   74]    Overall Loss 0.333077    Objective Loss 0.333077                                        LR 0.000010    Time 0.029132    
2022-12-15 15:07:26,804 - Epoch: [144][   74/   74]    Overall Loss 0.332034    Objective Loss 0.332034    Top1 92.129630    Top5 99.074074    LR 0.000010    Time 0.028772    
2022-12-15 15:07:26,865 - --- validate (epoch=144)-----------
2022-12-15 15:07:26,865 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:27,140 - Epoch: [144][    9/    9]    Loss 1.261816    Top1 64.980916    Top5 90.744275    
2022-12-15 15:07:27,197 - ==> Top1: 64.981    Top5: 90.744    Loss: 1.262

2022-12-15 15:07:27,199 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   1   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 111   0   8   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   6   0 126   2   3   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   7   0   0   0   4   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   2   0 128   0   4   0   0   1   0   0   4   1   0   0   2   0   0   0   1  13   0   0   1   5   0   9   0]
 [  0   6   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   1   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   8   5   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  10   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   8   0   0   1   4   4   0   0 150   1   2   0   1   0   0  12   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   2   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   0   1   1   2   5   0   0   0   0   0   2   2   0 113   0   2   5   0   0   0   0   0   2   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  76   9   0   0   0   0   0   7   0   5   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0   9   0   6   0   7   0   6 140   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  11   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  86   0   0   2   5   3   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   5   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   3   9   2   0   4   0   0   0   0   1   5   0   0   4   0   2   2   0   5   0   0   0   3   0 131   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:07:27,200 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:27,200 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:27,221 - 

2022-12-15 15:07:27,221 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:27,629 - Epoch: [145][   10/   74]    Overall Loss 0.333253    Objective Loss 0.333253                                        LR 0.000010    Time 0.040735    
2022-12-15 15:07:27,873 - Epoch: [145][   20/   74]    Overall Loss 0.336893    Objective Loss 0.336893                                        LR 0.000010    Time 0.032571    
2022-12-15 15:07:28,132 - Epoch: [145][   30/   74]    Overall Loss 0.333814    Objective Loss 0.333814                                        LR 0.000010    Time 0.030323    
2022-12-15 15:07:28,384 - Epoch: [145][   40/   74]    Overall Loss 0.329995    Objective Loss 0.329995                                        LR 0.000010    Time 0.029024    
2022-12-15 15:07:28,637 - Epoch: [145][   50/   74]    Overall Loss 0.331761    Objective Loss 0.331761                                        LR 0.000010    Time 0.028272    
2022-12-15 15:07:28,898 - Epoch: [145][   60/   74]    Overall Loss 0.331895    Objective Loss 0.331895                                        LR 0.000010    Time 0.027907    
2022-12-15 15:07:29,141 - Epoch: [145][   70/   74]    Overall Loss 0.331318    Objective Loss 0.331318                                        LR 0.000010    Time 0.027390    
2022-12-15 15:07:29,223 - Epoch: [145][   74/   74]    Overall Loss 0.331386    Objective Loss 0.331386    Top1 92.361111    Top5 99.305556    LR 0.000010    Time 0.027009    
2022-12-15 15:07:29,285 - --- validate (epoch=145)-----------
2022-12-15 15:07:29,285 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:29,564 - Epoch: [145][    9/    9]    Loss 1.248294    Top1 64.885496    Top5 90.839695    
2022-12-15 15:07:29,616 - ==> Top1: 64.885    Top5: 90.840    Loss: 1.248

2022-12-15 15:07:29,618 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 125   0   3   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   6   0   0   0   5   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  1   0   2   0   2   0 127   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0   9   0]
 [  0   6   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   1   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   6   4   0   2   0   0   0   1   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   4   4   0   0 149   2   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   5   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  11   1   0   2   0   1   1   2   5   0   0   0   0   0   2   2   0 114   0   2   5   0   0   0   0   0   2   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  76   9   0   0   0   0   0   7   0   6   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0   9   0   7   0   7   0   6 138   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  10   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  86   0   0   2   5   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   5   0   0  54   0   1   0   0]
 [  0   1   2   0   3   3  14   1   1   2   0   0   0   0   3   4   4   0   4   0   3   0   0   1   0   0   0  52   0  10   0]
 [  1   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   9   2   7   2   0   4   0   0   0   0   1   5   0   0   5   0   3   1   0   5   0   0   0   2   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:29,620 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:29,620 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:29,629 - 

2022-12-15 15:07:29,630 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:30,053 - Epoch: [146][   10/   74]    Overall Loss 0.313580    Objective Loss 0.313580                                        LR 0.000010    Time 0.042297    
2022-12-15 15:07:30,309 - Epoch: [146][   20/   74]    Overall Loss 0.332169    Objective Loss 0.332169                                        LR 0.000010    Time 0.033915    
2022-12-15 15:07:30,557 - Epoch: [146][   30/   74]    Overall Loss 0.333140    Objective Loss 0.333140                                        LR 0.000010    Time 0.030853    
2022-12-15 15:07:30,804 - Epoch: [146][   40/   74]    Overall Loss 0.329774    Objective Loss 0.329774                                        LR 0.000010    Time 0.029312    
2022-12-15 15:07:31,052 - Epoch: [146][   50/   74]    Overall Loss 0.337405    Objective Loss 0.337405                                        LR 0.000010    Time 0.028398    
2022-12-15 15:07:31,305 - Epoch: [146][   60/   74]    Overall Loss 0.334984    Objective Loss 0.334984                                        LR 0.000010    Time 0.027862    
2022-12-15 15:07:31,552 - Epoch: [146][   70/   74]    Overall Loss 0.333872    Objective Loss 0.333872                                        LR 0.000010    Time 0.027410    
2022-12-15 15:07:31,635 - Epoch: [146][   74/   74]    Overall Loss 0.331200    Objective Loss 0.331200    Top1 95.601852    Top5 100.000000    LR 0.000010    Time 0.027042    
2022-12-15 15:07:31,704 - --- validate (epoch=146)-----------
2022-12-15 15:07:31,704 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:31,974 - Epoch: [146][    9/    9]    Loss 1.257253    Top1 64.646947    Top5 90.744275    
2022-12-15 15:07:32,027 - ==> Top1: 64.647    Top5: 90.744    Loss: 1.257

2022-12-15 15:07:32,029 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   8   1   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   2   0   0   0   0   0   1   1   0   0]
 [  0   0 111   0   8   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 123   2   4   0   0   0   0   0   0   0   0   2   0   0   4   0   0   3   0   8   0   0   0   3   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  1   0   0   0   1   0 131   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  11   0   0   1   5   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   2  10   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   6   0   0   1   5   4   0   0 151   0   2   0   1   0   0  12   0   0   0   0   1   1   2   0   0]
 [  2   0   0   0   0   0   7   0   0   4   0   0   0   0   3   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   2   0   1   2   2   7   0   0   0   0   0   2   2   0 113   0   2   5   0   0   0   0   0   2   3   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75  10   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0  10   0   6   0   6   0   5 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  14   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  81   0   0   2   3   3   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   2   0   5   0   0  53   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   3   4   0   4   0   5   0   0   1   0   0   0  54   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   1   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   7   0   0]
 [  1   0   0   0  10   1   9   2   0   5   0   0   0   0   1   4   0   0   4   0   3   2   0   4   0   0   0   2   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:32,030 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:32,031 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:32,051 - 

2022-12-15 15:07:32,051 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:32,483 - Epoch: [147][   10/   74]    Overall Loss 0.334272    Objective Loss 0.334272                                        LR 0.000010    Time 0.043097    
2022-12-15 15:07:32,736 - Epoch: [147][   20/   74]    Overall Loss 0.338981    Objective Loss 0.338981                                        LR 0.000010    Time 0.034198    
2022-12-15 15:07:32,955 - Epoch: [147][   30/   74]    Overall Loss 0.340898    Objective Loss 0.340898                                        LR 0.000010    Time 0.030093    
2022-12-15 15:07:33,188 - Epoch: [147][   40/   74]    Overall Loss 0.339475    Objective Loss 0.339475                                        LR 0.000010    Time 0.028382    
2022-12-15 15:07:33,445 - Epoch: [147][   50/   74]    Overall Loss 0.338045    Objective Loss 0.338045                                        LR 0.000010    Time 0.027843    
2022-12-15 15:07:33,703 - Epoch: [147][   60/   74]    Overall Loss 0.335215    Objective Loss 0.335215                                        LR 0.000010    Time 0.027489    
2022-12-15 15:07:33,946 - Epoch: [147][   70/   74]    Overall Loss 0.330888    Objective Loss 0.330888                                        LR 0.000010    Time 0.027022    
2022-12-15 15:07:34,033 - Epoch: [147][   74/   74]    Overall Loss 0.331582    Objective Loss 0.331582    Top1 93.055556    Top5 99.537037    LR 0.000010    Time 0.026736    
2022-12-15 15:07:34,096 - --- validate (epoch=147)-----------
2022-12-15 15:07:34,096 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:34,375 - Epoch: [147][    9/    9]    Loss 1.300245    Top1 65.267176    Top5 90.791985    
2022-12-15 15:07:34,441 - ==> Top1: 65.267    Top5: 90.792    Loss: 1.300

2022-12-15 15:07:34,443 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  11   0   1   2   0   0   0   0   0   1   1   1   0]
 [  0   0 112   0   8   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 125   2   4   0   0   1   0   0   0   0   0   1   0   0   4   0   0   3   0   6   0   0   0   3   1   6   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  1   0   0   0   1   0 129   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  11   0   0   1   5   0  11   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   7   4   0   2   0   0   0   1   0   0   4   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   7   0   0   1   3   4   0   0 155   0   0   0   2   0   0  12   0   0   0   0   1   1   1   0   0]
 [  2   0   0   0   0   0   7   0   0   4   0   0   0   0   3   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   0   1   2   2   6   0   0   0   0   0   2   2   0 112   0   2   5   0   0   0   0   0   2   3   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75  10   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   0   0   0   0   0   0   0   2   0   0  10   0   6   0   6   0   5 140   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  12   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  85   0   0   2   4   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   1   2   0   2   3  13   0   1   2   0   0   0   0   3   3   3   0   3   0   6   0   0   2   0   0   0  54   0  10   0]
 [  1   2   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   5   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0  10   1   7   2   0   5   0   0   0   0   1   5   0   0   4   0   3   2   0   4   0   0   0   2   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:34,444 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:34,444 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:34,454 - 

2022-12-15 15:07:34,454 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:34,873 - Epoch: [148][   10/   74]    Overall Loss 0.322105    Objective Loss 0.322105                                        LR 0.000010    Time 0.041830    
2022-12-15 15:07:35,121 - Epoch: [148][   20/   74]    Overall Loss 0.326279    Objective Loss 0.326279                                        LR 0.000010    Time 0.033287    
2022-12-15 15:07:35,367 - Epoch: [148][   30/   74]    Overall Loss 0.331105    Objective Loss 0.331105                                        LR 0.000010    Time 0.030362    
2022-12-15 15:07:35,613 - Epoch: [148][   40/   74]    Overall Loss 0.333669    Objective Loss 0.333669                                        LR 0.000010    Time 0.028906    
2022-12-15 15:07:35,857 - Epoch: [148][   50/   74]    Overall Loss 0.332508    Objective Loss 0.332508                                        LR 0.000010    Time 0.027995    
2022-12-15 15:07:36,101 - Epoch: [148][   60/   74]    Overall Loss 0.330653    Objective Loss 0.330653                                        LR 0.000010    Time 0.027400    
2022-12-15 15:07:36,341 - Epoch: [148][   70/   74]    Overall Loss 0.332230    Objective Loss 0.332230                                        LR 0.000010    Time 0.026900    
2022-12-15 15:07:36,428 - Epoch: [148][   74/   74]    Overall Loss 0.331506    Objective Loss 0.331506    Top1 92.592593    Top5 99.537037    LR 0.000010    Time 0.026623    
2022-12-15 15:07:36,491 - --- validate (epoch=148)-----------
2022-12-15 15:07:36,491 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:36,760 - Epoch: [148][    9/    9]    Loss 1.289000    Top1 65.076336    Top5 90.648855    
2022-12-15 15:07:36,810 - ==> Top1: 65.076    Top5: 90.649    Loss: 1.289

2022-12-15 15:07:36,813 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   7   0 127   1   3   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   6   0   0   0   3   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  1   0   1   0   1   0 125   0   3   1   0   1   0   0   5   1   0   0   2   0   0   0   1  13   0   0   1   5   0  11   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   5   0   1  10   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  15   0   0   0   0   0   0   2   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   2   4   0   0 152   1   3   0   1   0   0  11   0   0   0   0   1   1   2   0   0]
 [  2   0   0   0   0   0   7   0   0   4   0   0   0   0   3   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  14   1   0   2   0   1   1   2   5   0   0   0   0   0   2   1   0 111   0   1   5   0   0   0   0   0   2   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   2   0   0   0   0   0   1   0   0   1   0   1   0  76  10   0   0   0   0   0   8   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0   9   0   6   0   7   0   6 139   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  1   1   5   0  17   0   9   0   1   1   0   4   0   0   0   0   0   0   5   0   0   1   2  85   0   0   2   5   3   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  12   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   1   0   0   0  55   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0  10   0   7   2   0   3   0   0   0   0   1   5   0   0   5   0   3   1   0   5   0   0   0   3   0 135   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:36,814 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:36,814 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:36,824 - 

2022-12-15 15:07:36,825 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:37,244 - Epoch: [149][   10/   74]    Overall Loss 0.322048    Objective Loss 0.322048                                        LR 0.000010    Time 0.041837    
2022-12-15 15:07:37,487 - Epoch: [149][   20/   74]    Overall Loss 0.336253    Objective Loss 0.336253                                        LR 0.000010    Time 0.033076    
2022-12-15 15:07:37,732 - Epoch: [149][   30/   74]    Overall Loss 0.331119    Objective Loss 0.331119                                        LR 0.000010    Time 0.030205    
2022-12-15 15:07:37,979 - Epoch: [149][   40/   74]    Overall Loss 0.331193    Objective Loss 0.331193                                        LR 0.000010    Time 0.028799    
2022-12-15 15:07:38,240 - Epoch: [149][   50/   74]    Overall Loss 0.329994    Objective Loss 0.329994                                        LR 0.000010    Time 0.028255    
2022-12-15 15:07:38,494 - Epoch: [149][   60/   74]    Overall Loss 0.328337    Objective Loss 0.328337                                        LR 0.000010    Time 0.027771    
2022-12-15 15:07:38,739 - Epoch: [149][   70/   74]    Overall Loss 0.329881    Objective Loss 0.329881                                        LR 0.000010    Time 0.027307    
2022-12-15 15:07:38,827 - Epoch: [149][   74/   74]    Overall Loss 0.331097    Objective Loss 0.331097    Top1 92.129630    Top5 98.611111    LR 0.000010    Time 0.027007    
2022-12-15 15:07:38,890 - --- validate (epoch=149)-----------
2022-12-15 15:07:38,890 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:39,159 - Epoch: [149][    9/    9]    Loss 1.269592    Top1 65.076336    Top5 90.648855    
2022-12-15 15:07:39,214 - ==> Top1: 65.076    Top5: 90.649    Loss: 1.270

2022-12-15 15:07:39,216 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  14   0   1   1   0   0   0   0   0   0   1   0   0]
 [  0   0 112   0   7   0   0   1   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 127   0   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   8   0   0   0   1   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   1   0 131   0   4   1   0   1   0   0   3   1   0   0   2   0   0   0   1  12   0   0   1   4   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  15   0   0   0  20   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  10   0   1   0   0   0   0  16   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   7   0   0   1   4   4   0   0 151   2   3   0   1   0   0   9   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  1   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   6   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  11   1   0   2   1   1   1   2   5   0   0   0   0   0   2   3   0 111   0   2   5   0   0   0   0   0   2   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75  10   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0  10   0   6   0   7   0   6 138   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  18   0  13   0   3   1   0   3   0   0   0   0   0   0   6   0   0   1   2  83   0   0   2   2   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   3   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0  10   0   9   2   0   6   0   0   0   0   0   5   0   0   4   0   3   1   0   3   0   0   0   2   0 135   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:39,217 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:39,217 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:39,227 - 

2022-12-15 15:07:39,227 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:39,618 - Epoch: [150][   10/   74]    Overall Loss 0.337670    Objective Loss 0.337670                                        LR 0.000010    Time 0.039002    
2022-12-15 15:07:39,840 - Epoch: [150][   20/   74]    Overall Loss 0.336646    Objective Loss 0.336646                                        LR 0.000010    Time 0.030561    
2022-12-15 15:07:40,107 - Epoch: [150][   30/   74]    Overall Loss 0.340844    Objective Loss 0.340844                                        LR 0.000010    Time 0.029271    
2022-12-15 15:07:40,388 - Epoch: [150][   40/   74]    Overall Loss 0.332274    Objective Loss 0.332274                                        LR 0.000010    Time 0.028952    
2022-12-15 15:07:40,649 - Epoch: [150][   50/   74]    Overall Loss 0.331693    Objective Loss 0.331693                                        LR 0.000010    Time 0.028388    
2022-12-15 15:07:40,912 - Epoch: [150][   60/   74]    Overall Loss 0.332058    Objective Loss 0.332058                                        LR 0.000010    Time 0.028030    
2022-12-15 15:07:41,163 - Epoch: [150][   70/   74]    Overall Loss 0.332682    Objective Loss 0.332682                                        LR 0.000010    Time 0.027597    
2022-12-15 15:07:41,251 - Epoch: [150][   74/   74]    Overall Loss 0.331649    Objective Loss 0.331649    Top1 92.824074    Top5 99.305556    LR 0.000010    Time 0.027298    
2022-12-15 15:07:41,310 - --- validate (epoch=150)-----------
2022-12-15 15:07:41,310 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:41,591 - Epoch: [150][    9/    9]    Loss 1.274116    Top1 65.028626    Top5 90.648855    
2022-12-15 15:07:41,645 - ==> Top1: 65.029    Top5: 90.649    Loss: 1.274

2022-12-15 15:07:41,647 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 113   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   6   0 125   0   4   0   0   0   0   0   0   0   0   2   0   0   4   0   0   3   0   7   0   0   0   3   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   0   0 131   0   3   2   0   1   0   0   3   1   0   0   2   0   0   0   1  13   0   0   1   4   0   9   0]
 [  0   6   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   1   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   8   0   0   1   2   4   0   0 151   2   2   0   1   0   0  12   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  13   1   0   2   0   1   1   2   5   0   0   0   0   0   2   2   0 112   0   1   5   0   0   0   0   0   1   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74   9   0   0   0   0   0   7   0   9   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0  10   0   6   0   7   0   6 139   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  11   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  85   0   0   2   3   3   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   1   2   0   3   3  14   0   1   3   0   0   0   0   3   3   4   0   3   0   5   0   0   2   0   0   0  51   0  10   0]
 [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0  10   2   8   2   0   5   0   0   0   0   1   5   0   0   4   0   2   1   0   4   0   0   0   3   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:41,649 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:41,649 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:41,667 - 

2022-12-15 15:07:41,667 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:42,212 - Epoch: [151][   10/   74]    Overall Loss 0.327346    Objective Loss 0.327346                                        LR 0.000010    Time 0.054429    
2022-12-15 15:07:42,463 - Epoch: [151][   20/   74]    Overall Loss 0.321732    Objective Loss 0.321732                                        LR 0.000010    Time 0.039713    
2022-12-15 15:07:42,714 - Epoch: [151][   30/   74]    Overall Loss 0.329938    Objective Loss 0.329938                                        LR 0.000010    Time 0.034836    
2022-12-15 15:07:42,967 - Epoch: [151][   40/   74]    Overall Loss 0.333632    Objective Loss 0.333632                                        LR 0.000010    Time 0.032437    
2022-12-15 15:07:43,214 - Epoch: [151][   50/   74]    Overall Loss 0.335166    Objective Loss 0.335166                                        LR 0.000010    Time 0.030888    
2022-12-15 15:07:43,462 - Epoch: [151][   60/   74]    Overall Loss 0.332579    Objective Loss 0.332579                                        LR 0.000010    Time 0.029865    
2022-12-15 15:07:43,701 - Epoch: [151][   70/   74]    Overall Loss 0.332728    Objective Loss 0.332728                                        LR 0.000010    Time 0.029002    
2022-12-15 15:07:43,791 - Epoch: [151][   74/   74]    Overall Loss 0.330792    Objective Loss 0.330792    Top1 91.666667    Top5 99.305556    LR 0.000010    Time 0.028648    
2022-12-15 15:07:43,858 - --- validate (epoch=151)-----------
2022-12-15 15:07:43,858 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:44,131 - Epoch: [151][    9/    9]    Loss 1.296816    Top1 65.314885    Top5 90.839695    
2022-12-15 15:07:44,177 - ==> Top1: 65.315    Top5: 90.840    Loss: 1.297

2022-12-15 15:07:44,179 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   1   0   5   1   0   1   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 126   1   3   0   0   1   0   0   0   0   0   1   0   0   5   0   0   3   0   8   0   0   0   3   0   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   0   0 128   0   3   1   0   1   0   0   4   1   0   0   3   0   0   0   1  14   0   0   1   5   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  10   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  15   0   0   0   0   0   0   2   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   3   4   0   0 152   1   1   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  11   1   0   2   0   1   1   3   5   0   0   0   0   0   2   1   0 113   0   1   5   0   0   0   0   0   1   4   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   0   0   1   0   1   0  75   9   0   0   0   0   0   8   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0  11   0   6   0   7   0   5 139   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  11   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  88   0   0   2   4   2   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  52   0  10   0]
 [  1   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0  10   0   8   2   0   3   0   0   0   0   1   5   0   0   5   0   3   1   0   5   0   0   0   2   0 135   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:44,181 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:44,181 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:44,191 - 

2022-12-15 15:07:44,191 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:44,613 - Epoch: [152][   10/   74]    Overall Loss 0.322612    Objective Loss 0.322612                                        LR 0.000010    Time 0.042084    
2022-12-15 15:07:44,858 - Epoch: [152][   20/   74]    Overall Loss 0.336444    Objective Loss 0.336444                                        LR 0.000010    Time 0.033256    
2022-12-15 15:07:45,103 - Epoch: [152][   30/   74]    Overall Loss 0.324244    Objective Loss 0.324244                                        LR 0.000010    Time 0.030344    
2022-12-15 15:07:45,351 - Epoch: [152][   40/   74]    Overall Loss 0.328762    Objective Loss 0.328762                                        LR 0.000010    Time 0.028940    
2022-12-15 15:07:45,598 - Epoch: [152][   50/   74]    Overall Loss 0.330071    Objective Loss 0.330071                                        LR 0.000010    Time 0.028087    
2022-12-15 15:07:45,859 - Epoch: [152][   60/   74]    Overall Loss 0.330774    Objective Loss 0.330774                                        LR 0.000010    Time 0.027742    
2022-12-15 15:07:46,110 - Epoch: [152][   70/   74]    Overall Loss 0.331792    Objective Loss 0.331792                                        LR 0.000010    Time 0.027362    
2022-12-15 15:07:46,198 - Epoch: [152][   74/   74]    Overall Loss 0.330392    Objective Loss 0.330392    Top1 93.750000    Top5 99.074074    LR 0.000010    Time 0.027067    
2022-12-15 15:07:46,271 - --- validate (epoch=152)-----------
2022-12-15 15:07:46,271 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:46,540 - Epoch: [152][    9/    9]    Loss 1.354210    Top1 64.980916    Top5 90.362595    
2022-12-15 15:07:46,602 - ==> Top1: 64.981    Top5: 90.363    Loss: 1.354

2022-12-15 15:07:46,604 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   1   0   6   2   0   1   0   2   0   0   0   0   0   0   0   0  12   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 112   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   6   0 126   1   4   0   0   0   0   0   0   0   0   2   0   0   4   0   0   2   0   8   0   0   0   2   1   5   0]
 [  0   3   1   0   1  37   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  1   0   1   0   0   0 130   0   4   0   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   4   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   4   0   2   0]
 [  0   0   0   0   0   0   6   0   8   5   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   3   4   0   0 150   2   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   7   0   0   2   0   0   0   0   1   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  14   1   0   3   0   1   1   2   7   0   0   0   0   0   1   2   0 109   0   1   5   0   0   0   0   0   1   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   0   0   0   0   1   0  76   9   0   0   0   0   0   8   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0  10   0   6   0   8   0   6 137   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   4   0  17   0  11   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  87   0   0   2   5   2   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   1   0   6   0   0  53   0   1   0   0]
 [  0   1   2   0   2   3  13   0   1   3   0   0   0   0   3   2   4   0   4   0   4   0   0   2   0   0   0  54   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   1   0   0   1   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0  10   0   9   2   0   4   0   0   0   0   1   5   0   0   5   0   3   1   0   4   0   0   0   2   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:46,605 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:46,605 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:46,626 - 

2022-12-15 15:07:46,626 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:47,006 - Epoch: [153][   10/   74]    Overall Loss 0.332576    Objective Loss 0.332576                                        LR 0.000010    Time 0.037859    
2022-12-15 15:07:47,215 - Epoch: [153][   20/   74]    Overall Loss 0.333619    Objective Loss 0.333619                                        LR 0.000010    Time 0.029369    
2022-12-15 15:07:47,431 - Epoch: [153][   30/   74]    Overall Loss 0.325404    Objective Loss 0.325404                                        LR 0.000010    Time 0.026751    
2022-12-15 15:07:47,655 - Epoch: [153][   40/   74]    Overall Loss 0.329217    Objective Loss 0.329217                                        LR 0.000010    Time 0.025660    
2022-12-15 15:07:47,905 - Epoch: [153][   50/   74]    Overall Loss 0.327064    Objective Loss 0.327064                                        LR 0.000010    Time 0.025515    
2022-12-15 15:07:48,155 - Epoch: [153][   60/   74]    Overall Loss 0.326657    Objective Loss 0.326657                                        LR 0.000010    Time 0.025425    
2022-12-15 15:07:48,400 - Epoch: [153][   70/   74]    Overall Loss 0.330327    Objective Loss 0.330327                                        LR 0.000010    Time 0.025282    
2022-12-15 15:07:48,488 - Epoch: [153][   74/   74]    Overall Loss 0.330404    Objective Loss 0.330404    Top1 90.972222    Top5 99.537037    LR 0.000010    Time 0.025102    
2022-12-15 15:07:48,552 - --- validate (epoch=153)-----------
2022-12-15 15:07:48,552 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:48,833 - Epoch: [153][    9/    9]    Loss 1.330894    Top1 65.219466    Top5 90.935115    
2022-12-15 15:07:48,884 - ==> Top1: 65.219    Top5: 90.935    Loss: 1.331

2022-12-15 15:07:48,886 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  12   0   0   4   1   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 124   1   3   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   7   0   0   0   4   1   6   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  1   0   0   0   1   0 129   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0  10   0]
 [  0   6   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   1   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   8   5   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  15   0   0   0   0   0   0   2   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   4   4   0   0 150   1   2   0   2   0   0  12   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   0   1   2   2   4   0   0   0   0   0   2   3   0 115   0   2   5   0   0   0   0   0   2   1   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   0   0   1   0   1   0  75   9   0   0   0   0   0   8   0   8   0]
 [  0   3   0   0   0   1   0   0   0   0   0   1   0   0   9   0   6   0   6   0   6 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  11   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  84   0   0   2   5   3   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   3   0   0   0   0   3   3   4   0   4   0   5   0   0   1   0   0   0  53   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   7   0   0   2   0   7   0   0   0   0   6   0   0]
 [  1   0   0   0   9   2   7   2   0   3   0   0   0   0   1   4   0   0   5   0   2   1   0   4   0   0   0   3   0 136   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   5   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:07:48,888 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:48,888 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:48,898 - 

2022-12-15 15:07:48,898 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:49,286 - Epoch: [154][   10/   74]    Overall Loss 0.315138    Objective Loss 0.315138                                        LR 0.000010    Time 0.038776    
2022-12-15 15:07:49,517 - Epoch: [154][   20/   74]    Overall Loss 0.325087    Objective Loss 0.325087                                        LR 0.000010    Time 0.030878    
2022-12-15 15:07:49,772 - Epoch: [154][   30/   74]    Overall Loss 0.328202    Objective Loss 0.328202                                        LR 0.000010    Time 0.029071    
2022-12-15 15:07:50,015 - Epoch: [154][   40/   74]    Overall Loss 0.328299    Objective Loss 0.328299                                        LR 0.000010    Time 0.027886    
2022-12-15 15:07:50,232 - Epoch: [154][   50/   74]    Overall Loss 0.329703    Objective Loss 0.329703                                        LR 0.000010    Time 0.026635    
2022-12-15 15:07:50,449 - Epoch: [154][   60/   74]    Overall Loss 0.329054    Objective Loss 0.329054                                        LR 0.000010    Time 0.025811    
2022-12-15 15:07:50,661 - Epoch: [154][   70/   74]    Overall Loss 0.329678    Objective Loss 0.329678                                        LR 0.000010    Time 0.025145    
2022-12-15 15:07:50,739 - Epoch: [154][   74/   74]    Overall Loss 0.330550    Objective Loss 0.330550    Top1 94.444444    Top5 99.537037    LR 0.000010    Time 0.024837    
2022-12-15 15:07:50,811 - --- validate (epoch=154)-----------
2022-12-15 15:07:50,811 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:51,105 - Epoch: [154][    9/    9]    Loss 1.298335    Top1 65.028626    Top5 90.887405    
2022-12-15 15:07:51,163 - ==> Top1: 65.029    Top5: 90.887    Loss: 1.298

2022-12-15 15:07:51,165 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   2   0   0   0   0   0   1   1   1   0]
 [  0   0 111   0   8   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 126   1   3   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   7   0   0   0   2   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   1   0 127   0   4   2   0   1   0   0   3   1   0   0   2   0   0   0   1  13   0   0   1   5   0  10   0]
 [  0   6   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   1   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   8   4   0   2   0   0   0   1   0   0   4   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   1   8   0   0   1   3   4   0   0 151   2   1   0   1   0   0  11   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  12   1   0   3   1   1   0   2   5   0   0   0   0   0   2   2   0 112   0   1   5   0   0   0   0   0   1   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   3   0   0   0   0   0   1   1   0   1   0   1   0  73   9   0   0   0   0   0   7   0   9   0]
 [  0   3   0   0   1   0   0   0   0   0   0   0   0   0  10   0   6   0   8   0   6 139   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  10   0   3   1   0   3   0   0   0   0   0   0   6   0   0   1   2  86   0   0   2   5   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  12   0   1   3   0   0   0   0   3   2   4   0   4   0   5   0   0   2   0   0   0  55   0  10   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  1   0   0   0  10   1   9   2   0   4   0   0   0   0   1   4   0   0   5   0   2   1   0   4   0   0   0   2   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:51,166 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:51,166 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:51,176 - 

2022-12-15 15:07:51,176 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:51,582 - Epoch: [155][   10/   74]    Overall Loss 0.329288    Objective Loss 0.329288                                        LR 0.000010    Time 0.040473    
2022-12-15 15:07:51,823 - Epoch: [155][   20/   74]    Overall Loss 0.336244    Objective Loss 0.336244                                        LR 0.000010    Time 0.032260    
2022-12-15 15:07:52,074 - Epoch: [155][   30/   74]    Overall Loss 0.331774    Objective Loss 0.331774                                        LR 0.000010    Time 0.029866    
2022-12-15 15:07:52,326 - Epoch: [155][   40/   74]    Overall Loss 0.336947    Objective Loss 0.336947                                        LR 0.000010    Time 0.028682    
2022-12-15 15:07:52,550 - Epoch: [155][   50/   74]    Overall Loss 0.333395    Objective Loss 0.333395                                        LR 0.000010    Time 0.027421    
2022-12-15 15:07:52,769 - Epoch: [155][   60/   74]    Overall Loss 0.330386    Objective Loss 0.330386                                        LR 0.000010    Time 0.026498    
2022-12-15 15:07:52,983 - Epoch: [155][   70/   74]    Overall Loss 0.331860    Objective Loss 0.331860                                        LR 0.000010    Time 0.025752    
2022-12-15 15:07:53,060 - Epoch: [155][   74/   74]    Overall Loss 0.329105    Objective Loss 0.329105    Top1 96.527778    Top5 99.537037    LR 0.000010    Time 0.025409    
2022-12-15 15:07:53,121 - --- validate (epoch=155)-----------
2022-12-15 15:07:53,121 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:53,388 - Epoch: [155][    9/    9]    Loss 1.240545    Top1 65.601145    Top5 90.744275    
2022-12-15 15:07:53,446 - ==> Top1: 65.601    Top5: 90.744    Loss: 1.241

2022-12-15 15:07:53,448 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 124   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   6   0   0   0   3   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   4   0   0   0   0   1   0   2   0   0]
 [  1   0   0   0   1   0 131   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  10   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   8   0   6   5   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  15   0   0   0  20   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  15   0   0   0   0   0   0   2   0   4   0]
 [  1   0   0   0   1   0   6   0   0   1   3   4   0   0 154   0   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  12   1   0   2   0   1   1   2   5   0   0   0   0   0   2   2   0 114   0   1   5   0   0   0   0   0   2   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  76   9   0   0   0   0   0   7   0   6   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0   9   0   6   0   7   0   6 140   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  11   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  85   0   0   2   5   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   3   4   0   4   0   4   0   0   2   0   0   0  55   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   9   0   0]
 [  0   0   0   0   9   0   8   2   0   5   0   0   0   0   1   5   0   0   5   0   3   1   0   5   0   0   0   2   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:53,450 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:53,450 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:53,460 - 

2022-12-15 15:07:53,460 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:53,882 - Epoch: [156][   10/   74]    Overall Loss 0.313494    Objective Loss 0.313494                                        LR 0.000010    Time 0.042160    
2022-12-15 15:07:54,136 - Epoch: [156][   20/   74]    Overall Loss 0.330758    Objective Loss 0.330758                                        LR 0.000010    Time 0.033761    
2022-12-15 15:07:54,386 - Epoch: [156][   30/   74]    Overall Loss 0.332616    Objective Loss 0.332616                                        LR 0.000010    Time 0.030817    
2022-12-15 15:07:54,637 - Epoch: [156][   40/   74]    Overall Loss 0.329609    Objective Loss 0.329609                                        LR 0.000010    Time 0.029373    
2022-12-15 15:07:54,884 - Epoch: [156][   50/   74]    Overall Loss 0.332287    Objective Loss 0.332287                                        LR 0.000010    Time 0.028426    
2022-12-15 15:07:55,137 - Epoch: [156][   60/   74]    Overall Loss 0.331217    Objective Loss 0.331217                                        LR 0.000010    Time 0.027904    
2022-12-15 15:07:55,382 - Epoch: [156][   70/   74]    Overall Loss 0.331269    Objective Loss 0.331269                                        LR 0.000010    Time 0.027414    
2022-12-15 15:07:55,470 - Epoch: [156][   74/   74]    Overall Loss 0.329740    Objective Loss 0.329740    Top1 94.444444    Top5 99.305556    LR 0.000010    Time 0.027124    
2022-12-15 15:07:55,527 - --- validate (epoch=156)-----------
2022-12-15 15:07:55,527 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:55,814 - Epoch: [156][    9/    9]    Loss 1.294116    Top1 65.219466    Top5 90.791985    
2022-12-15 15:07:55,862 - ==> Top1: 65.219    Top5: 90.792    Loss: 1.294

2022-12-15 15:07:55,864 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   1   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   2   0   0   0   0   0   1   1   0   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   6   0 126   0   4   0   0   0   0   0   0   0   0   1   0   0   4   0   0   3   0   6   0   0   0   5   1   5   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  1   0   1   0   1   0 131   0   4   1   0   1   0   0   3   1   0   0   2   0   0   0   1   9   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   6   5   0   2   0   0   0   0   0   0   5   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   1   7   0   0   1   3   4   0   0 152   1   2   0   1   0   0  10   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   0   1   2   2   5   0   0   0   0   0   2   3   0 113   0   1   5   0   0   0   0   0   1   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0   9   0   6   0   6   0   6 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  12   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  84   0   0   2   4   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   5   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   3   4   0   4   0   5   0   0   1   0   0   0  54   0  10   0]
 [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   4   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   2   9   2   0   5   0   0   0   0   1   5   0   0   4   0   3   1   0   5   0   0   0   2   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:07:55,866 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:55,866 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:55,876 - 

2022-12-15 15:07:55,876 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:56,293 - Epoch: [157][   10/   74]    Overall Loss 0.334410    Objective Loss 0.334410                                        LR 0.000010    Time 0.041614    
2022-12-15 15:07:56,543 - Epoch: [157][   20/   74]    Overall Loss 0.345358    Objective Loss 0.345358                                        LR 0.000010    Time 0.033258    
2022-12-15 15:07:56,804 - Epoch: [157][   30/   74]    Overall Loss 0.336702    Objective Loss 0.336702                                        LR 0.000010    Time 0.030871    
2022-12-15 15:07:57,063 - Epoch: [157][   40/   74]    Overall Loss 0.331907    Objective Loss 0.331907                                        LR 0.000010    Time 0.029607    
2022-12-15 15:07:57,332 - Epoch: [157][   50/   74]    Overall Loss 0.329537    Objective Loss 0.329537                                        LR 0.000010    Time 0.029063    
2022-12-15 15:07:57,593 - Epoch: [157][   60/   74]    Overall Loss 0.328105    Objective Loss 0.328105                                        LR 0.000010    Time 0.028568    
2022-12-15 15:07:57,843 - Epoch: [157][   70/   74]    Overall Loss 0.329189    Objective Loss 0.329189                                        LR 0.000010    Time 0.028046    
2022-12-15 15:07:57,929 - Epoch: [157][   74/   74]    Overall Loss 0.329906    Objective Loss 0.329906    Top1 90.972222    Top5 98.842593    LR 0.000010    Time 0.027697    
2022-12-15 15:07:57,994 - --- validate (epoch=157)-----------
2022-12-15 15:07:57,994 - 2096 samples (256 per mini-batch)
2022-12-15 15:07:58,269 - Epoch: [157][    9/    9]    Loss 1.279450    Top1 64.837786    Top5 90.887405    
2022-12-15 15:07:58,321 - ==> Top1: 64.838    Top5: 90.887    Loss: 1.279

2022-12-15 15:07:58,323 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 125   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   6   0   0   0   2   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   1   0 130   0   4   0   0   0   0   0   4   1   0   0   3   0   0   0   1  12   0   0   1   5   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   7   4   0   2   0   0   0   1   0   0   4   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   1   1   0  15   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   3   4   0   0 150   2   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   1   7   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  11   1   0   2   0   1   1   2   5   0   0   0   0   0   2   2   0 113   0   2   5   0   0   0   0   0   2   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0  10   0   6   0   8   0   6 138   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  12   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  86   0   0   2   4   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  15   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  52   0   9   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   8   2   9   2   0   7   0   0   0   0   1   5   0   0   4   0   3   1   0   6   0   0   0   2   0 130   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:07:58,325 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:07:58,325 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:07:58,346 - 

2022-12-15 15:07:58,347 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:07:58,770 - Epoch: [158][   10/   74]    Overall Loss 0.337537    Objective Loss 0.337537                                        LR 0.000010    Time 0.042268    
2022-12-15 15:07:59,018 - Epoch: [158][   20/   74]    Overall Loss 0.340179    Objective Loss 0.340179                                        LR 0.000010    Time 0.033489    
2022-12-15 15:07:59,266 - Epoch: [158][   30/   74]    Overall Loss 0.341000    Objective Loss 0.341000                                        LR 0.000010    Time 0.030585    
2022-12-15 15:07:59,515 - Epoch: [158][   40/   74]    Overall Loss 0.338260    Objective Loss 0.338260                                        LR 0.000010    Time 0.029162    
2022-12-15 15:07:59,766 - Epoch: [158][   50/   74]    Overall Loss 0.335295    Objective Loss 0.335295                                        LR 0.000010    Time 0.028330    
2022-12-15 15:08:00,017 - Epoch: [158][   60/   74]    Overall Loss 0.331548    Objective Loss 0.331548                                        LR 0.000010    Time 0.027783    
2022-12-15 15:08:00,267 - Epoch: [158][   70/   74]    Overall Loss 0.331170    Objective Loss 0.331170                                        LR 0.000010    Time 0.027383    
2022-12-15 15:08:00,355 - Epoch: [158][   74/   74]    Overall Loss 0.329229    Objective Loss 0.329229    Top1 94.675926    Top5 99.305556    LR 0.000010    Time 0.027089    
2022-12-15 15:08:00,419 - --- validate (epoch=158)-----------
2022-12-15 15:08:00,419 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:00,704 - Epoch: [158][    9/    9]    Loss 1.265492    Top1 64.885496    Top5 90.744275    
2022-12-15 15:08:00,758 - ==> Top1: 64.885    Top5: 90.744    Loss: 1.265

2022-12-15 15:08:00,760 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  14   0   1   1   0   0   0   0   0   1   1   0   0]
 [  0   0 110   0   8   1   1   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 123   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   8   0   0   0   2   1   6   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  0   0   1   0   0   0 129   0   4   2   0   1   0   0   3   1   0   0   2   0   0   0   1  13   0   0   1   5   0   9   0]
 [  0   6   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   1   0   3   0   0   0   0   0   0   4   0   2   0]
 [  0   0   0   0   0   0   7   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  15   0   0   0  20   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   1   8   0   0   1   4   4   0   0 148   2   2   0   1   0   0  11   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  1   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   6   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   9   1   0   2   0   1   2   2   5   0   0   0   0   0   2   3   0 116   0   1   5   0   0   0   0   0   1   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   1   0   2   0   0   0   0   0   1   0   0   1   0   1   0  75   8   0   0   0   0   0   8   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0   9   0   6   0   6   0   6 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  11   0   3   1   0   4   0   0   0   0   0   0   6   0   0   1   2  84   0   0   2   4   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   3   0   0   0   0   3   2   4   0   4   0   5   0   0   2   0   0   0  54   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   9   2  10   2   0   4   0   0   0   0   1   5   0   0   5   0   3   1   0   4   0   0   0   2   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:00,762 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:00,762 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:00,772 - 

2022-12-15 15:08:00,772 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:01,332 - Epoch: [159][   10/   74]    Overall Loss 0.324895    Objective Loss 0.324895                                        LR 0.000010    Time 0.055911    
2022-12-15 15:08:01,584 - Epoch: [159][   20/   74]    Overall Loss 0.332143    Objective Loss 0.332143                                        LR 0.000010    Time 0.040509    
2022-12-15 15:08:01,840 - Epoch: [159][   30/   74]    Overall Loss 0.331415    Objective Loss 0.331415                                        LR 0.000010    Time 0.035546    
2022-12-15 15:08:02,100 - Epoch: [159][   40/   74]    Overall Loss 0.326961    Objective Loss 0.326961                                        LR 0.000010    Time 0.033130    
2022-12-15 15:08:02,355 - Epoch: [159][   50/   74]    Overall Loss 0.328423    Objective Loss 0.328423                                        LR 0.000010    Time 0.031609    
2022-12-15 15:08:02,610 - Epoch: [159][   60/   74]    Overall Loss 0.329336    Objective Loss 0.329336                                        LR 0.000010    Time 0.030577    
2022-12-15 15:08:02,857 - Epoch: [159][   70/   74]    Overall Loss 0.327582    Objective Loss 0.327582                                        LR 0.000010    Time 0.029739    
2022-12-15 15:08:02,946 - Epoch: [159][   74/   74]    Overall Loss 0.328891    Objective Loss 0.328891    Top1 92.824074    Top5 99.537037    LR 0.000010    Time 0.029319    
2022-12-15 15:08:03,019 - --- validate (epoch=159)-----------
2022-12-15 15:08:03,019 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:03,299 - Epoch: [159][    9/    9]    Loss 1.268242    Top1 65.076336    Top5 90.601145    
2022-12-15 15:08:03,357 - ==> Top1: 65.076    Top5: 90.601    Loss: 1.268

2022-12-15 15:08:03,359 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   1   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 124   2   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   6   0   0   0   4   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   1   0 126   0   3   1   0   1   0   0   4   1   0   0   3   0   0   0   1  14   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   6   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   2   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  15   0   0   0   0   0   0   2   0   4   0]
 [  2   0   0   0   1   0   8   0   0   1   3   4   0   0 150   1   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   2   0   1   2   2   4   0   0   0   0   0   2   2   0 118   0   1   5   0   0   0   0   0   2   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   0   0   1   0   1   0  76   9   0   0   0   0   0   8   0   6   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0  11   0   7   0   7   0   5 137   0   0   0   0   2   0   0   3   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0   8   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  88   0   0   2   5   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   5   0   0  54   0   1   0   0]
 [  0   1   2   0   2   3  13   0   1   2   0   0   0   0   3   5   4   0   4   0   4   0   0   1   0   0   0  53   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   1   8   2   0   3   0   0   0   0   1   5   0   0   5   0   3   1   0   6   0   0   0   3   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:03,361 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:03,361 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:03,382 - 

2022-12-15 15:08:03,382 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:03,803 - Epoch: [160][   10/   74]    Overall Loss 0.350580    Objective Loss 0.350580                                        LR 0.000010    Time 0.041963    
2022-12-15 15:08:04,047 - Epoch: [160][   20/   74]    Overall Loss 0.341496    Objective Loss 0.341496                                        LR 0.000010    Time 0.033197    
2022-12-15 15:08:04,298 - Epoch: [160][   30/   74]    Overall Loss 0.332671    Objective Loss 0.332671                                        LR 0.000010    Time 0.030462    
2022-12-15 15:08:04,545 - Epoch: [160][   40/   74]    Overall Loss 0.331690    Objective Loss 0.331690                                        LR 0.000010    Time 0.029018    
2022-12-15 15:08:04,791 - Epoch: [160][   50/   74]    Overall Loss 0.331245    Objective Loss 0.331245                                        LR 0.000010    Time 0.028127    
2022-12-15 15:08:05,037 - Epoch: [160][   60/   74]    Overall Loss 0.330481    Objective Loss 0.330481                                        LR 0.000010    Time 0.027543    
2022-12-15 15:08:05,274 - Epoch: [160][   70/   74]    Overall Loss 0.328347    Objective Loss 0.328347                                        LR 0.000010    Time 0.026986    
2022-12-15 15:08:05,363 - Epoch: [160][   74/   74]    Overall Loss 0.328972    Objective Loss 0.328972    Top1 94.907407    Top5 99.074074    LR 0.000010    Time 0.026728    
2022-12-15 15:08:05,431 - --- validate (epoch=160)-----------
2022-12-15 15:08:05,431 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:05,707 - Epoch: [160][    9/    9]    Loss 1.300460    Top1 65.028626    Top5 90.791985    
2022-12-15 15:08:05,763 - ==> Top1: 65.029    Top5: 90.792    Loss: 1.300

2022-12-15 15:08:05,765 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 113   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 126   0   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   6   0   0   0   3   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   1   0 129   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   6   5   0   2   0   0   0   0   0   0   5   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   2   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   3   4   0   0 150   2   2   0   2   0   0  11   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  12   1   0   2   0   1   1   2   5   0   0   0   0   0   2   3   0 114   0   1   5   0   0   0   0   0   1   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74   9   0   0   0   0   0   7   0   9   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0   9   0   6   0   7   0   6 140   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  11   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  87   0   0   2   2   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   1   0   6   0   0  53   0   1   0   0]
 [  0   0   2   0   2   3  15   0   1   3   0   0   0   0   3   2   4   0   4   0   5   0   0   0   0   0   0  54   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   1   0   0   8   2  10   2   0   5   0   0   0   0   1   5   0   0   3   0   3   1   0   5   0   0   0   2   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:08:05,767 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:05,767 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:05,777 - 

2022-12-15 15:08:05,778 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:06,197 - Epoch: [161][   10/   74]    Overall Loss 0.337287    Objective Loss 0.337287                                        LR 0.000010    Time 0.041845    
2022-12-15 15:08:06,448 - Epoch: [161][   20/   74]    Overall Loss 0.335547    Objective Loss 0.335547                                        LR 0.000010    Time 0.033444    
2022-12-15 15:08:06,698 - Epoch: [161][   30/   74]    Overall Loss 0.337570    Objective Loss 0.337570                                        LR 0.000010    Time 0.030623    
2022-12-15 15:08:06,948 - Epoch: [161][   40/   74]    Overall Loss 0.334483    Objective Loss 0.334483                                        LR 0.000010    Time 0.029220    
2022-12-15 15:08:07,197 - Epoch: [161][   50/   74]    Overall Loss 0.332198    Objective Loss 0.332198                                        LR 0.000010    Time 0.028333    
2022-12-15 15:08:07,445 - Epoch: [161][   60/   74]    Overall Loss 0.332828    Objective Loss 0.332828                                        LR 0.000010    Time 0.027745    
2022-12-15 15:08:07,688 - Epoch: [161][   70/   74]    Overall Loss 0.330613    Objective Loss 0.330613                                        LR 0.000010    Time 0.027242    
2022-12-15 15:08:07,779 - Epoch: [161][   74/   74]    Overall Loss 0.328921    Objective Loss 0.328921    Top1 95.138889    Top5 98.611111    LR 0.000010    Time 0.027001    
2022-12-15 15:08:07,839 - --- validate (epoch=161)-----------
2022-12-15 15:08:07,839 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:08,116 - Epoch: [161][    9/    9]    Loss 1.336072    Top1 64.933206    Top5 90.696565    
2022-12-15 15:08:08,169 - ==> Top1: 64.933    Top5: 90.697    Loss: 1.336

2022-12-15 15:08:08,171 - ==> Confusion:
[[ 18   1   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   8   1   0   6   2   0   1   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 112   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   9   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   7   0 126   0   6   0   0   0   0   0   0   0   0   1   0   0   4   0   0   2   0   7   0   0   0   1   1   6   0]
 [  0   3   0   0   0  37   0   0   0   0   0   0   0   0   0   0   1   0   4   0   1   5   0   0   0   0   1   1   2   0   0]
 [  0   0   1   0   0   0 131   0   4   0   0   1   0   0   4   1   0   0   2   0   0   0   1  13   0   0   1   4   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   6   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  10   0   0   0   0   0   2   0   0   5   0   1   1   0   4   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  16   0   0   0  19   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   1   0   0   2   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   8   0   0   1   3   5   0   0 148   2   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   2   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   0   1   2   2   6   0   0   0   0   0   3   1   0 111   0   2   5   0   0   0   0   0   1   4   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0  10   0   7   0   6   0   6 138   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  12   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  87   0   0   2   3   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   1   6   0   0  54   0   1   0   0]
 [  0   1   2   0   2   3  14   0   1   2   0   0   0   0   3   3   4   0   4   0   3   0   0   2   0   0   0  54   0  10   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   5   0   0   2   0   7   0   0   0   0   9   0   0]
 [  0   0   0   0  10   2  11   2   0   6   0   0   0   0   1   4   0   0   4   0   2   1   0   4   0   0   0   2   0 131   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:08,173 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:08,173 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:08,193 - 

2022-12-15 15:08:08,193 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:08,616 - Epoch: [162][   10/   74]    Overall Loss 0.355261    Objective Loss 0.355261                                        LR 0.000010    Time 0.042205    
2022-12-15 15:08:08,857 - Epoch: [162][   20/   74]    Overall Loss 0.335051    Objective Loss 0.335051                                        LR 0.000010    Time 0.033121    
2022-12-15 15:08:09,115 - Epoch: [162][   30/   74]    Overall Loss 0.334800    Objective Loss 0.334800                                        LR 0.000010    Time 0.030670    
2022-12-15 15:08:09,372 - Epoch: [162][   40/   74]    Overall Loss 0.330138    Objective Loss 0.330138                                        LR 0.000010    Time 0.029417    
2022-12-15 15:08:09,629 - Epoch: [162][   50/   74]    Overall Loss 0.330540    Objective Loss 0.330540                                        LR 0.000010    Time 0.028667    
2022-12-15 15:08:09,883 - Epoch: [162][   60/   74]    Overall Loss 0.330304    Objective Loss 0.330304                                        LR 0.000010    Time 0.028108    
2022-12-15 15:08:10,138 - Epoch: [162][   70/   74]    Overall Loss 0.328655    Objective Loss 0.328655                                        LR 0.000010    Time 0.027735    
2022-12-15 15:08:10,227 - Epoch: [162][   74/   74]    Overall Loss 0.328420    Objective Loss 0.328420    Top1 93.981481    Top5 99.537037    LR 0.000010    Time 0.027435    
2022-12-15 15:08:10,294 - --- validate (epoch=162)-----------
2022-12-15 15:08:10,294 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:10,571 - Epoch: [162][    9/    9]    Loss 1.297012    Top1 65.171756    Top5 90.887405    
2022-12-15 15:08:10,637 - ==> Top1: 65.172    Top5: 90.887    Loss: 1.297

2022-12-15 15:08:10,639 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   1   0   5   1   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   2   0   0   0   0   0   0   1   0   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   8   0 124   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   6   0   0   0   3   1   5   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  1   0   1   0   0   0 130   0   4   1   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0   8   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   7   4   0   2   0   0   0   1   0   0   4   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   2   0   0   2   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  15   0   0   0   0   0   0   2   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   7   4   0   0 147   2   2   0   2   0   0  11   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   2   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   1   1   1   2   6   0   0   0   0   0   2   2   0 114   0   1   5   0   0   0   0   0   2   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  76   9   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   0   0   0   0   0   0   0   1   0   0   9   0   7   0   6   0   5 141   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  12   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  87   0   0   2   3   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  15   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   1   0   0   0  53   0   9   0]
 [  1   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   1  10   2   0   5   0   0   0   0   1   5   0   0   5   0   3   1   0   4   0   0   0   2   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:10,640 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:10,640 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:10,650 - 

2022-12-15 15:08:10,650 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:11,057 - Epoch: [163][   10/   74]    Overall Loss 0.334035    Objective Loss 0.334035                                        LR 0.000010    Time 0.040648    
2022-12-15 15:08:11,303 - Epoch: [163][   20/   74]    Overall Loss 0.346151    Objective Loss 0.346151                                        LR 0.000010    Time 0.032590    
2022-12-15 15:08:11,559 - Epoch: [163][   30/   74]    Overall Loss 0.342193    Objective Loss 0.342193                                        LR 0.000010    Time 0.030257    
2022-12-15 15:08:11,816 - Epoch: [163][   40/   74]    Overall Loss 0.341150    Objective Loss 0.341150                                        LR 0.000010    Time 0.029091    
2022-12-15 15:08:12,071 - Epoch: [163][   50/   74]    Overall Loss 0.337323    Objective Loss 0.337323                                        LR 0.000010    Time 0.028378    
2022-12-15 15:08:12,325 - Epoch: [163][   60/   74]    Overall Loss 0.331654    Objective Loss 0.331654                                        LR 0.000010    Time 0.027870    
2022-12-15 15:08:12,573 - Epoch: [163][   70/   74]    Overall Loss 0.329350    Objective Loss 0.329350                                        LR 0.000010    Time 0.027423    
2022-12-15 15:08:12,661 - Epoch: [163][   74/   74]    Overall Loss 0.328186    Objective Loss 0.328186    Top1 92.824074    Top5 99.074074    LR 0.000010    Time 0.027130    
2022-12-15 15:08:12,727 - --- validate (epoch=163)-----------
2022-12-15 15:08:12,727 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:13,005 - Epoch: [163][    9/    9]    Loss 1.254868    Top1 65.362595    Top5 90.791985    
2022-12-15 15:08:13,054 - ==> Top1: 65.363    Top5: 90.792    Loss: 1.255

2022-12-15 15:08:13,056 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 114   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 125   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   7   0   0   0   4   1   5   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  1   0   1   0   0   0 130   0   5   0   0   1   0   0   3   1   0   0   3   0   0   0   1  12   0   0   1   5   0   8   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   4   0   2   0]
 [  0   0   0   0   0   0   6   0   7   4   0   2   0   0   0   1   0   0   4   0   0   1   0   6   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  16   0   0   0  19   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   5   4   0   0 149   1   3   0   1   0   0  11   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  1   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   6   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   2   1   1   1   2   5   0   0   0   0   0   2   2   0 115   0   2   5   0   0   0   0   0   1   4   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74   9   0   0   0   0   0   7   0   9   0]
 [  0   3   0   0   0   0   0   0   0   0   0   2   0   0  10   0   6   0   8   0   5 138   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  10   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  88   0   0   2   4   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   1   6   0   0  54   0   1   0   0]
 [  0   1   2   0   2   3  13   0   1   2   0   0   0   0   3   4   4   0   4   0   3   0   0   2   0   0   0  54   0  10   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  1   0   0   0   9   0   9   2   0   6   0   0   0   0   1   4   0   0   4   0   3   1   0   7   0   0   0   2   0 131   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:13,057 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:13,057 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:13,077 - 

2022-12-15 15:08:13,078 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:13,498 - Epoch: [164][   10/   74]    Overall Loss 0.329690    Objective Loss 0.329690                                        LR 0.000010    Time 0.042017    
2022-12-15 15:08:13,745 - Epoch: [164][   20/   74]    Overall Loss 0.325882    Objective Loss 0.325882                                        LR 0.000010    Time 0.033294    
2022-12-15 15:08:13,991 - Epoch: [164][   30/   74]    Overall Loss 0.325664    Objective Loss 0.325664                                        LR 0.000010    Time 0.030385    
2022-12-15 15:08:14,234 - Epoch: [164][   40/   74]    Overall Loss 0.328565    Objective Loss 0.328565                                        LR 0.000010    Time 0.028873    
2022-12-15 15:08:14,479 - Epoch: [164][   50/   74]    Overall Loss 0.328761    Objective Loss 0.328761                                        LR 0.000010    Time 0.027991    
2022-12-15 15:08:14,724 - Epoch: [164][   60/   74]    Overall Loss 0.328757    Objective Loss 0.328757                                        LR 0.000010    Time 0.027394    
2022-12-15 15:08:14,966 - Epoch: [164][   70/   74]    Overall Loss 0.328128    Objective Loss 0.328128                                        LR 0.000010    Time 0.026936    
2022-12-15 15:08:15,054 - Epoch: [164][   74/   74]    Overall Loss 0.328381    Objective Loss 0.328381    Top1 93.055556    Top5 99.305556    LR 0.000010    Time 0.026660    
2022-12-15 15:08:15,112 - --- validate (epoch=164)-----------
2022-12-15 15:08:15,112 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:15,682 - Epoch: [164][    9/    9]    Loss 1.260086    Top1 65.219466    Top5 90.458015    
2022-12-15 15:08:15,738 - ==> Top1: 65.219    Top5: 90.458    Loss: 1.260

2022-12-15 15:08:15,740 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 111   0   9   0   0   1   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   8   0 123   1   3   0   0   0   0   0   0   0   0   2   0   0   4   0   0   3   0   6   0   0   0   5   1   5   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  1   0   0   0   0   0 128   0   3   1   0   1   0   0   4   2   0   0   2   0   0   0   1  13   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   5   0   1  10   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  15   0   0   0   0   0   0   2   0   4   0]
 [  1   0   0   0   1   0   6   0   0   1   2   4   0   0 155   0   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   7   0   0   2   0   0   0   0   1   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   0   1   2   2   5   0   0   0   0   0   2   3   0 115   0   1   5   0   0   0   0   0   1   2   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   0   0   1   0   1   0  75   9   0   0   0   0   0   8   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0  10   0   7   0   6   0   5 139   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  11   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  86   0   0   2   3   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   1   0   5   0   0  53   0   1   0   0]
 [  0   0   2   0   2   3  12   0   1   2   0   0   0   0   3   4   4   0   4   0   4   0   0   2   0   0   0  55   0  10   0]
 [  1   2   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  1   0   0   0  10   2   8   2   0   5   0   0   0   0   1   4   0   0   5   0   2   1   0   5   0   0   0   2   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:15,741 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:15,741 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:15,751 - 

2022-12-15 15:08:15,751 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:16,134 - Epoch: [165][   10/   74]    Overall Loss 0.337399    Objective Loss 0.337399                                        LR 0.000010    Time 0.038180    
2022-12-15 15:08:16,344 - Epoch: [165][   20/   74]    Overall Loss 0.322135    Objective Loss 0.322135                                        LR 0.000010    Time 0.029599    
2022-12-15 15:08:16,560 - Epoch: [165][   30/   74]    Overall Loss 0.329060    Objective Loss 0.329060                                        LR 0.000010    Time 0.026922    
2022-12-15 15:08:16,780 - Epoch: [165][   40/   74]    Overall Loss 0.325432    Objective Loss 0.325432                                        LR 0.000010    Time 0.025668    
2022-12-15 15:08:17,008 - Epoch: [165][   50/   74]    Overall Loss 0.325700    Objective Loss 0.325700                                        LR 0.000010    Time 0.025079    
2022-12-15 15:08:17,271 - Epoch: [165][   60/   74]    Overall Loss 0.328918    Objective Loss 0.328918                                        LR 0.000010    Time 0.025288    
2022-12-15 15:08:17,513 - Epoch: [165][   70/   74]    Overall Loss 0.327071    Objective Loss 0.327071                                        LR 0.000010    Time 0.025090    
2022-12-15 15:08:17,600 - Epoch: [165][   74/   74]    Overall Loss 0.327730    Objective Loss 0.327730    Top1 93.287037    Top5 99.074074    LR 0.000010    Time 0.024911    
2022-12-15 15:08:17,656 - --- validate (epoch=165)-----------
2022-12-15 15:08:17,656 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:17,932 - Epoch: [165][    9/    9]    Loss 1.294252    Top1 64.790076    Top5 90.982824    
2022-12-15 15:08:17,981 - ==> Top1: 64.790    Top5: 90.983    Loss: 1.294

2022-12-15 15:08:17,983 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 114   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 123   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   7   0   0   0   3   1   6   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  0   0   1   0   0   0 129   0   4   0   0   1   0   0   4   1   0   0   2   0   0   0   1  14   0   0   1   4   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   1   1   0  15   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   8   0   0   1   5   4   0   0 147   2   3   0   1   0   0  11   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   6   0   0   5   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   2   0   1   2   2   6   0   0   0   0   0   2   3   0 114   0   2   5   0   0   0   0   0   1   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   0   0   1   0   1   0  75   9   0   0   0   0   0   8   0   8   0]
 [  0   2   0   0   0   0   0   0   0   0   0   2   0   0  10   0   6   0   9   0   5 138   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  12   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  87   0   0   2   3   1   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   1   1   6   0   0  53   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   1   0   0   0  53   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   4   0   0   2   0   7   0   0   0   0   9   0   0]
 [  0   0   0   0   9   2  11   2   0   6   0   0   0   0   1   4   0   0   4   0   2   1   0   5   0   0   0   2   0 131   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:17,984 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:17,984 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:18,004 - 

2022-12-15 15:08:18,005 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:18,403 - Epoch: [166][   10/   74]    Overall Loss 0.330743    Objective Loss 0.330743                                        LR 0.000010    Time 0.039778    
2022-12-15 15:08:18,614 - Epoch: [166][   20/   74]    Overall Loss 0.342304    Objective Loss 0.342304                                        LR 0.000010    Time 0.030386    
2022-12-15 15:08:18,831 - Epoch: [166][   30/   74]    Overall Loss 0.337278    Objective Loss 0.337278                                        LR 0.000010    Time 0.027494    
2022-12-15 15:08:19,046 - Epoch: [166][   40/   74]    Overall Loss 0.328183    Objective Loss 0.328183                                        LR 0.000010    Time 0.025982    
2022-12-15 15:08:19,263 - Epoch: [166][   50/   74]    Overall Loss 0.327149    Objective Loss 0.327149                                        LR 0.000010    Time 0.025121    
2022-12-15 15:08:19,479 - Epoch: [166][   60/   74]    Overall Loss 0.329407    Objective Loss 0.329407                                        LR 0.000010    Time 0.024528    
2022-12-15 15:08:19,692 - Epoch: [166][   70/   74]    Overall Loss 0.328808    Objective Loss 0.328808                                        LR 0.000010    Time 0.024058    
2022-12-15 15:08:19,778 - Epoch: [166][   74/   74]    Overall Loss 0.328215    Objective Loss 0.328215    Top1 93.287037    Top5 97.916667    LR 0.000010    Time 0.023913    
2022-12-15 15:08:19,849 - --- validate (epoch=166)-----------
2022-12-15 15:08:19,849 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:20,120 - Epoch: [166][    9/    9]    Loss 1.255591    Top1 64.837786    Top5 90.887405    
2022-12-15 15:08:20,167 - ==> Top1: 64.838    Top5: 90.887    Loss: 1.256

2022-12-15 15:08:20,169 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   8   1   0   6   2   0   1   0   2   0   0   0   0   0   0   0   0  12   0   1   2   0   0   0   0   0   1   1   1   0]
 [  0   0 113   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   7   0 126   0   3   0   0   0   0   0   0   0   0   2   0   0   4   0   0   2   0   6   0   0   0   4   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  1   0   0   0   1   0 125   0   4   2   0   1   0   0   3   2   0   0   2   0   0   0   1  13   0   0   1   5   0  11   0]
 [  0   6   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   1   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   4   0   2   0   0   0   1   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   0   0   0   4   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  14   0   0   0   0   0   0   2   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   4   4   0   0 150   1   2   0   1   0   0  12   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  11   1   0   2   1   1   0   2   5   0   0   0   0   0   2   1   0 114   0   1   5   0   0   0   0   0   2   4   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75  10   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0   9   0   6   0   7   0   6 140   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  11   0   2   1   0   4   0   0   0   0   0   0   7   0   0   1   2  85   0   0   2   4   2   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   3   0   0   0   0   3   3   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0  10   1   9   2   0   5   0   0   0   0   1   5   0   0   5   0   3   1   0   4   0   0   0   2   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:20,171 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:20,171 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:20,182 - 

2022-12-15 15:08:20,182 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:20,604 - Epoch: [167][   10/   74]    Overall Loss 0.318259    Objective Loss 0.318259                                        LR 0.000010    Time 0.042101    
2022-12-15 15:08:20,848 - Epoch: [167][   20/   74]    Overall Loss 0.318686    Objective Loss 0.318686                                        LR 0.000010    Time 0.033266    
2022-12-15 15:08:21,073 - Epoch: [167][   30/   74]    Overall Loss 0.320221    Objective Loss 0.320221                                        LR 0.000010    Time 0.029642    
2022-12-15 15:08:21,305 - Epoch: [167][   40/   74]    Overall Loss 0.323527    Objective Loss 0.323527                                        LR 0.000010    Time 0.028030    
2022-12-15 15:08:21,526 - Epoch: [167][   50/   74]    Overall Loss 0.320955    Objective Loss 0.320955                                        LR 0.000010    Time 0.026826    
2022-12-15 15:08:21,755 - Epoch: [167][   60/   74]    Overall Loss 0.324460    Objective Loss 0.324460                                        LR 0.000010    Time 0.026163    
2022-12-15 15:08:21,967 - Epoch: [167][   70/   74]    Overall Loss 0.325916    Objective Loss 0.325916                                        LR 0.000010    Time 0.025461    
2022-12-15 15:08:22,045 - Epoch: [167][   74/   74]    Overall Loss 0.328423    Objective Loss 0.328423    Top1 91.203704    Top5 98.611111    LR 0.000010    Time 0.025134    
2022-12-15 15:08:22,112 - --- validate (epoch=167)-----------
2022-12-15 15:08:22,112 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:22,394 - Epoch: [167][    9/    9]    Loss 1.265943    Top1 65.219466    Top5 90.696565    
2022-12-15 15:08:22,449 - ==> Top1: 65.219    Top5: 90.697    Loss: 1.266

2022-12-15 15:08:22,452 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 113   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   7   0 125   1   3   0   0   0   0   0   0   0   0   2   0   0   4   0   0   2   0   6   0   0   0   5   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  1   0   1   0   0   0 128   0   4   1   0   1   0   0   3   1   0   0   2   0   0   0   1  13   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   4   0   2   0]
 [  0   0   0   0   0   0   6   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  15   0   0   0  20   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   0   1   0  15   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   6   3   0   0 150   1   2   0   1   0   0  10   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   1   0   0   0   5   0   2   0]
 [  1   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   6   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  11   1   0   2   0   1   2   2   5   0   0   0   0   0   2   3   0 113   0   2   5   0   0   0   0   0   1   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74  10   0   0   0   0   0   7   0   9   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0   9   0   6   0   7   0   6 140   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  10   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  85   0   0   2   4   3   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   3   0   0   0   0   3   2   4   0   4   0   5   0   0   1   0   0   0  54   0  10   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   3   9   2   1   3   0   0   0   0   1   4   0   0   4   0   2   1   0   5   0   0   0   2   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:22,454 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:22,454 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:22,464 - 

2022-12-15 15:08:22,464 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:22,867 - Epoch: [168][   10/   74]    Overall Loss 0.311298    Objective Loss 0.311298                                        LR 0.000010    Time 0.040205    
2022-12-15 15:08:23,108 - Epoch: [168][   20/   74]    Overall Loss 0.310016    Objective Loss 0.310016                                        LR 0.000010    Time 0.032151    
2022-12-15 15:08:23,363 - Epoch: [168][   30/   74]    Overall Loss 0.315814    Objective Loss 0.315814                                        LR 0.000010    Time 0.029930    
2022-12-15 15:08:23,624 - Epoch: [168][   40/   74]    Overall Loss 0.321883    Objective Loss 0.321883                                        LR 0.000010    Time 0.028954    
2022-12-15 15:08:23,884 - Epoch: [168][   50/   74]    Overall Loss 0.325495    Objective Loss 0.325495                                        LR 0.000010    Time 0.028360    
2022-12-15 15:08:24,141 - Epoch: [168][   60/   74]    Overall Loss 0.327085    Objective Loss 0.327085                                        LR 0.000010    Time 0.027894    
2022-12-15 15:08:24,385 - Epoch: [168][   70/   74]    Overall Loss 0.328672    Objective Loss 0.328672                                        LR 0.000010    Time 0.027394    
2022-12-15 15:08:24,474 - Epoch: [168][   74/   74]    Overall Loss 0.327026    Objective Loss 0.327026    Top1 93.750000    Top5 100.000000    LR 0.000010    Time 0.027114    
2022-12-15 15:08:24,535 - --- validate (epoch=168)-----------
2022-12-15 15:08:24,536 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:24,803 - Epoch: [168][    9/    9]    Loss 1.296684    Top1 64.885496    Top5 90.267176    
2022-12-15 15:08:24,865 - ==> Top1: 64.885    Top5: 90.267    Loss: 1.297

2022-12-15 15:08:24,867 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   1   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   2   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   8   1   1   0   0   0   0   0   0   0   0   0   0   0   2   0   1   1   0   7   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   7   0 126   0   3   0   0   0   0   0   0   0   0   2   0   0   4   0   0   2   0   6   0   0   0   4   1   6   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  0   0   0   0   0   0 129   0   4   1   0   1   0   0   4   1   0   0   1   0   0   0   1  14   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   7   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   5   0   1  10   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  15   0   0   0  20   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   8   0   0   1   6   4   0   0 148   1   2   0   1   0   0  10   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   3   0   0   0   0   0   1   1   0   0]
 [  3  11   1   0   2   1   1   1   2   6   0   0   0   0   0   2   2   0 112   0   1   5   0   0   0   0   0   1   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0  11   0   7   0   6   0   6 137   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  12   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  86   0   0   2   3   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   1   0   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   5   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   3   4   0   4   0   4   1   0   2   0   0   0  54   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   8   2   9   2   0   5   0   0   0   0   1   5   0   0   3   0   3   2   0   5   0   0   0   3   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:24,869 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:24,869 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:24,879 - 

2022-12-15 15:08:24,879 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:25,310 - Epoch: [169][   10/   74]    Overall Loss 0.308430    Objective Loss 0.308430                                        LR 0.000010    Time 0.043006    
2022-12-15 15:08:25,564 - Epoch: [169][   20/   74]    Overall Loss 0.322495    Objective Loss 0.322495                                        LR 0.000010    Time 0.034189    
2022-12-15 15:08:25,817 - Epoch: [169][   30/   74]    Overall Loss 0.320877    Objective Loss 0.320877                                        LR 0.000010    Time 0.031213    
2022-12-15 15:08:26,072 - Epoch: [169][   40/   74]    Overall Loss 0.324479    Objective Loss 0.324479                                        LR 0.000010    Time 0.029755    
2022-12-15 15:08:26,332 - Epoch: [169][   50/   74]    Overall Loss 0.325304    Objective Loss 0.325304                                        LR 0.000010    Time 0.029006    
2022-12-15 15:08:26,587 - Epoch: [169][   60/   74]    Overall Loss 0.324455    Objective Loss 0.324455                                        LR 0.000010    Time 0.028419    
2022-12-15 15:08:26,835 - Epoch: [169][   70/   74]    Overall Loss 0.325201    Objective Loss 0.325201                                        LR 0.000010    Time 0.027887    
2022-12-15 15:08:26,923 - Epoch: [169][   74/   74]    Overall Loss 0.327187    Objective Loss 0.327187    Top1 92.824074    Top5 99.305556    LR 0.000010    Time 0.027568    
2022-12-15 15:08:26,992 - --- validate (epoch=169)-----------
2022-12-15 15:08:26,992 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:27,261 - Epoch: [169][    9/    9]    Loss 1.288407    Top1 65.171756    Top5 90.410305    
2022-12-15 15:08:27,320 - ==> Top1: 65.172    Top5: 90.410    Loss: 1.288

2022-12-15 15:08:27,322 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 110   0   9   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 127   0   3   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   8   0   0   0   3   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  1   1   1   0   1   0 126   0   4   2   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   5   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  14   0   0   0   0   0   0   1   0   4   0]
 [  1   0   1   0   1   1   6   0   0   1   2   4   0   0 154   0   2   0   1   0   0  11   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   5   0   0   4   0   0   0   0   2   5   0   0   3   0   0   0   0   2   0   0   0   5   0   2   0]
 [  2   0   0   0   0   4   0   0   0   0   0   0   0   0   2   1  32   0   5   0   1   4   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  14   1   0   2   0   1   2   2   3   0   0   0   0   0   1   1   0 112   0   1   5   0   0   0   0   0   3   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74   9   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0  10   0   6   0   6   0   6 140   0   0   0   0   1   0   0   3   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  10   0   2   1   0   4   0   0   0   0   0   0   7   0   0   1   2  85   0   0   2   5   2   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   0   0   0   1   0   0   1   0   1   0   0   0   2   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   2   0   0   1   0   1   0   0   0   0   0   0   6   0   0  55   0   1   0   0]
 [  0   0   2   0   2   3  12   1   1   2   0   0   0   0   3   4   4   0   4   0   4   0   0   2   0   0   0  54   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   1   0   0   9   2   9   2   0   3   0   0   0   0   1   5   0   0   4   0   2   1   0   4   0   0   0   2   0 135   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:08:27,324 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:27,324 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:27,344 - 

2022-12-15 15:08:27,344 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:27,738 - Epoch: [170][   10/   74]    Overall Loss 0.319145    Objective Loss 0.319145                                        LR 0.000001    Time 0.039301    
2022-12-15 15:08:27,948 - Epoch: [170][   20/   74]    Overall Loss 0.320546    Objective Loss 0.320546                                        LR 0.000001    Time 0.030114    
2022-12-15 15:08:28,169 - Epoch: [170][   30/   74]    Overall Loss 0.318607    Objective Loss 0.318607                                        LR 0.000001    Time 0.027429    
2022-12-15 15:08:28,383 - Epoch: [170][   40/   74]    Overall Loss 0.324574    Objective Loss 0.324574                                        LR 0.000001    Time 0.025916    
2022-12-15 15:08:28,596 - Epoch: [170][   50/   74]    Overall Loss 0.321506    Objective Loss 0.321506                                        LR 0.000001    Time 0.024971    
2022-12-15 15:08:28,810 - Epoch: [170][   60/   74]    Overall Loss 0.322847    Objective Loss 0.322847                                        LR 0.000001    Time 0.024369    
2022-12-15 15:08:29,022 - Epoch: [170][   70/   74]    Overall Loss 0.324275    Objective Loss 0.324275                                        LR 0.000001    Time 0.023916    
2022-12-15 15:08:29,100 - Epoch: [170][   74/   74]    Overall Loss 0.324763    Objective Loss 0.324763    Top1 92.129630    Top5 99.074074    LR 0.000001    Time 0.023671    
2022-12-15 15:08:29,168 - --- validate (epoch=170)-----------
2022-12-15 15:08:29,169 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:29,740 - Epoch: [170][    9/    9]    Loss 1.317008    Top1 65.362595    Top5 90.505725    
2022-12-15 15:08:29,798 - ==> Top1: 65.363    Top5: 90.506    Loss: 1.317

2022-12-15 15:08:29,800 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 111   0   8   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 126   0   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   7   0   0   0   3   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  1   0   1   0   0   0 130   0   4   0   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   4   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  15   0   0   0   0   0   0   2   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   2   4   0   0 153   0   2   0   1   0   0  12   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  12   1   0   2   0   1   2   2   5   0   0   0   0   0   2   1   0 113   0   1   5   0   0   0   0   0   2   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0   9   0   6   0   6   0   5 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  18   0  11   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  84   0   0   2   3   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   9   0   0]
 [  0   0   0   0  10   2   8   2   0   4   0   0   0   0   1   5   0   0   5   0   2   1   0   4   0   0   0   3   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:29,802 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:29,802 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:29,811 - 

2022-12-15 15:08:29,812 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:30,198 - Epoch: [171][   10/   74]    Overall Loss 0.327066    Objective Loss 0.327066                                        LR 0.000001    Time 0.038553    
2022-12-15 15:08:30,404 - Epoch: [171][   20/   74]    Overall Loss 0.320949    Objective Loss 0.320949                                        LR 0.000001    Time 0.029581    
2022-12-15 15:08:30,649 - Epoch: [171][   30/   74]    Overall Loss 0.313889    Objective Loss 0.313889                                        LR 0.000001    Time 0.027861    
2022-12-15 15:08:30,899 - Epoch: [171][   40/   74]    Overall Loss 0.317836    Objective Loss 0.317836                                        LR 0.000001    Time 0.027140    
2022-12-15 15:08:31,152 - Epoch: [171][   50/   74]    Overall Loss 0.319159    Objective Loss 0.319159                                        LR 0.000001    Time 0.026759    
2022-12-15 15:08:31,408 - Epoch: [171][   60/   74]    Overall Loss 0.321591    Objective Loss 0.321591                                        LR 0.000001    Time 0.026549    
2022-12-15 15:08:31,653 - Epoch: [171][   70/   74]    Overall Loss 0.324289    Objective Loss 0.324289                                        LR 0.000001    Time 0.026260    
2022-12-15 15:08:31,741 - Epoch: [171][   74/   74]    Overall Loss 0.324084    Objective Loss 0.324084    Top1 92.361111    Top5 99.074074    LR 0.000001    Time 0.026024    
2022-12-15 15:08:31,802 - --- validate (epoch=171)-----------
2022-12-15 15:08:31,802 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:32,078 - Epoch: [171][    9/    9]    Loss 1.263940    Top1 65.362595    Top5 90.553435    
2022-12-15 15:08:32,132 - ==> Top1: 65.363    Top5: 90.553    Loss: 1.264

2022-12-15 15:08:32,134 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 126   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   7   0   0   0   3   1   5   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  1   0   1   0   0   0 128   0   3   1   0   1   0   0   4   1   0   0   3   0   0   0   1  13   0   0   1   5   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  15   0   0   0  20   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   2   4   0   0 153   0   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   7   0   0   2   0   0   0   0   1   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  11   1   0   2   0   1   2   2   4   0   0   0   0   0   2   1   0 115   0   1   5   0   0   0   0   0   2   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0  10   0   6   0   9   0   6 137   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  10   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  87   0   0   2   4   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  52   0  10   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   2   8   2   0   5   0   0   0   0   1   5   0   0   5   0   3   1   0   4   0   0   0   2   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:32,135 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:32,135 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:32,156 - 

2022-12-15 15:08:32,156 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:32,570 - Epoch: [172][   10/   74]    Overall Loss 0.299838    Objective Loss 0.299838                                        LR 0.000001    Time 0.041326    
2022-12-15 15:08:32,793 - Epoch: [172][   20/   74]    Overall Loss 0.314222    Objective Loss 0.314222                                        LR 0.000001    Time 0.031744    
2022-12-15 15:08:33,010 - Epoch: [172][   30/   74]    Overall Loss 0.314808    Objective Loss 0.314808                                        LR 0.000001    Time 0.028416    
2022-12-15 15:08:33,228 - Epoch: [172][   40/   74]    Overall Loss 0.316870    Objective Loss 0.316870                                        LR 0.000001    Time 0.026748    
2022-12-15 15:08:33,449 - Epoch: [172][   50/   74]    Overall Loss 0.316876    Objective Loss 0.316876                                        LR 0.000001    Time 0.025811    
2022-12-15 15:08:33,667 - Epoch: [172][   60/   74]    Overall Loss 0.320349    Objective Loss 0.320349                                        LR 0.000001    Time 0.025135    
2022-12-15 15:08:33,876 - Epoch: [172][   70/   74]    Overall Loss 0.322959    Objective Loss 0.322959                                        LR 0.000001    Time 0.024523    
2022-12-15 15:08:33,963 - Epoch: [172][   74/   74]    Overall Loss 0.324072    Objective Loss 0.324072    Top1 92.592593    Top5 99.305556    LR 0.000001    Time 0.024372    
2022-12-15 15:08:34,024 - --- validate (epoch=172)-----------
2022-12-15 15:08:34,024 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:34,299 - Epoch: [172][    9/    9]    Loss 1.308426    Top1 65.362595    Top5 90.696565    
2022-12-15 15:08:34,355 - ==> Top1: 65.363    Top5: 90.697    Loss: 1.308

2022-12-15 15:08:34,357 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 113   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   1   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 125   0   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   6   0   0   0   5   1   5   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  0   0   0   0   0   0 130   0   3   2   0   1   0   0   3   1   0   0   2   0   0   0   1  13   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   4   0   2   0   0   0   1   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   3   4   0   0 152   0   2   0   1   0   0  12   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   7   0   0   2   0   0   0   0   1   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   0   1   2   2   5   0   0   0   0   0   2   2   0 115   0   1   5   0   0   0   0   0   2   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   0   0   0   0   0   0   0   2   0   0  11   0   6   0   6   0   6 138   0   0   0   0   1   0   1   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  11   0   2   1   0   3   0   0   0   0   0   0   6   0   0   1   2  87   0   0   2   4   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0  10   2   9   2   0   4   0   0   0   0   1   5   0   0   5   0   2   1   0   4   0   0   0   3   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:34,359 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:34,359 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:34,369 - 

2022-12-15 15:08:34,369 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:34,813 - Epoch: [173][   10/   74]    Overall Loss 0.351121    Objective Loss 0.351121                                        LR 0.000001    Time 0.044300    
2022-12-15 15:08:35,061 - Epoch: [173][   20/   74]    Overall Loss 0.332136    Objective Loss 0.332136                                        LR 0.000001    Time 0.034547    
2022-12-15 15:08:35,318 - Epoch: [173][   30/   74]    Overall Loss 0.324841    Objective Loss 0.324841                                        LR 0.000001    Time 0.031576    
2022-12-15 15:08:35,567 - Epoch: [173][   40/   74]    Overall Loss 0.324467    Objective Loss 0.324467                                        LR 0.000001    Time 0.029909    
2022-12-15 15:08:35,822 - Epoch: [173][   50/   74]    Overall Loss 0.326411    Objective Loss 0.326411                                        LR 0.000001    Time 0.028987    
2022-12-15 15:08:36,070 - Epoch: [173][   60/   74]    Overall Loss 0.327483    Objective Loss 0.327483                                        LR 0.000001    Time 0.028280    
2022-12-15 15:08:36,320 - Epoch: [173][   70/   74]    Overall Loss 0.324985    Objective Loss 0.324985                                        LR 0.000001    Time 0.027811    
2022-12-15 15:08:36,409 - Epoch: [173][   74/   74]    Overall Loss 0.324151    Objective Loss 0.324151    Top1 92.361111    Top5 99.537037    LR 0.000001    Time 0.027505    
2022-12-15 15:08:36,469 - --- validate (epoch=173)-----------
2022-12-15 15:08:36,469 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:36,746 - Epoch: [173][    9/    9]    Loss 1.281776    Top1 65.362595    Top5 90.696565    
2022-12-15 15:08:36,799 - ==> Top1: 65.363    Top5: 90.697    Loss: 1.282

2022-12-15 15:08:36,801 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   1   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 113   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 125   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   7   0   0   0   3   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   1   0 128   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  13   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  10   0   0   0   0   0   2   0   0   5   0   1   1   0   4   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  16   0   0   0  19   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   4   4   0   0 152   1   1   0   1   0   0  11   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   1   1   1   2   5   0   0   0   0   0   2   3   0 114   0   1   5   0   0   0   0   0   1   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75  10   0   0   0   0   0   7   0   8   0]
 [  0   2   0   0   1   0   0   0   0   0   0   2   0   0   9   0   7   0   6   0   5 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  11   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  85   0   0   2   3   3   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   3   4   0   4   0   5   0   0   2   0   0   0  54   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   1   0   0   9   2   8   2   0   5   0   0   0   0   1   5   0   0   2   0   3   2   0   4   0   0   0   2   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:36,803 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:36,803 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:36,813 - 

2022-12-15 15:08:36,813 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:37,221 - Epoch: [174][   10/   74]    Overall Loss 0.318568    Objective Loss 0.318568                                        LR 0.000001    Time 0.040718    
2022-12-15 15:08:37,461 - Epoch: [174][   20/   74]    Overall Loss 0.324046    Objective Loss 0.324046                                        LR 0.000001    Time 0.032329    
2022-12-15 15:08:37,704 - Epoch: [174][   30/   74]    Overall Loss 0.315400    Objective Loss 0.315400                                        LR 0.000001    Time 0.029666    
2022-12-15 15:08:37,948 - Epoch: [174][   40/   74]    Overall Loss 0.313424    Objective Loss 0.313424                                        LR 0.000001    Time 0.028303    
2022-12-15 15:08:38,196 - Epoch: [174][   50/   74]    Overall Loss 0.316142    Objective Loss 0.316142                                        LR 0.000001    Time 0.027593    
2022-12-15 15:08:38,447 - Epoch: [174][   60/   74]    Overall Loss 0.316421    Objective Loss 0.316421                                        LR 0.000001    Time 0.027148    
2022-12-15 15:08:38,685 - Epoch: [174][   70/   74]    Overall Loss 0.321248    Objective Loss 0.321248                                        LR 0.000001    Time 0.026678    
2022-12-15 15:08:38,775 - Epoch: [174][   74/   74]    Overall Loss 0.324507    Objective Loss 0.324507    Top1 92.129630    Top5 98.611111    LR 0.000001    Time 0.026440    
2022-12-15 15:08:38,831 - --- validate (epoch=174)-----------
2022-12-15 15:08:38,831 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:39,112 - Epoch: [174][    9/    9]    Loss 1.275056    Top1 65.028626    Top5 90.696565    
2022-12-15 15:08:39,168 - ==> Top1: 65.029    Top5: 90.697    Loss: 1.275

2022-12-15 15:08:39,170 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   2   0   1   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 125   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   6   0   0   0   5   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   1   0 127   0   5   0   0   1   0   0   4   1   0   0   3   0   0   0   1  13   0   0   1   5   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   6   5   0   2   0   0   0   0   0   0   5   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  15   0   0   0   0   0   0   2   0   4   0]
 [  1   0   0   0   1   0   7   0   0   1   4   4   0   0 151   1   2   0   1   0   0  12   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   7   0   0   2   0   0   0   0   1   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   3   0   0   0   0   0   1   1   0   0]
 [  4   8   1   0   2   1   1   1   2   6   0   0   0   0   0   2   3   0 114   0   1   5   0   0   0   0   0   2   2   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75  10   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0  11   0   7   0   6   0   5 140   0   0   0   0   1   0   0   3   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  10   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  87   0   0   2   5   2   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   1   1   6   0   0  53   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   9   0   0]
 [  1   0   0   0  10   1  10   2   0   5   0   0   0   0   1   4   0   0   5   0   3   1   0   4   0   0   0   3   0 130   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   3]]

2022-12-15 15:08:39,171 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:39,171 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:39,181 - 

2022-12-15 15:08:39,181 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:39,609 - Epoch: [175][   10/   74]    Overall Loss 0.325538    Objective Loss 0.325538                                        LR 0.000001    Time 0.042701    
2022-12-15 15:08:39,861 - Epoch: [175][   20/   74]    Overall Loss 0.314398    Objective Loss 0.314398                                        LR 0.000001    Time 0.033903    
2022-12-15 15:08:40,120 - Epoch: [175][   30/   74]    Overall Loss 0.320603    Objective Loss 0.320603                                        LR 0.000001    Time 0.031241    
2022-12-15 15:08:40,389 - Epoch: [175][   40/   74]    Overall Loss 0.326141    Objective Loss 0.326141                                        LR 0.000001    Time 0.030091    
2022-12-15 15:08:40,631 - Epoch: [175][   50/   74]    Overall Loss 0.322693    Objective Loss 0.322693                                        LR 0.000001    Time 0.028903    
2022-12-15 15:08:40,869 - Epoch: [175][   60/   74]    Overall Loss 0.323293    Objective Loss 0.323293                                        LR 0.000001    Time 0.028054    
2022-12-15 15:08:41,082 - Epoch: [175][   70/   74]    Overall Loss 0.324924    Objective Loss 0.324924                                        LR 0.000001    Time 0.027085    
2022-12-15 15:08:41,169 - Epoch: [175][   74/   74]    Overall Loss 0.324543    Objective Loss 0.324543    Top1 92.824074    Top5 99.074074    LR 0.000001    Time 0.026786    
2022-12-15 15:08:41,232 - --- validate (epoch=175)-----------
2022-12-15 15:08:41,232 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:41,504 - Epoch: [175][    9/    9]    Loss 1.289785    Top1 65.219466    Top5 90.505725    
2022-12-15 15:08:41,550 - ==> Top1: 65.219    Top5: 90.506    Loss: 1.290

2022-12-15 15:08:41,552 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   8   0 123   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   6   0   0   0   5   1   5   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  1   0   0   0   1   0 130   0   4   0   0   1   0   0   4   1   0   0   2   0   0   0   1  11   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   2   4   0   0 152   1   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   9   1   0   2   0   1   2   2   4   0   0   0   0   0   2   1   0 116   0   1   5   0   0   0   0   0   1   4   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   0   0   0   0   0   0   0   2   0   0   9   0   6   0   6   0   5 141   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  10   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  85   0   0   2   5   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  52   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   1   9   2   0   7   0   0   0   0   1   5   0   0   4   0   3   1   0   5   0   0   0   2   0 131   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:41,554 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:41,554 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:41,563 - 

2022-12-15 15:08:41,564 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:41,953 - Epoch: [176][   10/   74]    Overall Loss 0.318332    Objective Loss 0.318332                                        LR 0.000001    Time 0.038840    
2022-12-15 15:08:42,164 - Epoch: [176][   20/   74]    Overall Loss 0.317435    Objective Loss 0.317435                                        LR 0.000001    Time 0.029961    
2022-12-15 15:08:42,375 - Epoch: [176][   30/   74]    Overall Loss 0.320937    Objective Loss 0.320937                                        LR 0.000001    Time 0.027012    
2022-12-15 15:08:42,612 - Epoch: [176][   40/   74]    Overall Loss 0.323438    Objective Loss 0.323438                                        LR 0.000001    Time 0.026158    
2022-12-15 15:08:42,862 - Epoch: [176][   50/   74]    Overall Loss 0.327453    Objective Loss 0.327453                                        LR 0.000001    Time 0.025914    
2022-12-15 15:08:43,109 - Epoch: [176][   60/   74]    Overall Loss 0.326602    Objective Loss 0.326602                                        LR 0.000001    Time 0.025704    
2022-12-15 15:08:43,352 - Epoch: [176][   70/   74]    Overall Loss 0.325458    Objective Loss 0.325458                                        LR 0.000001    Time 0.025501    
2022-12-15 15:08:43,441 - Epoch: [176][   74/   74]    Overall Loss 0.324656    Objective Loss 0.324656    Top1 94.675926    Top5 99.074074    LR 0.000001    Time 0.025318    
2022-12-15 15:08:43,503 - --- validate (epoch=176)-----------
2022-12-15 15:08:43,503 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:44,068 - Epoch: [176][    9/    9]    Loss 1.279036    Top1 65.410305    Top5 90.839695    
2022-12-15 15:08:44,129 - ==> Top1: 65.410    Top5: 90.840    Loss: 1.279

2022-12-15 15:08:44,131 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 126   1   5   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   7   0   0   0   2   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   0   0 130   0   3   1   0   1   0   0   4   2   0   0   2   0   0   0   1  13   0   0   1   4   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   4   0   2   0]
 [  0   0   0   0   0   0   6   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  15   0   0   0  20   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   7   0   0   1   3   4   0   0 152   1   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   5   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   0   1   2   2   5   0   0   0   0   0   2   2   0 115   0   1   5   0   0   0   0   0   1   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   3   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0  10   0   6   0   6   0   6 139   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  11   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  86   0   0   2   3   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   8   2   8   2   0   5   0   0   0   0   1   5   0   0   4   0   3   1   0   5   0   0   0   2   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:44,133 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:44,133 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:44,153 - 

2022-12-15 15:08:44,153 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:44,549 - Epoch: [177][   10/   74]    Overall Loss 0.325211    Objective Loss 0.325211                                        LR 0.000001    Time 0.039514    
2022-12-15 15:08:44,759 - Epoch: [177][   20/   74]    Overall Loss 0.326268    Objective Loss 0.326268                                        LR 0.000001    Time 0.030236    
2022-12-15 15:08:44,972 - Epoch: [177][   30/   74]    Overall Loss 0.326188    Objective Loss 0.326188                                        LR 0.000001    Time 0.027249    
2022-12-15 15:08:45,188 - Epoch: [177][   40/   74]    Overall Loss 0.322587    Objective Loss 0.322587                                        LR 0.000001    Time 0.025820    
2022-12-15 15:08:45,403 - Epoch: [177][   50/   74]    Overall Loss 0.322378    Objective Loss 0.322378                                        LR 0.000001    Time 0.024958    
2022-12-15 15:08:45,625 - Epoch: [177][   60/   74]    Overall Loss 0.323857    Objective Loss 0.323857                                        LR 0.000001    Time 0.024480    
2022-12-15 15:08:45,850 - Epoch: [177][   70/   74]    Overall Loss 0.325190    Objective Loss 0.325190                                        LR 0.000001    Time 0.024197    
2022-12-15 15:08:45,935 - Epoch: [177][   74/   74]    Overall Loss 0.324737    Objective Loss 0.324737    Top1 90.972222    Top5 99.305556    LR 0.000001    Time 0.024031    
2022-12-15 15:08:45,988 - --- validate (epoch=177)-----------
2022-12-15 15:08:45,988 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:46,260 - Epoch: [177][    9/    9]    Loss 1.282995    Top1 65.171756    Top5 90.553435    
2022-12-15 15:08:46,319 - ==> Top1: 65.172    Top5: 90.553    Loss: 1.283

2022-12-15 15:08:46,321 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 126   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   6   0   0   0   3   1   6   0]
 [  0   3   1   0   0  37   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  1   0   1   0   0   0 130   0   3   2   0   1   0   0   3   1   0   0   2   0   0   0   1  12   0   0   1   4   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   7   0   0   1   3   4   0   0 151   2   3   0   1   0   0  11   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  12   1   0   2   1   1   0   2   5   0   0   0   0   0   2   3   0 114   0   1   5   0   0   0   0   0   1   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74   9   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0  10   0   6   0   7   0   5 140   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  11   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  85   0   0   2   3   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   1   9   2   0   4   0   0   0   0   1   5   0   0   5   0   3   1   0   5   0   0   0   2   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:46,322 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:46,322 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:46,332 - 

2022-12-15 15:08:46,333 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:46,732 - Epoch: [178][   10/   74]    Overall Loss 0.312143    Objective Loss 0.312143                                        LR 0.000001    Time 0.039895    
2022-12-15 15:08:46,948 - Epoch: [178][   20/   74]    Overall Loss 0.320414    Objective Loss 0.320414                                        LR 0.000001    Time 0.030738    
2022-12-15 15:08:47,173 - Epoch: [178][   30/   74]    Overall Loss 0.326874    Objective Loss 0.326874                                        LR 0.000001    Time 0.027965    
2022-12-15 15:08:47,391 - Epoch: [178][   40/   74]    Overall Loss 0.323019    Objective Loss 0.323019                                        LR 0.000001    Time 0.026428    
2022-12-15 15:08:47,613 - Epoch: [178][   50/   74]    Overall Loss 0.323451    Objective Loss 0.323451                                        LR 0.000001    Time 0.025566    
2022-12-15 15:08:47,839 - Epoch: [178][   60/   74]    Overall Loss 0.321997    Objective Loss 0.321997                                        LR 0.000001    Time 0.025061    
2022-12-15 15:08:48,062 - Epoch: [178][   70/   74]    Overall Loss 0.322644    Objective Loss 0.322644                                        LR 0.000001    Time 0.024672    
2022-12-15 15:08:48,149 - Epoch: [178][   74/   74]    Overall Loss 0.324909    Objective Loss 0.324909    Top1 93.055556    Top5 99.074074    LR 0.000001    Time 0.024502    
2022-12-15 15:08:48,213 - --- validate (epoch=178)-----------
2022-12-15 15:08:48,214 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:48,490 - Epoch: [178][    9/    9]    Loss 1.278547    Top1 65.458015    Top5 90.601145    
2022-12-15 15:08:48,551 - ==> Top1: 65.458    Top5: 90.601    Loss: 1.279

2022-12-15 15:08:48,553 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   1   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   8   0 124   1   4   0   0   0   0   0   0   0   0   2   0   0   4   0   0   2   0   6   0   0   0   3   1   6   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  1   0   1   0   1   0 128   0   5   0   0   1   0   0   4   1   0   0   2   0   0   0   1  11   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   7   0   0   1   3   4   0   0 153   0   2   0   2   0   0  12   0   0   0   0   1   1   1   0   0]
 [  2   0   0   0   0   0   7   0   0   4   0   0   0   0   3   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   0   1   2   2   6   0   0   0   0   0   2   3   0 115   0   1   5   0   0   0   0   0   1   1   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75  10   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0  10   0   6   0   6   0   5 142   0   0   0   0   1   0   0   3   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  10   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  86   0   0   2   4   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   5   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   3   4   0   4   0   5   0   0   2   0   0   0  54   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  1   0   0   0   9   2   9   2   0   4   0   0   0   0   1   4   0   0   5   0   3   1   0   4   0   0   0   2   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:48,554 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:48,555 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:48,565 - 

2022-12-15 15:08:48,565 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:48,993 - Epoch: [179][   10/   74]    Overall Loss 0.324803    Objective Loss 0.324803                                        LR 0.000001    Time 0.042670    
2022-12-15 15:08:49,240 - Epoch: [179][   20/   74]    Overall Loss 0.322947    Objective Loss 0.322947                                        LR 0.000001    Time 0.033681    
2022-12-15 15:08:49,501 - Epoch: [179][   30/   74]    Overall Loss 0.325437    Objective Loss 0.325437                                        LR 0.000001    Time 0.031094    
2022-12-15 15:08:49,755 - Epoch: [179][   40/   74]    Overall Loss 0.316977    Objective Loss 0.316977                                        LR 0.000001    Time 0.029667    
2022-12-15 15:08:50,015 - Epoch: [179][   50/   74]    Overall Loss 0.320813    Objective Loss 0.320813                                        LR 0.000001    Time 0.028908    
2022-12-15 15:08:50,259 - Epoch: [179][   60/   74]    Overall Loss 0.322983    Objective Loss 0.322983                                        LR 0.000001    Time 0.028150    
2022-12-15 15:08:50,503 - Epoch: [179][   70/   74]    Overall Loss 0.323932    Objective Loss 0.323932                                        LR 0.000001    Time 0.027601    
2022-12-15 15:08:50,585 - Epoch: [179][   74/   74]    Overall Loss 0.324025    Objective Loss 0.324025    Top1 93.981481    Top5 98.611111    LR 0.000001    Time 0.027208    
2022-12-15 15:08:50,654 - --- validate (epoch=179)-----------
2022-12-15 15:08:50,654 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:50,921 - Epoch: [179][    9/    9]    Loss 1.275031    Top1 65.553435    Top5 90.648855    
2022-12-15 15:08:50,976 - ==> Top1: 65.553    Top5: 90.649    Loss: 1.275

2022-12-15 15:08:50,978 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 113   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   7   0 125   2   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   6   0   0   0   4   1   5   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  1   1   1   0   0   0 129   0   4   0   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  15   0   0   0  20   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  10   0   0   0   0   0   0  16   0   0   0   0   0   0   2   0   4   0]
 [  1   0   0   0   1   0   7   0   0   1   3   4   0   0 152   1   3   0   1   0   0  10   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   9   1   0   2   0   1   2   2   5   0   0   0   0   0   2   1   0 114   0   2   5   0   0   0   0   0   1   4   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0   9   0   6   0   6   0   5 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  11   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  87   0   0   2   3   2   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   4   0   0   2   0   7   0   0   0   0   9   0   0]
 [  0   0   0   0   9   1   9   2   0   4   0   0   0   0   1   5   0   0   5   0   3   1   0   5   0   0   0   2   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:50,979 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:50,979 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:50,997 - 

2022-12-15 15:08:50,997 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:51,400 - Epoch: [180][   10/   74]    Overall Loss 0.311048    Objective Loss 0.311048                                        LR 0.000001    Time 0.040225    
2022-12-15 15:08:51,628 - Epoch: [180][   20/   74]    Overall Loss 0.314898    Objective Loss 0.314898                                        LR 0.000001    Time 0.031481    
2022-12-15 15:08:51,859 - Epoch: [180][   30/   74]    Overall Loss 0.323751    Objective Loss 0.323751                                        LR 0.000001    Time 0.028689    
2022-12-15 15:08:52,097 - Epoch: [180][   40/   74]    Overall Loss 0.323415    Objective Loss 0.323415                                        LR 0.000001    Time 0.027444    
2022-12-15 15:08:52,324 - Epoch: [180][   50/   74]    Overall Loss 0.321757    Objective Loss 0.321757                                        LR 0.000001    Time 0.026490    
2022-12-15 15:08:52,553 - Epoch: [180][   60/   74]    Overall Loss 0.321250    Objective Loss 0.321250                                        LR 0.000001    Time 0.025888    
2022-12-15 15:08:52,773 - Epoch: [180][   70/   74]    Overall Loss 0.322198    Objective Loss 0.322198                                        LR 0.000001    Time 0.025321    
2022-12-15 15:08:52,859 - Epoch: [180][   74/   74]    Overall Loss 0.324270    Objective Loss 0.324270    Top1 91.666667    Top5 98.379630    LR 0.000001    Time 0.025115    
2022-12-15 15:08:52,941 - --- validate (epoch=180)-----------
2022-12-15 15:08:52,942 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:53,213 - Epoch: [180][    9/    9]    Loss 1.334515    Top1 65.171756    Top5 90.648855    
2022-12-15 15:08:53,263 - ==> Top1: 65.172    Top5: 90.649    Loss: 1.335

2022-12-15 15:08:53,265 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   1   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   1   1   0   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 126   1   5   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   7   0   0   0   2   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   0   0 132   0   4   1   0   1   0   0   4   1   0   0   1   0   0   0   1  13   0   0   1   4   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   5   0   1  10   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   7   0   0   1   3   4   0   0 152   1   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  12   1   0   2   0   1   2   2   6   0   0   0   0   0   2   3   0 110   0   2   5   0   0   0   0   0   1   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   3   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0  11   0   6   0   6   0   5 139   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  11   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  85   0   0   2   3   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   3   4   0   4   0   5   0   0   2   0   0   0  54   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   1   0   0  10   1  10   2   0   5   0   0   0   0   1   5   0   0   3   0   2   1   0   4   0   0   0   2   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:53,267 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:53,267 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:53,277 - 

2022-12-15 15:08:53,277 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:53,667 - Epoch: [181][   10/   74]    Overall Loss 0.322267    Objective Loss 0.322267                                        LR 0.000001    Time 0.038876    
2022-12-15 15:08:53,922 - Epoch: [181][   20/   74]    Overall Loss 0.321814    Objective Loss 0.321814                                        LR 0.000001    Time 0.032209    
2022-12-15 15:08:54,186 - Epoch: [181][   30/   74]    Overall Loss 0.321072    Objective Loss 0.321072                                        LR 0.000001    Time 0.030254    
2022-12-15 15:08:54,461 - Epoch: [181][   40/   74]    Overall Loss 0.319716    Objective Loss 0.319716                                        LR 0.000001    Time 0.029534    
2022-12-15 15:08:54,720 - Epoch: [181][   50/   74]    Overall Loss 0.323069    Objective Loss 0.323069                                        LR 0.000001    Time 0.028807    
2022-12-15 15:08:54,968 - Epoch: [181][   60/   74]    Overall Loss 0.322788    Objective Loss 0.322788                                        LR 0.000001    Time 0.028140    
2022-12-15 15:08:55,184 - Epoch: [181][   70/   74]    Overall Loss 0.324818    Objective Loss 0.324818                                        LR 0.000001    Time 0.027190    
2022-12-15 15:08:55,268 - Epoch: [181][   74/   74]    Overall Loss 0.324333    Objective Loss 0.324333    Top1 94.444444    Top5 99.537037    LR 0.000001    Time 0.026861    
2022-12-15 15:08:55,329 - --- validate (epoch=181)-----------
2022-12-15 15:08:55,329 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:55,600 - Epoch: [181][    9/    9]    Loss 1.252621    Top1 65.171756    Top5 90.839695    
2022-12-15 15:08:55,650 - ==> Top1: 65.172    Top5: 90.840    Loss: 1.253

2022-12-15 15:08:55,652 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   6   2   0   1   0   2   0   0   0   0   0   0   0   0  14   0   1   1   0   0   0   0   0   0   1   0   0]
 [  0   0 113   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   1   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 126   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   8   0   0   0   2   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  1   0   1   0   0   0 129   0   4   0   0   1   0   0   4   1   0   0   2   0   0   0   1  13   0   0   1   4   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   4   4   0   0 149   2   2   0   1   0   0  12   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   9   1   0   2   0   1   2   2   6   0   0   0   0   0   2   2   0 115   0   2   5   0   0   0   0   0   2   1   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74   9   0   0   0   0   0   7   0   9   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0   9   0   6   0   7   0   5 140   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  11   0   3   1   0   4   0   0   0   0   0   0   6   0   0   1   2  84   0   0   2   3   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   9   0   0]
 [  0   0   0   0   8   2   9   2   0   5   0   0   0   0   1   5   0   0   3   0   3   2   0   5   0   0   0   3   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:55,654 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:55,654 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:55,664 - 

2022-12-15 15:08:55,664 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:56,052 - Epoch: [182][   10/   74]    Overall Loss 0.315645    Objective Loss 0.315645                                        LR 0.000001    Time 0.038686    
2022-12-15 15:08:56,265 - Epoch: [182][   20/   74]    Overall Loss 0.326828    Objective Loss 0.326828                                        LR 0.000001    Time 0.030004    
2022-12-15 15:08:56,486 - Epoch: [182][   30/   74]    Overall Loss 0.323441    Objective Loss 0.323441                                        LR 0.000001    Time 0.027358    
2022-12-15 15:08:56,717 - Epoch: [182][   40/   74]    Overall Loss 0.324440    Objective Loss 0.324440                                        LR 0.000001    Time 0.026278    
2022-12-15 15:08:56,959 - Epoch: [182][   50/   74]    Overall Loss 0.326049    Objective Loss 0.326049                                        LR 0.000001    Time 0.025851    
2022-12-15 15:08:57,203 - Epoch: [182][   60/   74]    Overall Loss 0.324492    Objective Loss 0.324492                                        LR 0.000001    Time 0.025575    
2022-12-15 15:08:57,433 - Epoch: [182][   70/   74]    Overall Loss 0.324348    Objective Loss 0.324348                                        LR 0.000001    Time 0.025196    
2022-12-15 15:08:57,518 - Epoch: [182][   74/   74]    Overall Loss 0.324521    Objective Loss 0.324521    Top1 92.592593    Top5 98.611111    LR 0.000001    Time 0.024989    
2022-12-15 15:08:57,578 - --- validate (epoch=182)-----------
2022-12-15 15:08:57,578 - 2096 samples (256 per mini-batch)
2022-12-15 15:08:58,140 - Epoch: [182][    9/    9]    Loss 1.265691    Top1 64.980916    Top5 90.696565    
2022-12-15 15:08:58,205 - ==> Top1: 64.981    Top5: 90.697    Loss: 1.266

2022-12-15 15:08:58,206 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 111   0   8   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 125   1   5   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   8   0   0   0   1   1   5   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  0   0   1   0   0   0 131   0   4   1   0   1   0   0   3   1   0   0   3   0   0   0   1  13   0   0   1   4   0   8   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   5   0   2   9   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  12   0   0   0  23   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   4   4   0   0 151   1   1   0   1   0   0  12   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  4   9   1   0   2   0   1   2   2   6   0   0   0   0   0   2   3   0 113   0   2   5   0   0   0   0   0   1   2   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74   9   0   0   0   0   0   7   0   9   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0  10   0   6   0   6   0   6 140   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  11   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  87   0   0   2   3   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   1   0   0   8   2  10   2   0   5   0   0   0   0   1   5   0   0   3   0   2   1   0   6   0   0   0   2   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:08:58,208 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:08:58,208 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:08:58,218 - 

2022-12-15 15:08:58,218 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:08:58,606 - Epoch: [183][   10/   74]    Overall Loss 0.334850    Objective Loss 0.334850                                        LR 0.000001    Time 0.038766    
2022-12-15 15:08:58,821 - Epoch: [183][   20/   74]    Overall Loss 0.338450    Objective Loss 0.338450                                        LR 0.000001    Time 0.030072    
2022-12-15 15:08:59,047 - Epoch: [183][   30/   74]    Overall Loss 0.337442    Objective Loss 0.337442                                        LR 0.000001    Time 0.027559    
2022-12-15 15:08:59,266 - Epoch: [183][   40/   74]    Overall Loss 0.330894    Objective Loss 0.330894                                        LR 0.000001    Time 0.026143    
2022-12-15 15:08:59,486 - Epoch: [183][   50/   74]    Overall Loss 0.326007    Objective Loss 0.326007                                        LR 0.000001    Time 0.025316    
2022-12-15 15:08:59,710 - Epoch: [183][   60/   74]    Overall Loss 0.324669    Objective Loss 0.324669                                        LR 0.000001    Time 0.024815    
2022-12-15 15:08:59,922 - Epoch: [183][   70/   74]    Overall Loss 0.324576    Objective Loss 0.324576                                        LR 0.000001    Time 0.024299    
2022-12-15 15:09:00,005 - Epoch: [183][   74/   74]    Overall Loss 0.324671    Objective Loss 0.324671    Top1 93.518519    Top5 98.379630    LR 0.000001    Time 0.024097    
2022-12-15 15:09:00,070 - --- validate (epoch=183)-----------
2022-12-15 15:09:00,070 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:00,351 - Epoch: [183][    9/    9]    Loss 1.246573    Top1 65.314885    Top5 90.553435    
2022-12-15 15:09:00,407 - ==> Top1: 65.315    Top5: 90.553    Loss: 1.247

2022-12-15 15:09:00,409 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 113   0   6   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 124   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   6   0   0   0   4   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   1   0 130   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   4   4   0   0 151   0   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  12   1   0   2   0   1   2   2   5   0   0   0   0   0   2   3   0 113   0   1   5   0   0   0   0   0   1   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   0   0   1   0   1   0  75   9   0   0   0   0   0   8   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0   9   0   6   0   6   0   5 142   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  11   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  86   0   0   2   4   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   3   3  13   0   1   2   0   0   0   0   3   3   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   1   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   8   2   8   2   0   5   0   0   0   0   1   5   0   0   4   0   3   2   0   5   0   0   0   2   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:00,411 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:00,411 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:00,421 - 

2022-12-15 15:09:00,421 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:00,823 - Epoch: [184][   10/   74]    Overall Loss 0.314245    Objective Loss 0.314245                                        LR 0.000001    Time 0.040137    
2022-12-15 15:09:01,050 - Epoch: [184][   20/   74]    Overall Loss 0.322991    Objective Loss 0.322991                                        LR 0.000001    Time 0.031401    
2022-12-15 15:09:01,279 - Epoch: [184][   30/   74]    Overall Loss 0.327201    Objective Loss 0.327201                                        LR 0.000001    Time 0.028542    
2022-12-15 15:09:01,507 - Epoch: [184][   40/   74]    Overall Loss 0.328824    Objective Loss 0.328824                                        LR 0.000001    Time 0.027107    
2022-12-15 15:09:01,752 - Epoch: [184][   50/   74]    Overall Loss 0.323640    Objective Loss 0.323640                                        LR 0.000001    Time 0.026579    
2022-12-15 15:09:02,001 - Epoch: [184][   60/   74]    Overall Loss 0.322283    Objective Loss 0.322283                                        LR 0.000001    Time 0.026285    
2022-12-15 15:09:02,229 - Epoch: [184][   70/   74]    Overall Loss 0.324338    Objective Loss 0.324338                                        LR 0.000001    Time 0.025780    
2022-12-15 15:09:02,317 - Epoch: [184][   74/   74]    Overall Loss 0.324311    Objective Loss 0.324311    Top1 94.444444    Top5 99.074074    LR 0.000001    Time 0.025574    
2022-12-15 15:09:02,385 - --- validate (epoch=184)-----------
2022-12-15 15:09:02,385 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:02,656 - Epoch: [184][    9/    9]    Loss 1.251534    Top1 65.314885    Top5 90.935115    
2022-12-15 15:09:02,707 - ==> Top1: 65.315    Top5: 90.935    Loss: 1.252

2022-12-15 15:09:02,709 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   7   0 125   2   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   6   0   0   0   3   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   1   0 129   0   4   0   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  15   0   0   0   0   0   0   2   0   4   0]
 [  1   0   0   0   1   0   7   0   0   1   4   4   0   0 152   0   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   3   0   0   0   0   0   1   1   0   0]
 [  3   9   1   0   2   0   1   2   1   5   0   0   0   0   0   2   2   0 115   0   2   5   0   0   0   0   0   2   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   0   0   0   9   0   6   0   7   0   6 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  10   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  85   0   0   2   4   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   5   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   1   0   0   0  53   0  10   0]
 [  1   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   8   3  10   2   0   4   0   0   0   0   1   5   0   0   4   0   2   1   0   5   0   0   0   3   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:02,711 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:02,711 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:02,721 - 

2022-12-15 15:09:02,722 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:03,138 - Epoch: [185][   10/   74]    Overall Loss 0.319172    Objective Loss 0.319172                                        LR 0.000001    Time 0.041554    
2022-12-15 15:09:03,378 - Epoch: [185][   20/   74]    Overall Loss 0.322400    Objective Loss 0.322400                                        LR 0.000001    Time 0.032783    
2022-12-15 15:09:03,622 - Epoch: [185][   30/   74]    Overall Loss 0.319829    Objective Loss 0.319829                                        LR 0.000001    Time 0.029954    
2022-12-15 15:09:03,868 - Epoch: [185][   40/   74]    Overall Loss 0.323863    Objective Loss 0.323863                                        LR 0.000001    Time 0.028609    
2022-12-15 15:09:04,128 - Epoch: [185][   50/   74]    Overall Loss 0.323135    Objective Loss 0.323135                                        LR 0.000001    Time 0.028085    
2022-12-15 15:09:04,375 - Epoch: [185][   60/   74]    Overall Loss 0.323294    Objective Loss 0.323294                                        LR 0.000001    Time 0.027511    
2022-12-15 15:09:04,626 - Epoch: [185][   70/   74]    Overall Loss 0.323703    Objective Loss 0.323703                                        LR 0.000001    Time 0.027164    
2022-12-15 15:09:04,713 - Epoch: [185][   74/   74]    Overall Loss 0.325140    Objective Loss 0.325140    Top1 91.435185    Top5 99.074074    LR 0.000001    Time 0.026870    
2022-12-15 15:09:04,777 - --- validate (epoch=185)-----------
2022-12-15 15:09:04,777 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:05,044 - Epoch: [185][    9/    9]    Loss 1.252795    Top1 65.410305    Top5 90.744275    
2022-12-15 15:09:05,108 - ==> Top1: 65.410    Top5: 90.744    Loss: 1.253

2022-12-15 15:09:05,110 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 113   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   1   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 127   0   3   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   6   0   0   0   4   1   6   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  1   0   1   0   0   0 128   0   3   1   0   1   0   0   5   1   0   0   2   0   0   0   1  12   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   5   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  15   0   0   0   0   0   0   2   0   4   0]
 [  1   0   0   0   1   0   6   0   0   1   2   4   0   0 155   0   2   0   1   0   0  12   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   0   1   2   2   6   0   0   0   0   0   2   1   0 114   0   2   5   0   0   0   0   0   1   3   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75  10   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   0   0   0  10   0   7   0   7   0   6 140   0   0   0   0   1   0   0   3   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  10   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  84   0   0   2   6   3   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0   0   0   0   2   0   5   0   0  53   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   3   4   0   4   0   5   0   0   2   0   0   0  54   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   0   0   0   8   3   9   2   0   4   0   0   0   0   1   5   0   0   4   0   2   2   0   5   0   0   0   3   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:05,112 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:05,112 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:05,132 - 

2022-12-15 15:09:05,133 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:05,542 - Epoch: [186][   10/   74]    Overall Loss 0.338918    Objective Loss 0.338918                                        LR 0.000001    Time 0.040818    
2022-12-15 15:09:05,780 - Epoch: [186][   20/   74]    Overall Loss 0.331514    Objective Loss 0.331514                                        LR 0.000001    Time 0.032306    
2022-12-15 15:09:06,039 - Epoch: [186][   30/   74]    Overall Loss 0.319604    Objective Loss 0.319604                                        LR 0.000001    Time 0.030152    
2022-12-15 15:09:06,296 - Epoch: [186][   40/   74]    Overall Loss 0.323477    Objective Loss 0.323477                                        LR 0.000001    Time 0.029036    
2022-12-15 15:09:06,548 - Epoch: [186][   50/   74]    Overall Loss 0.324804    Objective Loss 0.324804                                        LR 0.000001    Time 0.028221    
2022-12-15 15:09:06,792 - Epoch: [186][   60/   74]    Overall Loss 0.325664    Objective Loss 0.325664                                        LR 0.000001    Time 0.027577    
2022-12-15 15:09:07,019 - Epoch: [186][   70/   74]    Overall Loss 0.324450    Objective Loss 0.324450                                        LR 0.000001    Time 0.026872    
2022-12-15 15:09:07,102 - Epoch: [186][   74/   74]    Overall Loss 0.324103    Objective Loss 0.324103    Top1 93.518519    Top5 98.611111    LR 0.000001    Time 0.026544    
2022-12-15 15:09:07,164 - --- validate (epoch=186)-----------
2022-12-15 15:09:07,164 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:07,438 - Epoch: [186][    9/    9]    Loss 1.258801    Top1 65.267176    Top5 90.601145    
2022-12-15 15:09:07,492 - ==> Top1: 65.267    Top5: 90.601    Loss: 1.259

2022-12-15 15:09:07,494 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 113   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   1   0   8   0   0   0   1   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 127   0   5   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   7   0   0   0   2   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  1   0   1   0   0   0 130   0   4   1   0   1   0   0   3   1   0   0   2   0   0   0   1  13   0   0   1   4   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  10   0   1   0   0   0   0  16   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   4   4   0   0 150   1   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   7   0   0   2   0   0   0   0   1   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  12   1   0   2   0   1   2   2   6   0   0   0   0   0   2   1   0 112   0   1   5   0   0   0   0   0   1   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74   9   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0   9   0   6   0   7   0   5 140   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  10   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  88   0   0   2   4   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   5   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   4   4   0   4   0   4   1   0   1   0   0   0  53   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   4   0   0   2   0   7   0   0   0   0   9   0   0]
 [  0   0   0   0   9   2  10   2   0   5   0   0   0   0   1   5   0   0   5   0   2   1   0   5   0   0   0   2   0 131   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:07,496 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:07,496 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:07,506 - 

2022-12-15 15:09:07,507 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:07,932 - Epoch: [187][   10/   74]    Overall Loss 0.325570    Objective Loss 0.325570                                        LR 0.000001    Time 0.042412    
2022-12-15 15:09:08,164 - Epoch: [187][   20/   74]    Overall Loss 0.329530    Objective Loss 0.329530                                        LR 0.000001    Time 0.032817    
2022-12-15 15:09:08,409 - Epoch: [187][   30/   74]    Overall Loss 0.325813    Objective Loss 0.325813                                        LR 0.000001    Time 0.030025    
2022-12-15 15:09:08,658 - Epoch: [187][   40/   74]    Overall Loss 0.321501    Objective Loss 0.321501                                        LR 0.000001    Time 0.028739    
2022-12-15 15:09:08,909 - Epoch: [187][   50/   74]    Overall Loss 0.320261    Objective Loss 0.320261                                        LR 0.000001    Time 0.027995    
2022-12-15 15:09:09,160 - Epoch: [187][   60/   74]    Overall Loss 0.324614    Objective Loss 0.324614                                        LR 0.000001    Time 0.027509    
2022-12-15 15:09:09,393 - Epoch: [187][   70/   74]    Overall Loss 0.325913    Objective Loss 0.325913                                        LR 0.000001    Time 0.026898    
2022-12-15 15:09:09,475 - Epoch: [187][   74/   74]    Overall Loss 0.324853    Objective Loss 0.324853    Top1 93.518519    Top5 98.842593    LR 0.000001    Time 0.026550    
2022-12-15 15:09:09,531 - --- validate (epoch=187)-----------
2022-12-15 15:09:09,532 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:09,807 - Epoch: [187][    9/    9]    Loss 1.273726    Top1 65.171756    Top5 90.791985    
2022-12-15 15:09:09,871 - ==> Top1: 65.172    Top5: 90.792    Loss: 1.274

2022-12-15 15:09:09,873 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   8   1   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  14   0   1   1   0   0   0   0   0   1   1   0   0]
 [  0   0 112   0   8   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   8   0 124   1   5   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   7   0   0   0   2   1   5   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  1   0   1   0   1   0 128   0   3   2   0   1   0   0   3   2   0   0   2   0   0   0   1  11   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   6   0   0   1   3   4   0   0 152   1   2   0   2   0   0  11   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   0   1   2   2   5   0   0   0   0   0   2   2   0 115   0   1   5   0   0   0   0   0   2   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   2   0   0   2   0   0   0   0   0   1   0   0   1   0   1   0  75  10   0   0   0   0   0   8   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0  11   0   6   0   7   0   5 139   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  11   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  86   0   0   2   4   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   3   3  12   0   1   2   0   0   0   0   3   3   4   0   4   0   5   0   0   2   0   0   0  54   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   8   2   8   2   0   6   0   0   0   0   1   5   0   0   4   0   3   1   0   4   0   0   0   2   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:09,875 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:09,875 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:09,895 - 

2022-12-15 15:09:09,895 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:10,456 - Epoch: [188][   10/   74]    Overall Loss 0.317338    Objective Loss 0.317338                                        LR 0.000001    Time 0.055999    
2022-12-15 15:09:10,713 - Epoch: [188][   20/   74]    Overall Loss 0.326129    Objective Loss 0.326129                                        LR 0.000001    Time 0.040804    
2022-12-15 15:09:10,970 - Epoch: [188][   30/   74]    Overall Loss 0.331366    Objective Loss 0.331366                                        LR 0.000001    Time 0.035756    
2022-12-15 15:09:11,220 - Epoch: [188][   40/   74]    Overall Loss 0.333282    Objective Loss 0.333282                                        LR 0.000001    Time 0.033076    
2022-12-15 15:09:11,477 - Epoch: [188][   50/   74]    Overall Loss 0.323739    Objective Loss 0.323739                                        LR 0.000001    Time 0.031593    
2022-12-15 15:09:11,734 - Epoch: [188][   60/   74]    Overall Loss 0.323216    Objective Loss 0.323216                                        LR 0.000001    Time 0.030607    
2022-12-15 15:09:11,982 - Epoch: [188][   70/   74]    Overall Loss 0.323943    Objective Loss 0.323943                                        LR 0.000001    Time 0.029770    
2022-12-15 15:09:12,073 - Epoch: [188][   74/   74]    Overall Loss 0.324558    Objective Loss 0.324558    Top1 93.287037    Top5 98.842593    LR 0.000001    Time 0.029379    
2022-12-15 15:09:12,149 - --- validate (epoch=188)-----------
2022-12-15 15:09:12,149 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:12,432 - Epoch: [188][    9/    9]    Loss 1.302656    Top1 65.124046    Top5 90.982824    
2022-12-15 15:09:12,491 - ==> Top1: 65.124    Top5: 90.983    Loss: 1.303

2022-12-15 15:09:12,494 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   4   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3  10   0 122   0   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   6   0   0   0   4   1   6   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  1   0   1   0   0   0 130   0   3   2   0   1   0   0   3   2   0   0   2   0   0   0   1  11   0   0   1   4   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   7   4   0   2   0   0   0   1   0   0   4   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   2  10   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   2   0   1   1   0  15   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   4   4   0   0 150   1   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   8   1   0   2   1   1   1   2   5   0   0   0   0   0   2   3   0 117   0   1   5   0   0   0   0   0   1   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   0   0   0   0   0   0   0   1   0   0  11   0   6   0   6   0   5 140   0   0   0   0   1   0   0   5   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  12   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  86   0   0   2   3   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   1   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   1   1   2   0   0   0   0   3   4   4   0   4   0   4   0   0   2   0   0   0  53   0  10   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   8   2   9   2   0   5   0   0   0   0   1   5   0   0   5   0   3   1   0   5   0   0   0   2   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:12,495 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:12,495 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:12,505 - 

2022-12-15 15:09:12,505 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:12,909 - Epoch: [189][   10/   74]    Overall Loss 0.314939    Objective Loss 0.314939                                        LR 0.000001    Time 0.040320    
2022-12-15 15:09:13,158 - Epoch: [189][   20/   74]    Overall Loss 0.325784    Objective Loss 0.325784                                        LR 0.000001    Time 0.032484    
2022-12-15 15:09:13,420 - Epoch: [189][   30/   74]    Overall Loss 0.328978    Objective Loss 0.328978                                        LR 0.000001    Time 0.030382    
2022-12-15 15:09:13,676 - Epoch: [189][   40/   74]    Overall Loss 0.326452    Objective Loss 0.326452                                        LR 0.000001    Time 0.029185    
2022-12-15 15:09:13,933 - Epoch: [189][   50/   74]    Overall Loss 0.324212    Objective Loss 0.324212                                        LR 0.000001    Time 0.028463    
2022-12-15 15:09:14,193 - Epoch: [189][   60/   74]    Overall Loss 0.322533    Objective Loss 0.322533                                        LR 0.000001    Time 0.028047    
2022-12-15 15:09:14,441 - Epoch: [189][   70/   74]    Overall Loss 0.324351    Objective Loss 0.324351                                        LR 0.000001    Time 0.027581    
2022-12-15 15:09:14,525 - Epoch: [189][   74/   74]    Overall Loss 0.324222    Objective Loss 0.324222    Top1 94.444444    Top5 99.074074    LR 0.000001    Time 0.027224    
2022-12-15 15:09:14,594 - --- validate (epoch=189)-----------
2022-12-15 15:09:14,594 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:14,869 - Epoch: [189][    9/    9]    Loss 1.230537    Top1 65.314885    Top5 90.648855    
2022-12-15 15:09:14,920 - ==> Top1: 65.315    Top5: 90.649    Loss: 1.231

2022-12-15 15:09:14,922 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   6   2   0   1   0   2   0   0   0   0   0   0   0   0  12   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 113   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   1   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   6   0 125   2   4   0   0   0   0   0   0   0   0   2   0   0   4   0   0   3   0   6   0   0   0   4   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   0   0 132   0   4   0   0   1   0   0   4   1   0   0   2   0   0   0   1  11   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   5   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  15   0   0   0   0   0   0   2   0   4   0]
 [  2   0   1   0   1   0   6   0   0   1   6   4   0   0 150   0   1   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  12   1   0   2   0   1   1   2   6   0   0   0   0   0   2   3   0 111   0   1   5   0   0   0   0   0   2   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   9   0]
 [  0   3   0   0   1   0   0   0   0   0   0   0   0   0  10   0   7   0   7   0   5 139   0   0   0   0   2   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  11   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  86   0   0   2   4   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   1   0   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   3   4   0   4   0   4   0   0   2   0   0   0  55   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   9   0   0]
 [  0   0   0   0   9   2  10   2   0   4   0   0   0   0   1   5   0   0   4   0   3   1   0   4   0   0   0   3   0 132   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:14,924 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:14,924 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:14,944 - 

2022-12-15 15:09:14,944 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:15,364 - Epoch: [190][   10/   74]    Overall Loss 0.330633    Objective Loss 0.330633                                        LR 0.000001    Time 0.041917    
2022-12-15 15:09:15,611 - Epoch: [190][   20/   74]    Overall Loss 0.318133    Objective Loss 0.318133                                        LR 0.000001    Time 0.033304    
2022-12-15 15:09:15,858 - Epoch: [190][   30/   74]    Overall Loss 0.322211    Objective Loss 0.322211                                        LR 0.000001    Time 0.030417    
2022-12-15 15:09:16,095 - Epoch: [190][   40/   74]    Overall Loss 0.319348    Objective Loss 0.319348                                        LR 0.000001    Time 0.028716    
2022-12-15 15:09:16,341 - Epoch: [190][   50/   74]    Overall Loss 0.325362    Objective Loss 0.325362                                        LR 0.000001    Time 0.027880    
2022-12-15 15:09:16,590 - Epoch: [190][   60/   74]    Overall Loss 0.326674    Objective Loss 0.326674                                        LR 0.000001    Time 0.027384    
2022-12-15 15:09:16,834 - Epoch: [190][   70/   74]    Overall Loss 0.324852    Objective Loss 0.324852                                        LR 0.000001    Time 0.026953    
2022-12-15 15:09:16,923 - Epoch: [190][   74/   74]    Overall Loss 0.324482    Objective Loss 0.324482    Top1 93.055556    Top5 98.379630    LR 0.000001    Time 0.026698    
2022-12-15 15:09:16,985 - --- validate (epoch=190)-----------
2022-12-15 15:09:16,985 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:17,275 - Epoch: [190][    9/    9]    Loss 1.357299    Top1 64.933206    Top5 90.601145    
2022-12-15 15:09:17,329 - ==> Top1: 64.933    Top5: 90.601    Loss: 1.357

2022-12-15 15:09:17,331 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   1   0   6   2   0   1   0   2   0   0   0   0   0   0   0   0  12   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 112   0   8   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 126   1   5   0   0   0   0   0   0   0   0   2   0   0   4   0   0   2   0   7   0   0   0   2   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   0   0 133   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   4   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   4   0   2   0   0   0   1   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   3   4   0   0 151   1   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   9   1   0   3   0   1   2   2   6   0   0   0   0   0   2   1   0 112   0   2   5   0   0   0   0   0   2   4   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75  10   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0  11   0   6   0   6   0   6 138   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  12   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  84   0   0   2   3   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   1   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  14   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  53   0   9   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   2  10   2   0   6   0   0   0   0   1   5   0   0   4   0   2   1   0   5   0   0   0   3   0 130   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:17,333 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:17,333 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:17,343 - 

2022-12-15 15:09:17,343 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:17,728 - Epoch: [191][   10/   74]    Overall Loss 0.340201    Objective Loss 0.340201                                        LR 0.000001    Time 0.038321    
2022-12-15 15:09:17,940 - Epoch: [191][   20/   74]    Overall Loss 0.326899    Objective Loss 0.326899                                        LR 0.000001    Time 0.029770    
2022-12-15 15:09:18,153 - Epoch: [191][   30/   74]    Overall Loss 0.330383    Objective Loss 0.330383                                        LR 0.000001    Time 0.026943    
2022-12-15 15:09:18,372 - Epoch: [191][   40/   74]    Overall Loss 0.324128    Objective Loss 0.324128                                        LR 0.000001    Time 0.025674    
2022-12-15 15:09:18,590 - Epoch: [191][   50/   74]    Overall Loss 0.328068    Objective Loss 0.328068                                        LR 0.000001    Time 0.024891    
2022-12-15 15:09:18,844 - Epoch: [191][   60/   74]    Overall Loss 0.324675    Objective Loss 0.324675                                        LR 0.000001    Time 0.024965    
2022-12-15 15:09:19,088 - Epoch: [191][   70/   74]    Overall Loss 0.324841    Objective Loss 0.324841                                        LR 0.000001    Time 0.024869    
2022-12-15 15:09:19,175 - Epoch: [191][   74/   74]    Overall Loss 0.324551    Objective Loss 0.324551    Top1 94.675926    Top5 99.074074    LR 0.000001    Time 0.024702    
2022-12-15 15:09:19,228 - --- validate (epoch=191)-----------
2022-12-15 15:09:19,228 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:19,499 - Epoch: [191][    9/    9]    Loss 1.258759    Top1 65.124046    Top5 90.744275    
2022-12-15 15:09:19,567 - ==> Top1: 65.124    Top5: 90.744    Loss: 1.259

2022-12-15 15:09:19,569 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 113   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   1   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   2   6   0 126   2   3   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   7   0   0   0   4   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   1   0 129   0   3   1   0   1   0   0   4   1   0   0   2   0   0   0   1  12   0   0   1   5   0  11   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   5   0   1  10   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  14   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   1   7   0   0   1   3   4   0   0 151   1   2   0   1   0   0  11   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   2   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   3   0   0   0   0   0   1   1   0   0]
 [  3  13   1   0   3   0   1   1   1   5   0   0   0   0   0   2   2   0 110   0   1   5   0   0   0   0   0   3   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   1   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   6   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0   9   0   6   0   7   0   6 140   0   0   0   0   1   0   0   3   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  11   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  85   0   0   2   5   1   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   3   0   0   0   0   3   4   4   0   4   0   5   0   0   1   0   0   0  53   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   1   0   0   9   3   7   2   0   4   0   0   0   0   1   5   0   0   2   0   2   2   0   5   0   0   0   3   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:19,571 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:19,571 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:19,581 - 

2022-12-15 15:09:19,581 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:19,996 - Epoch: [192][   10/   74]    Overall Loss 0.321013    Objective Loss 0.321013                                        LR 0.000001    Time 0.041431    
2022-12-15 15:09:20,244 - Epoch: [192][   20/   74]    Overall Loss 0.325022    Objective Loss 0.325022                                        LR 0.000001    Time 0.033091    
2022-12-15 15:09:20,490 - Epoch: [192][   30/   74]    Overall Loss 0.324069    Objective Loss 0.324069                                        LR 0.000001    Time 0.030235    
2022-12-15 15:09:20,737 - Epoch: [192][   40/   74]    Overall Loss 0.326090    Objective Loss 0.326090                                        LR 0.000001    Time 0.028847    
2022-12-15 15:09:20,988 - Epoch: [192][   50/   74]    Overall Loss 0.324027    Objective Loss 0.324027                                        LR 0.000001    Time 0.028097    
2022-12-15 15:09:21,245 - Epoch: [192][   60/   74]    Overall Loss 0.325360    Objective Loss 0.325360                                        LR 0.000001    Time 0.027681    
2022-12-15 15:09:21,485 - Epoch: [192][   70/   74]    Overall Loss 0.325680    Objective Loss 0.325680                                        LR 0.000001    Time 0.027151    
2022-12-15 15:09:21,575 - Epoch: [192][   74/   74]    Overall Loss 0.324598    Objective Loss 0.324598    Top1 93.055556    Top5 99.537037    LR 0.000001    Time 0.026898    
2022-12-15 15:09:21,636 - --- validate (epoch=192)-----------
2022-12-15 15:09:21,636 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:21,905 - Epoch: [192][    9/    9]    Loss 1.304277    Top1 65.124046    Top5 90.410305    
2022-12-15 15:09:21,965 - ==> Top1: 65.124    Top5: 90.410    Loss: 1.304

2022-12-15 15:09:21,967 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0   9   1   0   6   2   0   1   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 111   0   6   1   0   0   0   0   0   0   0   0   1   0   0   0   2   0   1   2   0   9   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 126   1   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   7   0   0   0   2   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  1   0   1   0   1   0 129   0   4   0   0   1   0   0   4   1   0   0   3   0   0   0   1  12   0   0   1   5   0   8   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   5   0   1  10   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   2   4   0   0 153   0   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   2   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   5   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  12   1   0   2   1   1   0   2   5   0   0   0   0   0   2   2   0 113   0   1   5   0   0   0   0   0   2   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0  10   0   6   0   8   0   5 140   0   0   0   0   1   0   0   3   0]
 [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  18   0  11   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  85   0   0   2   4   2   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   1   0   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   6   0   0  54   0   1   0   0]
 [  0   1   2   0   2   3  13   1   1   2   0   0   0   0   3   3   4   0   4   0   2   1   0   2   0   0   0  54   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  1   0   0   0   9   2  10   2   0   4   0   0   0   0   1   4   0   0   5   0   2   1   0   5   0   0   0   3   0 131   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:21,969 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:21,969 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:21,990 - 

2022-12-15 15:09:21,990 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:22,407 - Epoch: [193][   10/   74]    Overall Loss 0.322606    Objective Loss 0.322606                                        LR 0.000001    Time 0.041603    
2022-12-15 15:09:22,647 - Epoch: [193][   20/   74]    Overall Loss 0.322428    Objective Loss 0.322428                                        LR 0.000001    Time 0.032786    
2022-12-15 15:09:22,901 - Epoch: [193][   30/   74]    Overall Loss 0.323811    Objective Loss 0.323811                                        LR 0.000001    Time 0.030306    
2022-12-15 15:09:23,150 - Epoch: [193][   40/   74]    Overall Loss 0.323755    Objective Loss 0.323755                                        LR 0.000001    Time 0.028950    
2022-12-15 15:09:23,404 - Epoch: [193][   50/   74]    Overall Loss 0.325914    Objective Loss 0.325914                                        LR 0.000001    Time 0.028231    
2022-12-15 15:09:23,651 - Epoch: [193][   60/   74]    Overall Loss 0.324470    Objective Loss 0.324470                                        LR 0.000001    Time 0.027639    
2022-12-15 15:09:23,895 - Epoch: [193][   70/   74]    Overall Loss 0.325016    Objective Loss 0.325016                                        LR 0.000001    Time 0.027169    
2022-12-15 15:09:23,983 - Epoch: [193][   74/   74]    Overall Loss 0.324478    Objective Loss 0.324478    Top1 93.055556    Top5 99.305556    LR 0.000001    Time 0.026884    
2022-12-15 15:09:24,062 - --- validate (epoch=193)-----------
2022-12-15 15:09:24,062 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:24,335 - Epoch: [193][    9/    9]    Loss 1.273366    Top1 65.314885    Top5 90.553435    
2022-12-15 15:09:24,387 - ==> Top1: 65.315    Top5: 90.553    Loss: 1.273

2022-12-15 15:09:24,389 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   0   1   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   6   0 127   0   5   0   0   0   0   0   0   0   0   2   0   0   4   0   0   2   0   6   0   0   0   2   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   1   0 129   0   3   2   0   1   0   0   3   1   0   0   2   0   0   0   1  12   0   0   1   5   0  11   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   1   8   0   0   1   5   4   0   0 148   2   1   0   1   0   0  11   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   9   1   0   2   0   1   3   2   5   0   0   0   0   0   2   2   0 115   0   1   5   0   0   0   0   0   1   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   0   0   1   0   1   0  75   9   0   0   0   0   0   8   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0  11   0   6   0   6   0   6 139   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  11   0   2   1   0   3   0   0   0   0   0   0   6   0   0   1   2  87   0   0   2   4   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   1   0   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   2   0   0   1   0   1   0   0   0   0   0   0   6   0   0  55   0   1   0   0]
 [  0   0   2   0   2   3  12   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  54   0  10   0]
 [  1   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   7   0   0]
 [  0   1   0   0   9   2   8   2   0   5   0   0   0   0   1   5   0   0   3   0   3   1   0   4   0   0   0   2   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:24,390 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:24,390 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:24,400 - 

2022-12-15 15:09:24,400 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:24,797 - Epoch: [194][   10/   74]    Overall Loss 0.332643    Objective Loss 0.332643                                        LR 0.000001    Time 0.039575    
2022-12-15 15:09:25,010 - Epoch: [194][   20/   74]    Overall Loss 0.329064    Objective Loss 0.329064                                        LR 0.000001    Time 0.030433    
2022-12-15 15:09:25,222 - Epoch: [194][   30/   74]    Overall Loss 0.324541    Objective Loss 0.324541                                        LR 0.000001    Time 0.027338    
2022-12-15 15:09:25,441 - Epoch: [194][   40/   74]    Overall Loss 0.323458    Objective Loss 0.323458                                        LR 0.000001    Time 0.025971    
2022-12-15 15:09:25,653 - Epoch: [194][   50/   74]    Overall Loss 0.325369    Objective Loss 0.325369                                        LR 0.000001    Time 0.025000    
2022-12-15 15:09:25,875 - Epoch: [194][   60/   74]    Overall Loss 0.325033    Objective Loss 0.325033                                        LR 0.000001    Time 0.024526    
2022-12-15 15:09:26,084 - Epoch: [194][   70/   74]    Overall Loss 0.324960    Objective Loss 0.324960                                        LR 0.000001    Time 0.024013    
2022-12-15 15:09:26,170 - Epoch: [194][   74/   74]    Overall Loss 0.324557    Objective Loss 0.324557    Top1 92.824074    Top5 99.074074    LR 0.000001    Time 0.023866    
2022-12-15 15:09:26,230 - --- validate (epoch=194)-----------
2022-12-15 15:09:26,231 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:26,796 - Epoch: [194][    9/    9]    Loss 1.305256    Top1 65.076336    Top5 90.744275    
2022-12-15 15:09:26,856 - ==> Top1: 65.076    Top5: 90.744    Loss: 1.305

2022-12-15 15:09:26,859 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 126   0   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   6   0   0   0   2   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  0   0   1   0   0   0 127   0   4   3   0   1   0   0   3   1   0   0   2   0   0   0   1  13   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   4   4   0   0 151   1   1   0   1   0   0  12   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  1   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   6   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  12   1   0   2   0   1   2   2   5   0   0   0   0   0   2   2   0 113   0   1   5   0   0   0   0   0   1   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  76   9   0   0   0   0   0   7   0   6   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0   9   0   6   0   7   0   6 139   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  11   0   4   1   0   3   0   0   0   0   0   0   6   0   0   1   2  84   0   0   2   3   2   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   1   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   3   0   0   0   0   3   2   4   0   4   0   5   0   0   1   0   0   0  55   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   2   9   2   0   5   0   0   0   0   1   5   0   0   5   0   3   1   0   4   0   0   0   3   0 131   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:26,861 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:26,861 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:26,882 - 

2022-12-15 15:09:26,882 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:27,270 - Epoch: [195][   10/   74]    Overall Loss 0.316241    Objective Loss 0.316241                                        LR 0.000001    Time 0.038759    
2022-12-15 15:09:27,482 - Epoch: [195][   20/   74]    Overall Loss 0.326544    Objective Loss 0.326544                                        LR 0.000001    Time 0.029934    
2022-12-15 15:09:27,698 - Epoch: [195][   30/   74]    Overall Loss 0.324681    Objective Loss 0.324681                                        LR 0.000001    Time 0.027133    
2022-12-15 15:09:27,915 - Epoch: [195][   40/   74]    Overall Loss 0.320620    Objective Loss 0.320620                                        LR 0.000001    Time 0.025765    
2022-12-15 15:09:28,131 - Epoch: [195][   50/   74]    Overall Loss 0.320894    Objective Loss 0.320894                                        LR 0.000001    Time 0.024926    
2022-12-15 15:09:28,347 - Epoch: [195][   60/   74]    Overall Loss 0.324554    Objective Loss 0.324554                                        LR 0.000001    Time 0.024373    
2022-12-15 15:09:28,558 - Epoch: [195][   70/   74]    Overall Loss 0.324321    Objective Loss 0.324321                                        LR 0.000001    Time 0.023903    
2022-12-15 15:09:28,644 - Epoch: [195][   74/   74]    Overall Loss 0.324340    Objective Loss 0.324340    Top1 96.064815    Top5 99.768519    LR 0.000001    Time 0.023770    
2022-12-15 15:09:28,704 - --- validate (epoch=195)-----------
2022-12-15 15:09:28,704 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:28,989 - Epoch: [195][    9/    9]    Loss 1.296916    Top1 65.362595    Top5 90.791985    
2022-12-15 15:09:29,041 - ==> Top1: 65.363    Top5: 90.792    Loss: 1.297

2022-12-15 15:09:29,043 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   2   0   8   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 126   0   4   0   0   0   0   0   0   0   0   2   0   0   5   0   0   2   0   6   0   0   0   3   1   6   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  1   1   0   0   0   0 131   0   3   1   0   1   0   0   3   1   0   0   2   0   0   0   1  12   0   0   1   5   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   5   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   2   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  15   0   0   0  20   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   1   7   0   0   1   4   4   0   0 149   2   2   0   2   0   0  11   0   0   0   0   1   1   1   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  10   1   0   2   0   1   2   2   5   0   0   0   0   0   2   3   0 114   0   2   5   0   0   0   0   0   1   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74   9   0   0   0   0   0   7   0   9   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0   9   0   7   0   6   0   5 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  10   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  84   0   0   2   6   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   0   6   0   0  54   0   1   0   0]
 [  0   1   2   0   2   3  13   0   1   2   0   0   0   0   3   3   4   0   4   0   4   0   0   2   0   0   0  54   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   1   9   2   0   4   0   0   0   0   1   5   0   0   4   0   3   1   0   5   0   0   0   2   0 134   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:29,044 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:29,044 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:29,054 - 

2022-12-15 15:09:29,055 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:29,490 - Epoch: [196][   10/   74]    Overall Loss 0.305341    Objective Loss 0.305341                                        LR 0.000001    Time 0.043428    
2022-12-15 15:09:29,737 - Epoch: [196][   20/   74]    Overall Loss 0.316202    Objective Loss 0.316202                                        LR 0.000001    Time 0.034054    
2022-12-15 15:09:29,981 - Epoch: [196][   30/   74]    Overall Loss 0.315100    Objective Loss 0.315100                                        LR 0.000001    Time 0.030820    
2022-12-15 15:09:30,229 - Epoch: [196][   40/   74]    Overall Loss 0.320465    Objective Loss 0.320465                                        LR 0.000001    Time 0.029310    
2022-12-15 15:09:30,477 - Epoch: [196][   50/   74]    Overall Loss 0.322186    Objective Loss 0.322186                                        LR 0.000001    Time 0.028392    
2022-12-15 15:09:30,723 - Epoch: [196][   60/   74]    Overall Loss 0.325041    Objective Loss 0.325041                                        LR 0.000001    Time 0.027750    
2022-12-15 15:09:30,965 - Epoch: [196][   70/   74]    Overall Loss 0.325434    Objective Loss 0.325434                                        LR 0.000001    Time 0.027236    
2022-12-15 15:09:31,051 - Epoch: [196][   74/   74]    Overall Loss 0.324252    Objective Loss 0.324252    Top1 95.370370    Top5 99.768519    LR 0.000001    Time 0.026933    
2022-12-15 15:09:31,111 - --- validate (epoch=196)-----------
2022-12-15 15:09:31,111 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:31,388 - Epoch: [196][    9/    9]    Loss 1.331678    Top1 65.028626    Top5 90.553435    
2022-12-15 15:09:31,443 - ==> Top1: 65.029    Top5: 90.553    Loss: 1.332

2022-12-15 15:09:31,445 - ==> Confusion:
[[ 18   0   1   0   0   0   4   0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   2   0   2   0   2   0   0   0   0   0   0   0   0  12   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   7   0 126   0   5   0   0   0   0   0   0   0   0   1   0   0   4   0   0   2   0   7   0   0   0   3   1   5   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  1   0   0   0   0   0 131   0   4   1   0   1   0   0   3   1   0   0   2   0   0   0   1  12   0   0   1   4   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   6   5   0   2   0   0   0   0   0   0   5   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  13   0   0   0  22   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  1   0   0   0   1   0   7   0   0   1   6   4   0   0 151   0   1   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   5   0   0   2   0   0   0   0   2   0   0   0   5   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  13   1   0   2   0   1   2   2   5   0   0   0   0   0   2   2   0 111   0   1   5   0   0   0   0   0   1   3   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  74   9   0   0   0   0   0   7   0   9   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0   9   0   6   0   6   0   6 139   0   0   0   0   2   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  10   0   1   1   0   4   0   0   0   0   0   0   6   0   0   1   2  85   0   0   2   4   3   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   5   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   1   0   0   8   3   9   2   0   4   0   0   0   0   1   5   0   0   4   0   2   1   0   6   0   0   0   1   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:31,446 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:31,446 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:31,457 - 

2022-12-15 15:09:31,457 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:31,851 - Epoch: [197][   10/   74]    Overall Loss 0.333181    Objective Loss 0.333181                                        LR 0.000001    Time 0.039386    
2022-12-15 15:09:32,097 - Epoch: [197][   20/   74]    Overall Loss 0.329353    Objective Loss 0.329353                                        LR 0.000001    Time 0.031969    
2022-12-15 15:09:32,349 - Epoch: [197][   30/   74]    Overall Loss 0.324719    Objective Loss 0.324719                                        LR 0.000001    Time 0.029692    
2022-12-15 15:09:32,598 - Epoch: [197][   40/   74]    Overall Loss 0.324606    Objective Loss 0.324606                                        LR 0.000001    Time 0.028477    
2022-12-15 15:09:32,850 - Epoch: [197][   50/   74]    Overall Loss 0.321513    Objective Loss 0.321513                                        LR 0.000001    Time 0.027776    
2022-12-15 15:09:33,100 - Epoch: [197][   60/   74]    Overall Loss 0.324886    Objective Loss 0.324886                                        LR 0.000001    Time 0.027312    
2022-12-15 15:09:33,343 - Epoch: [197][   70/   74]    Overall Loss 0.325168    Objective Loss 0.325168                                        LR 0.000001    Time 0.026874    
2022-12-15 15:09:33,432 - Epoch: [197][   74/   74]    Overall Loss 0.324342    Objective Loss 0.324342    Top1 93.055556    Top5 99.305556    LR 0.000001    Time 0.026625    
2022-12-15 15:09:33,507 - --- validate (epoch=197)-----------
2022-12-15 15:09:33,507 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:33,782 - Epoch: [197][    9/    9]    Loss 1.321212    Top1 65.314885    Top5 90.601145    
2022-12-15 15:09:33,839 - ==> Top1: 65.315    Top5: 90.601    Loss: 1.321

2022-12-15 15:09:33,841 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   6   2   0   1   0   2   0   0   0   0   0   0   0   0  12   0   1   1   0   0   0   0   0   1   1   1   0]
 [  0   0 113   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   1   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   6   0 127   0   4   0   0   0   0   0   0   0   0   2   0   0   4   0   0   2   0   7   0   0   0   3   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  1   0   1   0   1   0 128   0   5   0   0   1   0   0   4   1   0   0   3   0   0   0   1  11   0   0   1   5   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   0   1   0  16   0   0   0   0   0   0   1   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   0   0   0   0   0  15   0   0   0   0   0   0   2   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   4   4   0   0 151   0   3   0   1   0   0  11   0   0   0   0   1   1   2   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  13   1   0   2   0   1   1   2   6   0   0   0   0   0   2   1   0 113   0   1   5   0   0   0   0   0   1   3   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   2   0   0   9   0   6   0   6   0   6 140   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0   8   0   2   1   0   4   0   0   0   0   0   0   6   0   0   1   2  87   0   0   2   5   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   1   0   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0   0   0   0   1   1   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  1   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   5   0   0   2   0   7   0   0   0   0   9   0   0]
 [  1   0   0   0  10   1  10   2   0   4   0   0   0   0   1   4   0   0   5   0   3   1   0   4   0   0   0   3   0 131   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:33,842 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:33,842 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:33,852 - 

2022-12-15 15:09:33,852 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:34,272 - Epoch: [198][   10/   74]    Overall Loss 0.333611    Objective Loss 0.333611                                        LR 0.000001    Time 0.041934    
2022-12-15 15:09:34,518 - Epoch: [198][   20/   74]    Overall Loss 0.328598    Objective Loss 0.328598                                        LR 0.000001    Time 0.033241    
2022-12-15 15:09:34,766 - Epoch: [198][   30/   74]    Overall Loss 0.325174    Objective Loss 0.325174                                        LR 0.000001    Time 0.030393    
2022-12-15 15:09:35,015 - Epoch: [198][   40/   74]    Overall Loss 0.321341    Objective Loss 0.321341                                        LR 0.000001    Time 0.029002    
2022-12-15 15:09:35,264 - Epoch: [198][   50/   74]    Overall Loss 0.322094    Objective Loss 0.322094                                        LR 0.000001    Time 0.028176    
2022-12-15 15:09:35,511 - Epoch: [198][   60/   74]    Overall Loss 0.322408    Objective Loss 0.322408                                        LR 0.000001    Time 0.027594    
2022-12-15 15:09:35,751 - Epoch: [198][   70/   74]    Overall Loss 0.323572    Objective Loss 0.323572                                        LR 0.000001    Time 0.027070    
2022-12-15 15:09:35,840 - Epoch: [198][   74/   74]    Overall Loss 0.324976    Objective Loss 0.324976    Top1 91.203704    Top5 97.916667    LR 0.000001    Time 0.026813    
2022-12-15 15:09:35,901 - --- validate (epoch=198)-----------
2022-12-15 15:09:35,902 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:36,177 - Epoch: [198][    9/    9]    Loss 1.257800    Top1 65.362595    Top5 90.505725    
2022-12-15 15:09:36,233 - ==> Top1: 65.363    Top5: 90.506    Loss: 1.258

2022-12-15 15:09:36,235 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  10   0   0   6   2   0   1   0   2   0   0   0   0   0   0   0   0  13   0   1   1   0   0   0   0   0   0   1   1   0]
 [  0   0 112   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   8   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   4   6   0 127   0   3   0   0   0   0   0   0   0   0   2   0   0   4   0   0   2   0   7   0   0   0   4   1   5   0]
 [  0   2   1   0   1  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   0   1   0   0]
 [  1   1   1   0   1   0 128   0   4   0   0   1   0   0   4   1   0   0   2   0   0   0   1  11   0   0   1   5   0  10   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   5   0   7   4   0   2   0   0   0   1   0   0   4   0   0   1   0   6   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   3   0   9   0]
 [  0   0   0   0   0   0   0   0   0   0  15   0   0   0  20   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   3   5   0   0 149   2   2   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   7   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   3   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3  12   1   0   2   1   1   1   2   5   0   0   0   0   0   2   1   0 113   0   1   5   0   0   0   0   0   1   4   3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   2   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   7   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0   9   0   6   0   7   0   6 139   0   0   0   0   2   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  13   2   0   0   1   0   0   0   0]
 [  0   1   5   0  17   0  10   0   3   1   0   3   0   0   0   0   0   0   6   0   0   1   2  87   0   0   2   4   2   5   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   1   0   0   1   0   0   0   1   0   0   0]
 [  0   0   3   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   0   4   0   0  55   0   1   0   0]
 [  0   0   2   0   2   3  13   1   1   2   0   0   0   0   3   3   4   0   4   0   4   0   0   2   0   0   0  54   0  10   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   5   0   0   2   0   7   0   0   0   0   9   0   0]
 [  0   0   0   0   9   2   8   2   0   5   0   0   0   0   1   5   0   0   4   0   2   1   0   5   0   0   0   3   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:36,236 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:36,237 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:36,246 - 

2022-12-15 15:09:36,246 - Training epoch: 18864 samples (256 per mini-batch)
2022-12-15 15:09:36,673 - Epoch: [199][   10/   74]    Overall Loss 0.344554    Objective Loss 0.344554                                        LR 0.000001    Time 0.042564    
2022-12-15 15:09:36,921 - Epoch: [199][   20/   74]    Overall Loss 0.324663    Objective Loss 0.324663                                        LR 0.000001    Time 0.033637    
2022-12-15 15:09:37,165 - Epoch: [199][   30/   74]    Overall Loss 0.324442    Objective Loss 0.324442                                        LR 0.000001    Time 0.030564    
2022-12-15 15:09:37,412 - Epoch: [199][   40/   74]    Overall Loss 0.330233    Objective Loss 0.330233                                        LR 0.000001    Time 0.029093    
2022-12-15 15:09:37,661 - Epoch: [199][   50/   74]    Overall Loss 0.328334    Objective Loss 0.328334                                        LR 0.000001    Time 0.028230    
2022-12-15 15:09:37,914 - Epoch: [199][   60/   74]    Overall Loss 0.324537    Objective Loss 0.324537                                        LR 0.000001    Time 0.027730    
2022-12-15 15:09:38,161 - Epoch: [199][   70/   74]    Overall Loss 0.326064    Objective Loss 0.326064                                        LR 0.000001    Time 0.027303    
2022-12-15 15:09:38,249 - Epoch: [199][   74/   74]    Overall Loss 0.324701    Objective Loss 0.324701    Top1 95.833333    Top5 99.305556    LR 0.000001    Time 0.027016    
2022-12-15 15:09:38,315 - --- validate (epoch=199)-----------
2022-12-15 15:09:38,315 - 2096 samples (256 per mini-batch)
2022-12-15 15:09:38,592 - Epoch: [199][    9/    9]    Loss 1.310085    Top1 65.314885    Top5 90.887405    
2022-12-15 15:09:38,645 - ==> Top1: 65.315    Top5: 90.887    Loss: 1.310

2022-12-15 15:09:38,647 - ==> Confusion:
[[ 18   0   1   0   0   0   3   0   1   0   0   1   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0]
 [  0  11   0   0   5   1   0   2   0   2   0   0   0   0   0   0   0   0  14   0   1   1   0   0   0   0   0   0   1   0   0]
 [  0   0 111   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   2   0   9   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]
 [  0   3   7   0 125   0   5   0   0   0   0   0   0   0   0   2   0   0   5   0   0   3   0   7   0   0   0   1   1   6   0]
 [  0   2   1   0   0  38   0   0   0   0   0   0   0   0   0   0   1   0   5   0   1   4   0   0   0   0   1   1   1   0   0]
 [  0   0   1   0   0   0 129   0   4   1   0   1   0   0   3   1   0   0   3   0   0   0   1  14   0   0   1   4   0   9   0]
 [  0   7   0   0   0   1   0   5   0   0   0   0   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0   5   0   1   0]
 [  0   0   0   0   0   0   6   0   7   5   0   2   0   0   0   0   0   0   4   0   0   1   0   6   0   0   0   1   1   0   0]
 [  1   0   0   0   0   0   4   0   1  11   0   0   0   0   0   2   0   0   5   0   1   1   0   3   0   0   0   2   0  10   0]
 [  0   0   0   0   0   0   0   0   0   0  14   0   0   0  21   0   0   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   1   0   1   1   0  16   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   1   0   0   0   0   0  11   0   1   0   0   0   0  15   0   0   0   0   0   0   1   0   4   0]
 [  2   0   0   0   1   0   7   0   0   1   5   4   0   0 150   1   1   0   1   0   0  11   0   0   0   0   1   1   3   0   0]
 [  3   0   0   0   0   0   6   0   0   4   0   0   0   0   2   6   0   0   2   0   0   0   0   2   0   0   0   4   0   2   0]
 [  2   0   0   0   0   3   0   0   0   0   0   0   0   0   2   1  33   0   5   0   0   4   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   0   1   0   0   0]
 [  3   7   1   0   2   0   1   2   2   6   0   0   0   0   0   2   3   0 115   0   2   5   0   0   0   0   0   2   1   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0   0   1   0   0   2   0   0   0   0   0   1   1   0   1   0   1   0  75   9   0   0   0   0   0   7   0   8   0]
 [  0   3   0   0   1   0   0   0   0   0   0   1   0   0   9   0   6   0   7   0   5 141   0   0   0   0   1   0   0   4   0]
 [  0   0   3   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0  12   3   0   0   1   0   0   0   0]
 [  0   1   5   0  16   0  11   0   3   1   0   3   0   0   0   0   0   0   6   0   0   1   2  87   0   0   2   3   2   6   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0   0   8   0   0   0   0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   3   0   0   1   0   1   0   0   0   0   0   1   6   0   0  54   0   1   0   0]
 [  0   0   2   0   2   3  13   0   1   2   0   0   0   0   3   4   4   0   4   0   5   0   0   2   0   0   0  53   0  10   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   6   0   0   2   0   7   0   0   0   0   8   0   0]
 [  0   0   0   0   9   2   9   2   0   5   0   0   0   0   1   5   0   0   4   0   3   1   0   4   0   0   0   2   0 133   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   4   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:38,649 - ==> Best [Top1: 66.746   Top5: 91.794   Sparsity:0.00   Params: 364479 on epoch: 88]
2022-12-15 15:09:38,649 - Saving checkpoint to: logs/2022.12.15-145848/qat_checkpoint.pth.tar
2022-12-15 15:09:38,669 - --- test ---------------------
2022-12-15 15:09:38,670 - 3935 samples (256 per mini-batch)
2022-12-15 15:09:38,977 - Test: [   10/   16]    Loss 1.276601    Top1 66.093750    Top5 89.414062    
2022-12-15 15:09:39,047 - Test: [   16/   16]    Loss 1.286195    Top1 66.124524    Top5 89.504447    
2022-12-15 15:09:39,103 - ==> Top1: 66.125    Top5: 89.504    Loss: 1.286

2022-12-15 15:09:39,105 - ==> Confusion:
[[ 37   0   1   0   0   0   4   0   1   0   0   0   0   0   3   3   0   0   3   0   0   1   0   0   0   0   0   1   0   0   0]
 [  0  18   0   0  17   0   0   1   1   0   0   0   0   0   0   0   2   0  31   0   2   0   0   1   0   0   0   1   1   0   0]
 [  2   5 128   0   7   0   1   2   0   0   0   0   0   1   0   0   0   0   7   0   1   0   0   4   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   5   8   0 112   1   4   0   1   1   0   0   0   0   0   0   0   0  10   0   1   3   0  14   0   0   1   4   0   9   0]
 [  0   3   0   0   1  55   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   3   0   0   0   0   1   1   0   1   0]
 [  0   0   4   0   5   0 176   0   4   4   0   3   0   1   1   1   0   0   4   0   0   0   1  15   0   0   1   6   0   8   0]
 [  0   2   0   0   0   0   0   6   0   0   0   0   0   1   0   0   1   0   2   0  10   1   0   0   0   0   0   2   0   3   0]
 [  1   0   1   0   0   0   2   0   8   1   1   1   0   0   0   0   0   0   2   0   0   0   0   4   0   0   0   2   0   0   0]
 [  1   0   0   0   0   0   9   1   2  20   0   1   0   0   2   1   1   0   8   0   1   0   0   0   0   0   0   3   0  15   0]
 [  0   0   0   0   0   0   0   0   0   0  21   1   0   0  26   1   0   0   0   0   0   3   0   0   0   0   1   0   1   1   0]
 [  1   0   0   0   0   1   2   0   5   1   0  54   0   0   9   0   0   0   2   0   0   3   1   2   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   1   0   0   0   0   0   0   0   0   6   0   0   0   0   0   0  11   0   0   0   0   0   0   4   0   4   0]
 [  0   0   0   0   0   0  10   0   1   3  15   2   0   0 239   1   0   0   0   0   0  21   2   0   0   0   4   4   1   0   0]
 [  4   0   0   0   0   0   6   0   4   9   1   0   0   0   3  12   0   0  11   0   0   0   0   3   0   0   0   2   0   4   0]
 [  3   0   0   0   0   5   1   0   1   3   1   0   0   0   5   1  69   0   7   0   4   2   0   0   0   0   2   3   0   0   0]
 [  0   0   0   0   0   2   0   0   1   1   1   0   0   0   1   0   6   0   5   0   2   7   0   0   0   0   0   1   0   1   1]
 [  3  13   1   0   6   0   1   2   3   8   0   0   0   1   0   4   0   0 197   0   3   5   0   5   0   0   0   2   5  11   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0]
 [  0   0   1   0   3   0   0   1   0   3   1   0   0   4   2   2   1   0   2   0 134  11   0   0   0   0   0   3   0  16   0]
 [  0   3   0   0   5  10   2   0   2   3   4   1   0   2  24   0   7   0  24   0  18 369   0   0   0   0  10   2   0   9   0]
 [  0   0   7   0   0   0   0   0   2   1   0   2   0   0   1   0   0   0   0   0   1   1  39  12   0   0   2   0   2   0   0]
 [  3   0   2   0  12   0   9   0   4   5   0   1   0   0   1   2   0   0   1   0   0   0   2 115   1   0   1   1   1   7   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   1   0   0   0   0   1   3   0   0   0   0   0   0]
 [  1   0   0   0   0   0   8   0   2   4   0   0   0   0   0   2   0   0   3   0   0   0   0   2   0   0   0   1   0   2   0]
 [  1   0   2   0   0   1   0   0   0   0   0   2   0   0   2   0   3   0   0   0   1   1   1   3   0   0 117   1   1   1   0]
 [  0   0   1   0   6   2  26   2   3   5   0   0   0   0   2   2   2   0   3   0   8   1   1   3   0   0   2  80   4   7   0]
 [  0   1   1   0   1   1   0   0   1   0   0   0   0   0   1   1   1   0   4   0   0   2   1  10   0   0   1   2   9   1   0]
 [  0   4   0   0  34   1  48   1   4  36   0   1   0   6   3   5   0   0  22   0  18  14   0  29   0   0   0  28   1 574   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   1   0   0   0   0   0   0   0   0   4]]

2022-12-15 15:09:39,107 - 
2022-12-15 15:09:39,107 - Log file for this run: /home/ubuntumaschin/KeyWordSpotting_on_MAX78000/ai8x-training/logs/2022.12.15-145848/2022.12.15-145848.log
